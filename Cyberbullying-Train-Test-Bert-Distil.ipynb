{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "# %pip install transformers[torch]==4.30.2\n",
        "# %pip install accelerate -U\n",
        "# %pip install optuna\n",
        "%pip install ipywidgets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ipywidgets as widgets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c9f7a182aec462dba24ae2270bc24d6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Dropdown(description='Model:', options=(('Distilbert', 1), ('Indobert', 2)), value=1)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_choice_int = 1\n",
        "bert_model_path = 'indolem/indobert-base-uncased'\n",
        "distilbert_model_path = 'cahya/distilbert-base-indonesian'\n",
        "\n",
        "# 0 = distilbert, 1 = bert\n",
        "\n",
        "widgets.Dropdown(\n",
        "    options=[('Distilbert', 1), ('Indobert', 2)],\n",
        "    value=1,\n",
        "    description='Model:',\n",
        "    disabled=False,\n",
        "    \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>encoded_label</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>kaka tidur yaa sudah pagi tidak boleh capek2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>makan nasi padang saja badannya</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>suka cukur jembut manggung</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>hai kak isyana ngefans sekali kak isyana suka ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>manusia bidadari sih herann deh cantik</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>ayu kinantii isyan sekarang berubah ya baju ny...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.0</td>\n",
              "      <td>gemesnya isyan mirip tango berlapis lapis ciaaaa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.0</td>\n",
              "      <td>jelek saja anaknya ayahnya cakep2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.0</td>\n",
              "      <td>anaknya mirip sudah tua begitu ya mukanya kart...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.0</td>\n",
              "      <td>muka anak nya ko tua sekali yaa tidak ngegemes...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   encoded_label                                         clean_text\n",
              "0            1.0       kaka tidur yaa sudah pagi tidak boleh capek2\n",
              "1            1.0                    makan nasi padang saja badannya\n",
              "2            0.0                         suka cukur jembut manggung\n",
              "3            1.0  hai kak isyana ngefans sekali kak isyana suka ...\n",
              "4            1.0             manusia bidadari sih herann deh cantik\n",
              "5            0.0  ayu kinantii isyan sekarang berubah ya baju ny...\n",
              "6            1.0   gemesnya isyan mirip tango berlapis lapis ciaaaa\n",
              "7            0.0                  jelek saja anaknya ayahnya cakep2\n",
              "8            0.0  anaknya mirip sudah tua begitu ya mukanya kart...\n",
              "9            0.0  muka anak nya ko tua sekali yaa tidak ngegemes..."
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "datasets = {}\n",
        "\n",
        "df = pd.read_csv('Dataset\\Pre-Processed Dataset\\combined_dataset.csv')\n",
        "datasets['combined_dataset'] = df[['encoded_label', 'clean_text']]\n",
        "\n",
        "datasets['combined_dataset'].head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffekHJZfwdmg"
      },
      "source": [
        "## Train-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353,
          "referenced_widgets": [
            "2c81cbcb517e438ea3c8d590052214f5",
            "de50dc3ddbcf4af9ba799c0391ba493d",
            "79c4f2796ef14b2ab8738c6421d4797f",
            "52f986d016a640008a94cba62c268bfe",
            "d99fd2c09b2847e0a0d2fac604d77eb9",
            "1680af92a9e8446996f2478effb9a3de",
            "b12290a8b0b94258a36f8f6ac5d5c4e4",
            "d37fa3a2c39049deb835e4ab450fe6d3",
            "cabad1cfb1774bde8f42e76e7d6502e5",
            "996403b2698c46cb997cd79aec731b06",
            "117dd252c2184eeab00ff4235c3bcbd3",
            "e5d651568c394bc2bcd4520612abdcad",
            "f015a9b67755439fb8e54899664ac3c1",
            "12f134ee2a424be3abea6d494e4bfbab",
            "9f6ff4717b324571b1f9f94dafeb2595",
            "00cff9e6d2134816bfb2ec87723bab2b",
            "d340ce23d06240cf906b8d342599af85",
            "1f8caf86d61640208c93cbec5b5dc2f2",
            "5f617d90baa54ce88cca00cc9e5e8b35",
            "af302a7f599b4821bdae724ed9c3d941",
            "afc865ab5ce8484c8a3bc88832b637d3",
            "3888bb2d61dd43f5b12aeef07b44546b",
            "d0ed0fbdb5a244fe93fef412a8b92050",
            "6808729f963a4e509ce9bc918cd67a81",
            "50cd16c5507149f0aca19242197a7663",
            "83ea2ddc426f41b0a00c7a21c5325992",
            "ce03369c12c54551bb57647b87fc2a1c",
            "b8c906bf36ee4d00b286f58d0ebeb463",
            "f98a639d3a1d4a3fb39b070f6aeac1d5",
            "dd049696ccb14b82a5ceec24dc607cc5",
            "5449b174bc2a4a1f948a3309abdb7e7e",
            "e2f87ac85d934a519af2ef9730be4772",
            "5fe67b7f7fc349b2b9423c0f95be97f2",
            "ad99c64fe4aa4692ae02d67218bf55c2",
            "5ff58b5e014b4ad48287b65ab8d02397",
            "3daa9b54e94e4febbe66d82447b9c22f",
            "8a0782fcba27442194860a56b63ab4f6",
            "dd3d0e9fd7fd430d837c4c0d0d6945c5",
            "ba5fad8a980e4d628d61b22f4807ab1e",
            "147e68434b744af29a94cc2609ef79bc",
            "855327eaff774f5887628fce5474d27a",
            "2bb57b1175f84b8cbb00733e1b94689a",
            "d30209173d6748ba8afaa62dac632079",
            "56c5cb0530e54ffe93e4e1ae552021da"
          ]
        },
        "id": "Dc2hcJcwAytc",
        "outputId": "e99dc2e0-029f-485b-fa18-8a55df73ba93"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset: combined_dataset, Train size: 3033, Test size: 759\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# Custom dataset\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(int(self.labels[idx]))\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# Load tokenizer\n",
        "if model_choice_int == 0:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(distilbert_model_path)\n",
        "    \n",
        "else:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(bert_model_path)\n",
        "\n",
        "\n",
        "# Dictionary to hold train and test custom datasets\n",
        "train_test_datasets = {}\n",
        "\n",
        "for name, df in datasets.items():\n",
        "    # Get text and labels\n",
        "    X = df['clean_text'].tolist()\n",
        "    y = df['encoded_label'].tolist()\n",
        "\n",
        "    # Train-test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Tokenize\n",
        "    train_encodings = tokenizer(X_train, truncation=True, padding=True)\n",
        "    test_encodings = tokenizer(X_test, truncation=True, padding=True)\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = CustomDataset(train_encodings, y_train)\n",
        "    test_dataset = CustomDataset(test_encodings, y_test)\n",
        "\n",
        "    # Store in Dict\n",
        "    train_test_datasets[name] = {\n",
        "        \"train\": train_dataset,\n",
        "        \"test\": test_dataset,\n",
        "        # \"val\": val_dataset\n",
        "\n",
        "    }\n",
        "\n",
        "    print(f\"Dataset: {name}, Train size: {len(train_dataset)}, Test size: {len(test_dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axFv5HXWw_Kq"
      },
      "source": [
        "## Train and Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments, BertForSequenceClassification\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_dir = f'./results/{name}'\n",
        "log_dir = f'./logs/{name}'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "default_training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    run_name=f'training_{name}',\n",
        "    num_train_epochs=4,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    # gradient_accumulation_steps=2,\n",
        "    warmup_steps=50,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=log_dir,\n",
        "    logging_steps=10,\n",
        "    do_eval=True,\n",
        "    eval_steps=500,\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=1,\n",
        "    report_to=[],\n",
        "    fp16=True,\n",
        "    \n",
        ")\n",
        "\n",
        "best_training_args_distil = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    run_name=f'training_{name}',\n",
        "    per_device_eval_batch_size=16,  # can stay as-is for evaluation\n",
        "    num_train_epochs=6,            # ⬅️ from Optuna\n",
        "    per_device_train_batch_size=16,  # ⬅️ from Optuna\n",
        "    warmup_steps=29,               # ⬅️ from Optuna\n",
        "    weight_decay=0.09793901282245424,  # ⬅️ from Optuna\n",
        "    learning_rate=3.694163912198525e-05,  # ⬅️ from Optuna\n",
        "    logging_dir=log_dir,\n",
        "    logging_steps=10,\n",
        "    do_eval=True,\n",
        "    eval_steps=500,\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=1,\n",
        "    report_to=[],\n",
        "    fp16=True,\n",
        ")\n",
        "\n",
        "best_training_args_bert = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    run_name=f'training_{name}',\n",
        "    per_device_eval_batch_size=8,\n",
        "    per_device_train_batch_size=8,  # From Optuna\n",
        "    num_train_epochs=9,             # From Optuna\n",
        "    warmup_steps=117,               # From Optuna\n",
        "    weight_decay=0.12399629519542921,  # From Optuna\n",
        "    learning_rate=2.9677882858655988e-05,  # From Optuna\n",
        "    logging_dir=log_dir,\n",
        "    logging_steps=10,\n",
        "    do_eval=True,\n",
        "    eval_steps=500,\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=1,\n",
        "    report_to=[],\n",
        "    fp16=True,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Default\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ[\"WANDB_MODE\"] = \"disabled\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 576,
          "referenced_widgets": [
            "75b2646922ab451b96ecaf6e24bd9c2b",
            "cd8e32adfe6a48bbb3b49a63cc7db9e6",
            "132d2b53c3df416bb8170ae1f36dd64c",
            "0079a78677fb455cbdd664642f43d149",
            "5974ddb863a24cdf8263d242011c71c6",
            "82225876103b45079803c3a10f64daa7",
            "b1abfc510db94181a9b979125398824a",
            "b4e15ccbf0c54cce94ffe77d6e5b4e51",
            "ab8b5d02e34e46f7bdc6b6d1e2098040",
            "e3407419c6574c5c825bbb9cdbfffa67",
            "4967c6af3ed64a3f83c7899a03863448",
            "c9438a2c8eed43f29f1e42b0c7fd186a",
            "c337f4764ef94235b217be28a6febe97",
            "4b5ed4dd432f4cb79aabc5356ce25e8e",
            "95ba3a1fe6384e1aabd44c2e98177a4e",
            "2a1575d12c194176979318c2eb907fa1",
            "1919e3d4ea3e458f97440ba5b72a21ab",
            "c8a439753dc845ed81c5649b29647b41",
            "f6991a814f78430d9258fb7a13d2c129",
            "8ff2ea0eb1674004a11b74f3d2c44817",
            "97a26a8fe0f64abe9644b7158bc13ad0",
            "9988f5cb7f7c41f58af4021da7cd5b3e"
          ]
        },
        "id": "IWDv5dKYA70f",
        "outputId": "545a2ed0-fd0d-4eb5-aadb-a40f99572183"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, test_dataset, batch_size, output_dir, dataset_name):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
        "            # Move inputs to device\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "\n",
        "            # Move to CPU and accumulate\n",
        "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "            all_preds.extend(preds)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Metrics\n",
        "    report = classification_report(all_labels, all_preds, digits=4)\n",
        "    with open(os.path.join(output_dir, \"classification_report.txt\"), \"w\") as f:\n",
        "        f.write(report)\n",
        "\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    plt.figure(figsize=(5, 4))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f'Confusion Matrix: {dataset_name}')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_dir, \"confusion_matrix.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"✅ Evaluation complete for {dataset_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🚀 Training on dataset: combined_dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_backend=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=no,\n",
            "fp16=True,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=2.9677882858655988e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=./logs/combined_dataset,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=10,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=9,\n",
            "optim=adamw_hf,\n",
            "optim_args=None,\n",
            "output_dir=./results/combined_dataset,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=8,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=[],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=training_combined_dataset,\n",
            "save_on_each_node=False,\n",
            "save_safetensors=False,\n",
            "save_steps=500,\n",
            "save_strategy=epoch,\n",
            "save_total_limit=1,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=117,\n",
            "weight_decay=0.12399629519542921,\n",
            "xpu_backend=None,\n",
            ")\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a6397dec7333445fb074feb5d23951a1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3420 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.6858, 'learning_rate': 1.7755998291503582e-06, 'epoch': 0.03}\n",
            "{'loss': 0.7449, 'learning_rate': 4.31217101365087e-06, 'epoch': 0.05}\n",
            "{'loss': 0.6916, 'learning_rate': 6.59508507970133e-06, 'epoch': 0.08}\n",
            "{'loss': 0.7761, 'learning_rate': 9.131656264201844e-06, 'epoch': 0.11}\n",
            "{'loss': 0.7092, 'learning_rate': 1.1668227448702355e-05, 'epoch': 0.13}\n",
            "{'loss': 0.7449, 'learning_rate': 1.3951141514752815e-05, 'epoch': 0.16}\n",
            "{'loss': 0.7206, 'learning_rate': 1.6234055580803276e-05, 'epoch': 0.18}\n",
            "{'loss': 0.7211, 'learning_rate': 1.8770626765303786e-05, 'epoch': 0.21}\n",
            "{'loss': 0.7213, 'learning_rate': 2.13071979498043e-05, 'epoch': 0.24}\n",
            "{'loss': 0.7765, 'learning_rate': 2.384376913430481e-05, 'epoch': 0.26}\n",
            "{'loss': 0.639, 'learning_rate': 2.638034031880532e-05, 'epoch': 0.29}\n",
            "{'loss': 0.6782, 'learning_rate': 2.8916911503305833e-05, 'epoch': 0.32}\n",
            "{'loss': 0.695, 'learning_rate': 2.9614986951901344e-05, 'epoch': 0.34}\n",
            "{'loss': 0.6061, 'learning_rate': 2.9525135656537564e-05, 'epoch': 0.37}\n",
            "{'loss': 0.5537, 'learning_rate': 2.9435284361173787e-05, 'epoch': 0.39}\n",
            "{'loss': 0.6606, 'learning_rate': 2.9345433065810007e-05, 'epoch': 0.42}\n",
            "{'loss': 0.5083, 'learning_rate': 2.925558177044623e-05, 'epoch': 0.45}\n",
            "{'loss': 0.5586, 'learning_rate': 2.916573047508245e-05, 'epoch': 0.47}\n",
            "{'loss': 0.4066, 'learning_rate': 2.907587917971867e-05, 'epoch': 0.5}\n",
            "{'loss': 0.4261, 'learning_rate': 2.8986027884354893e-05, 'epoch': 0.53}\n",
            "{'loss': 0.4563, 'learning_rate': 2.8896176588991116e-05, 'epoch': 0.55}\n",
            "{'loss': 0.4113, 'learning_rate': 2.880632529362734e-05, 'epoch': 0.58}\n",
            "{'loss': 0.4042, 'learning_rate': 2.871647399826356e-05, 'epoch': 0.61}\n",
            "{'loss': 0.3124, 'learning_rate': 2.8626622702899783e-05, 'epoch': 0.63}\n",
            "{'loss': 0.4021, 'learning_rate': 2.8536771407536003e-05, 'epoch': 0.66}\n",
            "{'loss': 0.5051, 'learning_rate': 2.8446920112172226e-05, 'epoch': 0.68}\n",
            "{'loss': 0.3409, 'learning_rate': 2.8357068816808446e-05, 'epoch': 0.71}\n",
            "{'loss': 0.4317, 'learning_rate': 2.826721752144467e-05, 'epoch': 0.74}\n",
            "{'loss': 0.45, 'learning_rate': 2.817736622608089e-05, 'epoch': 0.76}\n",
            "{'loss': 0.4379, 'learning_rate': 2.808751493071711e-05, 'epoch': 0.79}\n",
            "{'loss': 0.3315, 'learning_rate': 2.7997663635353332e-05, 'epoch': 0.82}\n",
            "{'loss': 0.5508, 'learning_rate': 2.7907812339989552e-05, 'epoch': 0.84}\n",
            "{'loss': 0.3418, 'learning_rate': 2.7817961044625775e-05, 'epoch': 0.87}\n",
            "{'loss': 0.6381, 'learning_rate': 2.7728109749261995e-05, 'epoch': 0.89}\n",
            "{'loss': 0.5454, 'learning_rate': 2.763825845389822e-05, 'epoch': 0.92}\n",
            "{'loss': 0.4435, 'learning_rate': 2.754840715853444e-05, 'epoch': 0.95}\n",
            "{'loss': 0.3188, 'learning_rate': 2.7458555863170665e-05, 'epoch': 0.97}\n",
            "{'loss': 0.2892, 'learning_rate': 2.7368704567806885e-05, 'epoch': 1.0}\n",
            "{'loss': 0.2701, 'learning_rate': 2.7278853272443108e-05, 'epoch': 1.03}\n",
            "{'loss': 0.3709, 'learning_rate': 2.7189001977079328e-05, 'epoch': 1.05}\n",
            "{'loss': 0.4075, 'learning_rate': 2.7099150681715548e-05, 'epoch': 1.08}\n",
            "{'loss': 0.4633, 'learning_rate': 2.700929938635177e-05, 'epoch': 1.11}\n",
            "{'loss': 0.2515, 'learning_rate': 2.691944809098799e-05, 'epoch': 1.13}\n",
            "{'loss': 0.1748, 'learning_rate': 2.6829596795624214e-05, 'epoch': 1.16}\n",
            "{'loss': 0.444, 'learning_rate': 2.6739745500260434e-05, 'epoch': 1.18}\n",
            "{'loss': 0.3444, 'learning_rate': 2.6649894204896657e-05, 'epoch': 1.21}\n",
            "{'loss': 0.0665, 'learning_rate': 2.6560042909532877e-05, 'epoch': 1.24}\n",
            "{'loss': 0.3355, 'learning_rate': 2.64701916141691e-05, 'epoch': 1.26}\n",
            "{'loss': 0.3096, 'learning_rate': 2.638034031880532e-05, 'epoch': 1.29}\n",
            "{'loss': 0.472, 'learning_rate': 2.6290489023441547e-05, 'epoch': 1.32}\n",
            "{'loss': 0.0848, 'learning_rate': 2.6200637728077767e-05, 'epoch': 1.34}\n",
            "{'loss': 0.5294, 'learning_rate': 2.6110786432713987e-05, 'epoch': 1.37}\n",
            "{'loss': 0.2143, 'learning_rate': 2.602093513735021e-05, 'epoch': 1.39}\n",
            "{'loss': 0.4445, 'learning_rate': 2.593108384198643e-05, 'epoch': 1.42}\n",
            "{'loss': 0.2587, 'learning_rate': 2.5841232546622653e-05, 'epoch': 1.45}\n",
            "{'loss': 0.2054, 'learning_rate': 2.5751381251258873e-05, 'epoch': 1.47}\n",
            "{'loss': 0.2852, 'learning_rate': 2.5661529955895096e-05, 'epoch': 1.5}\n",
            "{'loss': 0.1756, 'learning_rate': 2.5571678660531316e-05, 'epoch': 1.53}\n",
            "{'loss': 0.2072, 'learning_rate': 2.548182736516754e-05, 'epoch': 1.55}\n",
            "{'loss': 0.5409, 'learning_rate': 2.539197606980376e-05, 'epoch': 1.58}\n",
            "{'loss': 0.1773, 'learning_rate': 2.5302124774439983e-05, 'epoch': 1.61}\n",
            "{'loss': 0.3372, 'learning_rate': 2.5212273479076203e-05, 'epoch': 1.63}\n",
            "{'loss': 0.4427, 'learning_rate': 2.5122422183712422e-05, 'epoch': 1.66}\n",
            "{'loss': 0.1577, 'learning_rate': 2.5032570888348646e-05, 'epoch': 1.68}\n",
            "{'loss': 0.1678, 'learning_rate': 2.494271959298487e-05, 'epoch': 1.71}\n",
            "{'loss': 0.2197, 'learning_rate': 2.4852868297621092e-05, 'epoch': 1.74}\n",
            "{'loss': 0.3853, 'learning_rate': 2.4763017002257312e-05, 'epoch': 1.76}\n",
            "{'loss': 0.1973, 'learning_rate': 2.4673165706893535e-05, 'epoch': 1.79}\n",
            "{'loss': 0.3104, 'learning_rate': 2.4583314411529755e-05, 'epoch': 1.82}\n",
            "{'loss': 0.27, 'learning_rate': 2.449346311616598e-05, 'epoch': 1.84}\n",
            "{'loss': 0.2542, 'learning_rate': 2.44036118208022e-05, 'epoch': 1.87}\n",
            "{'loss': 0.2612, 'learning_rate': 2.431376052543842e-05, 'epoch': 1.89}\n",
            "{'loss': 0.1407, 'learning_rate': 2.422390923007464e-05, 'epoch': 1.92}\n",
            "{'loss': 0.1394, 'learning_rate': 2.413405793471086e-05, 'epoch': 1.95}\n",
            "{'loss': 0.3723, 'learning_rate': 2.4044206639347085e-05, 'epoch': 1.97}\n",
            "{'loss': 0.1485, 'learning_rate': 2.3954355343983304e-05, 'epoch': 2.0}\n",
            "{'loss': 0.2618, 'learning_rate': 2.3864504048619528e-05, 'epoch': 2.03}\n",
            "{'loss': 0.2106, 'learning_rate': 2.3774652753255748e-05, 'epoch': 2.05}\n",
            "{'loss': 0.0966, 'learning_rate': 2.3684801457891974e-05, 'epoch': 2.08}\n",
            "{'loss': 0.083, 'learning_rate': 2.3594950162528194e-05, 'epoch': 2.11}\n",
            "{'loss': 0.2412, 'learning_rate': 2.3505098867164417e-05, 'epoch': 2.13}\n",
            "{'loss': 0.1354, 'learning_rate': 2.3415247571800637e-05, 'epoch': 2.16}\n",
            "{'loss': 0.2122, 'learning_rate': 2.332539627643686e-05, 'epoch': 2.18}\n",
            "{'loss': 0.0939, 'learning_rate': 2.323554498107308e-05, 'epoch': 2.21}\n",
            "{'loss': 0.3008, 'learning_rate': 2.3145693685709304e-05, 'epoch': 2.24}\n",
            "{'loss': 0.0723, 'learning_rate': 2.3055842390345524e-05, 'epoch': 2.26}\n",
            "{'loss': 0.1272, 'learning_rate': 2.2965991094981743e-05, 'epoch': 2.29}\n",
            "{'loss': 0.1937, 'learning_rate': 2.2876139799617967e-05, 'epoch': 2.32}\n",
            "{'loss': 0.028, 'learning_rate': 2.2786288504254187e-05, 'epoch': 2.34}\n",
            "{'loss': 0.0444, 'learning_rate': 2.269643720889041e-05, 'epoch': 2.37}\n",
            "{'loss': 0.2989, 'learning_rate': 2.260658591352663e-05, 'epoch': 2.39}\n",
            "{'loss': 0.2627, 'learning_rate': 2.2516734618162853e-05, 'epoch': 2.42}\n",
            "{'loss': 0.1403, 'learning_rate': 2.2426883322799073e-05, 'epoch': 2.45}\n",
            "{'loss': 0.1991, 'learning_rate': 2.23370320274353e-05, 'epoch': 2.47}\n",
            "{'loss': 0.0079, 'learning_rate': 2.224718073207152e-05, 'epoch': 2.5}\n",
            "{'loss': 0.1178, 'learning_rate': 2.2157329436707743e-05, 'epoch': 2.53}\n",
            "{'loss': 0.1318, 'learning_rate': 2.2067478141343963e-05, 'epoch': 2.55}\n",
            "{'loss': 0.1976, 'learning_rate': 2.1977626845980182e-05, 'epoch': 2.58}\n",
            "{'loss': 0.1117, 'learning_rate': 2.1887775550616406e-05, 'epoch': 2.61}\n",
            "{'loss': 0.1331, 'learning_rate': 2.1797924255252626e-05, 'epoch': 2.63}\n",
            "{'loss': 0.1377, 'learning_rate': 2.170807295988885e-05, 'epoch': 2.66}\n",
            "{'loss': 0.0173, 'learning_rate': 2.161822166452507e-05, 'epoch': 2.68}\n",
            "{'loss': 0.1606, 'learning_rate': 2.1528370369161292e-05, 'epoch': 2.71}\n",
            "{'loss': 0.0788, 'learning_rate': 2.1438519073797512e-05, 'epoch': 2.74}\n",
            "{'loss': 0.1524, 'learning_rate': 2.1348667778433735e-05, 'epoch': 2.76}\n",
            "{'loss': 0.2158, 'learning_rate': 2.1258816483069955e-05, 'epoch': 2.79}\n",
            "{'loss': 0.0056, 'learning_rate': 2.1168965187706178e-05, 'epoch': 2.82}\n",
            "{'loss': 0.1058, 'learning_rate': 2.10791138923424e-05, 'epoch': 2.84}\n",
            "{'loss': 0.1166, 'learning_rate': 2.098926259697862e-05, 'epoch': 2.87}\n",
            "{'loss': 0.0097, 'learning_rate': 2.0899411301614845e-05, 'epoch': 2.89}\n",
            "{'loss': 0.1711, 'learning_rate': 2.0809560006251065e-05, 'epoch': 2.92}\n",
            "{'loss': 0.098, 'learning_rate': 2.0719708710887288e-05, 'epoch': 2.95}\n",
            "{'loss': 0.0891, 'learning_rate': 2.0629857415523508e-05, 'epoch': 2.97}\n",
            "{'loss': 0.0863, 'learning_rate': 2.054000612015973e-05, 'epoch': 3.0}\n",
            "{'loss': 0.1412, 'learning_rate': 2.045015482479595e-05, 'epoch': 3.03}\n",
            "{'loss': 0.1484, 'learning_rate': 2.0360303529432174e-05, 'epoch': 3.05}\n",
            "{'loss': 0.0013, 'learning_rate': 2.0270452234068394e-05, 'epoch': 3.08}\n",
            "{'loss': 0.0009, 'learning_rate': 2.0180600938704617e-05, 'epoch': 3.11}\n",
            "{'loss': 0.0061, 'learning_rate': 2.0090749643340837e-05, 'epoch': 3.13}\n",
            "{'loss': 0.0785, 'learning_rate': 2.0000898347977057e-05, 'epoch': 3.16}\n",
            "{'loss': 0.1585, 'learning_rate': 1.991104705261328e-05, 'epoch': 3.18}\n",
            "{'loss': 0.0006, 'learning_rate': 1.9821195757249504e-05, 'epoch': 3.21}\n",
            "{'loss': 0.1019, 'learning_rate': 1.9731344461885727e-05, 'epoch': 3.24}\n",
            "{'loss': 0.1454, 'learning_rate': 1.9641493166521947e-05, 'epoch': 3.26}\n",
            "{'loss': 0.0012, 'learning_rate': 1.955164187115817e-05, 'epoch': 3.29}\n",
            "{'loss': 0.0012, 'learning_rate': 1.946179057579439e-05, 'epoch': 3.32}\n",
            "{'loss': 0.0009, 'learning_rate': 1.9371939280430613e-05, 'epoch': 3.34}\n",
            "{'loss': 0.0217, 'learning_rate': 1.9282087985066833e-05, 'epoch': 3.37}\n",
            "{'loss': 0.0109, 'learning_rate': 1.9192236689703056e-05, 'epoch': 3.39}\n",
            "{'loss': 0.0005, 'learning_rate': 1.9102385394339276e-05, 'epoch': 3.42}\n",
            "{'loss': 0.0462, 'learning_rate': 1.9012534098975496e-05, 'epoch': 3.45}\n",
            "{'loss': 0.0004, 'learning_rate': 1.892268280361172e-05, 'epoch': 3.47}\n",
            "{'loss': 0.001, 'learning_rate': 1.883283150824794e-05, 'epoch': 3.5}\n",
            "{'loss': 0.0156, 'learning_rate': 1.8742980212884162e-05, 'epoch': 3.53}\n",
            "{'loss': 0.07, 'learning_rate': 1.8653128917520382e-05, 'epoch': 3.55}\n",
            "{'loss': 0.3245, 'learning_rate': 1.8563277622156606e-05, 'epoch': 3.58}\n",
            "{'loss': 0.0139, 'learning_rate': 1.847342632679283e-05, 'epoch': 3.61}\n",
            "{'loss': 0.1536, 'learning_rate': 1.8383575031429052e-05, 'epoch': 3.63}\n",
            "{'loss': 0.0762, 'learning_rate': 1.8293723736065272e-05, 'epoch': 3.66}\n",
            "{'loss': 0.0689, 'learning_rate': 1.8203872440701495e-05, 'epoch': 3.68}\n",
            "{'loss': 0.0793, 'learning_rate': 1.8114021145337715e-05, 'epoch': 3.71}\n",
            "{'loss': 0.001, 'learning_rate': 1.8024169849973935e-05, 'epoch': 3.74}\n",
            "{'loss': 0.1121, 'learning_rate': 1.7934318554610158e-05, 'epoch': 3.76}\n",
            "{'loss': 0.1364, 'learning_rate': 1.7844467259246378e-05, 'epoch': 3.79}\n",
            "{'loss': 0.0005, 'learning_rate': 1.77546159638826e-05, 'epoch': 3.82}\n",
            "{'loss': 0.1091, 'learning_rate': 1.766476466851882e-05, 'epoch': 3.84}\n",
            "{'loss': 0.0004, 'learning_rate': 1.7574913373155044e-05, 'epoch': 3.87}\n",
            "{'loss': 0.0393, 'learning_rate': 1.7485062077791264e-05, 'epoch': 3.89}\n",
            "{'loss': 0.0017, 'learning_rate': 1.7395210782427488e-05, 'epoch': 3.92}\n",
            "{'loss': 0.0894, 'learning_rate': 1.7305359487063708e-05, 'epoch': 3.95}\n",
            "{'loss': 0.0004, 'learning_rate': 1.7215508191699934e-05, 'epoch': 3.97}\n",
            "{'loss': 0.0894, 'learning_rate': 1.7125656896336154e-05, 'epoch': 4.0}\n",
            "{'loss': 0.0008, 'learning_rate': 1.7035805600972374e-05, 'epoch': 4.03}\n",
            "{'loss': 0.1073, 'learning_rate': 1.6945954305608597e-05, 'epoch': 4.05}\n",
            "{'loss': 0.0005, 'learning_rate': 1.6856103010244817e-05, 'epoch': 4.08}\n",
            "{'loss': 0.12, 'learning_rate': 1.676625171488104e-05, 'epoch': 4.11}\n",
            "{'loss': 0.1159, 'learning_rate': 1.667640041951726e-05, 'epoch': 4.13}\n",
            "{'loss': 0.0148, 'learning_rate': 1.6586549124153483e-05, 'epoch': 4.16}\n",
            "{'loss': 0.0003, 'learning_rate': 1.6496697828789703e-05, 'epoch': 4.18}\n",
            "{'loss': 0.0004, 'learning_rate': 1.6406846533425927e-05, 'epoch': 4.21}\n",
            "{'loss': 0.0008, 'learning_rate': 1.6316995238062146e-05, 'epoch': 4.24}\n",
            "{'loss': 0.0009, 'learning_rate': 1.622714394269837e-05, 'epoch': 4.26}\n",
            "{'loss': 0.0003, 'learning_rate': 1.613729264733459e-05, 'epoch': 4.29}\n",
            "{'loss': 0.0978, 'learning_rate': 1.604744135197081e-05, 'epoch': 4.32}\n",
            "{'loss': 0.069, 'learning_rate': 1.5957590056607033e-05, 'epoch': 4.34}\n",
            "{'loss': 0.1064, 'learning_rate': 1.5867738761243256e-05, 'epoch': 4.37}\n",
            "{'loss': 0.0004, 'learning_rate': 1.577788746587948e-05, 'epoch': 4.39}\n",
            "{'loss': 0.0005, 'learning_rate': 1.56880361705157e-05, 'epoch': 4.42}\n",
            "{'loss': 0.0122, 'learning_rate': 1.5598184875151922e-05, 'epoch': 4.45}\n",
            "{'loss': 0.0004, 'learning_rate': 1.5508333579788142e-05, 'epoch': 4.47}\n",
            "{'loss': 0.0574, 'learning_rate': 1.5418482284424366e-05, 'epoch': 4.5}\n",
            "{'loss': 0.0004, 'learning_rate': 1.5328630989060585e-05, 'epoch': 4.53}\n",
            "{'loss': 0.0003, 'learning_rate': 1.5238779693696807e-05, 'epoch': 4.55}\n",
            "{'loss': 0.0003, 'learning_rate': 1.5148928398333029e-05, 'epoch': 4.58}\n",
            "{'loss': 0.123, 'learning_rate': 1.505907710296925e-05, 'epoch': 4.61}\n",
            "{'loss': 0.0003, 'learning_rate': 1.4969225807605472e-05, 'epoch': 4.63}\n",
            "{'loss': 0.0003, 'learning_rate': 1.4879374512241693e-05, 'epoch': 4.66}\n",
            "{'loss': 0.0003, 'learning_rate': 1.4789523216877917e-05, 'epoch': 4.68}\n",
            "{'loss': 0.0003, 'learning_rate': 1.4699671921514138e-05, 'epoch': 4.71}\n",
            "{'loss': 0.0093, 'learning_rate': 1.460982062615036e-05, 'epoch': 4.74}\n",
            "{'loss': 0.0002, 'learning_rate': 1.451996933078658e-05, 'epoch': 4.76}\n",
            "{'loss': 0.0045, 'learning_rate': 1.4430118035422801e-05, 'epoch': 4.79}\n",
            "{'loss': 0.0003, 'learning_rate': 1.4340266740059023e-05, 'epoch': 4.82}\n",
            "{'loss': 0.0002, 'learning_rate': 1.4250415444695246e-05, 'epoch': 4.84}\n",
            "{'loss': 0.0002, 'learning_rate': 1.4160564149331468e-05, 'epoch': 4.87}\n",
            "{'loss': 0.0002, 'learning_rate': 1.4070712853967689e-05, 'epoch': 4.89}\n",
            "{'loss': 0.0703, 'learning_rate': 1.398086155860391e-05, 'epoch': 4.92}\n",
            "{'loss': 0.0613, 'learning_rate': 1.3891010263240132e-05, 'epoch': 4.95}\n",
            "{'loss': 0.1118, 'learning_rate': 1.3801158967876354e-05, 'epoch': 4.97}\n",
            "{'loss': 0.0002, 'learning_rate': 1.3711307672512575e-05, 'epoch': 5.0}\n",
            "{'loss': 0.0004, 'learning_rate': 1.3621456377148799e-05, 'epoch': 5.03}\n",
            "{'loss': 0.0031, 'learning_rate': 1.3531605081785019e-05, 'epoch': 5.05}\n",
            "{'loss': 0.0003, 'learning_rate': 1.344175378642124e-05, 'epoch': 5.08}\n",
            "{'loss': 0.0031, 'learning_rate': 1.3351902491057462e-05, 'epoch': 5.11}\n",
            "{'loss': 0.0982, 'learning_rate': 1.3262051195693683e-05, 'epoch': 5.13}\n",
            "{'loss': 0.0009, 'learning_rate': 1.3172199900329905e-05, 'epoch': 5.16}\n",
            "{'loss': 0.0007, 'learning_rate': 1.3082348604966126e-05, 'epoch': 5.18}\n",
            "{'loss': 0.0008, 'learning_rate': 1.299249730960235e-05, 'epoch': 5.21}\n",
            "{'loss': 0.0006, 'learning_rate': 1.2902646014238571e-05, 'epoch': 5.24}\n",
            "{'loss': 0.0004, 'learning_rate': 1.2812794718874793e-05, 'epoch': 5.26}\n",
            "{'loss': 0.0061, 'learning_rate': 1.2722943423511014e-05, 'epoch': 5.29}\n",
            "{'loss': 0.0003, 'learning_rate': 1.2633092128147236e-05, 'epoch': 5.32}\n",
            "{'loss': 0.0182, 'learning_rate': 1.2543240832783456e-05, 'epoch': 5.34}\n",
            "{'loss': 0.0002, 'learning_rate': 1.2453389537419677e-05, 'epoch': 5.37}\n",
            "{'loss': 0.0002, 'learning_rate': 1.23635382420559e-05, 'epoch': 5.39}\n",
            "{'loss': 0.0002, 'learning_rate': 1.2273686946692122e-05, 'epoch': 5.42}\n",
            "{'loss': 0.0444, 'learning_rate': 1.2183835651328344e-05, 'epoch': 5.45}\n",
            "{'loss': 0.0002, 'learning_rate': 1.2093984355964565e-05, 'epoch': 5.47}\n",
            "{'loss': 0.1042, 'learning_rate': 1.2004133060600787e-05, 'epoch': 5.5}\n",
            "{'loss': 0.0003, 'learning_rate': 1.1914281765237009e-05, 'epoch': 5.53}\n",
            "{'loss': 0.0004, 'learning_rate': 1.182443046987323e-05, 'epoch': 5.55}\n",
            "{'loss': 0.0007, 'learning_rate': 1.1734579174509452e-05, 'epoch': 5.58}\n",
            "{'loss': 0.0762, 'learning_rate': 1.1644727879145675e-05, 'epoch': 5.61}\n",
            "{'loss': 0.0004, 'learning_rate': 1.1554876583781895e-05, 'epoch': 5.63}\n",
            "{'loss': 0.0213, 'learning_rate': 1.1465025288418116e-05, 'epoch': 5.66}\n",
            "{'loss': 0.0034, 'learning_rate': 1.1375173993054338e-05, 'epoch': 5.68}\n",
            "{'loss': 0.0002, 'learning_rate': 1.128532269769056e-05, 'epoch': 5.71}\n",
            "{'loss': 0.0023, 'learning_rate': 1.1195471402326781e-05, 'epoch': 5.74}\n",
            "{'loss': 0.0955, 'learning_rate': 1.1105620106963003e-05, 'epoch': 5.76}\n",
            "{'loss': 0.0854, 'learning_rate': 1.1015768811599226e-05, 'epoch': 5.79}\n",
            "{'loss': 0.0002, 'learning_rate': 1.0925917516235448e-05, 'epoch': 5.82}\n",
            "{'loss': 0.0004, 'learning_rate': 1.0836066220871669e-05, 'epoch': 5.84}\n",
            "{'loss': 0.0004, 'learning_rate': 1.074621492550789e-05, 'epoch': 5.87}\n",
            "{'loss': 0.0383, 'learning_rate': 1.066534875968049e-05, 'epoch': 5.89}\n",
            "{'loss': 0.0002, 'learning_rate': 1.0575497464316711e-05, 'epoch': 5.92}\n",
            "{'loss': 0.0002, 'learning_rate': 1.0485646168952933e-05, 'epoch': 5.95}\n",
            "{'loss': 0.0002, 'learning_rate': 1.0395794873589155e-05, 'epoch': 5.97}\n",
            "{'loss': 0.0002, 'learning_rate': 1.0305943578225376e-05, 'epoch': 6.0}\n",
            "{'loss': 0.0004, 'learning_rate': 1.0216092282861598e-05, 'epoch': 6.03}\n",
            "{'loss': 0.0244, 'learning_rate': 1.0126240987497821e-05, 'epoch': 6.05}\n",
            "{'loss': 0.0002, 'learning_rate': 1.0036389692134041e-05, 'epoch': 6.08}\n",
            "{'loss': 0.0496, 'learning_rate': 9.946538396770262e-06, 'epoch': 6.11}\n",
            "{'loss': 0.0004, 'learning_rate': 9.856687101406484e-06, 'epoch': 6.13}\n",
            "{'loss': 0.0001, 'learning_rate': 9.766835806042706e-06, 'epoch': 6.16}\n",
            "{'loss': 0.0001, 'learning_rate': 9.676984510678927e-06, 'epoch': 6.18}\n",
            "{'loss': 0.0001, 'learning_rate': 9.587133215315149e-06, 'epoch': 6.21}\n",
            "{'loss': 0.0002, 'learning_rate': 9.497281919951372e-06, 'epoch': 6.24}\n",
            "{'loss': 0.0002, 'learning_rate': 9.407430624587594e-06, 'epoch': 6.26}\n",
            "{'loss': 0.0001, 'learning_rate': 9.317579329223815e-06, 'epoch': 6.29}\n",
            "{'loss': 0.053, 'learning_rate': 9.227728033860037e-06, 'epoch': 6.32}\n",
            "{'loss': 0.0001, 'learning_rate': 9.137876738496258e-06, 'epoch': 6.34}\n",
            "{'loss': 0.0001, 'learning_rate': 9.04802544313248e-06, 'epoch': 6.37}\n",
            "{'loss': 0.0001, 'learning_rate': 8.9581741477687e-06, 'epoch': 6.39}\n",
            "{'loss': 0.0001, 'learning_rate': 8.868322852404923e-06, 'epoch': 6.42}\n",
            "{'loss': 0.1023, 'learning_rate': 8.778471557041145e-06, 'epoch': 6.45}\n",
            "{'loss': 0.0001, 'learning_rate': 8.688620261677366e-06, 'epoch': 6.47}\n",
            "{'loss': 0.0001, 'learning_rate': 8.598768966313588e-06, 'epoch': 6.5}\n",
            "{'loss': 0.0001, 'learning_rate': 8.50891767094981e-06, 'epoch': 6.53}\n",
            "{'loss': 0.0001, 'learning_rate': 8.419066375586031e-06, 'epoch': 6.55}\n",
            "{'loss': 0.0001, 'learning_rate': 8.329215080222252e-06, 'epoch': 6.58}\n",
            "{'loss': 0.0001, 'learning_rate': 8.239363784858474e-06, 'epoch': 6.61}\n",
            "{'loss': 0.0001, 'learning_rate': 8.149512489494697e-06, 'epoch': 6.63}\n",
            "{'loss': 0.11, 'learning_rate': 8.059661194130919e-06, 'epoch': 6.66}\n",
            "{'loss': 0.0002, 'learning_rate': 7.969809898767139e-06, 'epoch': 6.68}\n",
            "{'loss': 0.0001, 'learning_rate': 7.87995860340336e-06, 'epoch': 6.71}\n",
            "{'loss': 0.0001, 'learning_rate': 7.790107308039582e-06, 'epoch': 6.74}\n",
            "{'loss': 0.0001, 'learning_rate': 7.700256012675803e-06, 'epoch': 6.76}\n",
            "{'loss': 0.1103, 'learning_rate': 7.610404717312025e-06, 'epoch': 6.79}\n",
            "{'loss': 0.109, 'learning_rate': 7.520553421948248e-06, 'epoch': 6.82}\n",
            "{'loss': 0.0002, 'learning_rate': 7.43070212658447e-06, 'epoch': 6.84}\n",
            "{'loss': 0.0003, 'learning_rate': 7.340850831220691e-06, 'epoch': 6.87}\n",
            "{'loss': 0.0003, 'learning_rate': 7.250999535856912e-06, 'epoch': 6.89}\n",
            "{'loss': 0.0003, 'learning_rate': 7.161148240493134e-06, 'epoch': 6.92}\n",
            "{'loss': 0.0003, 'learning_rate': 7.071296945129356e-06, 'epoch': 6.95}\n",
            "{'loss': 0.0003, 'learning_rate': 6.981445649765578e-06, 'epoch': 6.97}\n",
            "{'loss': 0.0002, 'learning_rate': 6.891594354401799e-06, 'epoch': 7.0}\n",
            "{'loss': 0.0014, 'learning_rate': 6.801743059038021e-06, 'epoch': 7.03}\n",
            "{'loss': 0.0003, 'learning_rate': 6.711891763674242e-06, 'epoch': 7.05}\n",
            "{'loss': 0.0398, 'learning_rate': 6.622040468310464e-06, 'epoch': 7.08}\n",
            "{'loss': 0.0003, 'learning_rate': 6.5321891729466855e-06, 'epoch': 7.11}\n",
            "{'loss': 0.0002, 'learning_rate': 6.442337877582908e-06, 'epoch': 7.13}\n",
            "{'loss': 0.0002, 'learning_rate': 6.3524865822191295e-06, 'epoch': 7.16}\n",
            "{'loss': 0.0002, 'learning_rate': 6.26263528685535e-06, 'epoch': 7.18}\n",
            "{'loss': 0.0002, 'learning_rate': 6.172783991491572e-06, 'epoch': 7.21}\n",
            "{'loss': 0.0002, 'learning_rate': 6.082932696127794e-06, 'epoch': 7.24}\n",
            "{'loss': 0.0002, 'learning_rate': 5.993081400764016e-06, 'epoch': 7.26}\n",
            "{'loss': 0.0002, 'learning_rate': 5.903230105400237e-06, 'epoch': 7.29}\n",
            "{'loss': 0.0002, 'learning_rate': 5.813378810036459e-06, 'epoch': 7.32}\n",
            "{'loss': 0.0002, 'learning_rate': 5.7235275146726805e-06, 'epoch': 7.34}\n",
            "{'loss': 0.0002, 'learning_rate': 5.633676219308902e-06, 'epoch': 7.37}\n",
            "{'loss': 0.0002, 'learning_rate': 5.543824923945124e-06, 'epoch': 7.39}\n",
            "{'loss': 0.057, 'learning_rate': 5.453973628581346e-06, 'epoch': 7.42}\n",
            "{'loss': 0.1046, 'learning_rate': 5.364122333217568e-06, 'epoch': 7.45}\n",
            "{'loss': 0.0154, 'learning_rate': 5.274271037853788e-06, 'epoch': 7.47}\n",
            "{'loss': 0.0002, 'learning_rate': 5.18441974249001e-06, 'epoch': 7.5}\n",
            "{'loss': 0.0002, 'learning_rate': 5.094568447126232e-06, 'epoch': 7.53}\n",
            "{'loss': 0.0002, 'learning_rate': 5.004717151762454e-06, 'epoch': 7.55}\n",
            "{'loss': 0.0002, 'learning_rate': 4.9148658563986755e-06, 'epoch': 7.58}\n",
            "{'loss': 0.0002, 'learning_rate': 4.825014561034898e-06, 'epoch': 7.61}\n",
            "{'loss': 0.0002, 'learning_rate': 4.735163265671119e-06, 'epoch': 7.63}\n",
            "{'loss': 0.0002, 'learning_rate': 4.64531197030734e-06, 'epoch': 7.66}\n",
            "{'loss': 0.0002, 'learning_rate': 4.555460674943562e-06, 'epoch': 7.68}\n",
            "{'loss': 0.0807, 'learning_rate': 4.465609379579784e-06, 'epoch': 7.71}\n",
            "{'loss': 0.0002, 'learning_rate': 4.375758084216006e-06, 'epoch': 7.74}\n",
            "{'loss': 0.0008, 'learning_rate': 4.285906788852227e-06, 'epoch': 7.76}\n",
            "{'loss': 0.0012, 'learning_rate': 4.196055493488448e-06, 'epoch': 7.79}\n",
            "{'loss': 0.0002, 'learning_rate': 4.1062041981246705e-06, 'epoch': 7.82}\n",
            "{'loss': 0.0002, 'learning_rate': 4.016352902760892e-06, 'epoch': 7.84}\n",
            "{'loss': 0.0002, 'learning_rate': 3.926501607397114e-06, 'epoch': 7.87}\n",
            "{'loss': 0.0002, 'learning_rate': 3.836650312033336e-06, 'epoch': 7.89}\n",
            "{'loss': 0.0002, 'learning_rate': 3.746799016669557e-06, 'epoch': 7.92}\n",
            "{'loss': 0.1279, 'learning_rate': 3.6569477213057788e-06, 'epoch': 7.95}\n",
            "{'loss': 0.0002, 'learning_rate': 3.5670964259420003e-06, 'epoch': 7.97}\n",
            "{'loss': 0.0003, 'learning_rate': 3.477245130578222e-06, 'epoch': 8.0}\n",
            "{'loss': 0.0003, 'learning_rate': 3.3873938352144435e-06, 'epoch': 8.03}\n",
            "{'loss': 0.0002, 'learning_rate': 3.297542539850665e-06, 'epoch': 8.05}\n",
            "{'loss': 0.0003, 'learning_rate': 3.207691244486887e-06, 'epoch': 8.08}\n",
            "{'loss': 0.0002, 'learning_rate': 3.1178399491231086e-06, 'epoch': 8.11}\n",
            "{'loss': 0.0002, 'learning_rate': 3.02798865375933e-06, 'epoch': 8.13}\n",
            "{'loss': 0.1031, 'learning_rate': 2.938137358395552e-06, 'epoch': 8.16}\n",
            "{'loss': 0.1005, 'learning_rate': 2.8482860630317733e-06, 'epoch': 8.18}\n",
            "{'loss': 0.0005, 'learning_rate': 2.7584347676679953e-06, 'epoch': 8.21}\n",
            "{'loss': 0.0003, 'learning_rate': 2.668583472304217e-06, 'epoch': 8.24}\n",
            "{'loss': 0.0004, 'learning_rate': 2.5787321769404385e-06, 'epoch': 8.26}\n",
            "{'loss': 0.0003, 'learning_rate': 2.48888088157666e-06, 'epoch': 8.29}\n",
            "{'loss': 0.0003, 'learning_rate': 2.399029586212882e-06, 'epoch': 8.32}\n",
            "{'loss': 0.0003, 'learning_rate': 2.3091782908491036e-06, 'epoch': 8.34}\n",
            "{'loss': 0.0003, 'learning_rate': 2.219326995485325e-06, 'epoch': 8.37}\n",
            "{'loss': 0.0003, 'learning_rate': 2.1294757001215467e-06, 'epoch': 8.39}\n",
            "{'loss': 0.0003, 'learning_rate': 2.0396244047577683e-06, 'epoch': 8.42}\n",
            "{'loss': 0.0003, 'learning_rate': 1.9497731093939903e-06, 'epoch': 8.45}\n",
            "{'loss': 0.0004, 'learning_rate': 1.8599218140302117e-06, 'epoch': 8.47}\n",
            "{'loss': 0.0003, 'learning_rate': 1.7700705186664334e-06, 'epoch': 8.5}\n",
            "{'loss': 0.0003, 'learning_rate': 1.680219223302655e-06, 'epoch': 8.53}\n",
            "{'loss': 0.0003, 'learning_rate': 1.5903679279388768e-06, 'epoch': 8.55}\n",
            "{'loss': 0.0003, 'learning_rate': 1.5005166325750984e-06, 'epoch': 8.58}\n",
            "{'loss': 0.0046, 'learning_rate': 1.41066533721132e-06, 'epoch': 8.61}\n",
            "{'loss': 0.0003, 'learning_rate': 1.3208140418475417e-06, 'epoch': 8.63}\n",
            "{'loss': 0.0724, 'learning_rate': 1.2309627464837633e-06, 'epoch': 8.66}\n",
            "{'loss': 0.0002, 'learning_rate': 1.141111451119985e-06, 'epoch': 8.68}\n",
            "{'loss': 0.0002, 'learning_rate': 1.0512601557562066e-06, 'epoch': 8.71}\n",
            "{'loss': 0.0002, 'learning_rate': 9.614088603924284e-07, 'epoch': 8.74}\n",
            "{'loss': 0.0003, 'learning_rate': 8.7155756502865e-07, 'epoch': 8.76}\n",
            "{'loss': 0.0002, 'learning_rate': 7.817062696648716e-07, 'epoch': 8.79}\n",
            "{'loss': 0.0002, 'learning_rate': 6.918549743010932e-07, 'epoch': 8.82}\n",
            "{'loss': 0.0002, 'learning_rate': 6.020036789373149e-07, 'epoch': 8.84}\n",
            "{'loss': 0.0003, 'learning_rate': 5.121523835735366e-07, 'epoch': 8.87}\n",
            "{'loss': 0.0003, 'learning_rate': 4.223010882097582e-07, 'epoch': 8.89}\n",
            "{'loss': 0.099, 'learning_rate': 3.324497928459799e-07, 'epoch': 8.92}\n",
            "{'loss': 0.0864, 'learning_rate': 2.425984974822015e-07, 'epoch': 8.95}\n",
            "{'loss': 0.0002, 'learning_rate': 1.527472021184232e-07, 'epoch': 8.97}\n",
            "{'loss': 0.0002, 'learning_rate': 6.289590675464484e-08, 'epoch': 9.0}\n",
            "{'train_runtime': 329.852, 'train_samples_per_second': 82.755, 'train_steps_per_second': 10.368, 'train_loss': 0.12292683184669728, 'epoch': 9.0}\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\n🚀 Training on dataset: {name}\")\n",
        "\n",
        "# Initialize model\n",
        "if model_choice_int == 0:\n",
        "    model = DistilBertForSequenceClassification.from_pretrained(\n",
        "            distilbert_model_path, num_labels=2\n",
        "    )\n",
        "\n",
        "    training_args = best_training_args_distil\n",
        "\n",
        "elif model_choice_int == 1:\n",
        "    model = BertForSequenceClassification.from_pretrained(\n",
        "            bert_model_path, num_labels=2\n",
        "    )\n",
        "\n",
        "    training_args = best_training_args_bert\n",
        "\n",
        "else:\n",
        "    model = DistilBertForSequenceClassification.from_pretrained(\n",
        "            distilbert_model_path, num_labels=2\n",
        "    )\n",
        "\n",
        "    training_args = default_training_args\n",
        "\n",
        "\n",
        "print(training_args)\n",
        "\n",
        "# Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_test_datasets[name]['train'],\n",
        "    eval_dataset=train_test_datasets[name]['test'],\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# Save model\n",
        "trainer.save_model(output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 190/190 [00:04<00:00, 43.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Evaluation complete for combined_dataset\n"
          ]
        }
      ],
      "source": [
        "# Evaluate and log\n",
        "evaluate_model(model, train_test_datasets[name]['test'], 4, output_dir, name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 95/95 [00:02<00:00, 41.57it/s]\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-08-18 18:46:11,828] A new study created in memory with name: no-name-0a59634a-c65b-43c4-bb13-5e7bf4e6e52d\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ffd448b7a68547a3b5f417f2c9766b84",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1520 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.463, 'learning_rate': 3.5904628330995795e-05, 'epoch': 1.32}\n",
            "{'loss': 0.1532, 'learning_rate': 1.8373071528751755e-05, 'epoch': 2.63}\n",
            "{'loss': 0.053, 'learning_rate': 8.415147265077139e-07, 'epoch': 3.95}\n",
            "{'train_runtime': 130.8412, 'train_samples_per_second': 92.723, 'train_steps_per_second': 11.617, 'train_loss': 0.22079304056732277, 'epoch': 4.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 95/95 [00:01<00:00, 55.88it/s]\n",
            "[I 2025-08-18 18:48:26,155] Trial 0 finished with value: 0.9654088050314465 and parameters: {'learning_rate': 2.4111941151269226e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.2871265242030436, 'num_train_epochs': 4, 'warmup_steps': 94}. Best is trial 0 with value: 0.9654088050314465.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c16e4af10f04bf182c5fb1c80af3877",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1520 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.3439, 'learning_rate': 3.6528866714183895e-05, 'epoch': 2.63}\n",
            "{'loss': 0.0648, 'learning_rate': 1.870990734141126e-05, 'epoch': 5.26}\n",
            "{'loss': 0.0225, 'learning_rate': 8.909479686386316e-07, 'epoch': 7.89}\n",
            "{'train_runtime': 148.6926, 'train_samples_per_second': 163.182, 'train_steps_per_second': 10.222, 'train_loss': 0.1423149692776956, 'epoch': 8.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 95/95 [00:01<00:00, 51.25it/s]\n",
            "[I 2025-08-18 18:50:58,459] Trial 1 finished with value: 0.9640062597809077 and parameters: {'learning_rate': 2.3341108257567182e-05, 'per_device_train_batch_size': 16, 'weight_decay': 0.06286913365127207, 'num_train_epochs': 8, 'warmup_steps': 117}. Best is trial 0 with value: 0.9654088050314465.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2e6da82975de451280515a38a385eef3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1140 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.3216, 'learning_rate': 2.8808243727598565e-05, 'epoch': 2.63}\n",
            "{'loss': 0.0442, 'learning_rate': 6.406810035842293e-06, 'epoch': 5.26}\n",
            "{'train_runtime': 114.5073, 'train_samples_per_second': 158.924, 'train_steps_per_second': 9.956, 'train_loss': 0.16310628966281288, 'epoch': 6.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 95/95 [00:01<00:00, 53.02it/s]\n",
            "[I 2025-08-18 18:52:56,568] Trial 2 finished with value: 0.9796557120500783 and parameters: {'learning_rate': 1.0673160333375926e-05, 'per_device_train_batch_size': 16, 'weight_decay': 0.04668752250156914, 'num_train_epochs': 6, 'warmup_steps': 24}. Best is trial 2 with value: 0.9796557120500783.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb5c2e396427421087e277de02e8cd45",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/760 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.4205, 'learning_rate': 2.6383399209486165e-05, 'epoch': 2.63}\n",
            "{'train_runtime': 74.1405, 'train_samples_per_second': 163.635, 'train_steps_per_second': 10.251, 'train_loss': 0.30330435602288497, 'epoch': 4.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 95/95 [00:01<00:00, 58.82it/s]\n",
            "[I 2025-08-18 18:54:13,960] Trial 3 finished with value: 0.9651898734177214 and parameters: {'learning_rate': 1.6726306539686333e-05, 'per_device_train_batch_size': 16, 'weight_decay': 0.2859658053547885, 'num_train_epochs': 4, 'warmup_steps': 254}. Best is trial 2 with value: 0.9796557120500783.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c133e5ba27f44e68db4dbd4bcefa8a0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2660 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.479, 'learning_rate': 4.316460741331208e-05, 'epoch': 1.32}\n",
            "{'loss': 0.177, 'learning_rate': 3.3200478278198486e-05, 'epoch': 2.63}\n",
            "{'loss': 0.0615, 'learning_rate': 2.3236349143084895e-05, 'epoch': 3.95}\n",
            "{'loss': 0.0207, 'learning_rate': 1.3272220007971303e-05, 'epoch': 5.26}\n",
            "{'loss': 0.0142, 'learning_rate': 3.3080908728577124e-06, 'epoch': 6.58}\n",
            "{'train_runtime': 224.0772, 'train_samples_per_second': 94.749, 'train_steps_per_second': 11.871, 'train_loss': 0.1423984403897049, 'epoch': 7.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 95/95 [00:01<00:00, 52.24it/s]\n",
            "[I 2025-08-18 18:58:01,644] Trial 4 finished with value: 0.9826224328593998 and parameters: {'learning_rate': 3.918392179981142e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.1081716243429309, 'num_train_epochs': 7, 'warmup_steps': 151}. Best is trial 4 with value: 0.9826224328593998.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b1407e1724be4dc6862bc242a1684363",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/6831 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.579, 'learning_rate': 4.6926836492891e-05, 'epoch': 0.66}\n",
            "{'loss': 0.4516, 'learning_rate': 4.322422985781991e-05, 'epoch': 1.32}\n",
            "{'loss': 0.3133, 'learning_rate': 3.9521623222748815e-05, 'epoch': 1.98}\n",
            "{'loss': 0.2329, 'learning_rate': 3.581901658767773e-05, 'epoch': 2.64}\n",
            "{'loss': 0.1362, 'learning_rate': 3.211640995260663e-05, 'epoch': 3.29}\n",
            "{'loss': 0.1677, 'learning_rate': 2.842120853080569e-05, 'epoch': 3.95}\n",
            "{'loss': 0.1259, 'learning_rate': 2.4718601895734598e-05, 'epoch': 4.61}\n",
            "{'loss': 0.0971, 'learning_rate': 2.1015995260663507e-05, 'epoch': 5.27}\n",
            "{'loss': 0.1039, 'learning_rate': 1.7313388625592416e-05, 'epoch': 5.93}\n",
            "{'loss': 0.0702, 'learning_rate': 1.3610781990521326e-05, 'epoch': 6.59}\n",
            "{'loss': 0.0734, 'learning_rate': 9.908175355450237e-06, 'epoch': 7.25}\n",
            "{'loss': 0.0554, 'learning_rate': 6.205568720379147e-06, 'epoch': 7.91}\n",
            "{'loss': 0.0436, 'learning_rate': 2.502962085308057e-06, 'epoch': 8.56}\n",
            "{'train_runtime': 558.4683, 'train_samples_per_second': 48.878, 'train_steps_per_second': 12.232, 'train_loss': 0.18205689329857394, 'epoch': 9.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 95/95 [00:01<00:00, 53.67it/s]\n",
            "[I 2025-08-18 19:07:23,555] Trial 5 finished with value: 0.9671361502347419 and parameters: {'learning_rate': 1.692254452337742e-05, 'per_device_train_batch_size': 4, 'weight_decay': 0.08019437096042144, 'num_train_epochs': 9, 'warmup_steps': 79}. Best is trial 4 with value: 0.9826224328593998.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89be4aefae164d63a79026541031b1be",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/6072 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.6425, 'learning_rate': 4.6913372582001685e-05, 'epoch': 0.66}\n",
            "{'loss': 0.5304, 'learning_rate': 4.2716568544995794e-05, 'epoch': 1.32}\n",
            "{'loss': 0.4849, 'learning_rate': 3.851976450798991e-05, 'epoch': 1.98}\n",
            "{'loss': 0.5976, 'learning_rate': 3.4314550042052145e-05, 'epoch': 2.64}\n",
            "{'loss': 0.7017, 'learning_rate': 3.0109335576114384e-05, 'epoch': 3.29}\n",
            "{'loss': 0.6985, 'learning_rate': 2.590412111017662e-05, 'epoch': 3.95}\n",
            "{'loss': 0.6999, 'learning_rate': 2.1698906644238856e-05, 'epoch': 4.61}\n",
            "{'loss': 0.6931, 'learning_rate': 1.7493692178301092e-05, 'epoch': 5.27}\n",
            "{'loss': 0.6955, 'learning_rate': 1.3288477712363332e-05, 'epoch': 5.93}\n",
            "{'loss': 0.6966, 'learning_rate': 9.083263246425568e-06, 'epoch': 6.59}\n",
            "{'loss': 0.6901, 'learning_rate': 4.8780487804878055e-06, 'epoch': 7.25}\n",
            "{'loss': 0.6886, 'learning_rate': 6.72834314550042e-07, 'epoch': 7.91}\n",
            "{'train_runtime': 487.6471, 'train_samples_per_second': 49.757, 'train_steps_per_second': 12.452, 'train_loss': 0.6521515023252866, 'epoch': 8.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 95/95 [00:01<00:00, 52.24it/s]\n",
            "[I 2025-08-18 19:15:34,689] Trial 6 finished with value: 0.0 and parameters: {'learning_rate': 4.6864538825921724e-05, 'per_device_train_batch_size': 4, 'weight_decay': 0.008295471453653835, 'num_train_epochs': 8, 'warmup_steps': 127}. Best is trial 4 with value: 0.9826224328593998.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "75de23d969414a2aa32dbbeba69d1bc9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2660 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.5005, 'learning_rate': 4.432841932841933e-05, 'epoch': 1.32}\n",
            "{'loss': 0.1774, 'learning_rate': 3.409090909090909e-05, 'epoch': 2.63}\n",
            "{'loss': 0.0637, 'learning_rate': 2.3853398853398853e-05, 'epoch': 3.95}\n",
            "{'loss': 0.0177, 'learning_rate': 1.3615888615888617e-05, 'epoch': 5.26}\n",
            "{'loss': 0.009, 'learning_rate': 3.3783783783783788e-06, 'epoch': 6.58}\n",
            "{'train_runtime': 213.7748, 'train_samples_per_second': 99.315, 'train_steps_per_second': 12.443, 'train_loss': 0.14545012129876847, 'epoch': 7.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 95/95 [00:01<00:00, 54.29it/s]\n",
            "[I 2025-08-18 19:19:11,892] Trial 7 finished with value: 0.967948717948718 and parameters: {'learning_rate': 3.3850662096055935e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.1913676089047663, 'num_train_epochs': 7, 'warmup_steps': 218}. Best is trial 4 with value: 0.9826224328593998.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62de32f4b6654acd9cf27c4c4e75950d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/570 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.3445, 'learning_rate': 8.296943231441049e-06, 'epoch': 2.63}\n",
            "{'train_runtime': 55.9941, 'train_samples_per_second': 162.499, 'train_steps_per_second': 10.18, 'train_loss': 0.31050122244316236, 'epoch': 3.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 95/95 [00:01<00:00, 51.69it/s]\n",
            "[I 2025-08-18 19:20:11,330] Trial 8 finished with value: 0.9438202247191011 and parameters: {'learning_rate': 4.426963547581735e-05, 'per_device_train_batch_size': 16, 'weight_decay': 0.13113619037197863, 'num_train_epochs': 3, 'warmup_steps': 112}. Best is trial 4 with value: 0.9826224328593998.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7c05aeeb327a4925894874d51746be7b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/6831 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.6057, 'learning_rate': 4.75390156062425e-05, 'epoch': 0.66}\n",
            "{'loss': 0.4223, 'learning_rate': 4.379501800720288e-05, 'epoch': 1.32}\n",
            "{'loss': 0.2217, 'learning_rate': 4.004351740696279e-05, 'epoch': 1.98}\n",
            "{'loss': 0.1473, 'learning_rate': 3.629201680672269e-05, 'epoch': 2.64}\n",
            "{'loss': 0.12, 'learning_rate': 3.25405162064826e-05, 'epoch': 3.29}\n",
            "{'loss': 0.0788, 'learning_rate': 2.8789015606242496e-05, 'epoch': 3.95}\n",
            "{'loss': 0.0371, 'learning_rate': 2.5037515006002404e-05, 'epoch': 4.61}\n",
            "{'loss': 0.0524, 'learning_rate': 2.1286014405762305e-05, 'epoch': 5.27}\n",
            "{'loss': 0.0189, 'learning_rate': 1.754201680672269e-05, 'epoch': 5.93}\n",
            "{'loss': 0.0095, 'learning_rate': 1.3790516206482592e-05, 'epoch': 6.59}\n",
            "{'loss': 0.0133, 'learning_rate': 1.0039015606242498e-05, 'epoch': 7.25}\n",
            "{'loss': 0.0047, 'learning_rate': 6.2875150060024004e-06, 'epoch': 7.91}\n",
            "{'loss': 0.0108, 'learning_rate': 2.543517406962785e-06, 'epoch': 8.56}\n",
            "{'train_runtime': 606.8944, 'train_samples_per_second': 44.978, 'train_steps_per_second': 11.256, 'train_loss': 0.12787675162985357, 'epoch': 9.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 95/95 [00:01<00:00, 54.87it/s]\n",
            "[I 2025-08-18 19:30:21,543] Trial 9 finished with value: 0.9748427672955976 and parameters: {'learning_rate': 2.1647774646251175e-05, 'per_device_train_batch_size': 4, 'weight_decay': 0.08535011955162826, 'num_train_epochs': 9, 'warmup_steps': 167}. Best is trial 4 with value: 0.9826224328593998.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "72117ebdbdba4c739d98c426d6f9ead9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2280 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.5244, 'learning_rate': 4.292929292929293e-05, 'epoch': 1.32}\n",
            "{'loss': 0.209, 'learning_rate': 3.090428090428091e-05, 'epoch': 2.63}\n",
            "{'loss': 0.0805, 'learning_rate': 1.887926887926888e-05, 'epoch': 3.95}\n",
            "{'loss': 0.0235, 'learning_rate': 6.854256854256854e-06, 'epoch': 5.26}\n",
            "{'train_runtime': 187.0095, 'train_samples_per_second': 97.311, 'train_steps_per_second': 12.192, 'train_loss': 0.18532144521412097, 'epoch': 6.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 95/95 [00:01<00:00, 51.83it/s]\n",
            "[I 2025-08-18 19:33:32,115] Trial 10 finished with value: 0.9685534591194969 and parameters: {'learning_rate': 3.313971781960163e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.19432666625223874, 'num_train_epochs': 6, 'warmup_steps': 201}. Best is trial 4 with value: 0.9826224328593998.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1932a48508bf4fc8bb6aa7fbe735e990",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2280 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.4619, 'learning_rate': 3.9609236234458264e-05, 'epoch': 1.32}\n",
            "{'loss': 0.1572, 'learning_rate': 2.8507992895204267e-05, 'epoch': 2.63}\n",
            "{'loss': 0.0558, 'learning_rate': 1.7406749555950266e-05, 'epoch': 3.95}\n",
            "{'loss': 0.0181, 'learning_rate': 6.305506216696271e-06, 'epoch': 5.26}\n",
            "{'train_runtime': 197.2122, 'train_samples_per_second': 92.276, 'train_steps_per_second': 11.561, 'train_loss': 0.1546648067340516, 'epoch': 6.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 95/95 [00:01<00:00, 51.33it/s]\n",
            "[I 2025-08-18 19:36:52,856] Trial 11 finished with value: 0.9750778816199377 and parameters: {'learning_rate': 1.0563481837762657e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.007174323851631512, 'num_train_epochs': 6, 'warmup_steps': 28}. Best is trial 4 with value: 0.9826224328593998.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "41ac793a49ae4e638e5c531be0c90cef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/950 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.3249, 'learning_rate': 2.4252136752136752e-05, 'epoch': 2.63}\n",
            "{'train_runtime': 92.1551, 'train_samples_per_second': 164.559, 'train_steps_per_second': 10.309, 'train_loss': 0.19048501667223477, 'epoch': 5.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 95/95 [00:01<00:00, 55.20it/s]\n",
            "[I 2025-08-18 19:38:28,366] Trial 12 finished with value: 0.9728867623604466 and parameters: {'learning_rate': 1.0261255510351852e-05, 'per_device_train_batch_size': 16, 'weight_decay': 0.12874328939594196, 'num_train_epochs': 5, 'warmup_steps': 14}. Best is trial 4 with value: 0.9826224328593998.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "44e3744a2fd941c89f7677dc35b1f30c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/380 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'train_runtime': 37.2263, 'train_samples_per_second': 162.949, 'train_steps_per_second': 10.208, 'train_loss': 0.3621800472861842, 'epoch': 2.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 95/95 [00:01<00:00, 52.11it/s]\n",
            "[I 2025-08-18 19:39:09,335] Trial 13 finished with value: 0.9290322580645162 and parameters: {'learning_rate': 1.3380754679059802e-05, 'per_device_train_batch_size': 16, 'weight_decay': 0.048579036780905124, 'num_train_epochs': 2, 'warmup_steps': 58}. Best is trial 4 with value: 0.9826224328593998.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "58f04031c69d4200af658e4ebdc31716",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3800 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.5123, 'learning_rate': 4.721428571428572e-05, 'epoch': 1.32}\n",
            "{'loss': 0.1876, 'learning_rate': 4.007142857142857e-05, 'epoch': 2.63}\n",
            "{'loss': 0.0516, 'learning_rate': 3.292857142857143e-05, 'epoch': 3.95}\n",
            "{'loss': 0.0226, 'learning_rate': 2.5785714285714284e-05, 'epoch': 5.26}\n",
            "{'loss': 0.0091, 'learning_rate': 1.8657142857142858e-05, 'epoch': 6.58}\n",
            "{'loss': 0.0054, 'learning_rate': 1.1514285714285715e-05, 'epoch': 7.89}\n",
            "{'loss': 0.0069, 'learning_rate': 4.371428571428571e-06, 'epoch': 9.21}\n",
            "{'train_runtime': 291.3101, 'train_samples_per_second': 104.116, 'train_steps_per_second': 13.045, 'train_loss': 0.10548730743558783, 'epoch': 10.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 95/95 [00:01<00:00, 58.32it/s]\n",
            "[I 2025-08-18 19:44:03,943] Trial 14 finished with value: 0.9922239502332814 and parameters: {'learning_rate': 3.164159687360286e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.1640557421098752, 'num_train_epochs': 10, 'warmup_steps': 300}. Best is trial 14 with value: 0.9922239502332814.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fee81001dbc745bfb91a7cae0165679a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3800 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.5141, 'learning_rate': 4.682629640124682e-05, 'epoch': 1.32}\n",
            "{'loss': 0.1834, 'learning_rate': 3.974213658260131e-05, 'epoch': 2.63}\n",
            "{'loss': 0.0717, 'learning_rate': 3.265797676395579e-05, 'epoch': 3.95}\n",
            "{'loss': 0.0322, 'learning_rate': 2.5573816945310287e-05, 'epoch': 5.26}\n",
            "{'loss': 0.0096, 'learning_rate': 1.8489657126664778e-05, 'epoch': 6.58}\n",
            "{'loss': 0.0109, 'learning_rate': 1.140549730801927e-05, 'epoch': 7.89}\n",
            "{'loss': 0.0105, 'learning_rate': 4.3213374893737605e-06, 'epoch': 9.21}\n",
            "{'train_runtime': 286.5391, 'train_samples_per_second': 105.849, 'train_steps_per_second': 13.262, 'train_loss': 0.1100570777842873, 'epoch': 10.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 95/95 [00:01<00:00, 56.57it/s]\n",
            "[I 2025-08-18 19:48:53,958] Trial 15 finished with value: 0.9732283464566929 and parameters: {'learning_rate': 3.415483189042178e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.17481038013263972, 'num_train_epochs': 10, 'warmup_steps': 271}. Best is trial 14 with value: 0.9922239502332814.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a9e083dfe8e41a2b3ce5971701aac52",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3800 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.5293, 'learning_rate': 4.54858243875585e-05, 'epoch': 1.32}\n",
            "{'loss': 0.2905, 'learning_rate': 3.861822185521607e-05, 'epoch': 2.63}\n",
            "{'loss': 0.1689, 'learning_rate': 3.1736856592347925e-05, 'epoch': 3.95}\n",
            "{'loss': 0.082, 'learning_rate': 2.485549132947977e-05, 'epoch': 5.26}\n",
            "{'loss': 0.0586, 'learning_rate': 1.7974126066611615e-05, 'epoch': 6.58}\n",
            "{'loss': 0.0401, 'learning_rate': 1.1092760803743462e-05, 'epoch': 7.89}\n",
            "{'loss': 0.038, 'learning_rate': 4.21139554087531e-06, 'epoch': 9.21}\n",
            "{'train_runtime': 291.8411, 'train_samples_per_second': 103.926, 'train_steps_per_second': 13.021, 'train_loss': 0.16147889839975457, 'epoch': 10.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 95/95 [00:01<00:00, 52.53it/s]\n",
            "[I 2025-08-18 19:53:49,366] Trial 16 finished with value: 0.9611197511664075 and parameters: {'learning_rate': 2.8727684502572765e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.2234835666926877, 'num_train_epochs': 10, 'warmup_steps': 167}. Best is trial 14 with value: 0.9922239502332814.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b020c584b5504166ba32126831f0676b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3040 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.5194, 'learning_rate': 4.52991452991453e-05, 'epoch': 1.32}\n",
            "{'loss': 0.2098, 'learning_rate': 3.6396011396011395e-05, 'epoch': 2.63}\n",
            "{'loss': 0.0859, 'learning_rate': 2.7492877492877494e-05, 'epoch': 3.95}\n",
            "{'loss': 0.0222, 'learning_rate': 1.860754985754986e-05, 'epoch': 5.26}\n",
            "{'loss': 0.009, 'learning_rate': 9.704415954415955e-06, 'epoch': 6.58}\n",
            "{'loss': 0.0067, 'learning_rate': 8.012820512820512e-07, 'epoch': 7.89}\n",
            "{'train_runtime': 245.85, 'train_samples_per_second': 98.694, 'train_steps_per_second': 12.365, 'train_loss': 0.1406049379980878, 'epoch': 8.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 95/95 [00:01<00:00, 56.32it/s]\n",
            "[I 2025-08-18 19:57:58,724] Trial 17 finished with value: 0.9635499207606973 and parameters: {'learning_rate': 3.9544372954998644e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.2319519653792289, 'num_train_epochs': 8, 'warmup_steps': 232}. Best is trial 14 with value: 0.9922239502332814.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f1d41c7577174b9d973b3b96b2ea88be",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3420 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.5088, 'learning_rate': 4.6844971172325435e-05, 'epoch': 1.32}\n",
            "{'loss': 0.1953, 'learning_rate': 3.883728379244074e-05, 'epoch': 2.63}\n",
            "{'loss': 0.0567, 'learning_rate': 3.082959641255605e-05, 'epoch': 3.95}\n",
            "{'loss': 0.0249, 'learning_rate': 2.2821909032671366e-05, 'epoch': 5.26}\n",
            "{'loss': 0.0094, 'learning_rate': 1.4814221652786675e-05, 'epoch': 6.58}\n",
            "{'loss': 0.0113, 'learning_rate': 6.8065342729019865e-06, 'epoch': 7.89}\n",
            "{'train_runtime': 278.4956, 'train_samples_per_second': 98.016, 'train_steps_per_second': 12.28, 'train_loss': 0.11817602431565, 'epoch': 9.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 95/95 [00:01<00:00, 53.41it/s]\n",
            "[I 2025-08-18 20:02:41,967] Trial 18 finished with value: 0.9905956112852665 and parameters: {'learning_rate': 2.985409318583019e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.10637062096469205, 'num_train_epochs': 9, 'warmup_steps': 298}. Best is trial 14 with value: 0.9922239502332814.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f7d7b786e3684934b0807129b7118d4f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3800 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.5197, 'learning_rate': 4.690604598353676e-05, 'epoch': 1.32}\n",
            "{'loss': 0.1889, 'learning_rate': 3.980982117513483e-05, 'epoch': 2.63}\n",
            "{'loss': 0.0606, 'learning_rate': 3.27135963667329e-05, 'epoch': 3.95}\n",
            "{'loss': 0.0238, 'learning_rate': 2.5617371558330973e-05, 'epoch': 5.26}\n",
            "{'loss': 0.0163, 'learning_rate': 1.852114674992904e-05, 'epoch': 6.58}\n",
            "{'loss': 0.0022, 'learning_rate': 1.1424921941527108e-05, 'epoch': 7.89}\n",
            "{'loss': 0.0007, 'learning_rate': 4.328697133125178e-06, 'epoch': 9.21}\n",
            "{'train_runtime': 316.7309, 'train_samples_per_second': 95.76, 'train_steps_per_second': 11.998, 'train_loss': 0.10688148015423825, 'epoch': 10.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 95/95 [00:01<00:00, 57.49it/s]\n",
            "[I 2025-08-18 20:08:02,176] Trial 19 finished with value: 0.9811320754716981 and parameters: {'learning_rate': 2.7573728191928755e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.15824457740424994, 'num_train_epochs': 10, 'warmup_steps': 277}. Best is trial 14 with value: 0.9922239502332814.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff2f9021d9624fbc8d54abcea1e6a654",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3420 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.5521, 'learning_rate': 4.6875e-05, 'epoch': 1.32}\n",
            "{'loss': 0.229, 'learning_rate': 3.886217948717949e-05, 'epoch': 2.63}\n",
            "{'loss': 0.0985, 'learning_rate': 3.0865384615384616e-05, 'epoch': 3.95}\n",
            "{'loss': 0.0647, 'learning_rate': 2.2852564102564103e-05, 'epoch': 5.26}\n",
            "{'loss': 0.0304, 'learning_rate': 1.483974358974359e-05, 'epoch': 6.58}\n",
            "{'loss': 0.0111, 'learning_rate': 6.826923076923076e-06, 'epoch': 7.89}\n",
            "{'train_runtime': 274.3172, 'train_samples_per_second': 99.509, 'train_steps_per_second': 12.467, 'train_loss': 0.14523575389594362, 'epoch': 9.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 95/95 [00:01<00:00, 57.78it/s]\n",
            "[I 2025-08-18 20:12:39,836] Trial 20 finished with value: 0.9683544303797469 and parameters: {'learning_rate': 1.8076339697662663e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.22779026810826972, 'num_train_epochs': 9, 'warmup_steps': 300}. Best is trial 14 with value: 0.9922239502332814.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6855fdd08b334e1badfd40ce73f03b22",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2660 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.4918, 'learning_rate': 4.5829805249788315e-05, 'epoch': 1.32}\n",
            "{'loss': 0.207, 'learning_rate': 3.524555461473328e-05, 'epoch': 2.63}\n",
            "{'loss': 0.0779, 'learning_rate': 2.466130397967824e-05, 'epoch': 3.95}\n",
            "{'loss': 0.0416, 'learning_rate': 1.40770533446232e-05, 'epoch': 5.26}\n",
            "{'loss': 0.0159, 'learning_rate': 3.4928027095681624e-06, 'epoch': 6.58}\n",
            "{'train_runtime': 212.0542, 'train_samples_per_second': 100.121, 'train_steps_per_second': 12.544, 'train_loss': 0.15751062425455653, 'epoch': 7.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 95/95 [00:01<00:00, 56.73it/s]\n",
            "[I 2025-08-18 20:16:15,225] Trial 21 finished with value: 0.965625 and parameters: {'learning_rate': 3.9326469827980505e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.10651663285181716, 'num_train_epochs': 7, 'warmup_steps': 298}. Best is trial 14 with value: 0.9922239502332814.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d67eeb75f014c06a5c285e9839bfe56",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3420 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.4974, 'learning_rate': 4.5333333333333335e-05, 'epoch': 1.32}\n",
            "{'loss': 0.1938, 'learning_rate': 3.758139534883721e-05, 'epoch': 2.63}\n",
            "{'loss': 0.0765, 'learning_rate': 2.9829457364341084e-05, 'epoch': 3.95}\n",
            "{'loss': 0.0488, 'learning_rate': 2.2077519379844965e-05, 'epoch': 5.26}\n",
            "{'loss': 0.0342, 'learning_rate': 1.434108527131783e-05, 'epoch': 6.58}\n",
            "{'loss': 0.0239, 'learning_rate': 6.589147286821707e-06, 'epoch': 7.89}\n",
            "{'train_runtime': 277.1369, 'train_samples_per_second': 98.496, 'train_steps_per_second': 12.34, 'train_loss': 0.13029738560057522, 'epoch': 9.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 95/95 [00:01<00:00, 54.60it/s]\n",
            "[I 2025-08-18 20:20:55,730] Trial 22 finished with value: 0.9716088328075709 and parameters: {'learning_rate': 2.8466883706833626e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.12073369898976337, 'num_train_epochs': 9, 'warmup_steps': 195}. Best is trial 14 with value: 0.9922239502332814.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "238f505c8ed242b4a6df8237aba0b5c9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2660 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.5016, 'learning_rate': 4.484258492129246e-05, 'epoch': 1.32}\n",
            "{'loss': 0.1956, 'learning_rate': 3.4486329743164876e-05, 'epoch': 2.63}\n",
            "{'loss': 0.0745, 'learning_rate': 2.413007456503728e-05, 'epoch': 3.95}\n",
            "{'loss': 0.0444, 'learning_rate': 1.3773819386909696e-05, 'epoch': 5.26}\n",
            "{'loss': 0.0271, 'learning_rate': 3.4175642087821044e-06, 'epoch': 6.58}\n",
            "{'train_runtime': 221.7271, 'train_samples_per_second': 95.753, 'train_steps_per_second': 11.997, 'train_loss': 0.15920075523225885, 'epoch': 7.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 95/95 [00:01<00:00, 57.34it/s]\n",
            "[I 2025-08-18 20:24:41,058] Trial 23 finished with value: 0.9797191887675506 and parameters: {'learning_rate': 3.841117027981422e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.09693061191752174, 'num_train_epochs': 7, 'warmup_steps': 246}. Best is trial 14 with value: 0.9922239502332814.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9909f7ca8b98443e91a28bc4c46e2f82",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3800 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.5436, 'learning_rate': 4.695849914724275e-05, 'epoch': 1.32}\n",
            "{'loss': 0.2059, 'learning_rate': 3.985218874360433e-05, 'epoch': 2.63}\n",
            "{'loss': 0.0842, 'learning_rate': 3.274587833996589e-05, 'epoch': 3.95}\n",
            "{'loss': 0.0275, 'learning_rate': 2.5639567936327456e-05, 'epoch': 5.26}\n",
            "{'loss': 0.0234, 'learning_rate': 1.8547470153496305e-05, 'epoch': 6.58}\n",
            "{'loss': 0.0223, 'learning_rate': 1.1441159749857874e-05, 'epoch': 7.89}\n",
            "{'loss': 0.0137, 'learning_rate': 4.34906196702672e-06, 'epoch': 9.21}\n",
            "{'train_runtime': 295.9213, 'train_samples_per_second': 102.493, 'train_steps_per_second': 12.841, 'train_loss': 0.12171447082569725, 'epoch': 10.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 95/95 [00:01<00:00, 55.57it/s]\n",
            "[I 2025-08-18 20:29:40,384] Trial 24 finished with value: 0.978125 and parameters: {'learning_rate': 2.9942886916170066e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.15497679014198357, 'num_train_epochs': 10, 'warmup_steps': 282}. Best is trial 14 with value: 0.9922239502332814.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c02cdd38a62f40e5aa7a1ffda7d00e8b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/6072 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.6802, 'learning_rate': 4.712692242690553e-05, 'epoch': 0.66}\n",
            "{'loss': 0.4601, 'learning_rate': 4.2910258576981584e-05, 'epoch': 1.32}\n",
            "{'loss': 0.3592, 'learning_rate': 3.868514449890147e-05, 'epoch': 1.98}\n",
            "{'loss': 0.2512, 'learning_rate': 3.4460030420821365e-05, 'epoch': 2.64}\n",
            "{'loss': 0.1843, 'learning_rate': 3.0243366570897414e-05, 'epoch': 3.29}\n",
            "{'loss': 0.1523, 'learning_rate': 2.6018252492817308e-05, 'epoch': 3.95}\n",
            "{'loss': 0.1612, 'learning_rate': 2.1793138414737198e-05, 'epoch': 4.61}\n",
            "{'loss': 0.0907, 'learning_rate': 1.756802433665709e-05, 'epoch': 5.27}\n",
            "{'loss': 0.1344, 'learning_rate': 1.3342910258576981e-05, 'epoch': 5.93}\n",
            "{'loss': 0.0974, 'learning_rate': 9.117796180496873e-06, 'epoch': 6.59}\n",
            "{'loss': 0.081, 'learning_rate': 4.892682102416765e-06, 'epoch': 7.25}\n",
            "{'loss': 0.0886, 'learning_rate': 6.675680243366571e-07, 'epoch': 7.91}\n",
            "{'train_runtime': 465.2218, 'train_samples_per_second': 52.156, 'train_steps_per_second': 13.052, 'train_loss': 0.22673306948896768, 'epoch': 8.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 95/95 [00:01<00:00, 54.81it/s]\n",
            "[I 2025-08-18 20:37:29,082] Trial 25 finished with value: 0.9513343799058085 and parameters: {'learning_rate': 4.890209235597461e-05, 'per_device_train_batch_size': 4, 'weight_decay': 0.14036593121687996, 'num_train_epochs': 8, 'warmup_steps': 155}. Best is trial 14 with value: 0.9922239502332814.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cfe09e58535045eaa7fbd4a88e17fefb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3420 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.5083, 'learning_rate': 4.5530987231392094e-05, 'epoch': 1.32}\n",
            "{'loss': 0.1724, 'learning_rate': 3.774525070071629e-05, 'epoch': 2.63}\n",
            "{'loss': 0.056, 'learning_rate': 2.9959514170040487e-05, 'epoch': 3.95}\n",
            "{'loss': 0.0259, 'learning_rate': 2.2173777639364685e-05, 'epoch': 5.26}\n",
            "{'loss': 0.0137, 'learning_rate': 1.4388041108688881e-05, 'epoch': 6.58}\n",
            "{'loss': 0.0096, 'learning_rate': 6.617876051074432e-06, 'epoch': 7.89}\n",
            "{'train_runtime': 300.6995, 'train_samples_per_second': 90.778, 'train_steps_per_second': 11.373, 'train_loss': 0.11613313900796991, 'epoch': 9.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 95/95 [00:02<00:00, 42.09it/s]\n",
            "[I 2025-08-18 20:42:33,827] Trial 26 finished with value: 0.978125 and parameters: {'learning_rate': 2.0543374996039574e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.1064471553629868, 'num_train_epochs': 9, 'warmup_steps': 209}. Best is trial 14 with value: 0.9922239502332814.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ce0fb3cb9954455699c8b88003ee2072",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2660 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.5025, 'learning_rate': 4.4975083056478404e-05, 'epoch': 1.32}\n",
            "{'loss': 0.186, 'learning_rate': 3.4593023255813954e-05, 'epoch': 2.63}\n",
            "{'loss': 0.0598, 'learning_rate': 2.4210963455149503e-05, 'epoch': 3.95}\n",
            "{'loss': 0.028, 'learning_rate': 1.382890365448505e-05, 'epoch': 5.26}\n",
            "{'loss': 0.0048, 'learning_rate': 3.446843853820598e-06, 'epoch': 6.58}\n",
            "{'train_runtime': 223.1161, 'train_samples_per_second': 95.157, 'train_steps_per_second': 11.922, 'train_loss': 0.14683581692047584, 'epoch': 7.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 95/95 [00:01<00:00, 53.29it/s]\n",
            "[I 2025-08-18 20:46:20,637] Trial 27 finished with value: 0.9716088328075709 and parameters: {'learning_rate': 2.553046282895703e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.17337773779947113, 'num_train_epochs': 7, 'warmup_steps': 252}. Best is trial 14 with value: 0.9922239502332814.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d11f352b1534fba8774e4a8af3ec1cc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1900 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.4806, 'learning_rate': 4.092765460910152e-05, 'epoch': 1.32}\n",
            "{'loss': 0.1697, 'learning_rate': 2.637106184364061e-05, 'epoch': 2.63}\n",
            "{'loss': 0.0486, 'learning_rate': 1.1814469078179698e-05, 'epoch': 3.95}\n",
            "{'train_runtime': 151.3257, 'train_samples_per_second': 100.214, 'train_steps_per_second': 12.556, 'train_loss': 0.18869317054748536, 'epoch': 5.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 95/95 [00:01<00:00, 56.95it/s]\n",
            "[I 2025-08-18 20:48:55,226] Trial 28 finished with value: 0.9795918367346939 and parameters: {'learning_rate': 3.217732490546123e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.03351354423237021, 'num_train_epochs': 5, 'warmup_steps': 186}. Best is trial 14 with value: 0.9922239502332814.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc6d6f5d966d41c0861a06fc2aeb47f3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3800 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.5101, 'learning_rate': 4.63684800897364e-05, 'epoch': 1.32}\n",
            "{'loss': 0.2169, 'learning_rate': 3.935782389231632e-05, 'epoch': 2.63}\n",
            "{'loss': 0.0893, 'learning_rate': 3.2347167694896246e-05, 'epoch': 3.95}\n",
            "{'loss': 0.0633, 'learning_rate': 2.533651149747617e-05, 'epoch': 5.26}\n",
            "{'loss': 0.0488, 'learning_rate': 1.8325855300056086e-05, 'epoch': 6.58}\n",
            "{'loss': 0.0298, 'learning_rate': 1.1315199102636007e-05, 'epoch': 7.89}\n",
            "{'loss': 0.0326, 'learning_rate': 4.304542905215928e-06, 'epoch': 9.21}\n",
            "{'train_runtime': 315.7421, 'train_samples_per_second': 96.059, 'train_steps_per_second': 12.035, 'train_loss': 0.13254492232674048, 'epoch': 10.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 95/95 [00:02<00:00, 47.10it/s]\n",
            "[I 2025-08-18 20:54:14,619] Trial 29 finished with value: 0.9761526232114467 and parameters: {'learning_rate': 4.258744059975119e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.2639083181574777, 'num_train_epochs': 10, 'warmup_steps': 234}. Best is trial 14 with value: 0.9922239502332814.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Best trial:\n",
            "FrozenTrial(number=14, state=TrialState.COMPLETE, values=[0.9922239502332814], datetime_start=datetime.datetime(2025, 8, 18, 19, 39, 9, 336919), datetime_complete=datetime.datetime(2025, 8, 18, 19, 44, 3, 943244), params={'learning_rate': 3.164159687360286e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.1640557421098752, 'num_train_epochs': 10, 'warmup_steps': 300}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'learning_rate': FloatDistribution(high=5e-05, log=True, low=1e-05, step=None), 'per_device_train_batch_size': CategoricalDistribution(choices=(4, 8, 16)), 'weight_decay': FloatDistribution(high=0.3, log=False, low=0.0, step=None), 'num_train_epochs': IntDistribution(high=10, log=False, low=2, step=1), 'warmup_steps': IntDistribution(high=300, log=False, low=0, step=1)}, trial_id=14, value=None)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from transformers import Trainer, DistilBertForSequenceClassification, BertForSequenceClassification\n",
        "import gc\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "from optuna import create_study\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def optuna_hp_space(trial):\n",
        "    return {\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 5e-5),\n",
        "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [4, 8, 16]),\n",
        "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.0, 0.3),\n",
        "        \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 2, 10),\n",
        "        \"warmup_steps\": trial.suggest_int(\"warmup_steps\", 0, 300),\n",
        "    }\n",
        "\n",
        "def manual_evaluate(model, dataset, batch_size=8):\n",
        "    model.eval()\n",
        "    model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
        "            inputs = {k: v.to(model.device) for k, v in batch.items() if k in [\"input_ids\", \"attention_mask\"]}\n",
        "            labels = batch[\"labels\"].to(model.device)\n",
        "\n",
        "            outputs = model(**inputs)\n",
        "            logits = outputs.logits\n",
        "            preds = torch.argmax(logits, dim=-1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    acc = f1_score(all_labels, all_preds)\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    return acc\n",
        "    \n",
        "\n",
        "# Subclass Trainer to inject memory cleanup\n",
        "class CleanTrainer(Trainer):\n",
        "    def train(self, *args, **kwargs):\n",
        "        result = super().train(*args, **kwargs)\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "        return result\n",
        "\n",
        "if model_choice_int == 0:\n",
        "    # Initialize model\n",
        "    model_init = lambda: DistilBertForSequenceClassification.from_pretrained(\n",
        "        distilbert_model_path, num_labels=2\n",
        "    )\n",
        "\n",
        "else:\n",
        "    model_init = lambda: BertForSequenceClassification.from_pretrained(\n",
        "        bert_model_path, num_labels=2\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = CleanTrainer(\n",
        "    model_init=model_init,\n",
        "    args=training_args,\n",
        "    train_dataset=train_test_datasets[name][\"train\"],\n",
        "    eval_dataset=train_test_datasets[name][\"test\"],\n",
        "    compute_metrics= manual_evaluate(trainer.model, train_test_datasets[name]['test'], batch_size=8),\n",
        ")\n",
        "\n",
        "def objective(trial):\n",
        "    hp = optuna_hp_space(trial)\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=f\"./results/optuna_trial_{trial.number}\",\n",
        "        num_train_epochs=hp[\"num_train_epochs\"],\n",
        "        per_device_train_batch_size=hp[\"per_device_train_batch_size\"],\n",
        "        warmup_steps=hp[\"warmup_steps\"],\n",
        "        weight_decay=hp[\"weight_decay\"],\n",
        "        save_strategy=\"no\",        # ← disables saving\n",
        "        save_total_limit=0,         # ← just in case (optional safety)\n",
        "        logging_dir=f\"./logs/optuna_trial_{trial.number}\",\n",
        "        report_to=[],  # Disable wandb\n",
        "        fp16=True,\n",
        "    )\n",
        "\n",
        "    model = model_init()\n",
        "\n",
        "    trainer = CleanTrainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_test_datasets[name][\"train\"],\n",
        "        eval_dataset=train_test_datasets[name][\"test\"],\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "\n",
        "    acc = manual_evaluate(trainer.model, train_test_datasets[name][\"test\"], batch_size=8)\n",
        "    return acc\n",
        "\n",
        "study = create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=30)\n",
        "\n",
        "print(\"✅ Best trial:\")\n",
        "print(study.best_trial)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'val'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[13], line 29\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# 4. Retrain model on TRAIN + VAL before final test evaluation (optional but recommended)\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConcatDataset\n\u001b[0;32m     27\u001b[0m train_val_dataset \u001b[38;5;241m=\u001b[39m ConcatDataset([\n\u001b[0;32m     28\u001b[0m     train_test_datasets[name][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m---> 29\u001b[0m     \u001b[43mtrain_test_datasets\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mval\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     30\u001b[0m ])\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Load the same tokenizer used to tokenize the dataset\u001b[39;00m\n\u001b[0;32m     33\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(distilbert_model_path \u001b[38;5;28;01mif\u001b[39;00m model_choice_int \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m bert_model_path)\n",
            "\u001b[1;31mKeyError\u001b[0m: 'val'"
          ]
        }
      ],
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "from transformers import AutoTokenizer  # Only if tokenizer not yet loaded\n",
        "\n",
        "\n",
        "# 1. Retrieve best hyperparameters from Optuna\n",
        "best_hp = study.best_trial.params\n",
        "\n",
        "# 2. Re-initialize training arguments with best parameters\n",
        "final_training_args = TrainingArguments(\n",
        "    output_dir=\"./results/final_eval\",\n",
        "    num_train_epochs=best_hp[\"num_train_epochs\"],\n",
        "    per_device_train_batch_size=best_hp[\"per_device_train_batch_size\"],\n",
        "    warmup_steps=best_hp[\"warmup_steps\"],\n",
        "    weight_decay=best_hp[\"weight_decay\"],\n",
        "    learning_rate=best_hp[\"learning_rate\"],\n",
        "    save_strategy=\"no\",\n",
        "    report_to=[],\n",
        "    fp16=True,\n",
        "    logging_dir=\"./logs/final_eval\"\n",
        ")\n",
        "\n",
        "# 3. Re-initialize model with same init function\n",
        "final_model = model_init()\n",
        "\n",
        "# 4. Retrain model on TRAIN + VAL before final test evaluation (optional but recommended)\n",
        "from torch.utils.data import ConcatDataset\n",
        "train_val_dataset = ConcatDataset([\n",
        "    train_test_datasets[name][\"train\"],\n",
        "    train_test_datasets[name][\"val\"]\n",
        "])\n",
        "\n",
        "# Load the same tokenizer used to tokenize the dataset\n",
        "tokenizer = AutoTokenizer.from_pretrained(distilbert_model_path if model_choice_int == 0 else bert_model_path)\n",
        "\n",
        "# Create a data collator to dynamically pad batches\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "\n",
        "final_trainer = CleanTrainer(\n",
        "    model=final_model,\n",
        "    args=final_training_args,\n",
        "    train_dataset=train_val_dataset,\n",
        "    data_collator=data_collator  # <- Fixes padding issue\n",
        ")\n",
        "\n",
        "# 5. Train on full train+val\n",
        "final_trainer.train()\n",
        "\n",
        "# 6. Final evaluation on the test set\n",
        "final_f1 = manual_evaluate(final_model, train_test_datasets[name][\"test\"], batch_size=8)\n",
        "\n",
        "print(f\"\\n🎯 Final Test F1 Score (macro): {final_f1:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tGPU3.8",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0079a78677fb455cbdd664642f43d149": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3407419c6574c5c825bbb9cdbfffa67",
            "placeholder": "​",
            "style": "IPY_MODEL_4967c6af3ed64a3f83c7899a03863448",
            "value": " 273M/273M [00:07&lt;00:00, 36.5MB/s]"
          }
        },
        "00cff9e6d2134816bfb2ec87723bab2b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "117dd252c2184eeab00ff4235c3bcbd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12f134ee2a424be3abea6d494e4bfbab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f617d90baa54ce88cca00cc9e5e8b35",
            "max": 473,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af302a7f599b4821bdae724ed9c3d941",
            "value": 473
          }
        },
        "132d2b53c3df416bb8170ae1f36dd64c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4e15ccbf0c54cce94ffe77d6e5b4e51",
            "max": 272513919,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab8b5d02e34e46f7bdc6b6d1e2098040",
            "value": 272513919
          }
        },
        "147e68434b744af29a94cc2609ef79bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1680af92a9e8446996f2478effb9a3de": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1919e3d4ea3e458f97440ba5b72a21ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f8caf86d61640208c93cbec5b5dc2f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a1575d12c194176979318c2eb907fa1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bb57b1175f84b8cbb00733e1b94689a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2c81cbcb517e438ea3c8d590052214f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de50dc3ddbcf4af9ba799c0391ba493d",
              "IPY_MODEL_79c4f2796ef14b2ab8738c6421d4797f",
              "IPY_MODEL_52f986d016a640008a94cba62c268bfe"
            ],
            "layout": "IPY_MODEL_d99fd2c09b2847e0a0d2fac604d77eb9"
          }
        },
        "3888bb2d61dd43f5b12aeef07b44546b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3daa9b54e94e4febbe66d82447b9c22f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_855327eaff774f5887628fce5474d27a",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2bb57b1175f84b8cbb00733e1b94689a",
            "value": 112
          }
        },
        "4967c6af3ed64a3f83c7899a03863448": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b5ed4dd432f4cb79aabc5356ce25e8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6991a814f78430d9258fb7a13d2c129",
            "max": 272501104,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8ff2ea0eb1674004a11b74f3d2c44817",
            "value": 272501104
          }
        },
        "50cd16c5507149f0aca19242197a7663": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd049696ccb14b82a5ceec24dc607cc5",
            "max": 229513,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5449b174bc2a4a1f948a3309abdb7e7e",
            "value": 229513
          }
        },
        "52f986d016a640008a94cba62c268bfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_996403b2698c46cb997cd79aec731b06",
            "placeholder": "​",
            "style": "IPY_MODEL_117dd252c2184eeab00ff4235c3bcbd3",
            "value": " 62.0/62.0 [00:00&lt;00:00, 1.43kB/s]"
          }
        },
        "5449b174bc2a4a1f948a3309abdb7e7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "56c5cb0530e54ffe93e4e1ae552021da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5974ddb863a24cdf8263d242011c71c6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f617d90baa54ce88cca00cc9e5e8b35": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fe67b7f7fc349b2b9423c0f95be97f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ff58b5e014b4ad48287b65ab8d02397": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba5fad8a980e4d628d61b22f4807ab1e",
            "placeholder": "​",
            "style": "IPY_MODEL_147e68434b744af29a94cc2609ef79bc",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "6808729f963a4e509ce9bc918cd67a81": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8c906bf36ee4d00b286f58d0ebeb463",
            "placeholder": "​",
            "style": "IPY_MODEL_f98a639d3a1d4a3fb39b070f6aeac1d5",
            "value": "vocab.txt: 100%"
          }
        },
        "75b2646922ab451b96ecaf6e24bd9c2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd8e32adfe6a48bbb3b49a63cc7db9e6",
              "IPY_MODEL_132d2b53c3df416bb8170ae1f36dd64c",
              "IPY_MODEL_0079a78677fb455cbdd664642f43d149"
            ],
            "layout": "IPY_MODEL_5974ddb863a24cdf8263d242011c71c6"
          }
        },
        "79c4f2796ef14b2ab8738c6421d4797f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d37fa3a2c39049deb835e4ab450fe6d3",
            "max": 62,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cabad1cfb1774bde8f42e76e7d6502e5",
            "value": 62
          }
        },
        "82225876103b45079803c3a10f64daa7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83ea2ddc426f41b0a00c7a21c5325992": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2f87ac85d934a519af2ef9730be4772",
            "placeholder": "​",
            "style": "IPY_MODEL_5fe67b7f7fc349b2b9423c0f95be97f2",
            "value": " 230k/230k [00:00&lt;00:00, 655kB/s]"
          }
        },
        "855327eaff774f5887628fce5474d27a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a0782fcba27442194860a56b63ab4f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d30209173d6748ba8afaa62dac632079",
            "placeholder": "​",
            "style": "IPY_MODEL_56c5cb0530e54ffe93e4e1ae552021da",
            "value": " 112/112 [00:00&lt;00:00, 4.48kB/s]"
          }
        },
        "8ff2ea0eb1674004a11b74f3d2c44817": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "95ba3a1fe6384e1aabd44c2e98177a4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97a26a8fe0f64abe9644b7158bc13ad0",
            "placeholder": "​",
            "style": "IPY_MODEL_9988f5cb7f7c41f58af4021da7cd5b3e",
            "value": " 273M/273M [00:25&lt;00:00, 7.21MB/s]"
          }
        },
        "97a26a8fe0f64abe9644b7158bc13ad0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "996403b2698c46cb997cd79aec731b06": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9988f5cb7f7c41f58af4021da7cd5b3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f6ff4717b324571b1f9f94dafeb2595": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afc865ab5ce8484c8a3bc88832b637d3",
            "placeholder": "​",
            "style": "IPY_MODEL_3888bb2d61dd43f5b12aeef07b44546b",
            "value": " 473/473 [00:00&lt;00:00, 6.95kB/s]"
          }
        },
        "ab8b5d02e34e46f7bdc6b6d1e2098040": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ad99c64fe4aa4692ae02d67218bf55c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ff58b5e014b4ad48287b65ab8d02397",
              "IPY_MODEL_3daa9b54e94e4febbe66d82447b9c22f",
              "IPY_MODEL_8a0782fcba27442194860a56b63ab4f6"
            ],
            "layout": "IPY_MODEL_dd3d0e9fd7fd430d837c4c0d0d6945c5"
          }
        },
        "af302a7f599b4821bdae724ed9c3d941": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "afc865ab5ce8484c8a3bc88832b637d3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b12290a8b0b94258a36f8f6ac5d5c4e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1abfc510db94181a9b979125398824a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4e15ccbf0c54cce94ffe77d6e5b4e51": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8c906bf36ee4d00b286f58d0ebeb463": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba5fad8a980e4d628d61b22f4807ab1e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c337f4764ef94235b217be28a6febe97": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1919e3d4ea3e458f97440ba5b72a21ab",
            "placeholder": "​",
            "style": "IPY_MODEL_c8a439753dc845ed81c5649b29647b41",
            "value": "model.safetensors: 100%"
          }
        },
        "c8a439753dc845ed81c5649b29647b41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9438a2c8eed43f29f1e42b0c7fd186a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c337f4764ef94235b217be28a6febe97",
              "IPY_MODEL_4b5ed4dd432f4cb79aabc5356ce25e8e",
              "IPY_MODEL_95ba3a1fe6384e1aabd44c2e98177a4e"
            ],
            "layout": "IPY_MODEL_2a1575d12c194176979318c2eb907fa1"
          }
        },
        "cabad1cfb1774bde8f42e76e7d6502e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cd8e32adfe6a48bbb3b49a63cc7db9e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82225876103b45079803c3a10f64daa7",
            "placeholder": "​",
            "style": "IPY_MODEL_b1abfc510db94181a9b979125398824a",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "ce03369c12c54551bb57647b87fc2a1c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0ed0fbdb5a244fe93fef412a8b92050": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6808729f963a4e509ce9bc918cd67a81",
              "IPY_MODEL_50cd16c5507149f0aca19242197a7663",
              "IPY_MODEL_83ea2ddc426f41b0a00c7a21c5325992"
            ],
            "layout": "IPY_MODEL_ce03369c12c54551bb57647b87fc2a1c"
          }
        },
        "d30209173d6748ba8afaa62dac632079": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d340ce23d06240cf906b8d342599af85": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d37fa3a2c39049deb835e4ab450fe6d3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d99fd2c09b2847e0a0d2fac604d77eb9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd049696ccb14b82a5ceec24dc607cc5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd3d0e9fd7fd430d837c4c0d0d6945c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de50dc3ddbcf4af9ba799c0391ba493d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1680af92a9e8446996f2478effb9a3de",
            "placeholder": "​",
            "style": "IPY_MODEL_b12290a8b0b94258a36f8f6ac5d5c4e4",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "e2f87ac85d934a519af2ef9730be4772": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3407419c6574c5c825bbb9cdbfffa67": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5d651568c394bc2bcd4520612abdcad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f015a9b67755439fb8e54899664ac3c1",
              "IPY_MODEL_12f134ee2a424be3abea6d494e4bfbab",
              "IPY_MODEL_9f6ff4717b324571b1f9f94dafeb2595"
            ],
            "layout": "IPY_MODEL_00cff9e6d2134816bfb2ec87723bab2b"
          }
        },
        "f015a9b67755439fb8e54899664ac3c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d340ce23d06240cf906b8d342599af85",
            "placeholder": "​",
            "style": "IPY_MODEL_1f8caf86d61640208c93cbec5b5dc2f2",
            "value": "config.json: 100%"
          }
        },
        "f6991a814f78430d9258fb7a13d2c129": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f98a639d3a1d4a3fb39b070f6aeac1d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
