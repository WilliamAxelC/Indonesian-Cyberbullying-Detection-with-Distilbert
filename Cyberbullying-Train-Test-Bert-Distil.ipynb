{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Libraries and Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "# %pip install transformers[torch]==4.30.2\n",
        "# %pip install accelerate -U\n",
        "# %pip install optuna\n",
        "# %pip install ipywidgets\n",
        "# %pip install ipywidgets-multiselect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>encoded_label</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>kaka tidur yaa sudah pagi tidak boleh capek2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>makan nasi padang saja badannya</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>suka cukur jembut manggung</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>hai kak isyana ngefans sekali kak isyana suka ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>manusia bidadari sih herann deh cantik</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>&lt;USERNAME&gt; kinantii isyan sekarang berubah ya ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>gemesnya isyan mirip tango berlapis lapis ciaaaa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>jelek saja anaknya ayahnya cakep2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>anaknya mirip sudah tua begitu ya mukanya kart...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>muka anak nya ko tua sekali yaa tidak ngegemes...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   encoded_label                                         clean_text\n",
              "0              1       kaka tidur yaa sudah pagi tidak boleh capek2\n",
              "1              1                    makan nasi padang saja badannya\n",
              "2              0                         suka cukur jembut manggung\n",
              "3              1  hai kak isyana ngefans sekali kak isyana suka ...\n",
              "4              1             manusia bidadari sih herann deh cantik\n",
              "5              0  <USERNAME> kinantii isyan sekarang berubah ya ...\n",
              "6              1   gemesnya isyan mirip tango berlapis lapis ciaaaa\n",
              "7              0                  jelek saja anaknya ayahnya cakep2\n",
              "8              0  anaknya mirip sudah tua begitu ya mukanya kart...\n",
              "9              0  muka anak nya ko tua sekali yaa tidak ngegemes..."
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Dictionary of dataset names and file paths\n",
        "dataset_files = {\n",
        "    \"combined_123\": \"Dataset/Pre-Processed Dataset/combined_123.csv\",\n",
        "    \"combined_1234\": \"Dataset/Pre-Processed Dataset/combined_1234.csv\",\n",
        "    \"dataset_1_Cyberbullying_Bahasa_Indonesia\": \"Dataset/Pre-Processed Dataset/dataset_1_Cyberbullying_Bahasa_Indonesia-Kaggle-CitaTiaraHanni.csv\",\n",
        "    \"dataset_2_cyberbullying_dataset\": \"Dataset/Pre-Processed Dataset/dataset_2_cyberbullying_dataset-Huggingface-aditdwi123.csv\",\n",
        "    \"dataset_3_dataset_komentar_instagram_cyberbullying\": \"Dataset/Pre-Processed Dataset/dataset_3_dataset_komentar_instagram_cyberbullying-github-rizalespe.csv\",\n",
        "    \"dataset_4_dataset_luqyana\": \"Dataset/Pre-Processed Dataset/dataset_4_dataset_luqyana.csv\",\n",
        "    \"combined_123_sastrawi\": \"Dataset/Pre-Processed Dataset/pySastrawi/combined_123_sastrawi.csv\",\n",
        "    \"combined_1234_sastrawi\": \"Dataset/Pre-Processed Dataset/pySastrawi/combined_1234_sastrawi.csv\",\n",
        "    \"combined_123_stopword\": \"Dataset/Pre-Processed Dataset/without-stopword/combined_123_stopword.csv\",\n",
        "    \"combined_1234_stopword\": \"Dataset/Pre-Processed Dataset/without-stopword/combined_1234_stopword.csv\",\n",
        "}\n",
        "\n",
        "# Load datasets into a dictionary\n",
        "datasets = {\n",
        "    name: pd.read_csv(path)[[\"encoded_label\", \"clean_text\"]]\n",
        "    for name, path in dataset_files.items()\n",
        "}\n",
        "\n",
        "# Example: show first 10 rows of combined_dataset\n",
        "datasets[\"combined_1234\"].head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                           Dataset  Samples  Positive (%)  Avg Text Length  Median Text Length\n",
            "                                      combined_123     2066     45.014521        73.882381                53.0\n",
            "                                     combined_1234     3435     46.724891        77.289374                56.0\n",
            "          dataset_1_Cyberbullying_Bahasa_Indonesia      650     50.000000        49.004615                43.0\n",
            "                   dataset_2_cyberbullying_dataset     1019     39.744848        72.024534                50.0\n",
            "dataset_3_dataset_komentar_instagram_cyberbullying      397     50.377834       119.382872                96.0\n",
            "                         dataset_4_dataset_luqyana     1369     49.306063        82.430972                61.0\n",
            "                             combined_123_sastrawi     2066     45.014521        56.330106                41.0\n",
            "                            combined_1234_sastrawi     3435     46.724891        58.606405                43.0\n",
            "                             combined_123_stopword     2066     45.014521        60.723136                44.0\n",
            "                            combined_1234_stopword     3435     46.724891        63.008151                46.0\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Sample examples from dataset_4_dataset_luqyana:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>encoded_label</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>427</th>\n",
              "      <td>0</td>\n",
              "      <td>tidak button dislike kalau opsi jari saya kasi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1087</th>\n",
              "      <td>0</td>\n",
              "      <td>username bilang itu kuin kamu gesek grepe ama ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>668</th>\n",
              "      <td>0</td>\n",
              "      <td>anak keras kepala mimi nya ulta tidak datang s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>572</th>\n",
              "      <td>1</td>\n",
              "      <td>&lt;USERNAME&gt; semangat ya tidak usah peduliin omo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>1</td>\n",
              "      <td>&lt;USERNAME&gt; pansos</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      encoded_label                                         clean_text\n",
              "427               0  tidak button dislike kalau opsi jari saya kasi...\n",
              "1087              0  username bilang itu kuin kamu gesek grepe ama ...\n",
              "668               0  anak keras kepala mimi nya ulta tidak datang s...\n",
              "572               1  <USERNAME> semangat ya tidak usah peduliin omo...\n",
              "115               1                                  <USERNAME> pansos"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Top words in combined_123:\n",
            "Top words (label 0): [('kamu', 396), ('tidak', 395), ('yang', 269), ('anjing', 264), ('orang', 230), ('saja', 212), ('nya', 188), ('sudah', 172), ('ya', 155), ('username', 143)]\n",
            "Top words (label 1): [('yang', 256), ('tidak', 235), ('cantik', 136), ('ya', 121), ('semoga', 111), ('sekali', 107), ('kalau', 103), ('nya', 99), ('saja', 95), ('sudah', 91)]\n",
            "\n",
            " Top words in combined_1234:\n",
            "Top words (label 0): [('tidak', 667), ('kamu', 581), ('yang', 466), ('orang', 378), ('saja', 353), ('nya', 327), ('username', 298), ('sudah', 277), ('anjing', 274), ('ya', 267)]\n",
            "Top words (label 1): [('yang', 534), ('tidak', 462), ('username', 235), ('ya', 232), ('cantik', 229), ('nya', 215), ('kalau', 203), ('saja', 187), ('sudah', 186), ('semoga', 178)]\n",
            "\n",
            " Top words in dataset_1_Cyberbullying_Bahasa_Indonesia:\n",
            "Top words (label 0): [('kamu', 109), ('tidak', 79), ('anjing', 53), ('saja', 48), ('muka', 47), ('sudah', 43), ('nya', 34), ('ya', 33), ('kek', 28), ('orang', 27)]\n",
            "Top words (label 1): [('tidak', 76), ('cantik', 57), ('ya', 46), ('yang', 44), ('sudah', 37), ('saja', 37), ('nya', 35), ('kak', 34), ('sekali', 34), ('orang', 29)]\n",
            "\n",
            " Top words in dataset_2_cyberbullying_dataset:\n",
            "Top words (label 0): [('kamu', 230), ('anjing', 204), ('tidak', 195), ('yang', 141), ('orang', 117), ('saja', 100), ('bangsat', 96), ('saya', 85), ('nya', 82), ('sudah', 78)]\n",
            "Top words (label 1): [('yang', 112), ('tidak', 82), ('anjing', 69), ('kamu', 48), ('anak', 46), ('semoga', 46), ('monyet', 44), ('sekali', 42), ('saya', 40), ('ya', 40)]\n",
            "\n",
            " Top words in dataset_3_dataset_komentar_instagram_cyberbullying:\n",
            "Top words (label 0): [('tidak', 121), ('yang', 114), ('orang', 86), ('nya', 72), ('username', 65), ('saja', 64), ('kamu', 57), ('ya', 52), ('sudah', 51), ('si', 37)]\n",
            "Top words (label 1): [('yang', 100), ('tidak', 77), ('semoga', 46), ('kalau', 39), ('cantik', 39), ('ya', 35), ('sekali', 31), ('nya', 31), ('sangat', 30), ('anak', 29)]\n",
            "\n",
            " Top words in dataset_4_dataset_luqyana:\n",
            "Top words (label 0): [('tidak', 272), ('yang', 197), ('kamu', 185), ('username', 155), ('orang', 148), ('saja', 141), ('nya', 139), ('ya', 112), ('sudah', 105), ('kalau', 91)]\n",
            "Top words (label 1): [('yang', 278), ('tidak', 227), ('username', 160), ('nya', 116), ('ya', 111), ('kalau', 100), ('sudah', 95), ('cantik', 93), ('saja', 92), ('orang', 88)]\n",
            "\n",
            " Top words in combined_123_sastrawi:\n",
            "Top words (label 0): [('anjing', 275), ('orang', 229), ('nya', 188), ('ya', 155), ('username', 143), ('si', 106), ('anak', 104), ('bangsat', 101), ('muka', 99), ('kaya', 79)]\n",
            "Top words (label 1): [('cantik', 148), ('ya', 121), ('moga', 111), ('anak', 102), ('nya', 101), ('orang', 76), ('username', 75), ('suka', 71), ('anjing', 70), ('keluarga', 59)]\n",
            "\n",
            " Top words in combined_1234_sastrawi:\n",
            "Top words (label 0): [('orang', 376), ('nya', 328), ('username', 298), ('anjing', 285), ('ya', 267), ('anak', 176), ('si', 164), ('muka', 156), ('kaya', 128), ('sih', 108)]\n",
            "Top words (label 1): [('cantik', 249), ('username', 235), ('ya', 232), ('nya', 218), ('moga', 178), ('anak', 165), ('orang', 164), ('suka', 116), ('keluarga', 98), ('allah', 96)]\n",
            "\n",
            " Top words in combined_123_stopword:\n",
            "Top words (label 0): [('anjing', 264), ('orang', 230), ('nya', 188), ('ya', 155), ('username', 143), ('si', 106), ('bangsat', 101), ('anak', 77), ('kaya', 75), ('monyet', 75)]\n",
            "Top words (label 1): [('cantik', 136), ('ya', 121), ('semoga', 111), ('nya', 99), ('anak', 82), ('username', 75), ('orang', 72), ('anjing', 69), ('suka', 65), ('allah', 52)]\n",
            "\n",
            " Top words in combined_1234_stopword:\n",
            "Top words (label 0): [('orang', 378), ('nya', 327), ('username', 298), ('anjing', 274), ('ya', 267), ('si', 164), ('anak', 129), ('kaya', 122), ('sih', 106), ('bangsat', 105)]\n",
            "Top words (label 1): [('username', 235), ('ya', 232), ('cantik', 229), ('nya', 215), ('semoga', 178), ('orang', 160), ('anak', 133), ('suka', 110), ('allah', 96), ('kak', 89)]\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Basic info summary\n",
        "summary = []\n",
        "for name, df in datasets.items():\n",
        "    summary.append({\n",
        "        \"Dataset\": name,\n",
        "        \"Samples\": len(df),\n",
        "        \"Positive (%)\": 100 * df[\"encoded_label\"].mean(),\n",
        "        \"Avg Text Length\": np.mean(df[\"clean_text\"].astype(str).apply(len)),\n",
        "        \"Median Text Length\": np.median(df[\"clean_text\"].astype(str).apply(len))\n",
        "    })\n",
        "summary_df = pd.DataFrame(summary)\n",
        "print(summary_df.to_string(index=False))\n",
        "\n",
        "# Basic info summary\n",
        "summary = []\n",
        "for name, df in datasets.items():\n",
        "    summary.append({\n",
        "        \"Dataset\": name,\n",
        "        \"Samples\": len(df),\n",
        "        \"Positive (%)\": 100 * df[\"encoded_label\"].mean(),\n",
        "        \"Avg Text Length\": np.mean(df[\"clean_text\"].astype(str).apply(len)),\n",
        "        \"Median Text Length\": np.median(df[\"clean_text\"].astype(str).apply(len))\n",
        "    })\n",
        "\n",
        "class_counts = []\n",
        "for name, df in datasets.items():\n",
        "    counts = df[\"encoded_label\"].value_counts().to_dict()\n",
        "    class_counts.append({\n",
        "        \"Dataset\": name,\n",
        "        \"Non-Bullying (0)\": counts.get(0, 0),\n",
        "        \"Bullying (1)\": counts.get(1, 0)\n",
        "    })\n",
        "\n",
        "class_counts_df = pd.DataFrame(class_counts)\n",
        "class_counts_melted = class_counts_df.melt(id_vars=\"Dataset\", var_name=\"Label\", value_name=\"Count\")\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "sns.barplot(data=class_counts_melted, x=\"Dataset\", y=\"Count\", hue=\"Label\")\n",
        "plt.title(\"Class Distribution per Dataset\")\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.ylabel(\"Number of Samples\")\n",
        "plt.xlabel(\"Dataset\")\n",
        "plt.legend(title=\"Label\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# --- 2 Text length distribution ---\n",
        "plt.figure(figsize=(8, 5))\n",
        "for name, df in datasets.items():\n",
        "    lengths = df[\"clean_text\"].astype(str).apply(len)\n",
        "    sns.kdeplot(lengths, label=name, fill=True, alpha=0.3)\n",
        "plt.title(\"Text Length Distribution Across Datasets\")\n",
        "plt.xlabel(\"Text Length (characters)\")\n",
        "plt.ylabel(\"Density\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# --- 3 Example texts ---\n",
        "print(\"\\n Sample examples from dataset_4_dataset_luqyana:\")\n",
        "display(datasets[\"dataset_4_dataset_luqyana\"].sample(5, random_state=42))\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.barplot(data=datasets[\"dataset_4_dataset_luqyana\"],\n",
        "            x=\"encoded_label\", \n",
        "            y=datasets[\"dataset_4_dataset_luqyana\"][\"clean_text\"].astype(str).apply(len))\n",
        "plt.title(\"Text Length by Label  Dataset 4 (Luqyana)\")\n",
        "plt.xlabel(\"Label (0=Non-Bullying, 1=Bullying)\")\n",
        "plt.ylabel(\"Average Text Length (characters)\")\n",
        "plt.show()\n",
        "\n",
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "def get_common_words(df, label, top_n=10):\n",
        "    texts = \" \".join(df[df[\"encoded_label\"] == label][\"clean_text\"].astype(str).tolist())\n",
        "    words = re.findall(r'\\w+', texts.lower())\n",
        "    return Counter(words).most_common(top_n)\n",
        "\n",
        "for dataset in datasets.keys():\n",
        "    print(f\"\\n Top words in {dataset}:\")\n",
        "    print(\"Top words (label 0):\", get_common_words(datasets[dataset], 0))\n",
        "    print(\"Top words (label 1):\", get_common_words(datasets[dataset], 1))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Options"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ipywidgets as widgets\n",
        "from ipywidgets import SelectMultiple\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c90cb86b82e44478bcce8629380f6f78",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Dropdown(description='Model:', index=1, options=(('Distilbert', 0), ('Indobert', 1), ('MeanDistilbert', 2), ('"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "144e554d6a79484ab9d85de7bc7a36f9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "BoundedIntText(value=30, description='optuna_trials:')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b95f2ff3941141bea4c66fa15839153f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "SelectMultiple(description='Datasets:', options=('combined_123', 'combined_1234', 'dataset_1_Cyberbullying_Bah"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a38627071ee04e228917b7ec2fab144b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Checkbox(value=False, description='Use Stratify')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0a798b9b6796411294f840fb64f79adf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Checkbox(value=False, description='Freeze Encoder Layers')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "00633f63b307443bbad5fae81cf0746d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Checkbox(value=False, description='Tune Dropout')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6b974bb49e064065b04a2b1e49fa4120",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Checkbox(value=False, description='Warmup Steps')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "abcd4ddc6b5f466ebe81bc9e4f524f46",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Checkbox(value=True, description='Tune LR scheduler type', style=DescriptionStyle(description_width='initial')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "bert_model_path = 'indolem/indobert-base-uncased'\n",
        "distilbert_model_path = 'cahya/distilbert-base-indonesian'\n",
        "\n",
        "import torch\n",
        "from transformers import BertModel, DistilBertModel\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "from torch import nn\n",
        "\n",
        "class BertMeanPoolingForSequenceClassification(nn.Module):\n",
        "    def __init__(self, model_name, num_labels=2):\n",
        "        super().__init__()\n",
        "        self.bert = BertModel.from_pretrained(model_name)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, labels=None):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=False)\n",
        "        last_hidden_state = outputs.last_hidden_state  # [batch, seq, hidden]\n",
        "        \n",
        "        # mask padding tokens before mean pooling\n",
        "        mask = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
        "        summed = torch.sum(last_hidden_state * mask, dim=1)\n",
        "        summed_mask = torch.clamp(mask.sum(dim=1), min=1e-9)\n",
        "        mean_pooled = summed / summed_mask\n",
        "        \n",
        "        logits = self.classifier(self.dropout(mean_pooled))\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fn = nn.CrossEntropyLoss()\n",
        "            loss = loss_fn(logits.view(-1, self.classifier.out_features), labels.view(-1))\n",
        "\n",
        "        return SequenceClassifierOutput(loss=loss, logits=logits)\n",
        "    \n",
        "class DistilBertMeanPoolingForSequenceClassification(nn.Module):\n",
        "    def __init__(self, model_name, num_labels=2):\n",
        "        super().__init__()\n",
        "        self.bert = DistilBertModel.from_pretrained(model_name)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, labels=None):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=False)\n",
        "        last_hidden_state = outputs.last_hidden_state\n",
        "        \n",
        "        mask = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
        "        summed = torch.sum(last_hidden_state * mask, dim=1)\n",
        "        summed_mask = torch.clamp(mask.sum(dim=1), min=1e-9)\n",
        "        mean_pooled = summed / summed_mask\n",
        "        \n",
        "        logits = self.classifier(self.dropout(mean_pooled))\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fn = nn.CrossEntropyLoss()\n",
        "            loss = loss_fn(logits.view(-1, self.classifier.out_features), labels.view(-1))\n",
        "\n",
        "        return SequenceClassifierOutput(loss=loss, logits=logits)\n",
        "\n",
        "\n",
        "\n",
        "# 0 = distilbert, 1 = bert\n",
        "model_choice_int = widgets.Dropdown(\n",
        "    options=[('Distilbert', 0), ('Indobert', 1), ('MeanDistilbert', 2), ('MeanIndobert', 3)],\n",
        "    value=1,\n",
        "    description='Model:',\n",
        "    disabled=False,\n",
        ")\n",
        "\n",
        "optuna_trials = widgets.BoundedIntText(\n",
        "    value=30,\n",
        "    min=0,\n",
        "    # max=50,\n",
        "    step=1,\n",
        "    description='optuna_trials:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "dataset_selector = widgets.SelectMultiple(\n",
        "    options=list(datasets.keys()),  # all dataset names\n",
        "    description='Datasets:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "use_pruning_checkbox = widgets.Checkbox(\n",
        "    value=True,  # default ON\n",
        "    description='Use Pruning',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "use_early_stopping_checkbox = widgets.Checkbox(\n",
        "    value=True,  # default ON\n",
        "    description='Use Early Stopping',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "use_stratify = widgets.Checkbox(\n",
        "    value=False,  # default ON\n",
        "    description='Use Stratify',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "use_freeze_encoder = widgets.Checkbox(\n",
        "    value=False,  # default OFF\n",
        "    description='Freeze Encoder Layers',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "use_dropout_tuning = widgets.Checkbox(\n",
        "    value=False,\n",
        "    description=\"Tune Dropout\",\n",
        "    icon=\"sliders-h\"\n",
        ")\n",
        "\n",
        "use_warmup_steps = widgets.Checkbox(\n",
        "    value=False,\n",
        "    description=\"Warmup Steps\",\n",
        "    icon=\"sliders-h\"\n",
        ")\n",
        "\n",
        "use_scheduler_tuning = widgets.Checkbox(\n",
        "    value=True,\n",
        "    description=\"Tune LR scheduler type\",\n",
        "    style={'description_width': 'initial'}\n",
        "    \n",
        ")\n",
        "\n",
        "display(\n",
        "    model_choice_int,\n",
        "    optuna_trials,\n",
        "    dataset_selector,\n",
        "    # use_pruning_checkbox,\n",
        "    # use_early_stopping_checkbox,\n",
        "    use_stratify,\n",
        "    use_freeze_encoder,\n",
        "    use_dropout_tuning,\n",
        "    use_warmup_steps,\n",
        "    use_scheduler_tuning\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffekHJZfwdmg"
      },
      "source": [
        "## Train-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353,
          "referenced_widgets": [
            "2c81cbcb517e438ea3c8d590052214f5",
            "de50dc3ddbcf4af9ba799c0391ba493d",
            "79c4f2796ef14b2ab8738c6421d4797f",
            "52f986d016a640008a94cba62c268bfe",
            "d99fd2c09b2847e0a0d2fac604d77eb9",
            "1680af92a9e8446996f2478effb9a3de",
            "b12290a8b0b94258a36f8f6ac5d5c4e4",
            "d37fa3a2c39049deb835e4ab450fe6d3",
            "cabad1cfb1774bde8f42e76e7d6502e5",
            "996403b2698c46cb997cd79aec731b06",
            "117dd252c2184eeab00ff4235c3bcbd3",
            "e5d651568c394bc2bcd4520612abdcad",
            "f015a9b67755439fb8e54899664ac3c1",
            "12f134ee2a424be3abea6d494e4bfbab",
            "9f6ff4717b324571b1f9f94dafeb2595",
            "00cff9e6d2134816bfb2ec87723bab2b",
            "d340ce23d06240cf906b8d342599af85",
            "1f8caf86d61640208c93cbec5b5dc2f2",
            "5f617d90baa54ce88cca00cc9e5e8b35",
            "af302a7f599b4821bdae724ed9c3d941",
            "afc865ab5ce8484c8a3bc88832b637d3",
            "3888bb2d61dd43f5b12aeef07b44546b",
            "d0ed0fbdb5a244fe93fef412a8b92050",
            "6808729f963a4e509ce9bc918cd67a81",
            "50cd16c5507149f0aca19242197a7663",
            "83ea2ddc426f41b0a00c7a21c5325992",
            "ce03369c12c54551bb57647b87fc2a1c",
            "b8c906bf36ee4d00b286f58d0ebeb463",
            "f98a639d3a1d4a3fb39b070f6aeac1d5",
            "dd049696ccb14b82a5ceec24dc607cc5",
            "5449b174bc2a4a1f948a3309abdb7e7e",
            "e2f87ac85d934a519af2ef9730be4772",
            "5fe67b7f7fc349b2b9423c0f95be97f2",
            "ad99c64fe4aa4692ae02d67218bf55c2",
            "5ff58b5e014b4ad48287b65ab8d02397",
            "3daa9b54e94e4febbe66d82447b9c22f",
            "8a0782fcba27442194860a56b63ab4f6",
            "dd3d0e9fd7fd430d837c4c0d0d6945c5",
            "ba5fad8a980e4d628d61b22f4807ab1e",
            "147e68434b744af29a94cc2609ef79bc",
            "855327eaff774f5887628fce5474d27a",
            "2bb57b1175f84b8cbb00733e1b94689a",
            "d30209173d6748ba8afaa62dac632079",
            "56c5cb0530e54ffe93e4e1ae552021da"
          ]
        },
        "id": "Dc2hcJcwAytc",
        "outputId": "e99dc2e0-029f-485b-fa18-8a55df73ba93"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# Custom dataset\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(int(self.labels[idx]))\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# Load tokenizer\n",
        "if model_choice_int.value == 0:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(distilbert_model_path)\n",
        "    \n",
        "else:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(bert_model_path)\n",
        "    \n",
        "from collections import Counter\n",
        "from transformers import DataCollatorWithPadding\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def encode_selected_datasets(selected_datasets=None, val_size=0.1, test_size=0.2):\n",
        "    \"\"\"\n",
        "    Returns: (train_val_test_dataset_dict, combo_name)\n",
        "    train_val_test_dataset_dict = {\"train\": train_dataset, \"val\": val_dataset, \"test\": test_dataset, \"collator\": data_collator}\n",
        "    \"\"\"\n",
        "    # --- Normalize selection ---\n",
        "    val = selected_datasets if selected_datasets is not None else dataset_selector.value\n",
        "    if isinstance(val, str):\n",
        "        selected = [val]\n",
        "    elif val is None:\n",
        "        selected = []\n",
        "    else:\n",
        "        selected = list(val)\n",
        "\n",
        "    if len(selected) == 0:\n",
        "        raise ValueError(\"No datasets selected. Please select at least one dataset.\")\n",
        "\n",
        "    missing = [s for s in selected if s not in datasets]\n",
        "    if missing:\n",
        "        raise KeyError(f\"Selected dataset(s) not found in `datasets`: {missing}\")\n",
        "\n",
        "    combo_name = selected[0] if len(selected) == 1 else \"+\".join(selected)\n",
        "\n",
        "    # --- Merge dataframes ---\n",
        "    if len(selected) == 1:\n",
        "        df = datasets[selected[0]].copy()\n",
        "    else:\n",
        "        df = pd.concat([datasets[name].copy() for name in selected], ignore_index=True)\n",
        "\n",
        "    if 'clean_text' not in df.columns or 'encoded_label' not in df.columns:\n",
        "        raise ValueError(f\"Dataset {combo_name} missing required columns 'clean_text' and/or 'encoded_label'.\")\n",
        "\n",
        "    X = df['clean_text'].tolist()\n",
        "    y = df['encoded_label'].tolist()\n",
        "\n",
        "    label_counts = Counter(y)\n",
        "\n",
        "    if use_stratify.value:\n",
        "        can_stratify = (len(label_counts) >= 2) and (min(label_counts.values()) >= 2)\n",
        "    else:\n",
        "        can_stratify = False\n",
        "\n",
        "    print(\"Stratify: \", can_stratify)\n",
        "\n",
        "    # --- First split train+val vs test ---\n",
        "    stratify = y if can_stratify else None\n",
        "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "        X, y, test_size=test_size, random_state=42, stratify=stratify\n",
        "    )\n",
        "\n",
        "    # --- Split temp into train and val ---\n",
        "    stratify_temp = y_temp if can_stratify else None\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X_temp, y_temp, test_size=val_size/(1-test_size), random_state=42, stratify=stratify_temp\n",
        "    )\n",
        "\n",
        "    print(f\"Selected: {selected}\")\n",
        "    print(f\"Combo name: {combo_name}\")\n",
        "    print(\"Label distribution (combined):\", dict(label_counts))\n",
        "    print(\"Train/val/test sizes:\", len(X_train), len(X_val), len(X_test))\n",
        "\n",
        "    # --- Tokenize ---\n",
        "    def tokenize_texts(texts):\n",
        "        # Ensure all inputs are strings, replace NaN/None, strip whitespace\n",
        "        clean_texts = [str(t) if not isinstance(t, float) and t is not None else \"\" for t in texts]\n",
        "        clean_texts = [t.strip() for t in clean_texts]\n",
        "\n",
        "        return tokenizer(\n",
        "            clean_texts,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=256,\n",
        "            return_attention_mask=True,\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "    train_dataset = CustomDataset(tokenize_texts(X_train), y_train)\n",
        "    val_dataset   = CustomDataset(tokenize_texts(X_val),   y_val)\n",
        "    test_dataset  = CustomDataset(tokenize_texts(X_test),  y_test)\n",
        "\n",
        "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "    return {\n",
        "        \"train\": train_dataset,\n",
        "        \"val\": val_dataset,\n",
        "        \"test\": test_dataset,\n",
        "        \"collator\": data_collator,\n",
        "    }, combo_name\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axFv5HXWw_Kq"
      },
      "source": [
        "## Train and Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments, BertForSequenceClassification\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_dir = f'./results/{dataset_selector.value}_{\"distilbert\" if model_choice_int.value == 0 else \"bert\"}'\n",
        "log_dir = f'./logs/{dataset_selector.value}_{\"distilbert\" if model_choice_int.value == 0 else \"bert\"}'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "default_training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    run_name=f'training_{dataset_selector.value}_{\"distilbert\" if model_choice_int.value == 0 else \"bert\"}',\n",
        "    \n",
        "    # Training setup\n",
        "    num_train_epochs=3,               # conservative, prevents overfitting on small datasets\n",
        "    per_device_train_batch_size=16,   # reasonable for most GPUs\n",
        "    per_device_eval_batch_size=32,    # eval can use larger batch\n",
        "    learning_rate=5e-5,               # good default for BERT/DistilBERT\n",
        "    \n",
        "    # Optimizer & regularization\n",
        "    weight_decay=0.01,\n",
        "    warmup_ratio=0.06,                # scale warmup to dataset size instead of fixed steps\n",
        "    lr_scheduler_type=\"linear\",\n",
        "    optim=\"adamw_torch\",\n",
        "    \n",
        "    # Logging\n",
        "    logging_dir=log_dir,\n",
        "    logging_steps=20,\n",
        "    evaluation_strategy=\"epoch\",      # eval once per epoch\n",
        "    do_eval=True,\n",
        "    \n",
        "    # No saving (you said youll only keep best params)\n",
        "    save_strategy=\"no\",\n",
        "    \n",
        "    # Misc\n",
        "    report_to=[],                     # no wandb/tensorboard unless needed\n",
        "    fp16=True                         # faster if GPU supports it\n",
        ")\n",
        "\n",
        "best_training_args_distil = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    run_name=f'training_{dataset_selector.value}_{\"distilbert\" if model_choice_int.value == 0 else \"bert\"}',\n",
        "    per_device_eval_batch_size=16,  # can stay as-is for evaluation\n",
        "    num_train_epochs=6,            #  from Optuna\n",
        "    per_device_train_batch_size=16,  #  from Optuna\n",
        "    warmup_steps=29,               #  from Optuna\n",
        "    weight_decay=0.09793901282245424,  #  from Optuna\n",
        "    learning_rate=3.694163912198525e-05,  #  from Optuna\n",
        "    logging_dir=log_dir,\n",
        "    logging_steps=10,\n",
        "    do_eval=True,\n",
        "    eval_steps=500,\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=1,\n",
        "    report_to=[],\n",
        "    fp16=True,\n",
        "    optim=\"adamw_torch\"\n",
        ")\n",
        "\n",
        "best_training_args_bert = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    run_name=f'training_{dataset_selector.value}_{\"distilbert\" if model_choice_int.value == 0 else \"bert\"}',\n",
        "    per_device_eval_batch_size=16,\n",
        "    per_device_train_batch_size=16,  # From Optuna\n",
        "    num_train_epochs=7,             # From Optuna\n",
        "    warmup_steps=164,               # From Optuna\n",
        "    weight_decay=0.028,  # From Optuna\n",
        "    learning_rate=7.83e-05,  # From Optuna\n",
        "    logging_dir=log_dir,\n",
        "    logging_steps=10,\n",
        "    do_eval=True,\n",
        "    eval_steps=500,\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=1,\n",
        "    report_to=[],\n",
        "    fp16=True,\n",
        "    optim=\"adamw_torch\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Default\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ[\"WANDB_MODE\"] = \"disabled\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 576,
          "referenced_widgets": [
            "75b2646922ab451b96ecaf6e24bd9c2b",
            "cd8e32adfe6a48bbb3b49a63cc7db9e6",
            "132d2b53c3df416bb8170ae1f36dd64c",
            "0079a78677fb455cbdd664642f43d149",
            "5974ddb863a24cdf8263d242011c71c6",
            "82225876103b45079803c3a10f64daa7",
            "b1abfc510db94181a9b979125398824a",
            "b4e15ccbf0c54cce94ffe77d6e5b4e51",
            "ab8b5d02e34e46f7bdc6b6d1e2098040",
            "e3407419c6574c5c825bbb9cdbfffa67",
            "4967c6af3ed64a3f83c7899a03863448",
            "c9438a2c8eed43f29f1e42b0c7fd186a",
            "c337f4764ef94235b217be28a6febe97",
            "4b5ed4dd432f4cb79aabc5356ce25e8e",
            "95ba3a1fe6384e1aabd44c2e98177a4e",
            "2a1575d12c194176979318c2eb907fa1",
            "1919e3d4ea3e458f97440ba5b72a21ab",
            "c8a439753dc845ed81c5649b29647b41",
            "f6991a814f78430d9258fb7a13d2c129",
            "8ff2ea0eb1674004a11b74f3d2c44817",
            "97a26a8fe0f64abe9644b7158bc13ad0",
            "9988f5cb7f7c41f58af4021da7cd5b3e"
          ]
        },
        "id": "IWDv5dKYA70f",
        "outputId": "545a2ed0-fd0d-4eb5-aadb-a40f99572183"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, test_dataset, batch_size, output_dir, dataset_name):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
        "            # Move inputs to device\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "\n",
        "            # Move to CPU and accumulate\n",
        "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "            all_preds.extend(preds)\n",
        "            all_labels.extend(labels.cpu().numpy().astype(int))\n",
        "\n",
        "    # Metrics\n",
        "    report = classification_report(all_labels, all_preds, digits=4)\n",
        "    print(\"classification_report:\\n\", report)\n",
        "    with open(os.path.join(output_dir, \"classification_report.txt\"), \"w\") as f:\n",
        "        f.write(report)\n",
        "\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    plt.figure(figsize=(5, 4))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f'Confusion Matrix: {dataset_name}')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_dir, \"confusion_matrix.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"Evaluation complete for {dataset_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from transformers import AutoConfig, Trainer, BertForSequenceClassification, DistilBertForSequenceClassification\n",
        "\n",
        "def default_start_model_training_and_evaluation(model_choice=model_choice_int.value):\n",
        "    dataset, name = encode_selected_datasets()\n",
        "    print(f\"\\nTraining on dataset: {name}\")\n",
        "    print(f\"Model: {model_choice_int.value}\")\n",
        "\n",
        "    #  Always set config explicitly with num_labels=2\n",
        "    if model_choice == 0:\n",
        "        config = AutoConfig.from_pretrained(distilbert_model_path, num_labels=2)\n",
        "        model = DistilBertForSequenceClassification.from_pretrained(distilbert_model_path, config=config)\n",
        "        training_args = best_training_args_distil\n",
        "\n",
        "    elif model_choice == 1:\n",
        "        config = AutoConfig.from_pretrained(bert_model_path, num_labels=2)\n",
        "        model = BertForSequenceClassification.from_pretrained(bert_model_path, config=config)\n",
        "        training_args = best_training_args_bert\n",
        "\n",
        "    elif model_choice == 2:\n",
        "        config = AutoConfig.from_pretrained(distilbert_model_path, num_labels=2)\n",
        "        model = DistilBertMeanPoolingForSequenceClassification(distilbert_model_path, config=config)\n",
        "        training_args = default_training_args\n",
        "        \n",
        "    elif model_choice == 3:\n",
        "        config = AutoConfig.from_pretrained(bert_model_path, num_labels=2)\n",
        "        model = BertMeanPoolingForSequenceClassification(bert_model_path, config=config)\n",
        "        training_args = default_training_args\n",
        "\n",
        "    else:\n",
        "        config = AutoConfig.from_pretrained(distilbert_model_path, num_labels=2)\n",
        "        model = DistilBertForSequenceClassification.from_pretrained(distilbert_model_path, config=config)\n",
        "        training_args = default_training_args\n",
        "\n",
        "    print(training_args)\n",
        "\n",
        "    # Trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=dataset[\"train\"],\n",
        "        eval_dataset=dataset[\"val\"],\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "\n",
        "    # Save model (you said you only save best, but leaving here for completeness)\n",
        "    trainer.save_model(output_dir)\n",
        "\n",
        "\n",
        "    # Evaluate and log\n",
        "    evaluate_model(model, dataset[\"test\"], 4, output_dir, name)\n",
        "\n",
        "    #  Inference time benchmarking\n",
        "    print(\"\\n Running inference speed benchmark...\")\n",
        "    model.eval()\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    #  Use only a small subset of the test set for benchmarking\n",
        "    benchmark_size = min(32, len(dataset[\"test\"]))  # up to 32 samples\n",
        "    subset_encodings = {\n",
        "        \"input_ids\": torch.tensor(dataset[\"test\"].encodings[\"input_ids\"][:benchmark_size]).to(device),\n",
        "        \"attention_mask\": torch.tensor(dataset[\"test\"].encodings[\"attention_mask\"][:benchmark_size]).to(device),\n",
        "    }\n",
        "\n",
        "    # Warm-up (GPU usually needs 1-2 warm passes for fair timing)\n",
        "    with torch.no_grad():\n",
        "        for _ in range(3):\n",
        "            _ = model(**subset_encodings)\n",
        "\n",
        "    # Benchmark\n",
        "    n_runs = 50\n",
        "    torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
        "    start = time.time()\n",
        "    with torch.no_grad():\n",
        "        for _ in range(n_runs):\n",
        "            _ = model(**subset_encodings)\n",
        "    torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
        "    end = time.time()\n",
        "\n",
        "    avg_time = (end - start) / n_runs\n",
        "    samples_per_second = benchmark_size / avg_time\n",
        "\n",
        "    print(f\" Avg batch inference time: {avg_time:.4f} sec\")\n",
        "    print(f\" Throughput: {samples_per_second:.2f} samples/sec\")\n",
        "\n",
        "\n",
        "# default_start_model_training_and_evaluation(model_choice_int.value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from transformers import Trainer, DistilBertForSequenceClassification, BertForSequenceClassification\n",
        "import gc\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "from optuna import create_study\n",
        "import tempfile\n",
        "from sklearn.metrics import f1_score\n",
        "import tempfile\n",
        "trial_dir = tempfile.mkdtemp(prefix=\"optuna_trial_\")\n",
        "\n",
        "output_dir_optuna = output_dir + '_optuna'\n",
        "\n",
        "def optuna_hp_space(trial):\n",
        "    space = {\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 5e-6, 1e-4, log=True),\n",
        "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [8, 16, 32]),\n",
        "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.0, 0.3),\n",
        "        \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 4, 10),\n",
        "        \"warmup_steps\": trial.suggest_int(\"warmup_steps\", 0, 300),\n",
        "        \"freeze_layers\": trial.suggest_categorical(\"freeze_layers\", [0, 3, 6, 9]),\n",
        "        \"dropout\": trial.suggest_float(\"dropout\", 0.1, 0.5),\n",
        "    }\n",
        "\n",
        "    if use_warmup_steps.value:\n",
        "        space[\"warmup_steps\"] = trial.suggest_int(\"warmup_steps\", 0, 300)\n",
        "    else:\n",
        "        space[\"warmup_steps\"] = 0  #  fixed to 0 if disabled\n",
        "\n",
        "    if use_dropout_tuning.value:  #  only add if toggle is ON\n",
        "        space[\"dropout\"] = trial.suggest_float(\"dropout\", 0.1, 0.5)\n",
        "    else:\n",
        "        space[\"dropout\"] = 0.1  # default dropout\n",
        "\n",
        "    #  Optional scheduler tuning\n",
        "    if use_scheduler_tuning.value:\n",
        "        space[\"lr_scheduler_type\"] = trial.suggest_categorical(\"lr_scheduler_type\", [\n",
        "            \"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\", \"constant_with_warmup\"\n",
        "        ])\n",
        "    else:\n",
        "        space[\"lr_scheduler_type\"] = \"linear\"\n",
        "\n",
        "    return space\n",
        "\n",
        "def manual_evaluate(model, dataset, batch_size=8, tokenizer=None):\n",
        "    model.eval()\n",
        "    model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "\n",
        "    collator = None\n",
        "    if tokenizer is not None:\n",
        "        from transformers import DataCollatorWithPadding\n",
        "        collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, collate_fn=collator)\n",
        "\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
        "            inputs = {k: v.to(device) for k, v in batch.items() if k in [\"input_ids\", \"attention_mask\"]}\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            outputs = model(**inputs)\n",
        "            preds = torch.argmax(outputs.logits, dim=-1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    print(\"Unique preds:\", np.unique(all_preds))\n",
        "    print(\"Unique labels:\", np.unique(all_labels))\n",
        "\n",
        "    f1 = f1_score(all_labels, all_preds)\n",
        "    return f1\n",
        "\n",
        "    \n",
        "\n",
        "# Subclass Trainer to inject memory cleanup\n",
        "class CleanTrainer(Trainer):\n",
        "    def train(self, *args, **kwargs):\n",
        "        result = super().train(*args, **kwargs)\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "        return result\n",
        "\n",
        "from transformers import AutoConfig\n",
        "\n",
        "def get_model_and_args(choice, dropout=None):\n",
        "    def apply_dropout(config):\n",
        "        if dropout is not None:\n",
        "            config.hidden_dropout_prob = dropout\n",
        "            config.attention_probs_dropout_prob = dropout\n",
        "        return config\n",
        "\n",
        "    if choice == 0:  # DistilBERT CLS baseline\n",
        "        config = AutoConfig.from_pretrained(distilbert_model_path, num_labels=2)\n",
        "        config = apply_dropout(config)\n",
        "        return (\n",
        "            lambda: DistilBertForSequenceClassification.from_pretrained(distilbert_model_path, config=config),\n",
        "            best_training_args_distil\n",
        "        )\n",
        "    elif choice == 1:  # BERT CLS baseline\n",
        "        config = AutoConfig.from_pretrained(bert_model_path, num_labels=2)\n",
        "        config = apply_dropout(config)\n",
        "        return (\n",
        "            lambda: BertForSequenceClassification.from_pretrained(bert_model_path, config=config),\n",
        "            best_training_args_bert\n",
        "        )\n",
        "    elif choice == 2:  # DistilBERT mean pooling\n",
        "        config = AutoConfig.from_pretrained(distilbert_model_path, num_labels=2)\n",
        "        config = apply_dropout(config)\n",
        "        return (\n",
        "            lambda: DistilBertMeanPoolingForSequenceClassification(distilbert_model_path, config=config,),\n",
        "            best_training_args_distil\n",
        "        )\n",
        "    elif choice == 3:  # BERT mean pooling\n",
        "        config = AutoConfig.from_pretrained(bert_model_path, num_labels=2)\n",
        "        config = apply_dropout(config)\n",
        "        return (\n",
        "            lambda: BertMeanPoolingForSequenceClassification(bert_model_path, config=config),\n",
        "            best_training_args_bert\n",
        "        )\n",
        "    else:\n",
        "        config = AutoConfig.from_pretrained(distilbert_model_path, num_labels=2)\n",
        "        config = apply_dropout(config)\n",
        "        return (\n",
        "            lambda: DistilBertForSequenceClassification.from_pretrained(distilbert_model_path, config=config),\n",
        "            default_training_args\n",
        "        )\n",
        "\n",
        "\n",
        "import optuna\n",
        "from optuna.pruners import MedianPruner\n",
        "from transformers import EarlyStoppingCallback\n",
        "import shutil\n",
        "\n",
        "#  config flags so you can turn them off easily\n",
        "\n",
        "def compute_metrics(p):\n",
        "    preds = np.argmax(p.predictions, axis=-1) if isinstance(p.predictions, np.ndarray) else np.argmax(p.predictions[0], axis=-1)\n",
        "    return {\"f1\": f1_score(p.label_ids, preds)}\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "    dataset, name = encode_selected_datasets()\n",
        "    hp = optuna_hp_space(trial)\n",
        "\n",
        "    print(f\" Scheduler tuning: {use_scheduler_tuning.value} | Using: {hp['lr_scheduler_type']}\")\n",
        "    print(f\" Warmup steps ({use_warmup_steps.value}): {hp['warmup_steps']}\")\n",
        "    print(f\" Dropout: ({use_dropout_tuning.value}){hp['dropout']}\")\n",
        "\n",
        "    output_dir = './results'\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=os.path.join(tempfile.gettempdir(), f\"optuna_trial_{trial.number}\"),\n",
        "        num_train_epochs=hp[\"num_train_epochs\"],\n",
        "        per_device_train_batch_size=hp[\"per_device_train_batch_size\"],\n",
        "        weight_decay=hp[\"weight_decay\"],\n",
        "        learning_rate=hp[\"learning_rate\"],\n",
        "        save_strategy=\"no\",\n",
        "        evaluation_strategy=\"no\",\n",
        "        logging_strategy=\"no\",\n",
        "        load_best_model_at_end=False,\n",
        "        fp16=torch.cuda.is_available(),\n",
        "        optim=\"adamw_torch\",\n",
        "        report_to=[]\n",
        "    )\n",
        "    \n",
        "    model_init, base_args = get_model_and_args(model_choice_int.value, dropout=hp[\"dropout\"])\n",
        "    model = model_init()\n",
        "\n",
        "    training_args = base_args\n",
        "    training_args.learning_rate = hp[\"learning_rate\"]\n",
        "    training_args.num_train_epochs = hp[\"num_train_epochs\"]\n",
        "    training_args.per_device_train_batch_size = hp[\"per_device_train_batch_size\"]\n",
        "    training_args.weight_decay = hp[\"weight_decay\"]\n",
        "    training_args.warmup_steps = hp[\"warmup_steps\"]\n",
        "    training_args.lr_scheduler_type = hp[\"lr_scheduler_type\"]\n",
        "\n",
        "    if use_freeze_encoder.value:\n",
        "        print(\" Freezing encoder layers...\")\n",
        "        if hasattr(model, \"bert\"):\n",
        "            for param in model.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "        elif hasattr(model, \"distilbert\"):\n",
        "            for param in model.distilbert.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "        if hasattr(model, \"bert\"):\n",
        "            encoder = model.bert.encoder.layer\n",
        "        elif hasattr(model, \"distilbert\"):\n",
        "            encoder = model.distilbert.transformer.layer\n",
        "        else:\n",
        "            encoder = None\n",
        "\n",
        "        if encoder is not None:\n",
        "            for layer in encoder[:hp[\"freeze_layers\"]]:\n",
        "                for param in layer.parameters():\n",
        "                    param.requires_grad = False\n",
        "\n",
        "\n",
        "    trainer = CleanTrainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=dataset[\"train\"],\n",
        "        eval_dataset=dataset[\"val\"],\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    f1 = manual_evaluate(trainer.model, dataset[\"test\"], batch_size=hp[\"per_device_train_batch_size\"])\n",
        "\n",
        "    #  Clean up after training\n",
        "    del trainer, model\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    shutil.rmtree(training_args.output_dir, ignore_errors=True)\n",
        "\n",
        "    import datetime\n",
        "\n",
        "    #  Append lightweight log entry\n",
        "    log_path = \"optuna_log.csv\"\n",
        "    header = not os.path.exists(log_path)\n",
        "\n",
        "    # Write a separator at the start of a new Optuna run\n",
        "    if trial.number == 0:\n",
        "        with open(log_path, \"a\") as f:\n",
        "            f.write(\"\\n\" + \"#\"*80 + \"\\n\")\n",
        "            f.write(f\"# New Optuna Run | {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "            f.write(f\"# Dataset: {name}\\n\")\n",
        "            f.write(f\"# Model: {model_choice_int.value} | Freeze encoder: {use_freeze_encoder.value} | Dropout tuning: {use_dropout_tuning.value}\\n\")\n",
        "            f.write(\"#\"*80 + \"\\n\")\n",
        "\n",
        "    # Write header if first time\n",
        "    if header:\n",
        "        with open(log_path, \"a\") as f:\n",
        "            f.write(\"trial,dataset,f1,learning_rate,batch_size,weight_decay,num_train_epochs,warmup_steps,dropout\\n\")\n",
        "\n",
        "    # Log this trials results\n",
        "    with open(log_path, \"a\") as f:\n",
        "        f.write(f\"{trial.number},{name},{f1:.4f},{hp['learning_rate']:.6f},{hp['per_device_train_batch_size']},\"\n",
        "                f\"{hp['weight_decay']:.4f},{hp['num_train_epochs']},{hp['warmup_steps']},\"\n",
        "                f\"{hp.get('dropout', 0.1):.2f}\\n\")\n",
        "\n",
        "    #  Append best trial so far for readability\n",
        "    try:\n",
        "        study = trial.study\n",
        "        best_trial = study.best_trial\n",
        "        with open(log_path, \"a\") as f:\n",
        "            f.write(f\"# Best so far (dataset={name}): Trial {best_trial.number} | F1={best_trial.value:.4f}\\n\")\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    return f1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import joblib\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from transformers import get_scheduler\n",
        "from transformers import AdamW as HFAdamW   # HF's AdamW wrapper (or use torch.optim.AdamW)\n",
        "\n",
        "\n",
        "def final_optuna_model(study, output_dir=f\"./results/final_eval\"):\n",
        "    dataset, name = encode_selected_datasets()\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    best_hp = study.best_trial.params\n",
        "\n",
        "    with open(os.path.join(output_dir, \"best_hyperparameters.json\"), \"w\") as f:\n",
        "        json.dump(best_hp, f, indent=4)\n",
        "\n",
        "    # --- Handle scheduler (default to linear if not tuned)\n",
        "    scheduler_type = best_hp.get(\"lr_scheduler_type\", \"linear\")\n",
        "    \n",
        "    final_training_args = TrainingArguments(\n",
        "        output_dir=output_dir,\n",
        "        num_train_epochs=best_hp[\"num_train_epochs\"],\n",
        "        per_device_train_batch_size=best_hp[\"per_device_train_batch_size\"],\n",
        "        learning_rate=best_hp[\"learning_rate\"],\n",
        "        weight_decay=best_hp[\"weight_decay\"],\n",
        "        warmup_steps=best_hp.get(\"warmup_steps\", 0),\n",
        "        lr_scheduler_type=scheduler_type,   # <- add this\n",
        "        save_strategy=\"no\",\n",
        "        evaluation_strategy=\"no\",\n",
        "        load_best_model_at_end=False,\n",
        "        logging_strategy=\"no\",\n",
        "        fp16=True,\n",
        "        report_to=[]\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    model_init, _ = get_model_and_args(model_choice_int.value, dropout=best_hp[\"dropout\"])\n",
        "    final_model = model_init()\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\n",
        "        distilbert_model_path if model_choice_int == 0 else bert_model_path\n",
        "    )\n",
        "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "    final_trainer = CleanTrainer(\n",
        "        model=final_model,\n",
        "        args=final_training_args,\n",
        "        train_dataset=dataset[\"train\"],\n",
        "        data_collator=data_collator\n",
        "    )\n",
        "\n",
        "    # 5. Train\n",
        "    train_result = final_trainer.train()\n",
        "\n",
        "    # Save training logs (loss per epoch, etc.)\n",
        "    with open(os.path.join(output_dir, \"train_log.json\"), \"w\") as f:\n",
        "        json.dump(train_result.metrics, f, indent=4)\n",
        "\n",
        "    # 6. Evaluate\n",
        "    final_f1 = manual_evaluate(final_trainer.model, dataset[\"test\"], batch_size=8, tokenizer=tokenizer)\n",
        "    print(f\"\\n Final Test F1 Score (macro): {final_f1:.4f}\")\n",
        "\n",
        "    # Save metrics\n",
        "    metrics = {\n",
        "        \"final_f1_macro\": final_f1,\n",
        "        \"dataset_used\": name,\n",
        "    }\n",
        "    with open(os.path.join(output_dir, \"metrics.json\"), \"w\") as f:\n",
        "        json.dump(metrics, f, indent=4)\n",
        "\n",
        "    # Optional: get more detailed metrics\n",
        "    y_true = dataset[\"test\"].labels\n",
        "    \n",
        "    # Reuse the manual evaluation pipeline\n",
        "    model = final_trainer.model\n",
        "    model.eval()\n",
        "    device = next(model.parameters()).device\n",
        "    collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "    dataloader = DataLoader(dataset[\"test\"], batch_size=8, collate_fn=collator)\n",
        "\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Final detailed eval\"):\n",
        "            inputs = {k: v.to(device) for k, v in batch.items() if k in [\"input_ids\", \"attention_mask\"]}\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "            outputs = model(**inputs)\n",
        "            preds = torch.argmax(outputs.logits, dim=-1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    y_true = all_labels\n",
        "    y_pred = all_preds\n",
        "\n",
        "\n",
        "    report = classification_report(y_true, y_pred, output_dict=True)\n",
        "    cm = confusion_matrix(y_true, y_pred).tolist()\n",
        "\n",
        "    with open(os.path.join(output_dir, \"classification_report.json\"), \"w\") as f:\n",
        "        json.dump(report, f, indent=4)\n",
        "    with open(os.path.join(output_dir, \"confusion_matrix.json\"), \"w\") as f:\n",
        "        json.dump(cm, f, indent=4)\n",
        "\n",
        "    # 7. Save model + tokenizer\n",
        "    final_trainer.save_model(output_dir)\n",
        "    tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "    # Save Optuna study object for later inspection\n",
        "    study.trials_dataframe().to_csv(os.path.join(output_dir, \"optuna_trials.csv\"), index=False)\n",
        "\n",
        "    print(f\" Final model, tokenizer, hyperparameters, and metrics saved to {output_dir}\")\n",
        "\n",
        "    del final_model, final_trainer\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    shutil.rmtree(final_training_args.output_dir, ignore_errors=True)\n",
        "\n",
        "\n",
        "def start_optuna():\n",
        "    study = create_study(direction=\"maximize\")\n",
        "    study.optimize(objective, n_trials=optuna_trials.value)\n",
        "\n",
        "    print(\" Best trial:\")\n",
        "    print(study.best_trial)\n",
        "\n",
        "    final_optuna_model(study, output_dir_optuna)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 21:30:29,457] A new study created in memory with name: no-name-d9d44a23-2482-4d52-a12b-e411d1af28b3\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: polynomial\n",
            " Warmup steps (True): 215\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a466ab3e0a2a45a9ba9cb541378418fb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/455 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7291, 'learning_rate': 1.0130359375668591e-06, 'epoch': 0.11}\n",
            "{'loss': 0.7139, 'learning_rate': 1.913512326515178e-06, 'epoch': 0.22}\n",
            "{'loss': 0.697, 'learning_rate': 2.9265482640820373e-06, 'epoch': 0.33}\n",
            "{'loss': 0.6973, 'learning_rate': 3.939584201648897e-06, 'epoch': 0.44}\n",
            "{'loss': 0.6741, 'learning_rate': 5.065179687834295e-06, 'epoch': 0.55}\n",
            "{'loss': 0.6952, 'learning_rate': 6.078215625401155e-06, 'epoch': 0.66}\n",
            "{'loss': 0.6714, 'learning_rate': 7.203811111586553e-06, 'epoch': 0.77}\n",
            "{'loss': 0.6783, 'learning_rate': 8.329406597771952e-06, 'epoch': 0.88}\n",
            "{'loss': 0.6856, 'learning_rate': 9.45500208395735e-06, 'epoch': 0.99}\n",
            "{'loss': 0.6815, 'learning_rate': 1.058059757014275e-05, 'epoch': 1.1}\n",
            "{'loss': 0.679, 'learning_rate': 1.1706193056328149e-05, 'epoch': 1.21}\n",
            "{'loss': 0.6451, 'learning_rate': 1.2831788542513547e-05, 'epoch': 1.32}\n",
            "{'loss': 0.6373, 'learning_rate': 1.3957384028698948e-05, 'epoch': 1.43}\n",
            "{'loss': 0.6073, 'learning_rate': 1.5082979514884346e-05, 'epoch': 1.54}\n",
            "{'loss': 0.5836, 'learning_rate': 1.6208575001069746e-05, 'epoch': 1.65}\n",
            "{'loss': 0.598, 'learning_rate': 1.7334170487255143e-05, 'epoch': 1.76}\n",
            "{'loss': 0.5256, 'learning_rate': 1.8459765973440543e-05, 'epoch': 1.87}\n",
            "{'loss': 0.5948, 'learning_rate': 1.9585361459625943e-05, 'epoch': 1.98}\n",
            "{'loss': 0.4791, 'learning_rate': 2.071095694581134e-05, 'epoch': 2.09}\n",
            "{'loss': 0.5798, 'learning_rate': 2.183655243199674e-05, 'epoch': 2.2}\n",
            "{'loss': 0.4122, 'learning_rate': 2.296214791818214e-05, 'epoch': 2.31}\n",
            "{'loss': 0.4454, 'learning_rate': 2.408774340436754e-05, 'epoch': 2.42}\n",
            "{'loss': 0.3489, 'learning_rate': 2.32965415922491e-05, 'epoch': 2.53}\n",
            "{'loss': 0.4874, 'learning_rate': 2.2292362302541347e-05, 'epoch': 2.64}\n",
            "{'loss': 0.3975, 'learning_rate': 2.1288183012833593e-05, 'epoch': 2.75}\n",
            "{'loss': 0.3594, 'learning_rate': 2.028400372312584e-05, 'epoch': 2.86}\n",
            "{'loss': 0.2716, 'learning_rate': 1.927982443341809e-05, 'epoch': 2.97}\n",
            "{'loss': 0.211, 'learning_rate': 1.8275645143710332e-05, 'epoch': 3.08}\n",
            "{'loss': 0.1635, 'learning_rate': 1.727146585400258e-05, 'epoch': 3.19}\n",
            "{'loss': 0.3213, 'learning_rate': 1.6267286564294828e-05, 'epoch': 3.3}\n",
            "{'loss': 0.3228, 'learning_rate': 1.5263107274587074e-05, 'epoch': 3.41}\n",
            "{'loss': 0.3082, 'learning_rate': 1.4258927984879322e-05, 'epoch': 3.52}\n",
            "{'loss': 0.3294, 'learning_rate': 1.325474869517157e-05, 'epoch': 3.63}\n",
            "{'loss': 0.1925, 'learning_rate': 1.2250569405463817e-05, 'epoch': 3.74}\n",
            "{'loss': 0.2072, 'learning_rate': 1.1246390115756062e-05, 'epoch': 3.85}\n",
            "{'loss': 0.2488, 'learning_rate': 1.0242210826048308e-05, 'epoch': 3.96}\n",
            "{'loss': 0.1916, 'learning_rate': 9.238031536340556e-06, 'epoch': 4.07}\n",
            "{'loss': 0.1331, 'learning_rate': 8.233852246632802e-06, 'epoch': 4.18}\n",
            "{'loss': 0.1155, 'learning_rate': 7.229672956925046e-06, 'epoch': 4.29}\n",
            "{'loss': 0.1134, 'learning_rate': 6.225493667217295e-06, 'epoch': 4.4}\n",
            "{'loss': 0.125, 'learning_rate': 5.221314377509542e-06, 'epoch': 4.51}\n",
            "{'loss': 0.3053, 'learning_rate': 4.217135087801787e-06, 'epoch': 4.62}\n",
            "{'loss': 0.0871, 'learning_rate': 3.2129557980940346e-06, 'epoch': 4.73}\n",
            "{'loss': 0.1847, 'learning_rate': 2.2087765083862824e-06, 'epoch': 4.84}\n",
            "{'loss': 0.1052, 'learning_rate': 1.2045972186785273e-06, 'epoch': 4.95}\n",
            "{'train_runtime': 73.2146, 'train_samples_per_second': 98.682, 'train_steps_per_second': 6.215, 'train_loss': 0.4254717577944745, 'epoch': 5.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 26/26 [00:01<00:00, 22.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 21:31:46,970] Trial 0 finished with value: 0.8976377952755904 and parameters: {'learning_rate': 2.4200302952986078e-05, 'per_device_train_batch_size': 16, 'weight_decay': 0.20246458785443827, 'num_train_epochs': 5, 'warmup_steps': 215, 'freeze_layers': 9, 'dropout': 0.3366301491364168, 'lr_scheduler_type': 'polynomial'}. Best is trial 0 with value: 0.8976377952755904.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: polynomial\n",
            " Warmup steps (True): 209\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0585f0b141204827935be6667ef01627",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1086 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7155, 'learning_rate': 3.3619080075329513e-06, 'epoch': 0.06}\n",
            "{'loss': 0.6966, 'learning_rate': 7.144054516007521e-06, 'epoch': 0.11}\n",
            "{'loss': 0.6903, 'learning_rate': 1.1346439525423711e-05, 'epoch': 0.17}\n",
            "{'loss': 0.6965, 'learning_rate': 1.5128586033898282e-05, 'epoch': 0.22}\n",
            "{'loss': 0.7221, 'learning_rate': 1.9330971043314472e-05, 'epoch': 0.28}\n",
            "{'loss': 0.6554, 'learning_rate': 2.353335605273066e-05, 'epoch': 0.33}\n",
            "{'loss': 0.6342, 'learning_rate': 2.7735741062146846e-05, 'epoch': 0.39}\n",
            "{'loss': 0.7101, 'learning_rate': 3.193812607156304e-05, 'epoch': 0.44}\n",
            "{'loss': 0.6278, 'learning_rate': 3.6140511080979224e-05, 'epoch': 0.5}\n",
            "{'loss': 0.5694, 'learning_rate': 4.0342896090395416e-05, 'epoch': 0.55}\n",
            "{'loss': 0.5798, 'learning_rate': 4.454528109981161e-05, 'epoch': 0.61}\n",
            "{'loss': 0.5688, 'learning_rate': 4.874766610922779e-05, 'epoch': 0.66}\n",
            "{'loss': 0.4588, 'learning_rate': 5.2950051118643985e-05, 'epoch': 0.72}\n",
            "{'loss': 0.5053, 'learning_rate': 5.715243612806017e-05, 'epoch': 0.77}\n",
            "{'loss': 0.6081, 'learning_rate': 6.093458263653474e-05, 'epoch': 0.83}\n",
            "{'loss': 0.5014, 'learning_rate': 6.513696764595094e-05, 'epoch': 0.88}\n",
            "{'loss': 0.7906, 'learning_rate': 6.933935265536713e-05, 'epoch': 0.94}\n",
            "{'loss': 0.6337, 'learning_rate': 7.354173766478332e-05, 'epoch': 0.99}\n",
            "{'loss': 0.5697, 'learning_rate': 7.77441226741995e-05, 'epoch': 1.05}\n",
            "{'loss': 0.627, 'learning_rate': 8.194650768361569e-05, 'epoch': 1.1}\n",
            "{'loss': 0.5683, 'learning_rate': 8.614889269303188e-05, 'epoch': 1.16}\n",
            "{'loss': 0.5099, 'learning_rate': 8.722964250046906e-05, 'epoch': 1.22}\n",
            "{'loss': 0.8478, 'learning_rate': 8.622930217325357e-05, 'epoch': 1.27}\n",
            "{'loss': 0.452, 'learning_rate': 8.522896184603808e-05, 'epoch': 1.33}\n",
            "{'loss': 0.3883, 'learning_rate': 8.42286215188226e-05, 'epoch': 1.38}\n",
            "{'loss': 0.5456, 'learning_rate': 8.32282811916071e-05, 'epoch': 1.44}\n",
            "{'loss': 0.578, 'learning_rate': 8.222794086439162e-05, 'epoch': 1.49}\n",
            "{'loss': 0.7677, 'learning_rate': 8.122760053717613e-05, 'epoch': 1.55}\n",
            "{'loss': 0.5552, 'learning_rate': 8.022726020996064e-05, 'epoch': 1.6}\n",
            "{'loss': 0.4409, 'learning_rate': 7.922691988274515e-05, 'epoch': 1.66}\n",
            "{'loss': 0.5385, 'learning_rate': 7.822657955552966e-05, 'epoch': 1.71}\n",
            "{'loss': 0.4362, 'learning_rate': 7.722623922831418e-05, 'epoch': 1.77}\n",
            "{'loss': 0.3757, 'learning_rate': 7.62258989010987e-05, 'epoch': 1.82}\n",
            "{'loss': 0.5511, 'learning_rate': 7.52255585738832e-05, 'epoch': 1.88}\n",
            "{'loss': 0.3496, 'learning_rate': 7.422521824666772e-05, 'epoch': 1.93}\n",
            "{'loss': 0.3889, 'learning_rate': 7.322487791945223e-05, 'epoch': 1.99}\n",
            "{'loss': 0.462, 'learning_rate': 7.222453759223674e-05, 'epoch': 2.04}\n",
            "{'loss': 0.1363, 'learning_rate': 7.122419726502123e-05, 'epoch': 2.1}\n",
            "{'loss': 0.3006, 'learning_rate': 7.022385693780574e-05, 'epoch': 2.15}\n",
            "{'loss': 0.4558, 'learning_rate': 6.922351661059026e-05, 'epoch': 2.21}\n",
            "{'loss': 0.4219, 'learning_rate': 6.822317628337478e-05, 'epoch': 2.27}\n",
            "{'loss': 0.348, 'learning_rate': 6.722283595615929e-05, 'epoch': 2.32}\n",
            "{'loss': 0.2948, 'learning_rate': 6.62224956289438e-05, 'epoch': 2.38}\n",
            "{'loss': 0.392, 'learning_rate': 6.522215530172831e-05, 'epoch': 2.43}\n",
            "{'loss': 0.3071, 'learning_rate': 6.422181497451282e-05, 'epoch': 2.49}\n",
            "{'loss': 0.3699, 'learning_rate': 6.322147464729733e-05, 'epoch': 2.54}\n",
            "{'loss': 0.57, 'learning_rate': 6.222113432008184e-05, 'epoch': 2.6}\n",
            "{'loss': 0.2341, 'learning_rate': 6.122079399286635e-05, 'epoch': 2.65}\n",
            "{'loss': 0.2578, 'learning_rate': 6.022045366565087e-05, 'epoch': 2.71}\n",
            "{'loss': 0.1726, 'learning_rate': 5.9220113338435376e-05, 'epoch': 2.76}\n",
            "{'loss': 0.4244, 'learning_rate': 5.8219773011219894e-05, 'epoch': 2.82}\n",
            "{'loss': 0.3258, 'learning_rate': 5.721943268400441e-05, 'epoch': 2.87}\n",
            "{'loss': 0.3372, 'learning_rate': 5.6219092356788915e-05, 'epoch': 2.93}\n",
            "{'loss': 0.2266, 'learning_rate': 5.521875202957343e-05, 'epoch': 2.98}\n",
            "{'loss': 0.2842, 'learning_rate': 5.4218411702357944e-05, 'epoch': 3.04}\n",
            "{'loss': 0.1546, 'learning_rate': 5.3218071375142454e-05, 'epoch': 3.09}\n",
            "{'loss': 0.1179, 'learning_rate': 5.2217731047926965e-05, 'epoch': 3.15}\n",
            "{'loss': 0.365, 'learning_rate': 5.121739072071147e-05, 'epoch': 3.2}\n",
            "{'loss': 0.3472, 'learning_rate': 5.021705039349599e-05, 'epoch': 3.26}\n",
            "{'loss': 0.0604, 'learning_rate': 4.9216710066280504e-05, 'epoch': 3.31}\n",
            "{'loss': 0.2883, 'learning_rate': 4.821636973906502e-05, 'epoch': 3.37}\n",
            "{'loss': 0.287, 'learning_rate': 4.721602941184951e-05, 'epoch': 3.43}\n",
            "{'loss': 0.4556, 'learning_rate': 4.621568908463403e-05, 'epoch': 3.48}\n",
            "{'loss': 0.2547, 'learning_rate': 4.521534875741855e-05, 'epoch': 3.54}\n",
            "{'loss': 0.2196, 'learning_rate': 4.421500843020305e-05, 'epoch': 3.59}\n",
            "{'loss': 0.3083, 'learning_rate': 4.321466810298756e-05, 'epoch': 3.65}\n",
            "{'loss': 0.2605, 'learning_rate': 4.221432777577207e-05, 'epoch': 3.7}\n",
            "{'loss': 0.1577, 'learning_rate': 4.1213987448556583e-05, 'epoch': 3.76}\n",
            "{'loss': 0.4059, 'learning_rate': 4.02136471213411e-05, 'epoch': 3.81}\n",
            "{'loss': 0.3643, 'learning_rate': 3.921330679412561e-05, 'epoch': 3.87}\n",
            "{'loss': 0.3411, 'learning_rate': 3.821296646691012e-05, 'epoch': 3.92}\n",
            "{'loss': 0.2662, 'learning_rate': 3.721262613969463e-05, 'epoch': 3.98}\n",
            "{'loss': 0.2304, 'learning_rate': 3.6212285812479144e-05, 'epoch': 4.03}\n",
            "{'loss': 0.3328, 'learning_rate': 3.521194548526365e-05, 'epoch': 4.09}\n",
            "{'loss': 0.1786, 'learning_rate': 3.4311639190769714e-05, 'epoch': 4.14}\n",
            "{'loss': 0.2365, 'learning_rate': 3.3311298863554225e-05, 'epoch': 4.2}\n",
            "{'loss': 0.2338, 'learning_rate': 3.2310958536338736e-05, 'epoch': 4.25}\n",
            "{'loss': 0.1338, 'learning_rate': 3.1310618209123253e-05, 'epoch': 4.31}\n",
            "{'loss': 0.0156, 'learning_rate': 3.031027788190776e-05, 'epoch': 4.36}\n",
            "{'loss': 0.1727, 'learning_rate': 2.930993755469227e-05, 'epoch': 4.42}\n",
            "{'loss': 0.0972, 'learning_rate': 2.8309597227476772e-05, 'epoch': 4.48}\n",
            "{'loss': 0.2568, 'learning_rate': 2.7309256900261286e-05, 'epoch': 4.53}\n",
            "{'loss': 0.4017, 'learning_rate': 2.6308916573045797e-05, 'epoch': 4.59}\n",
            "{'loss': 0.2472, 'learning_rate': 2.5308576245830308e-05, 'epoch': 4.64}\n",
            "{'loss': 0.204, 'learning_rate': 2.430823591861482e-05, 'epoch': 4.7}\n",
            "{'loss': 0.1779, 'learning_rate': 2.3307895591399336e-05, 'epoch': 4.75}\n",
            "{'loss': 0.3175, 'learning_rate': 2.2307555264183847e-05, 'epoch': 4.81}\n",
            "{'loss': 0.1668, 'learning_rate': 2.1307214936968358e-05, 'epoch': 4.86}\n",
            "{'loss': 0.2535, 'learning_rate': 2.030687460975287e-05, 'epoch': 4.92}\n",
            "{'loss': 0.1451, 'learning_rate': 1.9306534282537382e-05, 'epoch': 4.97}\n",
            "{'loss': 0.2874, 'learning_rate': 1.8306193955321893e-05, 'epoch': 5.03}\n",
            "{'loss': 0.2865, 'learning_rate': 1.7305853628106404e-05, 'epoch': 5.08}\n",
            "{'loss': 0.1795, 'learning_rate': 1.6305513300890918e-05, 'epoch': 5.14}\n",
            "{'loss': 0.1087, 'learning_rate': 1.530517297367543e-05, 'epoch': 5.19}\n",
            "{'loss': 0.1128, 'learning_rate': 1.4304832646459945e-05, 'epoch': 5.25}\n",
            "{'loss': 0.1571, 'learning_rate': 1.3304492319244455e-05, 'epoch': 5.3}\n",
            "{'loss': 0.2141, 'learning_rate': 1.2304151992028964e-05, 'epoch': 5.36}\n",
            "{'loss': 0.1935, 'learning_rate': 1.1303811664813468e-05, 'epoch': 5.41}\n",
            "{'loss': 0.1616, 'learning_rate': 1.0303471337597981e-05, 'epoch': 5.47}\n",
            "{'loss': 0.1587, 'learning_rate': 9.303131010382493e-06, 'epoch': 5.52}\n",
            "{'loss': 0.2797, 'learning_rate': 8.302790683167004e-06, 'epoch': 5.58}\n",
            "{'loss': 0.1099, 'learning_rate': 7.302450355951516e-06, 'epoch': 5.64}\n",
            "{'loss': 0.1805, 'learning_rate': 6.302110028736028e-06, 'epoch': 5.69}\n",
            "{'loss': 0.1914, 'learning_rate': 5.30176970152054e-06, 'epoch': 5.75}\n",
            "{'loss': 0.1148, 'learning_rate': 4.301429374305051e-06, 'epoch': 5.8}\n",
            "{'loss': 0.0696, 'learning_rate': 3.3010890470895634e-06, 'epoch': 5.86}\n",
            "{'loss': 0.1353, 'learning_rate': 2.3007487198740754e-06, 'epoch': 5.91}\n",
            "{'loss': 0.2167, 'learning_rate': 1.3004083926585874e-06, 'epoch': 5.97}\n",
            "{'train_runtime': 116.7397, 'train_samples_per_second': 74.268, 'train_steps_per_second': 9.303, 'train_loss': 0.3584716503352311, 'epoch': 6.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 52/52 [00:01<00:00, 38.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 21:33:47,588] Trial 1 finished with value: 0.8934010152284264 and parameters: {'learning_rate': 8.782984669679836e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.21289618611922206, 'num_train_epochs': 6, 'warmup_steps': 209, 'freeze_layers': 0, 'dropout': 0.254228217441567, 'lr_scheduler_type': 'polynomial'}. Best is trial 0 with value: 0.8976377952755904.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: polynomial\n",
            " Warmup steps (True): 94\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "274f72fc12b14decaf6b337b09984963",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/414 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7107, 'learning_rate': 1.70796569512955e-06, 'epoch': 0.22}\n",
            "{'loss': 0.6932, 'learning_rate': 3.659926489563322e-06, 'epoch': 0.43}\n",
            "{'loss': 0.7028, 'learning_rate': 6.099877482605536e-06, 'epoch': 0.65}\n",
            "{'loss': 0.6927, 'learning_rate': 8.53982847564775e-06, 'epoch': 0.87}\n",
            "{'loss': 0.6924, 'learning_rate': 1.0979779468689966e-05, 'epoch': 1.09}\n",
            "{'loss': 0.6779, 'learning_rate': 1.341973046173218e-05, 'epoch': 1.3}\n",
            "{'loss': 0.6487, 'learning_rate': 1.5859681454774396e-05, 'epoch': 1.52}\n",
            "{'loss': 0.6338, 'learning_rate': 1.8299632447816606e-05, 'epoch': 1.74}\n",
            "{'loss': 0.5811, 'learning_rate': 2.0739583440858823e-05, 'epoch': 1.96}\n",
            "{'loss': 0.5313, 'learning_rate': 2.28641782741762e-05, 'epoch': 2.17}\n",
            "{'loss': 0.4783, 'learning_rate': 2.2150567669970048e-05, 'epoch': 2.39}\n",
            "{'loss': 0.4153, 'learning_rate': 2.14369570657639e-05, 'epoch': 2.61}\n",
            "{'loss': 0.4075, 'learning_rate': 2.0723346461557748e-05, 'epoch': 2.83}\n",
            "{'loss': 0.3577, 'learning_rate': 2.00097358573516e-05, 'epoch': 3.04}\n",
            "{'loss': 0.3058, 'learning_rate': 1.9296125253145447e-05, 'epoch': 3.26}\n",
            "{'loss': 0.3748, 'learning_rate': 1.8582514648939295e-05, 'epoch': 3.48}\n",
            "{'loss': 0.3283, 'learning_rate': 1.7868904044733147e-05, 'epoch': 3.7}\n",
            "{'loss': 0.2851, 'learning_rate': 1.7155293440526995e-05, 'epoch': 3.91}\n",
            "{'loss': 0.1902, 'learning_rate': 1.6441682836320846e-05, 'epoch': 4.13}\n",
            "{'loss': 0.1902, 'learning_rate': 1.5728072232114694e-05, 'epoch': 4.35}\n",
            "{'loss': 0.2221, 'learning_rate': 1.5014461627908546e-05, 'epoch': 4.57}\n",
            "{'loss': 0.2276, 'learning_rate': 1.4300851023702396e-05, 'epoch': 4.78}\n",
            "{'loss': 0.1987, 'learning_rate': 1.3587240419496244e-05, 'epoch': 5.0}\n",
            "{'loss': 0.1888, 'learning_rate': 1.2873629815290092e-05, 'epoch': 5.22}\n",
            "{'loss': 0.1561, 'learning_rate': 1.2160019211083943e-05, 'epoch': 5.43}\n",
            "{'loss': 0.1279, 'learning_rate': 1.1446408606877793e-05, 'epoch': 5.65}\n",
            "{'loss': 0.1876, 'learning_rate': 1.0732798002671643e-05, 'epoch': 5.87}\n",
            "{'loss': 0.1014, 'learning_rate': 1.0019187398465493e-05, 'epoch': 6.09}\n",
            "{'loss': 0.0944, 'learning_rate': 9.305576794259341e-06, 'epoch': 6.3}\n",
            "{'loss': 0.1458, 'learning_rate': 8.59196619005319e-06, 'epoch': 6.52}\n",
            "{'loss': 0.1062, 'learning_rate': 7.87835558584704e-06, 'epoch': 6.74}\n",
            "{'loss': 0.1346, 'learning_rate': 7.1647449816408895e-06, 'epoch': 6.96}\n",
            "{'loss': 0.1016, 'learning_rate': 6.4511343774347376e-06, 'epoch': 7.17}\n",
            "{'loss': 0.0855, 'learning_rate': 5.737523773228588e-06, 'epoch': 7.39}\n",
            "{'loss': 0.0941, 'learning_rate': 5.023913169022437e-06, 'epoch': 7.61}\n",
            "{'loss': 0.1225, 'learning_rate': 4.310302564816287e-06, 'epoch': 7.83}\n",
            "{'loss': 0.0593, 'learning_rate': 3.5966919606101367e-06, 'epoch': 8.04}\n",
            "{'loss': 0.1035, 'learning_rate': 2.883081356403986e-06, 'epoch': 8.26}\n",
            "{'loss': 0.0649, 'learning_rate': 2.1694707521978355e-06, 'epoch': 8.48}\n",
            "{'loss': 0.0418, 'learning_rate': 1.455860147991685e-06, 'epoch': 8.7}\n",
            "{'loss': 0.0177, 'learning_rate': 7.422495437855345e-07, 'epoch': 8.91}\n",
            "{'train_runtime': 119.9113, 'train_samples_per_second': 108.455, 'train_steps_per_second': 3.453, 'train_loss': 0.3017672561648963, 'epoch': 9.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 13/13 [00:00<00:00, 13.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 21:35:51,008] Trial 2 finished with value: 0.8877005347593584 and parameters: {'learning_rate': 2.2935539334596816e-05, 'per_device_train_batch_size': 32, 'weight_decay': 0.05535327858876934, 'num_train_epochs': 9, 'warmup_steps': 94, 'freeze_layers': 3, 'dropout': 0.1813369447006497, 'lr_scheduler_type': 'polynomial'}. Best is trial 0 with value: 0.8976377952755904.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: polynomial\n",
            " Warmup steps (True): 153\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e4975a1bc08c44e3a7faca351264e52a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/322 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7044, 'learning_rate': 2.416636306703033e-06, 'epoch': 0.22}\n",
            "{'loss': 0.7143, 'learning_rate': 5.135352151743945e-06, 'epoch': 0.43}\n",
            "{'loss': 0.6788, 'learning_rate': 8.156147535122738e-06, 'epoch': 0.65}\n",
            "{'loss': 0.6653, 'learning_rate': 1.0874863380163649e-05, 'epoch': 0.87}\n",
            "{'loss': 0.6947, 'learning_rate': 1.3895658763542441e-05, 'epoch': 1.09}\n",
            "{'loss': 0.6638, 'learning_rate': 1.6916454146921233e-05, 'epoch': 1.3}\n",
            "{'loss': 0.6387, 'learning_rate': 1.9937249530300023e-05, 'epoch': 1.52}\n",
            "{'loss': 0.6128, 'learning_rate': 2.2958044913678817e-05, 'epoch': 1.74}\n",
            "{'loss': 0.5533, 'learning_rate': 2.5978840297057608e-05, 'epoch': 1.96}\n",
            "{'loss': 0.4819, 'learning_rate': 2.8999635680436398e-05, 'epoch': 2.17}\n",
            "{'loss': 0.4873, 'learning_rate': 3.202043106381519e-05, 'epoch': 2.39}\n",
            "{'loss': 0.4293, 'learning_rate': 3.504122644719398e-05, 'epoch': 2.61}\n",
            "{'loss': 0.4531, 'learning_rate': 3.806202183057277e-05, 'epoch': 2.83}\n",
            "{'loss': 0.3078, 'learning_rate': 4.108281721395156e-05, 'epoch': 3.04}\n",
            "{'loss': 0.3421, 'learning_rate': 4.410361259733036e-05, 'epoch': 3.26}\n",
            "{'loss': 0.3438, 'learning_rate': 4.539950363731038e-05, 'epoch': 3.48}\n",
            "{'loss': 0.3804, 'learning_rate': 4.2670617876026625e-05, 'epoch': 3.7}\n",
            "{'loss': 0.2551, 'learning_rate': 3.994173211474286e-05, 'epoch': 3.91}\n",
            "{'loss': 0.1378, 'learning_rate': 3.721284635345911e-05, 'epoch': 4.13}\n",
            "{'loss': 0.1467, 'learning_rate': 3.448396059217535e-05, 'epoch': 4.35}\n",
            "{'loss': 0.2892, 'learning_rate': 3.175507483089159e-05, 'epoch': 4.57}\n",
            "{'loss': 0.207, 'learning_rate': 2.9026189069607836e-05, 'epoch': 4.78}\n",
            "{'loss': 0.1545, 'learning_rate': 2.6297303308324073e-05, 'epoch': 5.0}\n",
            "{'loss': 0.0989, 'learning_rate': 2.3568417547040314e-05, 'epoch': 5.22}\n",
            "{'loss': 0.115, 'learning_rate': 2.083953178575656e-05, 'epoch': 5.43}\n",
            "{'loss': 0.0613, 'learning_rate': 1.81106460244728e-05, 'epoch': 5.65}\n",
            "{'loss': 0.0533, 'learning_rate': 1.5381760263189044e-05, 'epoch': 5.87}\n",
            "{'loss': 0.0588, 'learning_rate': 1.2652874501905284e-05, 'epoch': 6.09}\n",
            "{'loss': 0.039, 'learning_rate': 9.923988740621529e-06, 'epoch': 6.3}\n",
            "{'loss': 0.0375, 'learning_rate': 7.19510297933777e-06, 'epoch': 6.52}\n",
            "{'loss': 0.0386, 'learning_rate': 4.4662172180540145e-06, 'epoch': 6.74}\n",
            "{'loss': 0.0622, 'learning_rate': 1.7373314567702528e-06, 'epoch': 6.96}\n",
            "{'train_runtime': 90.8357, 'train_samples_per_second': 111.355, 'train_steps_per_second': 3.545, 'train_loss': 0.33873327658656316, 'epoch': 7.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 13/13 [00:01<00:00, 12.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 21:37:25,639] Trial 3 finished with value: 0.8948655256723717 and parameters: {'learning_rate': 4.621816936569551e-05, 'per_device_train_batch_size': 32, 'weight_decay': 0.2552065550129325, 'num_train_epochs': 7, 'warmup_steps': 153, 'freeze_layers': 6, 'dropout': 0.2222027968062808, 'lr_scheduler_type': 'polynomial'}. Best is trial 0 with value: 0.8976377952755904.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: constant_with_warmup\n",
            " Warmup steps (True): 137\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f8c497db32904903b1ddc993718d853d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1810 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7176, 'learning_rate': 2.276766266869831e-06, 'epoch': 0.06}\n",
            "{'loss': 0.7347, 'learning_rate': 5.529289505255304e-06, 'epoch': 0.11}\n",
            "{'loss': 0.6953, 'learning_rate': 8.131308095963683e-06, 'epoch': 0.17}\n",
            "{'loss': 0.6934, 'learning_rate': 1.1383831334349157e-05, 'epoch': 0.22}\n",
            "{'loss': 0.7218, 'learning_rate': 1.463635457273463e-05, 'epoch': 0.28}\n",
            "{'loss': 0.6574, 'learning_rate': 1.7888877811120103e-05, 'epoch': 0.33}\n",
            "{'loss': 0.7011, 'learning_rate': 2.0816148725667028e-05, 'epoch': 0.39}\n",
            "{'loss': 0.6944, 'learning_rate': 2.4068671964052503e-05, 'epoch': 0.44}\n",
            "{'loss': 0.6408, 'learning_rate': 2.7321195202437976e-05, 'epoch': 0.5}\n",
            "{'loss': 0.5701, 'learning_rate': 3.057371844082345e-05, 'epoch': 0.55}\n",
            "{'loss': 0.6476, 'learning_rate': 3.382624167920892e-05, 'epoch': 0.61}\n",
            "{'loss': 0.5799, 'learning_rate': 3.707876491759439e-05, 'epoch': 0.66}\n",
            "{'loss': 0.4408, 'learning_rate': 4.000603583214132e-05, 'epoch': 0.72}\n",
            "{'loss': 0.4641, 'learning_rate': 4.3258559070526796e-05, 'epoch': 0.77}\n",
            "{'loss': 0.5128, 'learning_rate': 4.455956836588098e-05, 'epoch': 0.83}\n",
            "{'loss': 0.3655, 'learning_rate': 4.455956836588098e-05, 'epoch': 0.88}\n",
            "{'loss': 0.434, 'learning_rate': 4.455956836588098e-05, 'epoch': 0.94}\n",
            "{'loss': 0.7054, 'learning_rate': 4.455956836588098e-05, 'epoch': 0.99}\n",
            "{'loss': 0.6319, 'learning_rate': 4.455956836588098e-05, 'epoch': 1.05}\n",
            "{'loss': 0.3965, 'learning_rate': 4.455956836588098e-05, 'epoch': 1.1}\n",
            "{'loss': 0.7505, 'learning_rate': 4.455956836588098e-05, 'epoch': 1.16}\n",
            "{'loss': 0.4888, 'learning_rate': 4.455956836588098e-05, 'epoch': 1.22}\n",
            "{'loss': 0.4085, 'learning_rate': 4.455956836588098e-05, 'epoch': 1.27}\n",
            "{'loss': 0.5001, 'learning_rate': 4.455956836588098e-05, 'epoch': 1.33}\n",
            "{'loss': 0.4296, 'learning_rate': 4.455956836588098e-05, 'epoch': 1.38}\n",
            "{'loss': 0.4344, 'learning_rate': 4.455956836588098e-05, 'epoch': 1.44}\n",
            "{'loss': 0.2664, 'learning_rate': 4.455956836588098e-05, 'epoch': 1.49}\n",
            "{'loss': 0.4965, 'learning_rate': 4.455956836588098e-05, 'epoch': 1.55}\n",
            "{'loss': 0.3379, 'learning_rate': 4.455956836588098e-05, 'epoch': 1.6}\n",
            "{'loss': 0.2696, 'learning_rate': 4.455956836588098e-05, 'epoch': 1.66}\n",
            "{'loss': 0.3744, 'learning_rate': 4.455956836588098e-05, 'epoch': 1.71}\n",
            "{'loss': 0.4025, 'learning_rate': 4.455956836588098e-05, 'epoch': 1.77}\n",
            "{'loss': 0.3228, 'learning_rate': 4.455956836588098e-05, 'epoch': 1.82}\n",
            "{'loss': 0.4711, 'learning_rate': 4.455956836588098e-05, 'epoch': 1.88}\n",
            "{'loss': 0.3299, 'learning_rate': 4.455956836588098e-05, 'epoch': 1.93}\n",
            "{'loss': 0.46, 'learning_rate': 4.455956836588098e-05, 'epoch': 1.99}\n",
            "{'loss': 0.2258, 'learning_rate': 4.455956836588098e-05, 'epoch': 2.04}\n",
            "{'loss': 0.0837, 'learning_rate': 4.455956836588098e-05, 'epoch': 2.1}\n",
            "{'loss': 0.2718, 'learning_rate': 4.455956836588098e-05, 'epoch': 2.15}\n",
            "{'loss': 0.3501, 'learning_rate': 4.455956836588098e-05, 'epoch': 2.21}\n",
            "{'loss': 0.1784, 'learning_rate': 4.455956836588098e-05, 'epoch': 2.27}\n",
            "{'loss': 0.1606, 'learning_rate': 4.455956836588098e-05, 'epoch': 2.32}\n",
            "{'loss': 0.3395, 'learning_rate': 4.455956836588098e-05, 'epoch': 2.38}\n",
            "{'loss': 0.2037, 'learning_rate': 4.455956836588098e-05, 'epoch': 2.43}\n",
            "{'loss': 0.2187, 'learning_rate': 4.455956836588098e-05, 'epoch': 2.49}\n",
            "{'loss': 0.1764, 'learning_rate': 4.455956836588098e-05, 'epoch': 2.54}\n",
            "{'loss': 0.2468, 'learning_rate': 4.455956836588098e-05, 'epoch': 2.6}\n",
            "{'loss': 0.1841, 'learning_rate': 4.455956836588098e-05, 'epoch': 2.65}\n",
            "{'loss': 0.2109, 'learning_rate': 4.455956836588098e-05, 'epoch': 2.71}\n",
            "{'loss': 0.2075, 'learning_rate': 4.455956836588098e-05, 'epoch': 2.76}\n",
            "{'loss': 0.3199, 'learning_rate': 4.455956836588098e-05, 'epoch': 2.82}\n",
            "{'loss': 0.4785, 'learning_rate': 4.455956836588098e-05, 'epoch': 2.87}\n",
            "{'loss': 0.4643, 'learning_rate': 4.455956836588098e-05, 'epoch': 2.93}\n",
            "{'loss': 0.2283, 'learning_rate': 4.455956836588098e-05, 'epoch': 2.98}\n",
            "{'loss': 0.0534, 'learning_rate': 4.455956836588098e-05, 'epoch': 3.04}\n",
            "{'loss': 0.0888, 'learning_rate': 4.455956836588098e-05, 'epoch': 3.09}\n",
            "{'loss': 0.073, 'learning_rate': 4.455956836588098e-05, 'epoch': 3.15}\n",
            "{'loss': 0.1917, 'learning_rate': 4.455956836588098e-05, 'epoch': 3.2}\n",
            "{'loss': 0.1439, 'learning_rate': 4.455956836588098e-05, 'epoch': 3.26}\n",
            "{'loss': 0.0007, 'learning_rate': 4.455956836588098e-05, 'epoch': 3.31}\n",
            "{'loss': 0.3143, 'learning_rate': 4.455956836588098e-05, 'epoch': 3.37}\n",
            "{'loss': 0.0754, 'learning_rate': 4.455956836588098e-05, 'epoch': 3.43}\n",
            "{'loss': 0.289, 'learning_rate': 4.455956836588098e-05, 'epoch': 3.48}\n",
            "{'loss': 0.1203, 'learning_rate': 4.455956836588098e-05, 'epoch': 3.54}\n",
            "{'loss': 0.1323, 'learning_rate': 4.455956836588098e-05, 'epoch': 3.59}\n",
            "{'loss': 0.2241, 'learning_rate': 4.455956836588098e-05, 'epoch': 3.65}\n",
            "{'loss': 0.1349, 'learning_rate': 4.455956836588098e-05, 'epoch': 3.7}\n",
            "{'loss': 0.1179, 'learning_rate': 4.455956836588098e-05, 'epoch': 3.76}\n",
            "{'loss': 0.161, 'learning_rate': 4.455956836588098e-05, 'epoch': 3.81}\n",
            "{'loss': 0.4443, 'learning_rate': 4.455956836588098e-05, 'epoch': 3.87}\n",
            "{'loss': 0.089, 'learning_rate': 4.455956836588098e-05, 'epoch': 3.92}\n",
            "{'loss': 0.2585, 'learning_rate': 4.455956836588098e-05, 'epoch': 3.98}\n",
            "{'loss': 0.061, 'learning_rate': 4.455956836588098e-05, 'epoch': 4.03}\n",
            "{'loss': 0.1527, 'learning_rate': 4.455956836588098e-05, 'epoch': 4.09}\n",
            "{'loss': 0.0549, 'learning_rate': 4.455956836588098e-05, 'epoch': 4.14}\n",
            "{'loss': 0.13, 'learning_rate': 4.455956836588098e-05, 'epoch': 4.2}\n",
            "{'loss': 0.1428, 'learning_rate': 4.455956836588098e-05, 'epoch': 4.25}\n",
            "{'loss': 0.0747, 'learning_rate': 4.455956836588098e-05, 'epoch': 4.31}\n",
            "{'loss': 0.0783, 'learning_rate': 4.455956836588098e-05, 'epoch': 4.36}\n",
            "{'loss': 0.0517, 'learning_rate': 4.455956836588098e-05, 'epoch': 4.42}\n",
            "{'loss': 0.052, 'learning_rate': 4.455956836588098e-05, 'epoch': 4.48}\n",
            "{'loss': 0.1523, 'learning_rate': 4.455956836588098e-05, 'epoch': 4.53}\n",
            "{'loss': 0.1878, 'learning_rate': 4.455956836588098e-05, 'epoch': 4.59}\n",
            "{'loss': 0.0069, 'learning_rate': 4.455956836588098e-05, 'epoch': 4.64}\n",
            "{'loss': 0.001, 'learning_rate': 4.455956836588098e-05, 'epoch': 4.7}\n",
            "{'loss': 0.0006, 'learning_rate': 4.455956836588098e-05, 'epoch': 4.75}\n",
            "{'loss': 0.228, 'learning_rate': 4.455956836588098e-05, 'epoch': 4.81}\n",
            "{'loss': 0.1014, 'learning_rate': 4.455956836588098e-05, 'epoch': 4.86}\n",
            "{'loss': 0.3559, 'learning_rate': 4.455956836588098e-05, 'epoch': 4.92}\n",
            "{'loss': 0.1289, 'learning_rate': 4.455956836588098e-05, 'epoch': 4.97}\n",
            "{'loss': 0.144, 'learning_rate': 4.455956836588098e-05, 'epoch': 5.03}\n",
            "{'loss': 0.0037, 'learning_rate': 4.455956836588098e-05, 'epoch': 5.08}\n",
            "{'loss': 0.0028, 'learning_rate': 4.455956836588098e-05, 'epoch': 5.14}\n",
            "{'loss': 0.135, 'learning_rate': 4.455956836588098e-05, 'epoch': 5.19}\n",
            "{'loss': 0.0534, 'learning_rate': 4.455956836588098e-05, 'epoch': 5.25}\n",
            "{'loss': 0.1473, 'learning_rate': 4.455956836588098e-05, 'epoch': 5.3}\n",
            "{'loss': 0.0014, 'learning_rate': 4.455956836588098e-05, 'epoch': 5.36}\n",
            "{'loss': 0.0282, 'learning_rate': 4.455956836588098e-05, 'epoch': 5.41}\n",
            "{'loss': 0.0244, 'learning_rate': 4.455956836588098e-05, 'epoch': 5.47}\n",
            "{'loss': 0.0007, 'learning_rate': 4.455956836588098e-05, 'epoch': 5.52}\n",
            "{'loss': 0.0568, 'learning_rate': 4.455956836588098e-05, 'epoch': 5.58}\n",
            "{'loss': 0.0981, 'learning_rate': 4.455956836588098e-05, 'epoch': 5.64}\n",
            "{'loss': 0.0008, 'learning_rate': 4.455956836588098e-05, 'epoch': 5.69}\n",
            "{'loss': 0.1391, 'learning_rate': 4.455956836588098e-05, 'epoch': 5.75}\n",
            "{'loss': 0.0999, 'learning_rate': 4.455956836588098e-05, 'epoch': 5.8}\n",
            "{'loss': 0.0614, 'learning_rate': 4.455956836588098e-05, 'epoch': 5.86}\n",
            "{'loss': 0.0005, 'learning_rate': 4.455956836588098e-05, 'epoch': 5.91}\n",
            "{'loss': 0.095, 'learning_rate': 4.455956836588098e-05, 'epoch': 5.97}\n",
            "{'loss': 0.0004, 'learning_rate': 4.455956836588098e-05, 'epoch': 6.02}\n",
            "{'loss': 0.0024, 'learning_rate': 4.455956836588098e-05, 'epoch': 6.08}\n",
            "{'loss': 0.0755, 'learning_rate': 4.455956836588098e-05, 'epoch': 6.13}\n",
            "{'loss': 0.0949, 'learning_rate': 4.455956836588098e-05, 'epoch': 6.19}\n",
            "{'loss': 0.0791, 'learning_rate': 4.455956836588098e-05, 'epoch': 6.24}\n",
            "{'loss': 0.0019, 'learning_rate': 4.455956836588098e-05, 'epoch': 6.3}\n",
            "{'loss': 0.0624, 'learning_rate': 4.455956836588098e-05, 'epoch': 6.35}\n",
            "{'loss': 0.0882, 'learning_rate': 4.455956836588098e-05, 'epoch': 6.41}\n",
            "{'loss': 0.0007, 'learning_rate': 4.455956836588098e-05, 'epoch': 6.46}\n",
            "{'loss': 0.0061, 'learning_rate': 4.455956836588098e-05, 'epoch': 6.52}\n",
            "{'loss': 0.0004, 'learning_rate': 4.455956836588098e-05, 'epoch': 6.57}\n",
            "{'loss': 0.0004, 'learning_rate': 4.455956836588098e-05, 'epoch': 6.63}\n",
            "{'loss': 0.0003, 'learning_rate': 4.455956836588098e-05, 'epoch': 6.69}\n",
            "{'loss': 0.0855, 'learning_rate': 4.455956836588098e-05, 'epoch': 6.74}\n",
            "{'loss': 0.0004, 'learning_rate': 4.455956836588098e-05, 'epoch': 6.8}\n",
            "{'loss': 0.1038, 'learning_rate': 4.455956836588098e-05, 'epoch': 6.85}\n",
            "{'loss': 0.0923, 'learning_rate': 4.455956836588098e-05, 'epoch': 6.91}\n",
            "{'loss': 0.0591, 'learning_rate': 4.455956836588098e-05, 'epoch': 6.96}\n",
            "{'loss': 0.0007, 'learning_rate': 4.455956836588098e-05, 'epoch': 7.02}\n",
            "{'loss': 0.0259, 'learning_rate': 4.455956836588098e-05, 'epoch': 7.07}\n",
            "{'loss': 0.0003, 'learning_rate': 4.455956836588098e-05, 'epoch': 7.13}\n",
            "{'loss': 0.0884, 'learning_rate': 4.455956836588098e-05, 'epoch': 7.18}\n",
            "{'loss': 0.0003, 'learning_rate': 4.455956836588098e-05, 'epoch': 7.24}\n",
            "{'loss': 0.0004, 'learning_rate': 4.455956836588098e-05, 'epoch': 7.29}\n",
            "{'loss': 0.0002, 'learning_rate': 4.455956836588098e-05, 'epoch': 7.35}\n",
            "{'loss': 0.0002, 'learning_rate': 4.455956836588098e-05, 'epoch': 7.4}\n",
            "{'loss': 0.0002, 'learning_rate': 4.455956836588098e-05, 'epoch': 7.46}\n",
            "{'loss': 0.109, 'learning_rate': 4.455956836588098e-05, 'epoch': 7.51}\n",
            "{'loss': 0.0004, 'learning_rate': 4.455956836588098e-05, 'epoch': 7.57}\n",
            "{'loss': 0.0006, 'learning_rate': 4.455956836588098e-05, 'epoch': 7.62}\n",
            "{'loss': 0.0004, 'learning_rate': 4.455956836588098e-05, 'epoch': 7.68}\n",
            "{'loss': 0.0004, 'learning_rate': 4.455956836588098e-05, 'epoch': 7.73}\n",
            "{'loss': 0.0004, 'learning_rate': 4.455956836588098e-05, 'epoch': 7.79}\n",
            "{'loss': 0.0003, 'learning_rate': 4.455956836588098e-05, 'epoch': 7.85}\n",
            "{'loss': 0.0003, 'learning_rate': 4.455956836588098e-05, 'epoch': 7.9}\n",
            "{'loss': 0.0002, 'learning_rate': 4.455956836588098e-05, 'epoch': 7.96}\n",
            "{'loss': 0.1039, 'learning_rate': 4.455956836588098e-05, 'epoch': 8.01}\n",
            "{'loss': 0.0004, 'learning_rate': 4.455956836588098e-05, 'epoch': 8.07}\n",
            "{'loss': 0.0009, 'learning_rate': 4.455956836588098e-05, 'epoch': 8.12}\n",
            "{'loss': 0.0004, 'learning_rate': 4.455956836588098e-05, 'epoch': 8.18}\n",
            "{'loss': 0.0003, 'learning_rate': 4.455956836588098e-05, 'epoch': 8.23}\n",
            "{'loss': 0.0379, 'learning_rate': 4.455956836588098e-05, 'epoch': 8.29}\n",
            "{'loss': 0.0975, 'learning_rate': 4.455956836588098e-05, 'epoch': 8.34}\n",
            "{'loss': 0.0026, 'learning_rate': 4.455956836588098e-05, 'epoch': 8.4}\n",
            "{'loss': 0.0012, 'learning_rate': 4.455956836588098e-05, 'epoch': 8.45}\n",
            "{'loss': 0.0084, 'learning_rate': 4.455956836588098e-05, 'epoch': 8.51}\n",
            "{'loss': 0.1017, 'learning_rate': 4.455956836588098e-05, 'epoch': 8.56}\n",
            "{'loss': 0.0005, 'learning_rate': 4.455956836588098e-05, 'epoch': 8.62}\n",
            "{'loss': 0.0774, 'learning_rate': 4.455956836588098e-05, 'epoch': 8.67}\n",
            "{'loss': 0.0003, 'learning_rate': 4.455956836588098e-05, 'epoch': 8.73}\n",
            "{'loss': 0.0003, 'learning_rate': 4.455956836588098e-05, 'epoch': 8.78}\n",
            "{'loss': 0.0824, 'learning_rate': 4.455956836588098e-05, 'epoch': 8.84}\n",
            "{'loss': 0.0003, 'learning_rate': 4.455956836588098e-05, 'epoch': 8.9}\n",
            "{'loss': 0.0003, 'learning_rate': 4.455956836588098e-05, 'epoch': 8.95}\n",
            "{'loss': 0.0004, 'learning_rate': 4.455956836588098e-05, 'epoch': 9.01}\n",
            "{'loss': 0.1009, 'learning_rate': 4.455956836588098e-05, 'epoch': 9.06}\n",
            "{'loss': 0.079, 'learning_rate': 4.455956836588098e-05, 'epoch': 9.12}\n",
            "{'loss': 0.0013, 'learning_rate': 4.455956836588098e-05, 'epoch': 9.17}\n",
            "{'loss': 0.0007, 'learning_rate': 4.455956836588098e-05, 'epoch': 9.23}\n",
            "{'loss': 0.0004, 'learning_rate': 4.455956836588098e-05, 'epoch': 9.28}\n",
            "{'loss': 0.0005, 'learning_rate': 4.455956836588098e-05, 'epoch': 9.34}\n",
            "{'loss': 0.0989, 'learning_rate': 4.455956836588098e-05, 'epoch': 9.39}\n",
            "{'loss': 0.0008, 'learning_rate': 4.455956836588098e-05, 'epoch': 9.45}\n",
            "{'loss': 0.001, 'learning_rate': 4.455956836588098e-05, 'epoch': 9.5}\n",
            "{'loss': 0.0008, 'learning_rate': 4.455956836588098e-05, 'epoch': 9.56}\n",
            "{'loss': 0.0005, 'learning_rate': 4.455956836588098e-05, 'epoch': 9.61}\n",
            "{'loss': 0.067, 'learning_rate': 4.455956836588098e-05, 'epoch': 9.67}\n",
            "{'loss': 0.0052, 'learning_rate': 4.455956836588098e-05, 'epoch': 9.72}\n",
            "{'loss': 0.0003, 'learning_rate': 4.455956836588098e-05, 'epoch': 9.78}\n",
            "{'loss': 0.0002, 'learning_rate': 4.455956836588098e-05, 'epoch': 9.83}\n",
            "{'loss': 0.0002, 'learning_rate': 4.455956836588098e-05, 'epoch': 9.89}\n",
            "{'loss': 0.0002, 'learning_rate': 4.455956836588098e-05, 'epoch': 9.94}\n",
            "{'loss': 0.0002, 'learning_rate': 4.455956836588098e-05, 'epoch': 10.0}\n",
            "{'train_runtime': 184.921, 'train_samples_per_second': 78.141, 'train_steps_per_second': 9.788, 'train_loss': 0.17193713861598647, 'epoch': 10.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 52/52 [00:01<00:00, 37.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 21:40:34,668] Trial 4 finished with value: 0.9168765743073047 and parameters: {'learning_rate': 4.455956836588098e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.21150147286090934, 'num_train_epochs': 10, 'warmup_steps': 137, 'freeze_layers': 0, 'dropout': 0.10500475121320228, 'lr_scheduler_type': 'constant_with_warmup'}. Best is trial 4 with value: 0.9168765743073047.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: constant_with_warmup\n",
            " Warmup steps (True): 191\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f9d302c7b8d4a81827897b7b3f1d981",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/322 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7128, 'learning_rate': 3.017871944884388e-06, 'epoch': 0.22}\n",
            "{'loss': 0.7063, 'learning_rate': 5.7004247847816215e-06, 'epoch': 0.43}\n",
            "{'loss': 0.6908, 'learning_rate': 9.053615834653165e-06, 'epoch': 0.65}\n",
            "{'loss': 0.6712, 'learning_rate': 1.2071487779537553e-05, 'epoch': 0.87}\n",
            "{'loss': 0.6603, 'learning_rate': 1.5424678829409093e-05, 'epoch': 1.09}\n",
            "{'loss': 0.6541, 'learning_rate': 1.8777869879280634e-05, 'epoch': 1.3}\n",
            "{'loss': 0.6491, 'learning_rate': 2.2131060929152178e-05, 'epoch': 1.52}\n",
            "{'loss': 0.6044, 'learning_rate': 2.548425197902372e-05, 'epoch': 1.74}\n",
            "{'loss': 0.5461, 'learning_rate': 2.8837443028895262e-05, 'epoch': 1.96}\n",
            "{'loss': 0.4816, 'learning_rate': 3.21906340787668e-05, 'epoch': 2.17}\n",
            "{'loss': 0.4428, 'learning_rate': 3.554382512863835e-05, 'epoch': 2.39}\n",
            "{'loss': 0.3709, 'learning_rate': 3.889701617850989e-05, 'epoch': 2.61}\n",
            "{'loss': 0.3107, 'learning_rate': 4.225020722838144e-05, 'epoch': 2.83}\n",
            "{'loss': 0.4874, 'learning_rate': 4.560339827825297e-05, 'epoch': 3.04}\n",
            "{'loss': 0.2541, 'learning_rate': 4.895658932812452e-05, 'epoch': 3.26}\n",
            "{'loss': 0.238, 'learning_rate': 5.230978037799606e-05, 'epoch': 3.48}\n",
            "{'loss': 0.2554, 'learning_rate': 5.566297142786761e-05, 'epoch': 3.7}\n",
            "{'loss': 0.2464, 'learning_rate': 5.901616247773914e-05, 'epoch': 3.91}\n",
            "{'loss': 0.1333, 'learning_rate': 6.23693535276107e-05, 'epoch': 4.13}\n",
            "{'loss': 0.1351, 'learning_rate': 6.404594905254646e-05, 'epoch': 4.35}\n",
            "{'loss': 0.3005, 'learning_rate': 6.404594905254646e-05, 'epoch': 4.57}\n",
            "{'loss': 0.2673, 'learning_rate': 6.404594905254646e-05, 'epoch': 4.78}\n",
            "{'loss': 0.1651, 'learning_rate': 6.404594905254646e-05, 'epoch': 5.0}\n",
            "{'loss': 0.1341, 'learning_rate': 6.404594905254646e-05, 'epoch': 5.22}\n",
            "{'loss': 0.1522, 'learning_rate': 6.404594905254646e-05, 'epoch': 5.43}\n",
            "{'loss': 0.1345, 'learning_rate': 6.404594905254646e-05, 'epoch': 5.65}\n",
            "{'loss': 0.0965, 'learning_rate': 6.404594905254646e-05, 'epoch': 5.87}\n",
            "{'loss': 0.1018, 'learning_rate': 6.404594905254646e-05, 'epoch': 6.09}\n",
            "{'loss': 0.084, 'learning_rate': 6.404594905254646e-05, 'epoch': 6.3}\n",
            "{'loss': 0.0918, 'learning_rate': 6.404594905254646e-05, 'epoch': 6.52}\n",
            "{'loss': 0.0892, 'learning_rate': 6.404594905254646e-05, 'epoch': 6.74}\n",
            "{'loss': 0.1788, 'learning_rate': 6.404594905254646e-05, 'epoch': 6.96}\n",
            "{'train_runtime': 89.6548, 'train_samples_per_second': 112.822, 'train_steps_per_second': 3.592, 'train_loss': 0.3440503431773334, 'epoch': 7.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 13/13 [00:00<00:00, 13.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 21:42:07,816] Trial 5 finished with value: 0.88 and parameters: {'learning_rate': 6.404594905254646e-05, 'per_device_train_batch_size': 32, 'weight_decay': 0.2534020404300848, 'num_train_epochs': 7, 'warmup_steps': 191, 'freeze_layers': 0, 'dropout': 0.2931745250364981, 'lr_scheduler_type': 'constant_with_warmup'}. Best is trial 4 with value: 0.9168765743073047.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: polynomial\n",
            " Warmup steps (True): 146\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e9406be947c042fbbeb0f0cbf60002d8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1086 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7176, 'learning_rate': 1.965738058038252e-06, 'epoch': 0.06}\n",
            "{'loss': 0.7321, 'learning_rate': 4.773935283807184e-06, 'epoch': 0.11}\n",
            "{'loss': 0.6836, 'learning_rate': 7.020493064422328e-06, 'epoch': 0.17}\n",
            "{'loss': 0.6872, 'learning_rate': 9.82869029019126e-06, 'epoch': 0.22}\n",
            "{'loss': 0.7232, 'learning_rate': 1.2636887515960193e-05, 'epoch': 0.28}\n",
            "{'loss': 0.6902, 'learning_rate': 1.5445084741729125e-05, 'epoch': 0.33}\n",
            "{'loss': 0.6776, 'learning_rate': 1.8253281967498056e-05, 'epoch': 0.39}\n",
            "{'loss': 0.7316, 'learning_rate': 2.106147919326699e-05, 'epoch': 0.44}\n",
            "{'loss': 0.6555, 'learning_rate': 2.3869676419035917e-05, 'epoch': 0.5}\n",
            "{'loss': 0.5897, 'learning_rate': 2.667787364480485e-05, 'epoch': 0.55}\n",
            "{'loss': 0.6318, 'learning_rate': 2.9486070870573782e-05, 'epoch': 0.61}\n",
            "{'loss': 0.564, 'learning_rate': 3.229426809634271e-05, 'epoch': 0.66}\n",
            "{'loss': 0.4827, 'learning_rate': 3.510246532211164e-05, 'epoch': 0.72}\n",
            "{'loss': 0.4743, 'learning_rate': 3.791066254788058e-05, 'epoch': 0.77}\n",
            "{'loss': 0.5247, 'learning_rate': 4.0718859773649504e-05, 'epoch': 0.83}\n",
            "{'loss': 0.3143, 'learning_rate': 4.0608086820198696e-05, 'epoch': 0.88}\n",
            "{'loss': 0.4017, 'learning_rate': 4.017298384683459e-05, 'epoch': 0.94}\n",
            "{'loss': 0.8944, 'learning_rate': 3.973788087347048e-05, 'epoch': 0.99}\n",
            "{'loss': 0.5417, 'learning_rate': 3.930277790010637e-05, 'epoch': 1.05}\n",
            "{'loss': 0.3806, 'learning_rate': 3.886767492674226e-05, 'epoch': 1.1}\n",
            "{'loss': 0.513, 'learning_rate': 3.843257195337815e-05, 'epoch': 1.16}\n",
            "{'loss': 0.5491, 'learning_rate': 3.799746898001404e-05, 'epoch': 1.22}\n",
            "{'loss': 0.2759, 'learning_rate': 3.7562366006649925e-05, 'epoch': 1.27}\n",
            "{'loss': 0.4086, 'learning_rate': 3.712726303328582e-05, 'epoch': 1.33}\n",
            "{'loss': 0.4532, 'learning_rate': 3.6692160059921704e-05, 'epoch': 1.38}\n",
            "{'loss': 0.3441, 'learning_rate': 3.62570570865576e-05, 'epoch': 1.44}\n",
            "{'loss': 0.3267, 'learning_rate': 3.582195411319349e-05, 'epoch': 1.49}\n",
            "{'loss': 0.4353, 'learning_rate': 3.5386851139829376e-05, 'epoch': 1.55}\n",
            "{'loss': 0.3724, 'learning_rate': 3.495174816646526e-05, 'epoch': 1.6}\n",
            "{'loss': 0.3633, 'learning_rate': 3.4516645193101154e-05, 'epoch': 1.66}\n",
            "{'loss': 0.3683, 'learning_rate': 3.408154221973704e-05, 'epoch': 1.71}\n",
            "{'loss': 0.5058, 'learning_rate': 3.3646439246372926e-05, 'epoch': 1.77}\n",
            "{'loss': 0.2572, 'learning_rate': 3.321133627300882e-05, 'epoch': 1.82}\n",
            "{'loss': 0.3243, 'learning_rate': 3.277623329964471e-05, 'epoch': 1.88}\n",
            "{'loss': 0.3226, 'learning_rate': 3.23411303262806e-05, 'epoch': 1.93}\n",
            "{'loss': 0.3991, 'learning_rate': 3.190602735291649e-05, 'epoch': 1.99}\n",
            "{'loss': 0.2586, 'learning_rate': 3.1470924379552377e-05, 'epoch': 2.04}\n",
            "{'loss': 0.0941, 'learning_rate': 3.103582140618826e-05, 'epoch': 2.1}\n",
            "{'loss': 0.2837, 'learning_rate': 3.0600718432824155e-05, 'epoch': 2.15}\n",
            "{'loss': 0.4429, 'learning_rate': 3.0165615459460045e-05, 'epoch': 2.21}\n",
            "{'loss': 0.1573, 'learning_rate': 2.973051248609593e-05, 'epoch': 2.27}\n",
            "{'loss': 0.2812, 'learning_rate': 2.9295409512731827e-05, 'epoch': 2.32}\n",
            "{'loss': 0.2767, 'learning_rate': 2.886030653936771e-05, 'epoch': 2.38}\n",
            "{'loss': 0.2203, 'learning_rate': 2.8468713863340015e-05, 'epoch': 2.43}\n",
            "{'loss': 0.2998, 'learning_rate': 2.8033610889975898e-05, 'epoch': 2.49}\n",
            "{'loss': 0.3733, 'learning_rate': 2.7598507916611794e-05, 'epoch': 2.54}\n",
            "{'loss': 0.3077, 'learning_rate': 2.716340494324768e-05, 'epoch': 2.6}\n",
            "{'loss': 0.2531, 'learning_rate': 2.6728301969883566e-05, 'epoch': 2.65}\n",
            "{'loss': 0.1274, 'learning_rate': 2.629319899651946e-05, 'epoch': 2.71}\n",
            "{'loss': 0.3315, 'learning_rate': 2.5858096023155348e-05, 'epoch': 2.76}\n",
            "{'loss': 0.2574, 'learning_rate': 2.5422993049791234e-05, 'epoch': 2.82}\n",
            "{'loss': 0.2465, 'learning_rate': 2.4987890076427123e-05, 'epoch': 2.87}\n",
            "{'loss': 0.296, 'learning_rate': 2.4552787103063016e-05, 'epoch': 2.93}\n",
            "{'loss': 0.1984, 'learning_rate': 2.4117684129698905e-05, 'epoch': 2.98}\n",
            "{'loss': 0.147, 'learning_rate': 2.3682581156334795e-05, 'epoch': 3.04}\n",
            "{'loss': 0.0601, 'learning_rate': 2.3247478182970684e-05, 'epoch': 3.09}\n",
            "{'loss': 0.0033, 'learning_rate': 2.2812375209606573e-05, 'epoch': 3.15}\n",
            "{'loss': 0.0452, 'learning_rate': 2.2377272236242463e-05, 'epoch': 3.2}\n",
            "{'loss': 0.1319, 'learning_rate': 2.1942169262878356e-05, 'epoch': 3.26}\n",
            "{'loss': 0.0011, 'learning_rate': 2.1507066289514238e-05, 'epoch': 3.31}\n",
            "{'loss': 0.3174, 'learning_rate': 2.107196331615013e-05, 'epoch': 3.37}\n",
            "{'loss': 0.078, 'learning_rate': 2.0636860342786024e-05, 'epoch': 3.43}\n",
            "{'loss': 0.1311, 'learning_rate': 2.020175736942191e-05, 'epoch': 3.48}\n",
            "{'loss': 0.1352, 'learning_rate': 1.97666543960578e-05, 'epoch': 3.54}\n",
            "{'loss': 0.0811, 'learning_rate': 1.9331551422693685e-05, 'epoch': 3.59}\n",
            "{'loss': 0.4014, 'learning_rate': 1.8896448449329578e-05, 'epoch': 3.65}\n",
            "{'loss': 0.0544, 'learning_rate': 1.8461345475965467e-05, 'epoch': 3.7}\n",
            "{'loss': 0.0048, 'learning_rate': 1.8026242502601357e-05, 'epoch': 3.76}\n",
            "{'loss': 0.0231, 'learning_rate': 1.7591139529237246e-05, 'epoch': 3.81}\n",
            "{'loss': 0.0849, 'learning_rate': 1.715603655587314e-05, 'epoch': 3.87}\n",
            "{'loss': 0.1648, 'learning_rate': 1.6720933582509025e-05, 'epoch': 3.92}\n",
            "{'loss': 0.2083, 'learning_rate': 1.6285830609144914e-05, 'epoch': 3.98}\n",
            "{'loss': 0.1069, 'learning_rate': 1.58507276357808e-05, 'epoch': 4.03}\n",
            "{'loss': 0.1705, 'learning_rate': 1.5415624662416693e-05, 'epoch': 4.09}\n",
            "{'loss': 0.1368, 'learning_rate': 1.4980521689052586e-05, 'epoch': 4.14}\n",
            "{'loss': 0.0254, 'learning_rate': 1.4545418715688473e-05, 'epoch': 4.2}\n",
            "{'loss': 0.0842, 'learning_rate': 1.4110315742324363e-05, 'epoch': 4.25}\n",
            "{'loss': 0.0779, 'learning_rate': 1.3675212768960252e-05, 'epoch': 4.31}\n",
            "{'loss': 0.0662, 'learning_rate': 1.324010979559614e-05, 'epoch': 4.36}\n",
            "{'loss': 0.0022, 'learning_rate': 1.2805006822232031e-05, 'epoch': 4.42}\n",
            "{'loss': 0.0496, 'learning_rate': 1.2369903848867922e-05, 'epoch': 4.48}\n",
            "{'loss': 0.0747, 'learning_rate': 1.1934800875503808e-05, 'epoch': 4.53}\n",
            "{'loss': 0.0291, 'learning_rate': 1.1499697902139699e-05, 'epoch': 4.59}\n",
            "{'loss': 0.0962, 'learning_rate': 1.106459492877559e-05, 'epoch': 4.64}\n",
            "{'loss': 0.0308, 'learning_rate': 1.0629491955411478e-05, 'epoch': 4.7}\n",
            "{'loss': 0.001, 'learning_rate': 1.0194388982047369e-05, 'epoch': 4.75}\n",
            "{'loss': 0.0862, 'learning_rate': 9.759286008683255e-06, 'epoch': 4.81}\n",
            "{'loss': 0.0673, 'learning_rate': 9.324183035319146e-06, 'epoch': 4.86}\n",
            "{'loss': 0.0421, 'learning_rate': 8.889080061955037e-06, 'epoch': 4.92}\n",
            "{'loss': 0.1368, 'learning_rate': 8.453977088590923e-06, 'epoch': 4.97}\n",
            "{'loss': 0.138, 'learning_rate': 8.018874115226814e-06, 'epoch': 5.03}\n",
            "{'loss': 0.0008, 'learning_rate': 7.583771141862705e-06, 'epoch': 5.08}\n",
            "{'loss': 0.0461, 'learning_rate': 7.148668168498591e-06, 'epoch': 5.14}\n",
            "{'loss': 0.0007, 'learning_rate': 6.713565195134482e-06, 'epoch': 5.19}\n",
            "{'loss': 0.0365, 'learning_rate': 6.278462221770372e-06, 'epoch': 5.25}\n",
            "{'loss': 0.0978, 'learning_rate': 5.843359248406259e-06, 'epoch': 5.3}\n",
            "{'loss': 0.1566, 'learning_rate': 5.40825627504215e-06, 'epoch': 5.36}\n",
            "{'loss': 0.0009, 'learning_rate': 4.973153301678037e-06, 'epoch': 5.41}\n",
            "{'loss': 0.0024, 'learning_rate': 4.538050328313928e-06, 'epoch': 5.47}\n",
            "{'loss': 0.0692, 'learning_rate': 4.1029473549498185e-06, 'epoch': 5.52}\n",
            "{'loss': 0.0021, 'learning_rate': 3.6678443815857057e-06, 'epoch': 5.58}\n",
            "{'loss': 0.0007, 'learning_rate': 3.232741408221596e-06, 'epoch': 5.64}\n",
            "{'loss': 0.0007, 'learning_rate': 2.7976384348574874e-06, 'epoch': 5.69}\n",
            "{'loss': 0.0716, 'learning_rate': 2.362535461493374e-06, 'epoch': 5.75}\n",
            "{'loss': 0.071, 'learning_rate': 1.927432488129265e-06, 'epoch': 5.8}\n",
            "{'loss': 0.0006, 'learning_rate': 1.492329514765156e-06, 'epoch': 5.86}\n",
            "{'loss': 0.0019, 'learning_rate': 1.0572265414010424e-06, 'epoch': 5.91}\n",
            "{'loss': 0.1483, 'learning_rate': 6.221235680369335e-07, 'epoch': 5.97}\n",
            "{'train_runtime': 124.8174, 'train_samples_per_second': 69.461, 'train_steps_per_second': 8.701, 'train_loss': 0.25070869335373025, 'epoch': 6.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 52/52 [00:01<00:00, 40.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 21:44:16,403] Trial 6 finished with value: 0.910025706940874 and parameters: {'learning_rate': 4.09996794962264e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.21117686622845075, 'num_train_epochs': 6, 'warmup_steps': 146, 'freeze_layers': 3, 'dropout': 0.3337858428286894, 'lr_scheduler_type': 'polynomial'}. Best is trial 4 with value: 0.9168765743073047.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: cosine_with_restarts\n",
            " Warmup steps (True): 17\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d9d41816e2d4ce2b1a2b1dcd91fcd71",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1448 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7051, 'learning_rate': 8.666158116913312e-06, 'epoch': 0.06}\n",
            "{'loss': 0.7462, 'learning_rate': 2.1665395292283274e-05, 'epoch': 0.11}\n",
            "{'loss': 0.7141, 'learning_rate': 2.455222121574195e-05, 'epoch': 0.17}\n",
            "{'loss': 0.7371, 'learning_rate': 2.454453008076273e-05, 'epoch': 0.22}\n",
            "{'loss': 0.6343, 'learning_rate': 2.453092662299678e-05, 'epoch': 0.28}\n",
            "{'loss': 0.6784, 'learning_rate': 2.4511417398646418e-05, 'epoch': 0.33}\n",
            "{'loss': 0.6252, 'learning_rate': 2.4486011810205065e-05, 'epoch': 0.39}\n",
            "{'loss': 0.6996, 'learning_rate': 2.4454722101925665e-05, 'epoch': 0.44}\n",
            "{'loss': 0.6336, 'learning_rate': 2.4417563353919595e-05, 'epoch': 0.5}\n",
            "{'loss': 0.5725, 'learning_rate': 2.4374553474888758e-05, 'epoch': 0.55}\n",
            "{'loss': 0.5725, 'learning_rate': 2.4325713193494467e-05, 'epoch': 0.61}\n",
            "{'loss': 0.5409, 'learning_rate': 2.4276791343014845e-05, 'epoch': 0.66}\n",
            "{'loss': 0.4343, 'learning_rate': 2.4216940459376628e-05, 'epoch': 0.72}\n",
            "{'loss': 0.4981, 'learning_rate': 2.4151335135151455e-05, 'epoch': 0.77}\n",
            "{'loss': 0.5172, 'learning_rate': 2.408000698890179e-05, 'epoch': 0.83}\n",
            "{'loss': 0.3488, 'learning_rate': 2.400299039731084e-05, 'epoch': 0.88}\n",
            "{'loss': 0.4402, 'learning_rate': 2.3920322478614668e-05, 'epoch': 0.94}\n",
            "{'loss': 0.7572, 'learning_rate': 2.383204307471303e-05, 'epoch': 0.99}\n",
            "{'loss': 0.3982, 'learning_rate': 2.3738194731967505e-05, 'epoch': 1.05}\n",
            "{'loss': 0.2819, 'learning_rate': 2.3638822680696247e-05, 'epoch': 1.1}\n",
            "{'loss': 0.5957, 'learning_rate': 2.353397481337517e-05, 'epoch': 1.16}\n",
            "{'loss': 0.3974, 'learning_rate': 2.34237016615561e-05, 'epoch': 1.22}\n",
            "{'loss': 0.292, 'learning_rate': 2.3308056371513073e-05, 'epoch': 1.27}\n",
            "{'loss': 0.4674, 'learning_rate': 2.3187094678628378e-05, 'epoch': 1.33}\n",
            "{'loss': 0.4755, 'learning_rate': 2.306087488053087e-05, 'epoch': 1.38}\n",
            "{'loss': 0.386, 'learning_rate': 2.292945780899933e-05, 'epoch': 1.44}\n",
            "{'loss': 0.2948, 'learning_rate': 2.2792906800644517e-05, 'epoch': 1.49}\n",
            "{'loss': 0.4001, 'learning_rate': 2.265128766638404e-05, 'epoch': 1.55}\n",
            "{'loss': 0.2142, 'learning_rate': 2.250466865972469e-05, 'epoch': 1.6}\n",
            "{'loss': 0.3374, 'learning_rate': 2.235312044386758e-05, 'epoch': 1.66}\n",
            "{'loss': 0.4796, 'learning_rate': 2.2196716057651957e-05, 'epoch': 1.71}\n",
            "{'loss': 0.4623, 'learning_rate': 2.2035530880354005e-05, 'epoch': 1.77}\n",
            "{'loss': 0.3675, 'learning_rate': 2.186964259535776e-05, 'epoch': 1.82}\n",
            "{'loss': 0.2976, 'learning_rate': 2.1699131152715495e-05, 'epoch': 1.88}\n",
            "{'loss': 0.6251, 'learning_rate': 2.1524078730615688e-05, 'epoch': 1.93}\n",
            "{'loss': 0.2834, 'learning_rate': 2.134456969577717e-05, 'epoch': 1.99}\n",
            "{'loss': 0.2137, 'learning_rate': 2.116069056278846e-05, 'epoch': 2.04}\n",
            "{'loss': 0.2852, 'learning_rate': 2.099153611140694e-05, 'epoch': 2.1}\n",
            "{'loss': 0.2526, 'learning_rate': 2.079959964848413e-05, 'epoch': 2.15}\n",
            "{'loss': 0.2631, 'learning_rate': 2.0603555736360497e-05, 'epoch': 2.21}\n",
            "{'loss': 0.2271, 'learning_rate': 2.0403498858627934e-05, 'epoch': 2.27}\n",
            "{'loss': 0.2767, 'learning_rate': 2.0199525432931808e-05, 'epoch': 2.32}\n",
            "{'loss': 0.2994, 'learning_rate': 1.999173376450232e-05, 'epoch': 2.38}\n",
            "{'loss': 0.1305, 'learning_rate': 1.978022399877621e-05, 'epoch': 2.43}\n",
            "{'loss': 0.2807, 'learning_rate': 1.956509807313156e-05, 'epoch': 2.49}\n",
            "{'loss': 0.2489, 'learning_rate': 1.9346459667758915e-05, 'epoch': 2.54}\n",
            "{'loss': 0.3255, 'learning_rate': 1.9124414155692534e-05, 'epoch': 2.6}\n",
            "{'loss': 0.2122, 'learning_rate': 1.8899068552025716e-05, 'epoch': 2.65}\n",
            "{'loss': 0.1845, 'learning_rate': 1.8670531462334745e-05, 'epoch': 2.71}\n",
            "{'loss': 0.2414, 'learning_rate': 1.843891303033632e-05, 'epoch': 2.76}\n",
            "{'loss': 0.2179, 'learning_rate': 1.820432488480365e-05, 'epoch': 2.82}\n",
            "{'loss': 0.3013, 'learning_rate': 1.7966880085766854e-05, 'epoch': 2.87}\n",
            "{'loss': 0.4184, 'learning_rate': 1.7726693070023514e-05, 'epoch': 2.93}\n",
            "{'loss': 0.1538, 'learning_rate': 1.748387959598578e-05, 'epoch': 2.98}\n",
            "{'loss': 0.1094, 'learning_rate': 1.7238556687890416e-05, 'epoch': 3.04}\n",
            "{'loss': 0.0879, 'learning_rate': 1.6990842579398856e-05, 'epoch': 3.09}\n",
            "{'loss': 0.0829, 'learning_rate': 1.6740856656614354e-05, 'epoch': 3.15}\n",
            "{'loss': 0.2014, 'learning_rate': 1.6488719400543716e-05, 'epoch': 3.2}\n",
            "{'loss': 0.2217, 'learning_rate': 1.623455232903133e-05, 'epoch': 3.26}\n",
            "{'loss': 0.1155, 'learning_rate': 1.597847793819349e-05, 'epoch': 3.31}\n",
            "{'loss': 0.3792, 'learning_rate': 1.5720619643381275e-05, 'epoch': 3.37}\n",
            "{'loss': 0.109, 'learning_rate': 1.5461101719700357e-05, 'epoch': 3.43}\n",
            "{'loss': 0.1449, 'learning_rate': 1.5200049242116483e-05, 'epoch': 3.48}\n",
            "{'loss': 0.1713, 'learning_rate': 1.493758802517543e-05, 'epoch': 3.54}\n",
            "{'loss': 0.1392, 'learning_rate': 1.4673844562366557e-05, 'epoch': 3.59}\n",
            "{'loss': 0.3777, 'learning_rate': 1.4408945965159112e-05, 'epoch': 3.65}\n",
            "{'loss': 0.1624, 'learning_rate': 1.414301990174071e-05, 'epoch': 3.7}\n",
            "{'loss': 0.1745, 'learning_rate': 1.3876194535487509e-05, 'epoch': 3.76}\n",
            "{'loss': 0.1761, 'learning_rate': 1.3608598463195717e-05, 'epoch': 3.81}\n",
            "{'loss': 0.3768, 'learning_rate': 1.3340360653104203e-05, 'epoch': 3.87}\n",
            "{'loss': 0.1378, 'learning_rate': 1.3071610382738132e-05, 'epoch': 3.92}\n",
            "{'loss': 0.2797, 'learning_rate': 1.2802477176603485e-05, 'epoch': 3.98}\n",
            "{'loss': 0.0067, 'learning_rate': 1.2533090743762588e-05, 'epoch': 4.03}\n",
            "{'loss': 0.0606, 'learning_rate': 1.2263580915320666e-05, 'epoch': 4.09}\n",
            "{'loss': 0.0037, 'learning_rate': 1.1994077581853616e-05, 'epoch': 4.14}\n",
            "{'loss': 0.1462, 'learning_rate': 1.1724710630807053e-05, 'epoch': 4.2}\n",
            "{'loss': 0.0972, 'learning_rate': 1.1455609883896935e-05, 'epoch': 4.25}\n",
            "{'loss': 0.0858, 'learning_rate': 1.1186905034541822e-05, 'epoch': 4.31}\n",
            "{'loss': 0.0734, 'learning_rate': 1.0918725585356997e-05, 'epoch': 4.36}\n",
            "{'loss': 0.0528, 'learning_rate': 1.0651200785740509e-05, 'epoch': 4.42}\n",
            "{'loss': 0.0873, 'learning_rate': 1.038445956958128e-05, 'epoch': 4.48}\n",
            "{'loss': 0.0248, 'learning_rate': 1.011863049311929e-05, 'epoch': 4.53}\n",
            "{'loss': 0.0827, 'learning_rate': 9.853841672987708e-06, 'epoch': 4.59}\n",
            "{'loss': 0.2503, 'learning_rate': 9.590220724466968e-06, 'epoch': 4.64}\n",
            "{'loss': 0.0028, 'learning_rate': 9.327894699980404e-06, 'epoch': 4.7}\n",
            "{'loss': 0.076, 'learning_rate': 9.06699002786122e-06, 'epoch': 4.75}\n",
            "{'loss': 0.2571, 'learning_rate': 8.807632451420188e-06, 'epoch': 4.81}\n",
            "{'loss': 0.0235, 'learning_rate': 8.549946968343502e-06, 'epoch': 4.86}\n",
            "{'loss': 0.101, 'learning_rate': 8.294057770450022e-06, 'epoch': 4.92}\n",
            "{'loss': 0.1876, 'learning_rate': 8.040088183836861e-06, 'epoch': 4.97}\n",
            "{'loss': 0.0424, 'learning_rate': 7.788160609442254e-06, 'epoch': 5.03}\n",
            "{'loss': 0.0301, 'learning_rate': 7.538396464054252e-06, 'epoch': 5.08}\n",
            "{'loss': 0.0597, 'learning_rate': 7.290916121793779e-06, 'epoch': 5.14}\n",
            "{'loss': 0.0634, 'learning_rate': 7.045838856100192e-06, 'epoch': 5.19}\n",
            "{'loss': 0.0525, 'learning_rate': 6.803282782247277e-06, 'epoch': 5.25}\n",
            "{'loss': 0.0962, 'learning_rate': 6.563364800417493e-06, 'epoch': 5.3}\n",
            "{'loss': 0.0607, 'learning_rate': 6.326200539361761e-06, 'epoch': 5.36}\n",
            "{'loss': 0.0198, 'learning_rate': 6.0919043006720715e-06, 'epoch': 5.41}\n",
            "{'loss': 0.0542, 'learning_rate': 5.860589003693686e-06, 'epoch': 5.47}\n",
            "{'loss': 0.0804, 'learning_rate': 5.632366131103549e-06, 'epoch': 5.52}\n",
            "{'loss': 0.045, 'learning_rate': 5.40734567518106e-06, 'epoch': 5.58}\n",
            "{'loss': 0.0697, 'learning_rate': 5.185636084797167e-06, 'epoch': 5.64}\n",
            "{'loss': 0.0705, 'learning_rate': 4.967344213147326e-06, 'epoch': 5.69}\n",
            "{'loss': 0.0935, 'learning_rate': 4.7525752662534525e-06, 'epoch': 5.75}\n",
            "{'loss': 0.0111, 'learning_rate': 4.541432752259787e-06, 'epoch': 5.8}\n",
            "{'loss': 0.0755, 'learning_rate': 4.334018431546992e-06, 'epoch': 5.86}\n",
            "{'loss': 0.0005, 'learning_rate': 4.130432267688638e-06, 'epoch': 5.91}\n",
            "{'loss': 0.0837, 'learning_rate': 3.93077237927365e-06, 'epoch': 5.97}\n",
            "{'loss': 0.0012, 'learning_rate': 3.7351349926179075e-06, 'epoch': 6.02}\n",
            "{'loss': 0.0011, 'learning_rate': 3.5436143953879e-06, 'epoch': 6.08}\n",
            "{'loss': 0.0005, 'learning_rate': 3.35630289115864e-06, 'epoch': 6.13}\n",
            "{'loss': 0.0819, 'learning_rate': 3.1732907549278754e-06, 'epoch': 6.19}\n",
            "{'loss': 0.0138, 'learning_rate': 2.9946661896079235e-06, 'epoch': 6.24}\n",
            "{'loss': 0.1416, 'learning_rate': 2.820515283516206e-06, 'epoch': 6.3}\n",
            "{'loss': 0.0559, 'learning_rate': 2.650921968884851e-06, 'epoch': 6.35}\n",
            "{'loss': 0.0187, 'learning_rate': 2.485967981409473e-06, 'epoch': 6.41}\n",
            "{'loss': 0.0006, 'learning_rate': 2.3257328208565693e-06, 'epoch': 6.46}\n",
            "{'loss': 0.0006, 'learning_rate': 2.170293712748485e-06, 'epoch': 6.52}\n",
            "{'loss': 0.0009, 'learning_rate': 2.0197255711445204e-06, 'epoch': 6.57}\n",
            "{'loss': 0.0048, 'learning_rate': 1.8741009625359727e-06, 'epoch': 6.63}\n",
            "{'loss': 0.0004, 'learning_rate': 1.7334900708726686e-06, 'epoch': 6.69}\n",
            "{'loss': 0.0007, 'learning_rate': 1.5979606637377004e-06, 'epoch': 6.74}\n",
            "{'loss': 0.0952, 'learning_rate': 1.4675780596867689e-06, 'epoch': 6.8}\n",
            "{'loss': 0.0814, 'learning_rate': 1.3424050967678401e-06, 'epoch': 6.85}\n",
            "{'loss': 0.0662, 'learning_rate': 1.2225021022362544e-06, 'epoch': 6.91}\n",
            "{'loss': 0.0122, 'learning_rate': 1.1079268634799597e-06, 'epoch': 6.96}\n",
            "{'loss': 0.0041, 'learning_rate': 9.987346001687847e-07, 'epoch': 7.02}\n",
            "{'loss': 0.0056, 'learning_rate': 8.949779376412804e-07, 'epoch': 7.07}\n",
            "{'loss': 0.0012, 'learning_rate': 7.967068815418645e-07, 'epoch': 7.13}\n",
            "{'loss': 0.07, 'learning_rate': 7.039687937205407e-07, 'epoch': 7.18}\n",
            "{'loss': 0.0004, 'learning_rate': 6.168083694068014e-07, 'epoch': 7.24}\n",
            "{'loss': 0.0005, 'learning_rate': 5.352676156687155e-07, 'epoch': 7.29}\n",
            "{'loss': 0.0005, 'learning_rate': 4.593858311675721e-07, 'epoch': 7.35}\n",
            "{'loss': 0.0004, 'learning_rate': 3.8919958721783565e-07, 'epoch': 7.4}\n",
            "{'loss': 0.0019, 'learning_rate': 3.2474271016156785e-07, 'epoch': 7.46}\n",
            "{'loss': 0.0035, 'learning_rate': 2.660462650657813e-07, 'epoch': 7.51}\n",
            "{'loss': 0.0003, 'learning_rate': 2.1313854075058815e-07, 'epoch': 7.57}\n",
            "{'loss': 0.0821, 'learning_rate': 1.660450361553789e-07, 'epoch': 7.62}\n",
            "{'loss': 0.0003, 'learning_rate': 1.2478844804956906e-07, 'epoch': 7.68}\n",
            "{'loss': 0.0818, 'learning_rate': 8.93886600938767e-08, 'epoch': 7.73}\n",
            "{'loss': 0.0036, 'learning_rate': 5.986273325735836e-08, 'epoch': 7.79}\n",
            "{'loss': 0.0253, 'learning_rate': 3.6224897594860167e-08, 'epoch': 7.85}\n",
            "{'loss': 0.0004, 'learning_rate': 1.8486545388826824e-08, 'epoch': 7.9}\n",
            "{'loss': 0.0009, 'learning_rate': 6.6562256587718725e-09, 'epoch': 7.96}\n",
            "{'train_runtime': 149.5098, 'train_samples_per_second': 77.319, 'train_steps_per_second': 9.685, 'train_loss': 0.20290493471975676, 'epoch': 8.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 52/52 [00:01<00:00, 37.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 21:46:49,928] Trial 7 finished with value: 0.9057591623036648 and parameters: {'learning_rate': 2.4554114664587713e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.2272708079762016, 'num_train_epochs': 8, 'warmup_steps': 17, 'freeze_layers': 0, 'dropout': 0.13133760133784125, 'lr_scheduler_type': 'cosine_with_restarts'}. Best is trial 4 with value: 0.9168765743073047.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: cosine_with_restarts\n",
            " Warmup steps (True): 204\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae07cd1b325442de9df2fada722b79ec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/414 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7116, 'learning_rate': 2.2925285035978996e-06, 'epoch': 0.22}\n",
            "{'loss': 0.7025, 'learning_rate': 5.1581891330952746e-06, 'epoch': 0.43}\n",
            "{'loss': 0.6841, 'learning_rate': 7.737283699642912e-06, 'epoch': 0.65}\n",
            "{'loss': 0.6825, 'learning_rate': 1.0316378266190549e-05, 'epoch': 0.87}\n",
            "{'loss': 0.6756, 'learning_rate': 1.3182038895687923e-05, 'epoch': 1.09}\n",
            "{'loss': 0.6674, 'learning_rate': 1.60476995251853e-05, 'epoch': 1.3}\n",
            "{'loss': 0.6311, 'learning_rate': 1.8626794091732936e-05, 'epoch': 1.52}\n",
            "{'loss': 0.6087, 'learning_rate': 2.149245472123031e-05, 'epoch': 1.74}\n",
            "{'loss': 0.5896, 'learning_rate': 2.4358115350727687e-05, 'epoch': 1.96}\n",
            "{'loss': 0.5278, 'learning_rate': 2.722377598022506e-05, 'epoch': 2.17}\n",
            "{'loss': 0.5201, 'learning_rate': 3.0089436609722432e-05, 'epoch': 2.39}\n",
            "{'loss': 0.4603, 'learning_rate': 3.295509723921981e-05, 'epoch': 2.61}\n",
            "{'loss': 0.4717, 'learning_rate': 3.5534191805767445e-05, 'epoch': 2.83}\n",
            "{'loss': 0.3569, 'learning_rate': 3.839985243526482e-05, 'epoch': 3.04}\n",
            "{'loss': 0.3103, 'learning_rate': 4.1265513064762197e-05, 'epoch': 3.26}\n",
            "{'loss': 0.4682, 'learning_rate': 4.413117369425957e-05, 'epoch': 3.48}\n",
            "{'loss': 0.312, 'learning_rate': 4.699683432375695e-05, 'epoch': 3.7}\n",
            "{'loss': 0.318, 'learning_rate': 4.986249495325432e-05, 'epoch': 3.91}\n",
            "{'loss': 0.2069, 'learning_rate': 5.272815558275169e-05, 'epoch': 4.13}\n",
            "{'loss': 0.3035, 'learning_rate': 5.559381621224907e-05, 'epoch': 4.35}\n",
            "{'loss': 0.2895, 'learning_rate': 5.8459476841746444e-05, 'epoch': 4.57}\n",
            "{'loss': 0.236, 'learning_rate': 5.813300481392967e-05, 'epoch': 4.78}\n",
            "{'loss': 0.2477, 'learning_rate': 5.716088157610201e-05, 'epoch': 5.0}\n",
            "{'loss': 0.1807, 'learning_rate': 5.5564822755011214e-05, 'epoch': 5.22}\n",
            "{'loss': 0.1692, 'learning_rate': 5.338048166731266e-05, 'epoch': 5.43}\n",
            "{'loss': 0.1239, 'learning_rate': 5.065665288339053e-05, 'epoch': 5.65}\n",
            "{'loss': 0.1261, 'learning_rate': 4.745418223728608e-05, 'epoch': 5.87}\n",
            "{'loss': 0.1009, 'learning_rate': 4.384460763130983e-05, 'epoch': 6.09}\n",
            "{'loss': 0.093, 'learning_rate': 3.9908560997516824e-05, 'epoch': 6.3}\n",
            "{'loss': 0.0571, 'learning_rate': 3.5733967113584696e-05, 'epoch': 6.52}\n",
            "{'loss': 0.117, 'learning_rate': 3.141407950857178e-05, 'epoch': 6.74}\n",
            "{'loss': 0.106, 'learning_rate': 2.7045397333174666e-05, 'epoch': 6.96}\n",
            "{'loss': 0.0284, 'learning_rate': 2.272550972816175e-05, 'epoch': 7.17}\n",
            "{'loss': 0.0211, 'learning_rate': 1.8550915844229624e-05, 'epoch': 7.39}\n",
            "{'loss': 0.0663, 'learning_rate': 1.4614869210436618e-05, 'epoch': 7.61}\n",
            "{'loss': 0.1327, 'learning_rate': 1.1005294604460368e-05, 'epoch': 7.83}\n",
            "{'loss': 0.0156, 'learning_rate': 7.802823958355925e-06, 'epoch': 8.04}\n",
            "{'loss': 0.0298, 'learning_rate': 5.078995174433793e-06, 'epoch': 8.26}\n",
            "{'loss': 0.0457, 'learning_rate': 2.8946540867352336e-06, 'epoch': 8.48}\n",
            "{'loss': 0.0163, 'learning_rate': 1.298595265644437e-06, 'epoch': 8.7}\n",
            "{'loss': 0.0082, 'learning_rate': 3.264720278167704e-07, 'epoch': 8.91}\n",
            "{'train_runtime': 120.5695, 'train_samples_per_second': 107.863, 'train_steps_per_second': 3.434, 'train_loss': 0.30001457058937075, 'epoch': 9.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 13/13 [00:00<00:00, 13.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 21:48:54,014] Trial 8 finished with value: 0.8960396039603961 and parameters: {'learning_rate': 5.8459476841746444e-05, 'per_device_train_batch_size': 32, 'weight_decay': 0.13215030154376892, 'num_train_epochs': 9, 'warmup_steps': 204, 'freeze_layers': 9, 'dropout': 0.37545432811405943, 'lr_scheduler_type': 'cosine_with_restarts'}. Best is trial 4 with value: 0.9168765743073047.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: polynomial\n",
            " Warmup steps (True): 57\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa1857748b094a41aa6a602447fc673c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/322 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7055, 'learning_rate': 1.3805266102429053e-06, 'epoch': 0.22}\n",
            "{'loss': 0.7187, 'learning_rate': 2.9336190467661735e-06, 'epoch': 0.43}\n",
            "{'loss': 0.6865, 'learning_rate': 4.314145657009079e-06, 'epoch': 0.65}\n",
            "{'loss': 0.6755, 'learning_rate': 6.039803919812711e-06, 'epoch': 0.87}\n",
            "{'loss': 0.7057, 'learning_rate': 7.765462182616343e-06, 'epoch': 1.09}\n",
            "{'loss': 0.6886, 'learning_rate': 9.491120445419974e-06, 'epoch': 1.3}\n",
            "{'loss': 0.6677, 'learning_rate': 9.542327506343547e-06, 'epoch': 1.52}\n",
            "{'loss': 0.673, 'learning_rate': 9.174921766797106e-06, 'epoch': 1.74}\n",
            "{'loss': 0.6282, 'learning_rate': 8.807516027250665e-06, 'epoch': 1.96}\n",
            "{'loss': 0.6155, 'learning_rate': 8.440110287704224e-06, 'epoch': 2.17}\n",
            "{'loss': 0.5903, 'learning_rate': 8.072704548157781e-06, 'epoch': 2.39}\n",
            "{'loss': 0.599, 'learning_rate': 7.70529880861134e-06, 'epoch': 2.61}\n",
            "{'loss': 0.5203, 'learning_rate': 7.337893069064898e-06, 'epoch': 2.83}\n",
            "{'loss': 0.4792, 'learning_rate': 6.970487329518457e-06, 'epoch': 3.04}\n",
            "{'loss': 0.4299, 'learning_rate': 6.603081589972014e-06, 'epoch': 3.26}\n",
            "{'loss': 0.4488, 'learning_rate': 6.235675850425574e-06, 'epoch': 3.48}\n",
            "{'loss': 0.4052, 'learning_rate': 5.868270110879131e-06, 'epoch': 3.7}\n",
            "{'loss': 0.4002, 'learning_rate': 5.50086437133269e-06, 'epoch': 3.91}\n",
            "{'loss': 0.3398, 'learning_rate': 5.133458631786249e-06, 'epoch': 4.13}\n",
            "{'loss': 0.3219, 'learning_rate': 4.766052892239807e-06, 'epoch': 4.35}\n",
            "{'loss': 0.3611, 'learning_rate': 4.3986471526933656e-06, 'epoch': 4.57}\n",
            "{'loss': 0.4161, 'learning_rate': 4.031241413146924e-06, 'epoch': 4.78}\n",
            "{'loss': 0.3518, 'learning_rate': 3.6638356736004825e-06, 'epoch': 5.0}\n",
            "{'loss': 0.3143, 'learning_rate': 3.2964299340540414e-06, 'epoch': 5.22}\n",
            "{'loss': 0.3709, 'learning_rate': 2.9290241945076e-06, 'epoch': 5.43}\n",
            "{'loss': 0.3118, 'learning_rate': 2.5616184549611583e-06, 'epoch': 5.65}\n",
            "{'loss': 0.3205, 'learning_rate': 2.194212715414716e-06, 'epoch': 5.87}\n",
            "{'loss': 0.2792, 'learning_rate': 1.8268069758682744e-06, 'epoch': 6.09}\n",
            "{'loss': 0.2991, 'learning_rate': 1.4594012363218333e-06, 'epoch': 6.3}\n",
            "{'loss': 0.2998, 'learning_rate': 1.0919954967753918e-06, 'epoch': 6.52}\n",
            "{'loss': 0.2976, 'learning_rate': 7.245897572289504e-07, 'epoch': 6.74}\n",
            "{'loss': 0.297, 'learning_rate': 3.5718401768250896e-07, 'epoch': 6.96}\n",
            "{'train_runtime': 89.2116, 'train_samples_per_second': 113.382, 'train_steps_per_second': 3.609, 'train_loss': 0.47412919794550595, 'epoch': 7.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 13/13 [00:01<00:00, 12.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 21:50:26,875] Trial 9 finished with value: 0.8608923884514437 and parameters: {'learning_rate': 9.8362520979807e-06, 'per_device_train_batch_size': 32, 'weight_decay': 0.08745667101343828, 'num_train_epochs': 7, 'warmup_steps': 57, 'freeze_layers': 3, 'dropout': 0.39716203679363893, 'lr_scheduler_type': 'polynomial'}. Best is trial 4 with value: 0.9168765743073047.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: constant_with_warmup\n",
            " Warmup steps (True): 291\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "734c1d10d3f6437cac158b2a11aef638",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/910 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7054, 'learning_rate': 1.754157248317396e-07, 'epoch': 0.11}\n",
            "{'loss': 0.7041, 'learning_rate': 3.3134081357106367e-07, 'epoch': 0.22}\n",
            "{'loss': 0.7098, 'learning_rate': 5.067565384028033e-07, 'epoch': 0.33}\n",
            "{'loss': 0.7036, 'learning_rate': 7.016628993269584e-07, 'epoch': 0.44}\n",
            "{'loss': 0.707, 'learning_rate': 8.965692602511134e-07, 'epoch': 0.55}\n",
            "{'loss': 0.6896, 'learning_rate': 1.0914756211752687e-06, 'epoch': 0.66}\n",
            "{'loss': 0.6775, 'learning_rate': 1.2668913460070082e-06, 'epoch': 0.77}\n",
            "{'loss': 0.7083, 'learning_rate': 1.461797706931163e-06, 'epoch': 0.88}\n",
            "{'loss': 0.691, 'learning_rate': 1.6567040678553184e-06, 'epoch': 0.99}\n",
            "{'loss': 0.6862, 'learning_rate': 1.8516104287794735e-06, 'epoch': 1.1}\n",
            "{'loss': 0.6781, 'learning_rate': 2.0465167897036286e-06, 'epoch': 1.21}\n",
            "{'loss': 0.6724, 'learning_rate': 2.2414231506277837e-06, 'epoch': 1.32}\n",
            "{'loss': 0.7023, 'learning_rate': 2.436329511551939e-06, 'epoch': 1.43}\n",
            "{'loss': 0.668, 'learning_rate': 2.631235872476094e-06, 'epoch': 1.54}\n",
            "{'loss': 0.6854, 'learning_rate': 2.826142233400249e-06, 'epoch': 1.65}\n",
            "{'loss': 0.6843, 'learning_rate': 3.0015579582319887e-06, 'epoch': 1.76}\n",
            "{'loss': 0.6728, 'learning_rate': 3.196464319156144e-06, 'epoch': 1.87}\n",
            "{'loss': 0.6829, 'learning_rate': 3.3913706800802985e-06, 'epoch': 1.98}\n",
            "{'loss': 0.6368, 'learning_rate': 3.5862770410044536e-06, 'epoch': 2.09}\n",
            "{'loss': 0.6935, 'learning_rate': 3.7811834019286087e-06, 'epoch': 2.2}\n",
            "{'loss': 0.6347, 'learning_rate': 3.976089762852764e-06, 'epoch': 2.31}\n",
            "{'loss': 0.6426, 'learning_rate': 4.17099612377692e-06, 'epoch': 2.42}\n",
            "{'loss': 0.6898, 'learning_rate': 4.365902484701075e-06, 'epoch': 2.53}\n",
            "{'loss': 0.6564, 'learning_rate': 4.56080884562523e-06, 'epoch': 2.64}\n",
            "{'loss': 0.6459, 'learning_rate': 4.755715206549384e-06, 'epoch': 2.75}\n",
            "{'loss': 0.6537, 'learning_rate': 4.950621567473539e-06, 'epoch': 2.86}\n",
            "{'loss': 0.6241, 'learning_rate': 5.1455279283976945e-06, 'epoch': 2.97}\n",
            "{'loss': 0.614, 'learning_rate': 5.3404342893218496e-06, 'epoch': 3.08}\n",
            "{'loss': 0.5737, 'learning_rate': 5.535340650246005e-06, 'epoch': 3.19}\n",
            "{'loss': 0.5762, 'learning_rate': 5.6717751028929135e-06, 'epoch': 3.3}\n",
            "{'loss': 0.5508, 'learning_rate': 5.6717751028929135e-06, 'epoch': 3.41}\n",
            "{'loss': 0.5623, 'learning_rate': 5.6717751028929135e-06, 'epoch': 3.52}\n",
            "{'loss': 0.5092, 'learning_rate': 5.6717751028929135e-06, 'epoch': 3.63}\n",
            "{'loss': 0.5587, 'learning_rate': 5.6717751028929135e-06, 'epoch': 3.74}\n",
            "{'loss': 0.5212, 'learning_rate': 5.6717751028929135e-06, 'epoch': 3.85}\n",
            "{'loss': 0.4982, 'learning_rate': 5.6717751028929135e-06, 'epoch': 3.96}\n",
            "{'loss': 0.4848, 'learning_rate': 5.6717751028929135e-06, 'epoch': 4.07}\n",
            "{'loss': 0.4457, 'learning_rate': 5.6717751028929135e-06, 'epoch': 4.18}\n",
            "{'loss': 0.4697, 'learning_rate': 5.6717751028929135e-06, 'epoch': 4.29}\n",
            "{'loss': 0.3898, 'learning_rate': 5.6717751028929135e-06, 'epoch': 4.4}\n",
            "{'loss': 0.4206, 'learning_rate': 5.6717751028929135e-06, 'epoch': 4.51}\n",
            "{'loss': 0.4539, 'learning_rate': 5.6717751028929135e-06, 'epoch': 4.62}\n",
            "{'loss': 0.421, 'learning_rate': 5.6717751028929135e-06, 'epoch': 4.73}\n",
            "{'loss': 0.4205, 'learning_rate': 5.6717751028929135e-06, 'epoch': 4.84}\n",
            "{'loss': 0.3769, 'learning_rate': 5.6717751028929135e-06, 'epoch': 4.95}\n",
            "{'loss': 0.3893, 'learning_rate': 5.6717751028929135e-06, 'epoch': 5.05}\n",
            "{'loss': 0.3422, 'learning_rate': 5.6717751028929135e-06, 'epoch': 5.16}\n",
            "{'loss': 0.3389, 'learning_rate': 5.6717751028929135e-06, 'epoch': 5.27}\n",
            "{'loss': 0.2932, 'learning_rate': 5.6717751028929135e-06, 'epoch': 5.38}\n",
            "{'loss': 0.2888, 'learning_rate': 5.6717751028929135e-06, 'epoch': 5.49}\n",
            "{'loss': 0.3474, 'learning_rate': 5.6717751028929135e-06, 'epoch': 5.6}\n",
            "{'loss': 0.3028, 'learning_rate': 5.6717751028929135e-06, 'epoch': 5.71}\n",
            "{'loss': 0.3754, 'learning_rate': 5.6717751028929135e-06, 'epoch': 5.82}\n",
            "{'loss': 0.3134, 'learning_rate': 5.6717751028929135e-06, 'epoch': 5.93}\n",
            "{'loss': 0.2748, 'learning_rate': 5.6717751028929135e-06, 'epoch': 6.04}\n",
            "{'loss': 0.2608, 'learning_rate': 5.6717751028929135e-06, 'epoch': 6.15}\n",
            "{'loss': 0.2465, 'learning_rate': 5.6717751028929135e-06, 'epoch': 6.26}\n",
            "{'loss': 0.2729, 'learning_rate': 5.6717751028929135e-06, 'epoch': 6.37}\n",
            "{'loss': 0.2989, 'learning_rate': 5.6717751028929135e-06, 'epoch': 6.48}\n",
            "{'loss': 0.3099, 'learning_rate': 5.6717751028929135e-06, 'epoch': 6.59}\n",
            "{'loss': 0.3445, 'learning_rate': 5.6717751028929135e-06, 'epoch': 6.7}\n",
            "{'loss': 0.3594, 'learning_rate': 5.6717751028929135e-06, 'epoch': 6.81}\n",
            "{'loss': 0.3076, 'learning_rate': 5.6717751028929135e-06, 'epoch': 6.92}\n",
            "{'loss': 0.268, 'learning_rate': 5.6717751028929135e-06, 'epoch': 7.03}\n",
            "{'loss': 0.2436, 'learning_rate': 5.6717751028929135e-06, 'epoch': 7.14}\n",
            "{'loss': 0.194, 'learning_rate': 5.6717751028929135e-06, 'epoch': 7.25}\n",
            "{'loss': 0.2424, 'learning_rate': 5.6717751028929135e-06, 'epoch': 7.36}\n",
            "{'loss': 0.2873, 'learning_rate': 5.6717751028929135e-06, 'epoch': 7.47}\n",
            "{'loss': 0.1898, 'learning_rate': 5.6717751028929135e-06, 'epoch': 7.58}\n",
            "{'loss': 0.2262, 'learning_rate': 5.6717751028929135e-06, 'epoch': 7.69}\n",
            "{'loss': 0.2903, 'learning_rate': 5.6717751028929135e-06, 'epoch': 7.8}\n",
            "{'loss': 0.2001, 'learning_rate': 5.6717751028929135e-06, 'epoch': 7.91}\n",
            "{'loss': 0.2319, 'learning_rate': 5.6717751028929135e-06, 'epoch': 8.02}\n",
            "{'loss': 0.2015, 'learning_rate': 5.6717751028929135e-06, 'epoch': 8.13}\n",
            "{'loss': 0.1513, 'learning_rate': 5.6717751028929135e-06, 'epoch': 8.24}\n",
            "{'loss': 0.3412, 'learning_rate': 5.6717751028929135e-06, 'epoch': 8.35}\n",
            "{'loss': 0.2221, 'learning_rate': 5.6717751028929135e-06, 'epoch': 8.46}\n",
            "{'loss': 0.1993, 'learning_rate': 5.6717751028929135e-06, 'epoch': 8.57}\n",
            "{'loss': 0.1794, 'learning_rate': 5.6717751028929135e-06, 'epoch': 8.68}\n",
            "{'loss': 0.2102, 'learning_rate': 5.6717751028929135e-06, 'epoch': 8.79}\n",
            "{'loss': 0.0888, 'learning_rate': 5.6717751028929135e-06, 'epoch': 8.9}\n",
            "{'loss': 0.1252, 'learning_rate': 5.6717751028929135e-06, 'epoch': 9.01}\n",
            "{'loss': 0.1696, 'learning_rate': 5.6717751028929135e-06, 'epoch': 9.12}\n",
            "{'loss': 0.1245, 'learning_rate': 5.6717751028929135e-06, 'epoch': 9.23}\n",
            "{'loss': 0.1528, 'learning_rate': 5.6717751028929135e-06, 'epoch': 9.34}\n",
            "{'loss': 0.1618, 'learning_rate': 5.6717751028929135e-06, 'epoch': 9.45}\n",
            "{'loss': 0.2113, 'learning_rate': 5.6717751028929135e-06, 'epoch': 9.56}\n",
            "{'loss': 0.1062, 'learning_rate': 5.6717751028929135e-06, 'epoch': 9.67}\n",
            "{'loss': 0.1978, 'learning_rate': 5.6717751028929135e-06, 'epoch': 9.78}\n",
            "{'loss': 0.197, 'learning_rate': 5.6717751028929135e-06, 'epoch': 9.89}\n",
            "{'loss': 0.1621, 'learning_rate': 5.6717751028929135e-06, 'epoch': 10.0}\n",
            "{'train_runtime': 150.0339, 'train_samples_per_second': 96.312, 'train_steps_per_second': 6.065, 'train_loss': 0.4219342730857514, 'epoch': 10.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 26/26 [00:01<00:00, 22.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 21:53:00,669] Trial 10 finished with value: 0.8970588235294118 and parameters: {'learning_rate': 5.6717751028929135e-06, 'per_device_train_batch_size': 16, 'weight_decay': 0.29762223253736864, 'num_train_epochs': 10, 'warmup_steps': 291, 'freeze_layers': 6, 'dropout': 0.49875330072001983, 'lr_scheduler_type': 'constant_with_warmup'}. Best is trial 4 with value: 0.9168765743073047.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: cosine\n",
            " Warmup steps (True): 118\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "095db2fc1bba4a138f13c4effd8b58c2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/724 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7611, 'learning_rate': 1.7974012097561327e-06, 'epoch': 0.06}\n",
            "{'loss': 0.6877, 'learning_rate': 4.793069892683021e-06, 'epoch': 0.11}\n",
            "{'loss': 0.7028, 'learning_rate': 7.788738575609909e-06, 'epoch': 0.17}\n",
            "{'loss': 0.7487, 'learning_rate': 1.0784407258536797e-05, 'epoch': 0.22}\n",
            "{'loss': 0.6823, 'learning_rate': 1.3780075941463684e-05, 'epoch': 0.28}\n",
            "{'loss': 0.6372, 'learning_rate': 1.6775744624390574e-05, 'epoch': 0.33}\n",
            "{'loss': 0.6672, 'learning_rate': 1.977141330731746e-05, 'epoch': 0.39}\n",
            "{'loss': 0.6736, 'learning_rate': 2.2767081990244347e-05, 'epoch': 0.44}\n",
            "{'loss': 0.6655, 'learning_rate': 2.5762750673171232e-05, 'epoch': 0.5}\n",
            "{'loss': 0.5697, 'learning_rate': 2.8758419356098124e-05, 'epoch': 0.55}\n",
            "{'loss': 0.5799, 'learning_rate': 3.175408803902501e-05, 'epoch': 0.61}\n",
            "{'loss': 0.4278, 'learning_rate': 3.47497567219519e-05, 'epoch': 0.66}\n",
            "{'loss': 0.3744, 'learning_rate': 3.533369240340344e-05, 'epoch': 0.72}\n",
            "{'loss': 0.5126, 'learning_rate': 3.5271995097504094e-05, 'epoch': 0.77}\n",
            "{'loss': 0.5426, 'learning_rate': 3.516301431141818e-05, 'epoch': 0.83}\n",
            "{'loss': 0.3768, 'learning_rate': 3.5007042869480825e-05, 'epoch': 0.88}\n",
            "{'loss': 0.3831, 'learning_rate': 3.480449985688512e-05, 'epoch': 0.94}\n",
            "{'loss': 0.7915, 'learning_rate': 3.455592949362728e-05, 'epoch': 0.99}\n",
            "{'loss': 0.4589, 'learning_rate': 3.42619996722227e-05, 'epoch': 1.05}\n",
            "{'loss': 0.3061, 'learning_rate': 3.392350016312185e-05, 'epoch': 1.1}\n",
            "{'loss': 0.7857, 'learning_rate': 3.3541340492648084e-05, 'epoch': 1.16}\n",
            "{'loss': 0.4368, 'learning_rate': 3.311654749915915e-05, 'epoch': 1.22}\n",
            "{'loss': 0.3196, 'learning_rate': 3.265026257399879e-05, 'epoch': 1.27}\n",
            "{'loss': 0.3953, 'learning_rate': 3.214373859465197e-05, 'epoch': 1.33}\n",
            "{'loss': 0.4365, 'learning_rate': 3.159833655834391e-05, 'epoch': 1.38}\n",
            "{'loss': 0.3345, 'learning_rate': 3.1015521925128456e-05, 'epoch': 1.44}\n",
            "{'loss': 0.4235, 'learning_rate': 3.0396860680291534e-05, 'epoch': 1.49}\n",
            "{'loss': 0.4553, 'learning_rate': 2.9744015126649816e-05, 'epoch': 1.55}\n",
            "{'loss': 0.3077, 'learning_rate': 2.905873941805038e-05, 'epoch': 1.6}\n",
            "{'loss': 0.3565, 'learning_rate': 2.8342874846072596e-05, 'epoch': 1.66}\n",
            "{'loss': 0.4363, 'learning_rate': 2.7598344892596544e-05, 'epoch': 1.71}\n",
            "{'loss': 0.4764, 'learning_rate': 2.6827150061531397e-05, 'epoch': 1.77}\n",
            "{'loss': 0.3017, 'learning_rate': 2.6031362503590637e-05, 'epoch': 1.82}\n",
            "{'loss': 0.4097, 'learning_rate': 2.5213120448556823e-05, 'epoch': 1.88}\n",
            "{'loss': 0.4294, 'learning_rate': 2.4374622459996294e-05, 'epoch': 1.93}\n",
            "{'loss': 0.2904, 'learning_rate': 2.3518121527860797e-05, 'epoch': 1.99}\n",
            "{'loss': 0.2238, 'learning_rate': 2.2645919014848984e-05, 'epoch': 2.04}\n",
            "{'loss': 0.0777, 'learning_rate': 2.1760358472793436e-05, 'epoch': 2.1}\n",
            "{'loss': 0.1978, 'learning_rate': 2.0863819345688214e-05, 'epoch': 2.15}\n",
            "{'loss': 0.2579, 'learning_rate': 1.9958710576276518e-05, 'epoch': 2.21}\n",
            "{'loss': 0.1604, 'learning_rate': 1.9047464133377052e-05, 'epoch': 2.27}\n",
            "{'loss': 0.1951, 'learning_rate': 1.8132528477340846e-05, 'epoch': 2.32}\n",
            "{'loss': 0.3112, 'learning_rate': 1.721636198119643e-05, 'epoch': 2.38}\n",
            "{'loss': 0.2482, 'learning_rate': 1.6301426325160228e-05, 'epoch': 2.43}\n",
            "{'loss': 0.1534, 'learning_rate': 1.539017988226076e-05, 'epoch': 2.49}\n",
            "{'loss': 0.3771, 'learning_rate': 1.4485071112849063e-05, 'epoch': 2.54}\n",
            "{'loss': 0.3032, 'learning_rate': 1.3588531985743847e-05, 'epoch': 2.6}\n",
            "{'loss': 0.2803, 'learning_rate': 1.2702971443688295e-05, 'epoch': 2.65}\n",
            "{'loss': 0.1826, 'learning_rate': 1.183076893067648e-05, 'epoch': 2.71}\n",
            "{'loss': 0.1283, 'learning_rate': 1.0974267998540984e-05, 'epoch': 2.76}\n",
            "{'loss': 0.3109, 'learning_rate': 1.0135770009980459e-05, 'epoch': 2.82}\n",
            "{'loss': 0.2235, 'learning_rate': 9.317527954946646e-06, 'epoch': 2.87}\n",
            "{'loss': 0.2637, 'learning_rate': 8.521740397005877e-06, 'epoch': 2.93}\n",
            "{'loss': 0.1356, 'learning_rate': 7.750545565940737e-06, 'epoch': 2.98}\n",
            "{'loss': 0.0532, 'learning_rate': 7.006015612464681e-06, 'epoch': 3.04}\n",
            "{'loss': 0.0865, 'learning_rate': 6.290151040486897e-06, 'epoch': 3.09}\n",
            "{'loss': 0.0082, 'learning_rate': 5.6048753318874626e-06, 'epoch': 3.15}\n",
            "{'loss': 0.1851, 'learning_rate': 4.952029778245746e-06, 'epoch': 3.2}\n",
            "{'loss': 0.112, 'learning_rate': 4.333368533408826e-06, 'epoch': 3.26}\n",
            "{'loss': 0.0077, 'learning_rate': 3.750553900193369e-06, 'epoch': 3.31}\n",
            "{'loss': 0.2537, 'learning_rate': 3.2051518638853076e-06, 'epoch': 3.37}\n",
            "{'loss': 0.0691, 'learning_rate': 2.6986278845384858e-06, 'epoch': 3.43}\n",
            "{'loss': 0.1591, 'learning_rate': 2.23234295937813e-06, 'epoch': 3.48}\n",
            "{'loss': 0.1385, 'learning_rate': 1.8075499658891906e-06, 'epoch': 3.54}\n",
            "{'loss': 0.0642, 'learning_rate': 1.4253902954154254e-06, 'epoch': 3.59}\n",
            "{'loss': 0.2442, 'learning_rate': 1.086890786314577e-06, 'epoch': 3.65}\n",
            "{'loss': 0.1326, 'learning_rate': 7.929609649100011e-07, 'epoch': 3.7}\n",
            "{'loss': 0.005, 'learning_rate': 5.443906016521607e-07, 'epoch': 3.76}\n",
            "{'loss': 0.1768, 'learning_rate': 3.4184758905644924e-07, 'epoch': 3.81}\n",
            "{'loss': 0.1228, 'learning_rate': 1.8587614711909272e-07, 'epoch': 3.87}\n",
            "{'loss': 0.0754, 'learning_rate': 7.689536103318702e-08, 'epoch': 3.92}\n",
            "{'loss': 0.1683, 'learning_rate': 1.5198055133836575e-08, 'epoch': 3.98}\n",
            "{'train_runtime': 73.906, 'train_samples_per_second': 78.207, 'train_steps_per_second': 9.796, 'train_loss': 0.3358082110628239, 'epoch': 4.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 52/52 [00:01<00:00, 36.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 21:54:18,637] Trial 11 finished with value: 0.8974358974358975 and parameters: {'learning_rate': 3.534889045853728e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.15482132525654918, 'num_train_epochs': 4, 'warmup_steps': 118, 'freeze_layers': 3, 'dropout': 0.10685480939673744, 'lr_scheduler_type': 'cosine'}. Best is trial 4 with value: 0.9168765743073047.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: linear\n",
            " Warmup steps (True): 143\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "06be820ed45447eea9a255a7c17effbf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/905 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7003, 'learning_rate': 6.286057648239624e-07, 'epoch': 0.06}\n",
            "{'loss': 0.7091, 'learning_rate': 1.4368131767404854e-06, 'epoch': 0.11}\n",
            "{'loss': 0.6904, 'learning_rate': 2.3348214122032886e-06, 'epoch': 0.17}\n",
            "{'loss': 0.7031, 'learning_rate': 3.232829647666092e-06, 'epoch': 0.22}\n",
            "{'loss': 0.6896, 'learning_rate': 4.130837883128895e-06, 'epoch': 0.28}\n",
            "{'loss': 0.6907, 'learning_rate': 4.939045295045419e-06, 'epoch': 0.33}\n",
            "{'loss': 0.6812, 'learning_rate': 5.837053530508222e-06, 'epoch': 0.39}\n",
            "{'loss': 0.7181, 'learning_rate': 6.735061765971025e-06, 'epoch': 0.44}\n",
            "{'loss': 0.6808, 'learning_rate': 7.633070001433828e-06, 'epoch': 0.5}\n",
            "{'loss': 0.6704, 'learning_rate': 8.531078236896632e-06, 'epoch': 0.55}\n",
            "{'loss': 0.7095, 'learning_rate': 9.429086472359435e-06, 'epoch': 0.61}\n",
            "{'loss': 0.6586, 'learning_rate': 1.0327094707822239e-05, 'epoch': 0.66}\n",
            "{'loss': 0.6626, 'learning_rate': 1.1135302119738761e-05, 'epoch': 0.72}\n",
            "{'loss': 0.6701, 'learning_rate': 1.2033310355201565e-05, 'epoch': 0.77}\n",
            "{'loss': 0.6706, 'learning_rate': 1.2824665381596935e-05, 'epoch': 0.83}\n",
            "{'loss': 0.6514, 'learning_rate': 1.2656141526385411e-05, 'epoch': 0.88}\n",
            "{'loss': 0.6364, 'learning_rate': 1.248761767117389e-05, 'epoch': 0.94}\n",
            "{'loss': 0.6284, 'learning_rate': 1.2319093815962365e-05, 'epoch': 0.99}\n",
            "{'loss': 0.5903, 'learning_rate': 1.2150569960750843e-05, 'epoch': 1.05}\n",
            "{'loss': 0.6038, 'learning_rate': 1.1982046105539318e-05, 'epoch': 1.1}\n",
            "{'loss': 0.6129, 'learning_rate': 1.1813522250327794e-05, 'epoch': 1.16}\n",
            "{'loss': 0.6681, 'learning_rate': 1.1644998395116271e-05, 'epoch': 1.22}\n",
            "{'loss': 0.5657, 'learning_rate': 1.1476474539904747e-05, 'epoch': 1.27}\n",
            "{'loss': 0.5334, 'learning_rate': 1.1307950684693224e-05, 'epoch': 1.33}\n",
            "{'loss': 0.4985, 'learning_rate': 1.1139426829481701e-05, 'epoch': 1.38}\n",
            "{'loss': 0.4782, 'learning_rate': 1.0970902974270178e-05, 'epoch': 1.44}\n",
            "{'loss': 0.4153, 'learning_rate': 1.0802379119058654e-05, 'epoch': 1.49}\n",
            "{'loss': 0.5127, 'learning_rate': 1.0633855263847131e-05, 'epoch': 1.55}\n",
            "{'loss': 0.3514, 'learning_rate': 1.0465331408635607e-05, 'epoch': 1.6}\n",
            "{'loss': 0.493, 'learning_rate': 1.0296807553424084e-05, 'epoch': 1.66}\n",
            "{'loss': 0.453, 'learning_rate': 1.012828369821256e-05, 'epoch': 1.71}\n",
            "{'loss': 0.4406, 'learning_rate': 9.959759843001037e-06, 'epoch': 1.77}\n",
            "{'loss': 0.3456, 'learning_rate': 9.791235987789514e-06, 'epoch': 1.82}\n",
            "{'loss': 0.383, 'learning_rate': 9.62271213257799e-06, 'epoch': 1.88}\n",
            "{'loss': 0.5885, 'learning_rate': 9.454188277366467e-06, 'epoch': 1.93}\n",
            "{'loss': 0.3712, 'learning_rate': 9.285664422154942e-06, 'epoch': 1.99}\n",
            "{'loss': 0.4079, 'learning_rate': 9.11714056694342e-06, 'epoch': 2.04}\n",
            "{'loss': 0.2522, 'learning_rate': 8.948616711731895e-06, 'epoch': 2.1}\n",
            "{'loss': 0.3102, 'learning_rate': 8.780092856520373e-06, 'epoch': 2.15}\n",
            "{'loss': 0.3837, 'learning_rate': 8.611569001308848e-06, 'epoch': 2.21}\n",
            "{'loss': 0.3081, 'learning_rate': 8.443045146097325e-06, 'epoch': 2.27}\n",
            "{'loss': 0.3201, 'learning_rate': 8.274521290885803e-06, 'epoch': 2.32}\n",
            "{'loss': 0.3903, 'learning_rate': 8.105997435674278e-06, 'epoch': 2.38}\n",
            "{'loss': 0.3023, 'learning_rate': 7.937473580462755e-06, 'epoch': 2.43}\n",
            "{'loss': 0.2772, 'learning_rate': 7.768949725251231e-06, 'epoch': 2.49}\n",
            "{'loss': 0.3937, 'learning_rate': 7.600425870039708e-06, 'epoch': 2.54}\n",
            "{'loss': 0.4974, 'learning_rate': 7.431902014828185e-06, 'epoch': 2.6}\n",
            "{'loss': 0.3491, 'learning_rate': 7.263378159616661e-06, 'epoch': 2.65}\n",
            "{'loss': 0.2957, 'learning_rate': 7.094854304405138e-06, 'epoch': 2.71}\n",
            "{'loss': 0.2537, 'learning_rate': 6.926330449193615e-06, 'epoch': 2.76}\n",
            "{'loss': 0.4135, 'learning_rate': 6.757806593982091e-06, 'epoch': 2.82}\n",
            "{'loss': 0.301, 'learning_rate': 6.5892827387705675e-06, 'epoch': 2.87}\n",
            "{'loss': 0.3479, 'learning_rate': 6.420758883559044e-06, 'epoch': 2.93}\n",
            "{'loss': 0.1853, 'learning_rate': 6.25223502834752e-06, 'epoch': 2.98}\n",
            "{'loss': 0.3118, 'learning_rate': 6.083711173135997e-06, 'epoch': 3.04}\n",
            "{'loss': 0.239, 'learning_rate': 5.915187317924474e-06, 'epoch': 3.09}\n",
            "{'loss': 0.1982, 'learning_rate': 5.74666346271295e-06, 'epoch': 3.15}\n",
            "{'loss': 0.2637, 'learning_rate': 5.578139607501427e-06, 'epoch': 3.2}\n",
            "{'loss': 0.2355, 'learning_rate': 5.409615752289903e-06, 'epoch': 3.26}\n",
            "{'loss': 0.1124, 'learning_rate': 5.24109189707838e-06, 'epoch': 3.31}\n",
            "{'loss': 0.4304, 'learning_rate': 5.072568041866856e-06, 'epoch': 3.37}\n",
            "{'loss': 0.3109, 'learning_rate': 4.904044186655332e-06, 'epoch': 3.43}\n",
            "{'loss': 0.4734, 'learning_rate': 4.735520331443809e-06, 'epoch': 3.48}\n",
            "{'loss': 0.2316, 'learning_rate': 4.566996476232286e-06, 'epoch': 3.54}\n",
            "{'loss': 0.1272, 'learning_rate': 4.3984726210207625e-06, 'epoch': 3.59}\n",
            "{'loss': 0.4662, 'learning_rate': 4.229948765809239e-06, 'epoch': 3.65}\n",
            "{'loss': 0.3398, 'learning_rate': 4.061424910597715e-06, 'epoch': 3.7}\n",
            "{'loss': 0.1905, 'learning_rate': 3.8929010553861925e-06, 'epoch': 3.76}\n",
            "{'loss': 0.1971, 'learning_rate': 3.7243772001746685e-06, 'epoch': 3.81}\n",
            "{'loss': 0.4495, 'learning_rate': 3.555853344963145e-06, 'epoch': 3.87}\n",
            "{'loss': 0.3164, 'learning_rate': 3.3873294897516213e-06, 'epoch': 3.92}\n",
            "{'loss': 0.3223, 'learning_rate': 3.218805634540098e-06, 'epoch': 3.98}\n",
            "{'loss': 0.235, 'learning_rate': 3.0502817793285746e-06, 'epoch': 4.03}\n",
            "{'loss': 0.1058, 'learning_rate': 2.881757924117051e-06, 'epoch': 4.09}\n",
            "{'loss': 0.2081, 'learning_rate': 2.713234068905528e-06, 'epoch': 4.14}\n",
            "{'loss': 0.3519, 'learning_rate': 2.5447102136940042e-06, 'epoch': 4.2}\n",
            "{'loss': 0.2356, 'learning_rate': 2.376186358482481e-06, 'epoch': 4.25}\n",
            "{'loss': 0.1198, 'learning_rate': 2.207662503270957e-06, 'epoch': 4.31}\n",
            "{'loss': 0.1632, 'learning_rate': 2.039138648059434e-06, 'epoch': 4.36}\n",
            "{'loss': 0.2282, 'learning_rate': 1.8706147928479103e-06, 'epoch': 4.42}\n",
            "{'loss': 0.2649, 'learning_rate': 1.702090937636387e-06, 'epoch': 4.48}\n",
            "{'loss': 0.2231, 'learning_rate': 1.5335670824248635e-06, 'epoch': 4.53}\n",
            "{'loss': 0.287, 'learning_rate': 1.3650432272133401e-06, 'epoch': 4.59}\n",
            "{'loss': 0.3111, 'learning_rate': 1.1965193720018167e-06, 'epoch': 4.64}\n",
            "{'loss': 0.2106, 'learning_rate': 1.0279955167902932e-06, 'epoch': 4.7}\n",
            "{'loss': 0.2017, 'learning_rate': 8.594716615787698e-07, 'epoch': 4.75}\n",
            "{'loss': 0.3076, 'learning_rate': 6.909478063672462e-07, 'epoch': 4.81}\n",
            "{'loss': 0.2718, 'learning_rate': 5.224239511557227e-07, 'epoch': 4.86}\n",
            "{'loss': 0.1576, 'learning_rate': 3.5390009594419926e-07, 'epoch': 4.92}\n",
            "{'loss': 0.2487, 'learning_rate': 1.853762407326758e-07, 'epoch': 4.97}\n",
            "{'train_runtime': 88.5047, 'train_samples_per_second': 81.634, 'train_steps_per_second': 10.225, 'train_loss': 0.4053369830326481, 'epoch': 5.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 52/52 [00:01<00:00, 41.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 21:55:50,823] Trial 12 finished with value: 0.8723404255319149 and parameters: {'learning_rate': 1.2841517767118088e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.1638805607956564, 'num_train_epochs': 5, 'warmup_steps': 143, 'freeze_layers': 3, 'dropout': 0.4501732685716785, 'lr_scheduler_type': 'linear'}. Best is trial 4 with value: 0.9168765743073047.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: constant_with_warmup\n",
            " Warmup steps (True): 74\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a87f40a2cdd3495b8e8d956014a93422",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1810 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7154, 'learning_rate': 3.372021820858596e-06, 'epoch': 0.06}\n",
            "{'loss': 0.6971, 'learning_rate': 8.18919585065659e-06, 'epoch': 0.11}\n",
            "{'loss': 0.6972, 'learning_rate': 1.3006369880454582e-05, 'epoch': 0.17}\n",
            "{'loss': 0.7239, 'learning_rate': 1.6860109104292977e-05, 'epoch': 0.22}\n",
            "{'loss': 0.6877, 'learning_rate': 2.167728313409097e-05, 'epoch': 0.28}\n",
            "{'loss': 0.6604, 'learning_rate': 2.6494457163888964e-05, 'epoch': 0.33}\n",
            "{'loss': 0.6579, 'learning_rate': 3.1311631193686957e-05, 'epoch': 0.39}\n",
            "{'loss': 0.7321, 'learning_rate': 3.5647087820505153e-05, 'epoch': 0.44}\n",
            "{'loss': 0.6359, 'learning_rate': 3.5647087820505153e-05, 'epoch': 0.5}\n",
            "{'loss': 0.5788, 'learning_rate': 3.5647087820505153e-05, 'epoch': 0.55}\n",
            "{'loss': 0.5429, 'learning_rate': 3.5647087820505153e-05, 'epoch': 0.61}\n",
            "{'loss': 0.42, 'learning_rate': 3.5647087820505153e-05, 'epoch': 0.66}\n",
            "{'loss': 0.3552, 'learning_rate': 3.5647087820505153e-05, 'epoch': 0.72}\n",
            "{'loss': 0.5081, 'learning_rate': 3.5647087820505153e-05, 'epoch': 0.77}\n",
            "{'loss': 0.5493, 'learning_rate': 3.5647087820505153e-05, 'epoch': 0.83}\n",
            "{'loss': 0.343, 'learning_rate': 3.5647087820505153e-05, 'epoch': 0.88}\n",
            "{'loss': 0.4427, 'learning_rate': 3.5647087820505153e-05, 'epoch': 0.94}\n",
            "{'loss': 1.0182, 'learning_rate': 3.5647087820505153e-05, 'epoch': 0.99}\n",
            "{'loss': 0.4233, 'learning_rate': 3.5647087820505153e-05, 'epoch': 1.05}\n",
            "{'loss': 0.3935, 'learning_rate': 3.5647087820505153e-05, 'epoch': 1.1}\n",
            "{'loss': 0.6854, 'learning_rate': 3.5647087820505153e-05, 'epoch': 1.16}\n",
            "{'loss': 0.321, 'learning_rate': 3.5647087820505153e-05, 'epoch': 1.22}\n",
            "{'loss': 0.2004, 'learning_rate': 3.5647087820505153e-05, 'epoch': 1.27}\n",
            "{'loss': 0.3775, 'learning_rate': 3.5647087820505153e-05, 'epoch': 1.33}\n",
            "{'loss': 0.4782, 'learning_rate': 3.5647087820505153e-05, 'epoch': 1.38}\n",
            "{'loss': 0.4109, 'learning_rate': 3.5647087820505153e-05, 'epoch': 1.44}\n",
            "{'loss': 0.2604, 'learning_rate': 3.5647087820505153e-05, 'epoch': 1.49}\n",
            "{'loss': 0.4528, 'learning_rate': 3.5647087820505153e-05, 'epoch': 1.55}\n",
            "{'loss': 0.4177, 'learning_rate': 3.5647087820505153e-05, 'epoch': 1.6}\n",
            "{'loss': 0.392, 'learning_rate': 3.5647087820505153e-05, 'epoch': 1.66}\n",
            "{'loss': 0.3185, 'learning_rate': 3.5647087820505153e-05, 'epoch': 1.71}\n",
            "{'loss': 0.4118, 'learning_rate': 3.5647087820505153e-05, 'epoch': 1.77}\n",
            "{'loss': 0.3014, 'learning_rate': 3.5647087820505153e-05, 'epoch': 1.82}\n",
            "{'loss': 0.3491, 'learning_rate': 3.5647087820505153e-05, 'epoch': 1.88}\n",
            "{'loss': 0.354, 'learning_rate': 3.5647087820505153e-05, 'epoch': 1.93}\n",
            "{'loss': 0.3816, 'learning_rate': 3.5647087820505153e-05, 'epoch': 1.99}\n",
            "{'loss': 0.2917, 'learning_rate': 3.5647087820505153e-05, 'epoch': 2.04}\n",
            "{'loss': 0.091, 'learning_rate': 3.5647087820505153e-05, 'epoch': 2.1}\n",
            "{'loss': 0.3001, 'learning_rate': 3.5647087820505153e-05, 'epoch': 2.15}\n",
            "{'loss': 0.3712, 'learning_rate': 3.5647087820505153e-05, 'epoch': 2.21}\n",
            "{'loss': 0.145, 'learning_rate': 3.5647087820505153e-05, 'epoch': 2.27}\n",
            "{'loss': 0.2236, 'learning_rate': 3.5647087820505153e-05, 'epoch': 2.32}\n",
            "{'loss': 0.4275, 'learning_rate': 3.5647087820505153e-05, 'epoch': 2.38}\n",
            "{'loss': 0.2312, 'learning_rate': 3.5647087820505153e-05, 'epoch': 2.43}\n",
            "{'loss': 0.2309, 'learning_rate': 3.5647087820505153e-05, 'epoch': 2.49}\n",
            "{'loss': 0.3386, 'learning_rate': 3.5647087820505153e-05, 'epoch': 2.54}\n",
            "{'loss': 0.2741, 'learning_rate': 3.5647087820505153e-05, 'epoch': 2.6}\n",
            "{'loss': 0.3346, 'learning_rate': 3.5647087820505153e-05, 'epoch': 2.65}\n",
            "{'loss': 0.2442, 'learning_rate': 3.5647087820505153e-05, 'epoch': 2.71}\n",
            "{'loss': 0.3149, 'learning_rate': 3.5647087820505153e-05, 'epoch': 2.76}\n",
            "{'loss': 0.2638, 'learning_rate': 3.5647087820505153e-05, 'epoch': 2.82}\n",
            "{'loss': 0.2087, 'learning_rate': 3.5647087820505153e-05, 'epoch': 2.87}\n",
            "{'loss': 0.3441, 'learning_rate': 3.5647087820505153e-05, 'epoch': 2.93}\n",
            "{'loss': 0.1229, 'learning_rate': 3.5647087820505153e-05, 'epoch': 2.98}\n",
            "{'loss': 0.0978, 'learning_rate': 3.5647087820505153e-05, 'epoch': 3.04}\n",
            "{'loss': 0.0057, 'learning_rate': 3.5647087820505153e-05, 'epoch': 3.09}\n",
            "{'loss': 0.0527, 'learning_rate': 3.5647087820505153e-05, 'epoch': 3.15}\n",
            "{'loss': 0.0801, 'learning_rate': 3.5647087820505153e-05, 'epoch': 3.2}\n",
            "{'loss': 0.1694, 'learning_rate': 3.5647087820505153e-05, 'epoch': 3.26}\n",
            "{'loss': 0.0012, 'learning_rate': 3.5647087820505153e-05, 'epoch': 3.31}\n",
            "{'loss': 0.4958, 'learning_rate': 3.5647087820505153e-05, 'epoch': 3.37}\n",
            "{'loss': 0.1691, 'learning_rate': 3.5647087820505153e-05, 'epoch': 3.43}\n",
            "{'loss': 0.0886, 'learning_rate': 3.5647087820505153e-05, 'epoch': 3.48}\n",
            "{'loss': 0.1601, 'learning_rate': 3.5647087820505153e-05, 'epoch': 3.54}\n",
            "{'loss': 0.1631, 'learning_rate': 3.5647087820505153e-05, 'epoch': 3.59}\n",
            "{'loss': 0.6486, 'learning_rate': 3.5647087820505153e-05, 'epoch': 3.65}\n",
            "{'loss': 0.1799, 'learning_rate': 3.5647087820505153e-05, 'epoch': 3.7}\n",
            "{'loss': 0.1365, 'learning_rate': 3.5647087820505153e-05, 'epoch': 3.76}\n",
            "{'loss': 0.0582, 'learning_rate': 3.5647087820505153e-05, 'epoch': 3.81}\n",
            "{'loss': 0.2318, 'learning_rate': 3.5647087820505153e-05, 'epoch': 3.87}\n",
            "{'loss': 0.2194, 'learning_rate': 3.5647087820505153e-05, 'epoch': 3.92}\n",
            "{'loss': 0.2384, 'learning_rate': 3.5647087820505153e-05, 'epoch': 3.98}\n",
            "{'loss': 0.1299, 'learning_rate': 3.5647087820505153e-05, 'epoch': 4.03}\n",
            "{'loss': 0.021, 'learning_rate': 3.5647087820505153e-05, 'epoch': 4.09}\n",
            "{'loss': 0.0371, 'learning_rate': 3.5647087820505153e-05, 'epoch': 4.14}\n",
            "{'loss': 0.1698, 'learning_rate': 3.5647087820505153e-05, 'epoch': 4.2}\n",
            "{'loss': 0.1427, 'learning_rate': 3.5647087820505153e-05, 'epoch': 4.25}\n",
            "{'loss': 0.0733, 'learning_rate': 3.5647087820505153e-05, 'epoch': 4.31}\n",
            "{'loss': 0.0126, 'learning_rate': 3.5647087820505153e-05, 'epoch': 4.36}\n",
            "{'loss': 0.0819, 'learning_rate': 3.5647087820505153e-05, 'epoch': 4.42}\n",
            "{'loss': 0.0012, 'learning_rate': 3.5647087820505153e-05, 'epoch': 4.48}\n",
            "{'loss': 0.1599, 'learning_rate': 3.5647087820505153e-05, 'epoch': 4.53}\n",
            "{'loss': 0.185, 'learning_rate': 3.5647087820505153e-05, 'epoch': 4.59}\n",
            "{'loss': 0.0093, 'learning_rate': 3.5647087820505153e-05, 'epoch': 4.64}\n",
            "{'loss': 0.2245, 'learning_rate': 3.5647087820505153e-05, 'epoch': 4.7}\n",
            "{'loss': 0.0034, 'learning_rate': 3.5647087820505153e-05, 'epoch': 4.75}\n",
            "{'loss': 0.1247, 'learning_rate': 3.5647087820505153e-05, 'epoch': 4.81}\n",
            "{'loss': 0.1728, 'learning_rate': 3.5647087820505153e-05, 'epoch': 4.86}\n",
            "{'loss': 0.0011, 'learning_rate': 3.5647087820505153e-05, 'epoch': 4.92}\n",
            "{'loss': 0.1895, 'learning_rate': 3.5647087820505153e-05, 'epoch': 4.97}\n",
            "{'loss': 0.1523, 'learning_rate': 3.5647087820505153e-05, 'epoch': 5.03}\n",
            "{'loss': 0.003, 'learning_rate': 3.5647087820505153e-05, 'epoch': 5.08}\n",
            "{'loss': 0.067, 'learning_rate': 3.5647087820505153e-05, 'epoch': 5.14}\n",
            "{'loss': 0.0608, 'learning_rate': 3.5647087820505153e-05, 'epoch': 5.19}\n",
            "{'loss': 0.1568, 'learning_rate': 3.5647087820505153e-05, 'epoch': 5.25}\n",
            "{'loss': 0.0892, 'learning_rate': 3.5647087820505153e-05, 'epoch': 5.3}\n",
            "{'loss': 0.0471, 'learning_rate': 3.5647087820505153e-05, 'epoch': 5.36}\n",
            "{'loss': 0.0019, 'learning_rate': 3.5647087820505153e-05, 'epoch': 5.41}\n",
            "{'loss': 0.0014, 'learning_rate': 3.5647087820505153e-05, 'epoch': 5.47}\n",
            "{'loss': 0.087, 'learning_rate': 3.5647087820505153e-05, 'epoch': 5.52}\n",
            "{'loss': 0.0012, 'learning_rate': 3.5647087820505153e-05, 'epoch': 5.58}\n",
            "{'loss': 0.1629, 'learning_rate': 3.5647087820505153e-05, 'epoch': 5.64}\n",
            "{'loss': 0.0017, 'learning_rate': 3.5647087820505153e-05, 'epoch': 5.69}\n",
            "{'loss': 0.012, 'learning_rate': 3.5647087820505153e-05, 'epoch': 5.75}\n",
            "{'loss': 0.0008, 'learning_rate': 3.5647087820505153e-05, 'epoch': 5.8}\n",
            "{'loss': 0.2032, 'learning_rate': 3.5647087820505153e-05, 'epoch': 5.86}\n",
            "{'loss': 0.0672, 'learning_rate': 3.5647087820505153e-05, 'epoch': 5.91}\n",
            "{'loss': 0.1033, 'learning_rate': 3.5647087820505153e-05, 'epoch': 5.97}\n",
            "{'loss': 0.0006, 'learning_rate': 3.5647087820505153e-05, 'epoch': 6.02}\n",
            "{'loss': 0.0004, 'learning_rate': 3.5647087820505153e-05, 'epoch': 6.08}\n",
            "{'loss': 0.0004, 'learning_rate': 3.5647087820505153e-05, 'epoch': 6.13}\n",
            "{'loss': 0.0004, 'learning_rate': 3.5647087820505153e-05, 'epoch': 6.19}\n",
            "{'loss': 0.0003, 'learning_rate': 3.5647087820505153e-05, 'epoch': 6.24}\n",
            "{'loss': 0.0331, 'learning_rate': 3.5647087820505153e-05, 'epoch': 6.3}\n",
            "{'loss': 0.0697, 'learning_rate': 3.5647087820505153e-05, 'epoch': 6.35}\n",
            "{'loss': 0.0004, 'learning_rate': 3.5647087820505153e-05, 'epoch': 6.41}\n",
            "{'loss': 0.0002, 'learning_rate': 3.5647087820505153e-05, 'epoch': 6.46}\n",
            "{'loss': 0.1019, 'learning_rate': 3.5647087820505153e-05, 'epoch': 6.52}\n",
            "{'loss': 0.0003, 'learning_rate': 3.5647087820505153e-05, 'epoch': 6.57}\n",
            "{'loss': 0.0002, 'learning_rate': 3.5647087820505153e-05, 'epoch': 6.63}\n",
            "{'loss': 0.2653, 'learning_rate': 3.5647087820505153e-05, 'epoch': 6.69}\n",
            "{'loss': 0.1045, 'learning_rate': 3.5647087820505153e-05, 'epoch': 6.74}\n",
            "{'loss': 0.0009, 'learning_rate': 3.5647087820505153e-05, 'epoch': 6.8}\n",
            "{'loss': 0.0006, 'learning_rate': 3.5647087820505153e-05, 'epoch': 6.85}\n",
            "{'loss': 0.0882, 'learning_rate': 3.5647087820505153e-05, 'epoch': 6.91}\n",
            "{'loss': 0.0135, 'learning_rate': 3.5647087820505153e-05, 'epoch': 6.96}\n",
            "{'loss': 0.0703, 'learning_rate': 3.5647087820505153e-05, 'epoch': 7.02}\n",
            "{'loss': 0.0008, 'learning_rate': 3.5647087820505153e-05, 'epoch': 7.07}\n",
            "{'loss': 0.0061, 'learning_rate': 3.5647087820505153e-05, 'epoch': 7.13}\n",
            "{'loss': 0.0005, 'learning_rate': 3.5647087820505153e-05, 'epoch': 7.18}\n",
            "{'loss': 0.0005, 'learning_rate': 3.5647087820505153e-05, 'epoch': 7.24}\n",
            "{'loss': 0.0004, 'learning_rate': 3.5647087820505153e-05, 'epoch': 7.29}\n",
            "{'loss': 0.0004, 'learning_rate': 3.5647087820505153e-05, 'epoch': 7.35}\n",
            "{'loss': 0.0003, 'learning_rate': 3.5647087820505153e-05, 'epoch': 7.4}\n",
            "{'loss': 0.0194, 'learning_rate': 3.5647087820505153e-05, 'epoch': 7.46}\n",
            "{'loss': 0.0995, 'learning_rate': 3.5647087820505153e-05, 'epoch': 7.51}\n",
            "{'loss': 0.0849, 'learning_rate': 3.5647087820505153e-05, 'epoch': 7.57}\n",
            "{'loss': 0.0426, 'learning_rate': 3.5647087820505153e-05, 'epoch': 7.62}\n",
            "{'loss': 0.0005, 'learning_rate': 3.5647087820505153e-05, 'epoch': 7.68}\n",
            "{'loss': 0.1032, 'learning_rate': 3.5647087820505153e-05, 'epoch': 7.73}\n",
            "{'loss': 0.0016, 'learning_rate': 3.5647087820505153e-05, 'epoch': 7.79}\n",
            "{'loss': 0.2436, 'learning_rate': 3.5647087820505153e-05, 'epoch': 7.85}\n",
            "{'loss': 0.0839, 'learning_rate': 3.5647087820505153e-05, 'epoch': 7.9}\n",
            "{'loss': 0.0444, 'learning_rate': 3.5647087820505153e-05, 'epoch': 7.96}\n",
            "{'loss': 0.0004, 'learning_rate': 3.5647087820505153e-05, 'epoch': 8.01}\n",
            "{'loss': 0.0004, 'learning_rate': 3.5647087820505153e-05, 'epoch': 8.07}\n",
            "{'loss': 0.0004, 'learning_rate': 3.5647087820505153e-05, 'epoch': 8.12}\n",
            "{'loss': 0.0004, 'learning_rate': 3.5647087820505153e-05, 'epoch': 8.18}\n",
            "{'loss': 0.0003, 'learning_rate': 3.5647087820505153e-05, 'epoch': 8.23}\n",
            "{'loss': 0.0003, 'learning_rate': 3.5647087820505153e-05, 'epoch': 8.29}\n",
            "{'loss': 0.0907, 'learning_rate': 3.5647087820505153e-05, 'epoch': 8.34}\n",
            "{'loss': 0.0011, 'learning_rate': 3.5647087820505153e-05, 'epoch': 8.4}\n",
            "{'loss': 0.0732, 'learning_rate': 3.5647087820505153e-05, 'epoch': 8.45}\n",
            "{'loss': 0.1668, 'learning_rate': 3.5647087820505153e-05, 'epoch': 8.51}\n",
            "{'loss': 0.001, 'learning_rate': 3.5647087820505153e-05, 'epoch': 8.56}\n",
            "{'loss': 0.0005, 'learning_rate': 3.5647087820505153e-05, 'epoch': 8.62}\n",
            "{'loss': 0.0701, 'learning_rate': 3.5647087820505153e-05, 'epoch': 8.67}\n",
            "{'loss': 0.0002, 'learning_rate': 3.5647087820505153e-05, 'epoch': 8.73}\n",
            "{'loss': 0.0003, 'learning_rate': 3.5647087820505153e-05, 'epoch': 8.78}\n",
            "{'loss': 0.0007, 'learning_rate': 3.5647087820505153e-05, 'epoch': 8.84}\n",
            "{'loss': 0.0003, 'learning_rate': 3.5647087820505153e-05, 'epoch': 8.9}\n",
            "{'loss': 0.0788, 'learning_rate': 3.5647087820505153e-05, 'epoch': 8.95}\n",
            "{'loss': 0.0002, 'learning_rate': 3.5647087820505153e-05, 'epoch': 9.01}\n",
            "{'loss': 0.1169, 'learning_rate': 3.5647087820505153e-05, 'epoch': 9.06}\n",
            "{'loss': 0.0003, 'learning_rate': 3.5647087820505153e-05, 'epoch': 9.12}\n",
            "{'loss': 0.0919, 'learning_rate': 3.5647087820505153e-05, 'epoch': 9.17}\n",
            "{'loss': 0.0003, 'learning_rate': 3.5647087820505153e-05, 'epoch': 9.23}\n",
            "{'loss': 0.0026, 'learning_rate': 3.5647087820505153e-05, 'epoch': 9.28}\n",
            "{'loss': 0.0766, 'learning_rate': 3.5647087820505153e-05, 'epoch': 9.34}\n",
            "{'loss': 0.0854, 'learning_rate': 3.5647087820505153e-05, 'epoch': 9.39}\n",
            "{'loss': 0.001, 'learning_rate': 3.5647087820505153e-05, 'epoch': 9.45}\n",
            "{'loss': 0.0033, 'learning_rate': 3.5647087820505153e-05, 'epoch': 9.5}\n",
            "{'loss': 0.0003, 'learning_rate': 3.5647087820505153e-05, 'epoch': 9.56}\n",
            "{'loss': 0.0002, 'learning_rate': 3.5647087820505153e-05, 'epoch': 9.61}\n",
            "{'loss': 0.0664, 'learning_rate': 3.5647087820505153e-05, 'epoch': 9.67}\n",
            "{'loss': 0.0462, 'learning_rate': 3.5647087820505153e-05, 'epoch': 9.72}\n",
            "{'loss': 0.0002, 'learning_rate': 3.5647087820505153e-05, 'epoch': 9.78}\n",
            "{'loss': 0.1866, 'learning_rate': 3.5647087820505153e-05, 'epoch': 9.83}\n",
            "{'loss': 0.1063, 'learning_rate': 3.5647087820505153e-05, 'epoch': 9.89}\n",
            "{'loss': 0.013, 'learning_rate': 3.5647087820505153e-05, 'epoch': 9.94}\n",
            "{'loss': 0.0669, 'learning_rate': 3.5647087820505153e-05, 'epoch': 10.0}\n",
            "{'train_runtime': 196.822, 'train_samples_per_second': 73.417, 'train_steps_per_second': 9.196, 'train_loss': 0.17482083769468848, 'epoch': 10.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 52/52 [00:01<00:00, 40.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 21:59:11,363] Trial 13 finished with value: 0.9076923076923076 and parameters: {'learning_rate': 3.5647087820505153e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.0023566151926759094, 'num_train_epochs': 10, 'warmup_steps': 74, 'freeze_layers': 0, 'dropout': 0.30477163229818194, 'lr_scheduler_type': 'constant_with_warmup'}. Best is trial 4 with value: 0.9168765743073047.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: cosine\n",
            " Warmup steps (True): 276\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "05ae99f5b2a84b6cb3de438f99c75091",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1086 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.761, 'learning_rate': 2.026875416493092e-06, 'epoch': 0.06}\n",
            "{'loss': 0.6862, 'learning_rate': 5.06718854123273e-06, 'epoch': 0.11}\n",
            "{'loss': 0.7062, 'learning_rate': 8.445314235387885e-06, 'epoch': 0.17}\n",
            "{'loss': 0.7408, 'learning_rate': 1.1485627360127522e-05, 'epoch': 0.22}\n",
            "{'loss': 0.6802, 'learning_rate': 1.4863753054282675e-05, 'epoch': 0.28}\n",
            "{'loss': 0.6765, 'learning_rate': 1.824187874843783e-05, 'epoch': 0.33}\n",
            "{'loss': 0.6171, 'learning_rate': 2.1620004442592984e-05, 'epoch': 0.39}\n",
            "{'loss': 0.6786, 'learning_rate': 2.499813013674814e-05, 'epoch': 0.44}\n",
            "{'loss': 0.6665, 'learning_rate': 2.8376255830903293e-05, 'epoch': 0.5}\n",
            "{'loss': 0.5759, 'learning_rate': 3.175438152505845e-05, 'epoch': 0.55}\n",
            "{'loss': 0.6089, 'learning_rate': 3.51325072192136e-05, 'epoch': 0.61}\n",
            "{'loss': 0.4883, 'learning_rate': 3.851063291336875e-05, 'epoch': 0.66}\n",
            "{'loss': 0.4394, 'learning_rate': 4.18887586075239e-05, 'epoch': 0.72}\n",
            "{'loss': 0.6073, 'learning_rate': 4.526688430167906e-05, 'epoch': 0.77}\n",
            "{'loss': 0.5273, 'learning_rate': 4.864500999583421e-05, 'epoch': 0.83}\n",
            "{'loss': 0.412, 'learning_rate': 5.202313568998937e-05, 'epoch': 0.88}\n",
            "{'loss': 0.4536, 'learning_rate': 5.540126138414452e-05, 'epoch': 0.94}\n",
            "{'loss': 0.6207, 'learning_rate': 5.877938707829968e-05, 'epoch': 0.99}\n",
            "{'loss': 0.6185, 'learning_rate': 6.215751277245482e-05, 'epoch': 1.05}\n",
            "{'loss': 0.5259, 'learning_rate': 6.553563846660999e-05, 'epoch': 1.1}\n",
            "{'loss': 0.421, 'learning_rate': 6.891376416076512e-05, 'epoch': 1.16}\n",
            "{'loss': 0.3124, 'learning_rate': 7.229188985492029e-05, 'epoch': 1.22}\n",
            "{'loss': 0.2905, 'learning_rate': 7.567001554907544e-05, 'epoch': 1.27}\n",
            "{'loss': 0.5922, 'learning_rate': 7.904814124323059e-05, 'epoch': 1.33}\n",
            "{'loss': 0.4364, 'learning_rate': 8.242626693738576e-05, 'epoch': 1.38}\n",
            "{'loss': 0.3206, 'learning_rate': 8.58043926315409e-05, 'epoch': 1.44}\n",
            "{'loss': 0.3304, 'learning_rate': 8.918251832569606e-05, 'epoch': 1.49}\n",
            "{'loss': 0.6096, 'learning_rate': 9.256064401985121e-05, 'epoch': 1.55}\n",
            "{'loss': 0.5377, 'learning_rate': 9.321383035317905e-05, 'epoch': 1.6}\n",
            "{'loss': 0.3966, 'learning_rate': 9.312270972586622e-05, 'epoch': 1.66}\n",
            "{'loss': 0.7053, 'learning_rate': 9.29616417999918e-05, 'epoch': 1.71}\n",
            "{'loss': 0.6279, 'learning_rate': 9.27308688370164e-05, 'epoch': 1.77}\n",
            "{'loss': 0.3291, 'learning_rate': 9.243073794139784e-05, 'epoch': 1.82}\n",
            "{'loss': 0.5138, 'learning_rate': 9.2061700538513e-05, 'epoch': 1.88}\n",
            "{'loss': 0.6482, 'learning_rate': 9.162431169567126e-05, 'epoch': 1.93}\n",
            "{'loss': 0.5888, 'learning_rate': 9.111922928724049e-05, 'epoch': 1.99}\n",
            "{'loss': 0.4316, 'learning_rate': 9.054721300514152e-05, 'epoch': 2.04}\n",
            "{'loss': 0.2916, 'learning_rate': 8.990912321619934e-05, 'epoch': 2.1}\n",
            "{'loss': 0.3011, 'learning_rate': 8.920591966806966e-05, 'epoch': 2.15}\n",
            "{'loss': 0.3942, 'learning_rate': 8.843866004568725e-05, 'epoch': 2.21}\n",
            "{'loss': 0.2321, 'learning_rate': 8.760849838040734e-05, 'epoch': 2.27}\n",
            "{'loss': 0.2752, 'learning_rate': 8.671668331423286e-05, 'epoch': 2.32}\n",
            "{'loss': 0.58, 'learning_rate': 8.57645562217382e-05, 'epoch': 2.38}\n",
            "{'loss': 0.4514, 'learning_rate': 8.475354919251451e-05, 'epoch': 2.43}\n",
            "{'loss': 0.1924, 'learning_rate': 8.368518287717083e-05, 'epoch': 2.49}\n",
            "{'loss': 0.3458, 'learning_rate': 8.256106420013124e-05, 'epoch': 2.54}\n",
            "{'loss': 0.5366, 'learning_rate': 8.138288394266775e-05, 'epoch': 2.6}\n",
            "{'loss': 0.3367, 'learning_rate': 8.015241419980473e-05, 'epoch': 2.65}\n",
            "{'loss': 0.2027, 'learning_rate': 7.887150571491967e-05, 'epoch': 2.71}\n",
            "{'loss': 0.2841, 'learning_rate': 7.754208509604932e-05, 'epoch': 2.76}\n",
            "{'loss': 0.3193, 'learning_rate': 7.616615191808816e-05, 'epoch': 2.82}\n",
            "{'loss': 0.2099, 'learning_rate': 7.474577571523787e-05, 'epoch': 2.87}\n",
            "{'loss': 0.131, 'learning_rate': 7.328309286823124e-05, 'epoch': 2.93}\n",
            "{'loss': 0.2736, 'learning_rate': 7.178030339101266e-05, 'epoch': 2.98}\n",
            "{'loss': 0.2205, 'learning_rate': 7.023966762170818e-05, 'epoch': 3.04}\n",
            "{'loss': 0.3233, 'learning_rate': 6.866350282286217e-05, 'epoch': 3.09}\n",
            "{'loss': 0.2156, 'learning_rate': 6.705417969605444e-05, 'epoch': 3.15}\n",
            "{'loss': 0.2057, 'learning_rate': 6.541411881613977e-05, 'epoch': 3.2}\n",
            "{'loss': 0.142, 'learning_rate': 6.374578699047346e-05, 'epoch': 3.26}\n",
            "{'loss': 0.0615, 'learning_rate': 6.205169354859874e-05, 'epoch': 3.31}\n",
            "{'loss': 0.3587, 'learning_rate': 6.033438656797672e-05, 'epoch': 3.37}\n",
            "{'loss': 0.3352, 'learning_rate': 5.8596449041435904e-05, 'epoch': 3.43}\n",
            "{'loss': 0.2242, 'learning_rate': 5.684049499210556e-05, 'epoch': 3.48}\n",
            "{'loss': 0.2029, 'learning_rate': 5.5069165541676664e-05, 'epoch': 3.54}\n",
            "{'loss': 0.1171, 'learning_rate': 5.328512493790396e-05, 'epoch': 3.59}\n",
            "{'loss': 0.4317, 'learning_rate': 5.149105654732431e-05, 'epoch': 3.65}\n",
            "{'loss': 0.2423, 'learning_rate': 4.9689658819218437e-05, 'epoch': 3.7}\n",
            "{'loss': 0.1486, 'learning_rate': 4.788364122688698e-05, 'epoch': 3.76}\n",
            "{'loss': 0.2183, 'learning_rate': 4.6075720192345195e-05, 'epoch': 3.81}\n",
            "{'loss': 0.2742, 'learning_rate': 4.426861500056622e-05, 'epoch': 3.87}\n",
            "{'loss': 0.2216, 'learning_rate': 4.246504370941821e-05, 'epoch': 3.92}\n",
            "{'loss': 0.2528, 'learning_rate': 4.066771906144705e-05, 'epoch': 3.98}\n",
            "{'loss': 0.1605, 'learning_rate': 3.887934440365396e-05, 'epoch': 4.03}\n",
            "{'loss': 0.1085, 'learning_rate': 3.710260962140468e-05, 'epoch': 4.09}\n",
            "{'loss': 0.0862, 'learning_rate': 3.5340187092586504e-05, 'epoch': 4.14}\n",
            "{'loss': 0.1356, 'learning_rate': 3.359472766809801e-05, 'epoch': 4.2}\n",
            "{'loss': 0.201, 'learning_rate': 3.186885668471749e-05, 'epoch': 4.25}\n",
            "{'loss': 0.1292, 'learning_rate': 3.0165170016347128e-05, 'epoch': 4.31}\n",
            "{'loss': 0.1738, 'learning_rate': 2.8486230169571917e-05, 'epoch': 4.36}\n",
            "{'loss': 0.0648, 'learning_rate': 2.683456242940655e-05, 'epoch': 4.42}\n",
            "{'loss': 0.1829, 'learning_rate': 2.521265106102664e-05, 'epoch': 4.48}\n",
            "{'loss': 0.3806, 'learning_rate': 2.3622935573198145e-05, 'epoch': 4.53}\n",
            "{'loss': 0.2642, 'learning_rate': 2.206780704902424e-05, 'epoch': 4.59}\n",
            "{'loss': 0.1983, 'learning_rate': 2.0549604549529343e-05, 'epoch': 4.64}\n",
            "{'loss': 0.1582, 'learning_rate': 1.907061159548909e-05, 'epoch': 4.7}\n",
            "{'loss': 0.1271, 'learning_rate': 1.7633052732798185e-05, 'epoch': 4.75}\n",
            "{'loss': 0.1866, 'learning_rate': 1.6239090186542033e-05, 'epoch': 4.81}\n",
            "{'loss': 0.1361, 'learning_rate': 1.4890820608804861e-05, 'epoch': 4.86}\n",
            "{'loss': 0.0853, 'learning_rate': 1.3590271925105782e-05, 'epoch': 4.92}\n",
            "{'loss': 0.1206, 'learning_rate': 1.2339400284206207e-05, 'epoch': 4.97}\n",
            "{'loss': 0.1236, 'learning_rate': 1.1140087115876272e-05, 'epoch': 5.03}\n",
            "{'loss': 0.1286, 'learning_rate': 9.994136301045741e-06, 'epoch': 5.08}\n",
            "{'loss': 0.2009, 'learning_rate': 8.903271458595768e-06, 'epoch': 5.14}\n",
            "{'loss': 0.0089, 'learning_rate': 7.86913335287231e-06, 'epoch': 5.19}\n",
            "{'loss': 0.0404, 'learning_rate': 6.893277425820764e-06, 'epoch': 5.25}\n",
            "{'loss': 0.1753, 'learning_rate': 5.977171457453461e-06, 'epoch': 5.3}\n",
            "{'loss': 0.0379, 'learning_rate': 5.122193358169144e-06, 'epoch': 5.36}\n",
            "{'loss': 0.0788, 'learning_rate': 4.329629096244825e-06, 'epoch': 5.41}\n",
            "{'loss': 0.0818, 'learning_rate': 3.6006707636173392e-06, 'epoch': 5.47}\n",
            "{'loss': 0.1282, 'learning_rate': 2.93641478286383e-06, 'epoch': 5.52}\n",
            "{'loss': 0.2161, 'learning_rate': 2.3378602580780453e-06, 'epoch': 5.58}\n",
            "{'loss': 0.074, 'learning_rate': 1.8059074721228864e-06, 'epoch': 5.64}\n",
            "{'loss': 0.1402, 'learning_rate': 1.3413565325194422e-06, 'epoch': 5.69}\n",
            "{'loss': 0.1311, 'learning_rate': 9.449061680092878e-07, 'epoch': 5.75}\n",
            "{'loss': 0.1337, 'learning_rate': 6.171526776000676e-07, 'epoch': 5.8}\n",
            "{'loss': 0.021, 'learning_rate': 3.5858903367517464e-07, 'epoch': 5.86}\n",
            "{'loss': 0.0157, 'learning_rate': 1.6960414051643122e-07, 'epoch': 5.91}\n",
            "{'loss': 0.1803, 'learning_rate': 5.0482249355104354e-08, 'epoch': 5.97}\n",
            "{'train_runtime': 110.7559, 'train_samples_per_second': 78.28, 'train_steps_per_second': 9.805, 'train_loss': 0.3181997524646435, 'epoch': 6.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 52/52 [00:01<00:00, 35.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 22:01:06,107] Trial 14 finished with value: 0.915 and parameters: {'learning_rate': 9.323626915868224e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.18509355959041482, 'num_train_epochs': 6, 'warmup_steps': 276, 'freeze_layers': 0, 'dropout': 0.1911639157134058, 'lr_scheduler_type': 'cosine'}. Best is trial 4 with value: 0.9168765743073047.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: cosine\n",
            " Warmup steps (True): 285\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "44c9311428bb4b2ca0a018e45695b32e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1448 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7087, 'learning_rate': 2.4420082812748986e-06, 'epoch': 0.06}\n",
            "{'loss': 0.7085, 'learning_rate': 5.232874888446211e-06, 'epoch': 0.11}\n",
            "{'loss': 0.7322, 'learning_rate': 8.721458147410351e-06, 'epoch': 0.17}\n",
            "{'loss': 0.6861, 'learning_rate': 1.221004140637449e-05, 'epoch': 0.22}\n",
            "{'loss': 0.6793, 'learning_rate': 1.5698624665338632e-05, 'epoch': 0.28}\n",
            "{'loss': 0.6682, 'learning_rate': 1.9187207924302773e-05, 'epoch': 0.33}\n",
            "{'loss': 0.6397, 'learning_rate': 2.267579118326691e-05, 'epoch': 0.39}\n",
            "{'loss': 0.6774, 'learning_rate': 2.6164374442231052e-05, 'epoch': 0.44}\n",
            "{'loss': 0.6301, 'learning_rate': 2.9652957701195193e-05, 'epoch': 0.5}\n",
            "{'loss': 0.5532, 'learning_rate': 3.314154096015933e-05, 'epoch': 0.55}\n",
            "{'loss': 0.6081, 'learning_rate': 3.663012421912347e-05, 'epoch': 0.61}\n",
            "{'loss': 0.4589, 'learning_rate': 4.011870747808761e-05, 'epoch': 0.66}\n",
            "{'loss': 0.417, 'learning_rate': 4.3607290737051754e-05, 'epoch': 0.72}\n",
            "{'loss': 0.451, 'learning_rate': 4.7095873996015896e-05, 'epoch': 0.77}\n",
            "{'loss': 0.5465, 'learning_rate': 5.0584457254980043e-05, 'epoch': 0.83}\n",
            "{'loss': 0.4066, 'learning_rate': 5.4073040513944185e-05, 'epoch': 0.88}\n",
            "{'loss': 0.6399, 'learning_rate': 5.756162377290832e-05, 'epoch': 0.94}\n",
            "{'loss': 0.6194, 'learning_rate': 6.105020703187246e-05, 'epoch': 0.99}\n",
            "{'loss': 0.7715, 'learning_rate': 6.453879029083661e-05, 'epoch': 1.05}\n",
            "{'loss': 0.5488, 'learning_rate': 6.802737354980074e-05, 'epoch': 1.1}\n",
            "{'loss': 0.5427, 'learning_rate': 7.151595680876488e-05, 'epoch': 1.16}\n",
            "{'loss': 0.5064, 'learning_rate': 7.500454006772902e-05, 'epoch': 1.22}\n",
            "{'loss': 0.4125, 'learning_rate': 7.849312332669316e-05, 'epoch': 1.27}\n",
            "{'loss': 0.5101, 'learning_rate': 8.198170658565731e-05, 'epoch': 1.33}\n",
            "{'loss': 0.8174, 'learning_rate': 8.547028984462144e-05, 'epoch': 1.38}\n",
            "{'loss': 0.4096, 'learning_rate': 8.895887310358559e-05, 'epoch': 1.44}\n",
            "{'loss': 0.3634, 'learning_rate': 9.244745636254972e-05, 'epoch': 1.49}\n",
            "{'loss': 0.6591, 'learning_rate': 9.593603962151387e-05, 'epoch': 1.55}\n",
            "{'loss': 0.3604, 'learning_rate': 9.9424622880478e-05, 'epoch': 1.6}\n",
            "{'loss': 0.3181, 'learning_rate': 9.940648661483354e-05, 'epoch': 1.66}\n",
            "{'loss': 0.5266, 'learning_rate': 9.935209105100569e-05, 'epoch': 1.71}\n",
            "{'loss': 0.5953, 'learning_rate': 9.926147587865548e-05, 'epoch': 1.77}\n",
            "{'loss': 0.4792, 'learning_rate': 9.913470721503998e-05, 'epoch': 1.82}\n",
            "{'loss': 0.4674, 'learning_rate': 9.897187755676987e-05, 'epoch': 1.88}\n",
            "{'loss': 0.5197, 'learning_rate': 9.87731057123194e-05, 'epoch': 1.93}\n",
            "{'loss': 0.4361, 'learning_rate': 9.853853671533798e-05, 'epoch': 1.99}\n",
            "{'loss': 0.4242, 'learning_rate': 9.826834171882643e-05, 'epoch': 2.04}\n",
            "{'loss': 0.3836, 'learning_rate': 9.796271787025552e-05, 'epoch': 2.1}\n",
            "{'loss': 0.4895, 'learning_rate': 9.762188816771742e-05, 'epoch': 2.15}\n",
            "{'loss': 0.4369, 'learning_rate': 9.72461012972155e-05, 'epoch': 2.21}\n",
            "{'loss': 0.2678, 'learning_rate': 9.683563145121081e-05, 'epoch': 2.27}\n",
            "{'loss': 0.509, 'learning_rate': 9.639077812855788e-05, 'epoch': 2.32}\n",
            "{'loss': 0.3977, 'learning_rate': 9.591186591597569e-05, 'epoch': 2.38}\n",
            "{'loss': 0.392, 'learning_rate': 9.539924425121347e-05, 'epoch': 2.43}\n",
            "{'loss': 0.5074, 'learning_rate': 9.485328716808362e-05, 'epoch': 2.49}\n",
            "{'loss': 0.7206, 'learning_rate': 9.42743930235486e-05, 'epoch': 2.54}\n",
            "{'loss': 0.6151, 'learning_rate': 9.366298420706007e-05, 'epoch': 2.6}\n",
            "{'loss': 0.4764, 'learning_rate': 9.3019506832363e-05, 'epoch': 2.65}\n",
            "{'loss': 0.3443, 'learning_rate': 9.234443041198915e-05, 'epoch': 2.71}\n",
            "{'loss': 0.4191, 'learning_rate': 9.163824751467803e-05, 'epoch': 2.76}\n",
            "{'loss': 0.5208, 'learning_rate': 9.090147340597443e-05, 'epoch': 2.82}\n",
            "{'loss': 0.1918, 'learning_rate': 9.013464567226561e-05, 'epoch': 2.87}\n",
            "{'loss': 0.3562, 'learning_rate': 8.933832382853205e-05, 'epoch': 2.93}\n",
            "{'loss': 0.4094, 'learning_rate': 8.851308891009795e-05, 'epoch': 2.98}\n",
            "{'loss': 0.2031, 'learning_rate': 8.765954304867938e-05, 'epoch': 3.04}\n",
            "{'loss': 0.2989, 'learning_rate': 8.677830903303973e-05, 'epoch': 3.09}\n",
            "{'loss': 0.204, 'learning_rate': 8.587002985457242e-05, 'epoch': 3.15}\n",
            "{'loss': 0.3739, 'learning_rate': 8.493536823814309e-05, 'epoch': 3.2}\n",
            "{'loss': 0.302, 'learning_rate': 8.397500615853315e-05, 'epoch': 3.26}\n",
            "{'loss': 0.2024, 'learning_rate': 8.29896443428376e-05, 'epoch': 3.31}\n",
            "{'loss': 0.6245, 'learning_rate': 8.198000175918032e-05, 'epoch': 3.37}\n",
            "{'loss': 0.5051, 'learning_rate': 8.094681509211985e-05, 'epoch': 3.43}\n",
            "{'loss': 0.4888, 'learning_rate': 7.989083820512825e-05, 'epoch': 3.48}\n",
            "{'loss': 0.3851, 'learning_rate': 7.881284159053563e-05, 'epoch': 3.54}\n",
            "{'loss': 0.2341, 'learning_rate': 7.771361180734108e-05, 'epoch': 3.59}\n",
            "{'loss': 0.4273, 'learning_rate': 7.659395090730102e-05, 'epoch': 3.65}\n",
            "{'loss': 0.2134, 'learning_rate': 7.545467584971292e-05, 'epoch': 3.7}\n",
            "{'loss': 0.2277, 'learning_rate': 7.429661790532189e-05, 'epoch': 3.76}\n",
            "{'loss': 0.2832, 'learning_rate': 7.3120622049785e-05, 'epoch': 3.81}\n",
            "{'loss': 0.3799, 'learning_rate': 7.192754634713564e-05, 'epoch': 3.87}\n",
            "{'loss': 0.3387, 'learning_rate': 7.071826132369825e-05, 'epoch': 3.92}\n",
            "{'loss': 0.7887, 'learning_rate': 6.949364933290955e-05, 'epoch': 3.98}\n",
            "{'loss': 0.4521, 'learning_rate': 6.825460391151059e-05, 'epoch': 4.03}\n",
            "{'loss': 0.2214, 'learning_rate': 6.700202912757856e-05, 'epoch': 4.09}\n",
            "{'loss': 0.0937, 'learning_rate': 6.573683892087455e-05, 'epoch': 4.14}\n",
            "{'loss': 0.533, 'learning_rate': 6.445995643598849e-05, 'epoch': 4.2}\n",
            "{'loss': 0.3326, 'learning_rate': 6.317231334876775e-05, 'epoch': 4.25}\n",
            "{'loss': 0.1709, 'learning_rate': 6.187484918652092e-05, 'epoch': 4.31}\n",
            "{'loss': 0.0789, 'learning_rate': 6.0568510642492693e-05, 'epoch': 4.36}\n",
            "{'loss': 0.2218, 'learning_rate': 5.925425088511043e-05, 'epoch': 4.42}\n",
            "{'loss': 0.1213, 'learning_rate': 5.7933028862505616e-05, 'epoch': 4.48}\n",
            "{'loss': 0.5223, 'learning_rate': 5.660580860281874e-05, 'epoch': 4.53}\n",
            "{'loss': 0.2673, 'learning_rate': 5.5273558510797084e-05, 'epoch': 4.59}\n",
            "{'loss': 0.1983, 'learning_rate': 5.3937250661199305e-05, 'epoch': 4.64}\n",
            "{'loss': 0.353, 'learning_rate': 5.2597860089522306e-05, 'epoch': 4.7}\n",
            "{'loss': 0.1822, 'learning_rate': 5.1256364080567606e-05, 'epoch': 4.75}\n",
            "{'loss': 0.4641, 'learning_rate': 4.9913741455366635e-05, 'epoch': 4.81}\n",
            "{'loss': 0.4166, 'learning_rate': 4.857097185698511e-05, 'epoch': 4.86}\n",
            "{'loss': 0.3541, 'learning_rate': 4.7229035035727484e-05, 'epoch': 4.92}\n",
            "{'loss': 0.252, 'learning_rate': 4.5888910134263424e-05, 'epoch': 4.97}\n",
            "{'loss': 0.2478, 'learning_rate': 4.4551574973197317e-05, 'epoch': 5.03}\n",
            "{'loss': 0.17, 'learning_rate': 4.32180053376027e-05, 'epoch': 5.08}\n",
            "{'loss': 0.3715, 'learning_rate': 4.188917426504173e-05, 'epoch': 5.14}\n",
            "{'loss': 0.2077, 'learning_rate': 4.056605133558944e-05, 'epoch': 5.19}\n",
            "{'loss': 0.1726, 'learning_rate': 3.924960196438082e-05, 'epoch': 5.25}\n",
            "{'loss': 0.2029, 'learning_rate': 3.79407866971966e-05, 'epoch': 5.3}\n",
            "{'loss': 0.2088, 'learning_rate': 3.664056050960236e-05, 'epoch': 5.36}\n",
            "{'loss': 0.2114, 'learning_rate': 3.5349872110151426e-05, 'epoch': 5.41}\n",
            "{'loss': 0.162, 'learning_rate': 3.4069663248161005e-05, 'epoch': 5.47}\n",
            "{'loss': 0.2975, 'learning_rate': 3.280086802656569e-05, 'epoch': 5.52}\n",
            "{'loss': 0.2356, 'learning_rate': 3.1544412220350426e-05, 'epoch': 5.58}\n",
            "{'loss': 0.1657, 'learning_rate': 3.0301212601059784e-05, 'epoch': 5.64}\n",
            "{'loss': 0.4367, 'learning_rate': 2.907217626787672e-05, 'epoch': 5.69}\n",
            "{'loss': 0.2082, 'learning_rate': 2.7858199985758598e-05, 'epoch': 5.75}\n",
            "{'loss': 0.1711, 'learning_rate': 2.6660169531113772e-05, 'epoch': 5.8}\n",
            "{'loss': 0.1763, 'learning_rate': 2.5478959045495724e-05, 'epoch': 5.86}\n",
            "{'loss': 0.1797, 'learning_rate': 2.431543039778681e-05, 'epoch': 5.91}\n",
            "{'loss': 0.2357, 'learning_rate': 2.3170432555336483e-05, 'epoch': 5.97}\n",
            "{'loss': 0.1113, 'learning_rate': 2.2044800964513316e-05, 'epoch': 6.02}\n",
            "{'loss': 0.0601, 'learning_rate': 2.0939356941122466e-05, 'epoch': 6.08}\n",
            "{'loss': 0.0712, 'learning_rate': 1.9854907071133625e-05, 'epoch': 6.13}\n",
            "{'loss': 0.0103, 'learning_rate': 1.8792242622156367e-05, 'epoch': 6.19}\n",
            "{'loss': 0.2364, 'learning_rate': 1.7752138966092698e-05, 'epoch': 6.24}\n",
            "{'loss': 0.3887, 'learning_rate': 1.673535501338784e-05, 'epoch': 6.3}\n",
            "{'loss': 0.1636, 'learning_rate': 1.574263265929211e-05, 'epoch': 6.35}\n",
            "{'loss': 0.2927, 'learning_rate': 1.4774696242537815e-05, 'epoch': 6.41}\n",
            "{'loss': 0.0662, 'learning_rate': 1.383225201682644e-05, 'epoch': 6.46}\n",
            "{'loss': 0.0757, 'learning_rate': 1.2915987635511326e-05, 'epoch': 6.52}\n",
            "{'loss': 0.1763, 'learning_rate': 1.2026571649852258e-05, 'epoch': 6.57}\n",
            "{'loss': 0.2344, 'learning_rate': 1.1164653021207775e-05, 'epoch': 6.63}\n",
            "{'loss': 0.3036, 'learning_rate': 1.0330860647521284e-05, 'epoch': 6.69}\n",
            "{'loss': 0.291, 'learning_rate': 9.525802904446353e-06, 'epoch': 6.74}\n",
            "{'loss': 0.1644, 'learning_rate': 8.750067201446123e-06, 'epoch': 6.8}\n",
            "{'loss': 0.2941, 'learning_rate': 8.004219553190674e-06, 'epoch': 6.85}\n",
            "{'loss': 0.285, 'learning_rate': 7.288804166565084e-06, 'epoch': 6.91}\n",
            "{'loss': 0.2164, 'learning_rate': 6.60434304358946e-06, 'epoch': 6.96}\n",
            "{'loss': 0.1486, 'learning_rate': 5.951335600540769e-06, 'epoch': 7.02}\n",
            "{'loss': 0.1263, 'learning_rate': 5.330258303554333e-06, 'epoch': 7.07}\n",
            "{'loss': 0.1142, 'learning_rate': 4.741564320970836e-06, 'epoch': 7.13}\n",
            "{'loss': 0.0114, 'learning_rate': 4.1856831926826285e-06, 'epoch': 7.18}\n",
            "{'loss': 0.1321, 'learning_rate': 3.663020516720329e-06, 'epoch': 7.24}\n",
            "{'loss': 0.1178, 'learning_rate': 3.1739576533087677e-06, 'epoch': 7.29}\n",
            "{'loss': 0.1708, 'learning_rate': 2.718851446607894e-06, 'epoch': 7.35}\n",
            "{'loss': 0.1214, 'learning_rate': 2.298033964341871e-06, 'epoch': 7.4}\n",
            "{'loss': 0.1334, 'learning_rate': 1.911812255506197e-06, 'epoch': 7.46}\n",
            "{'loss': 0.2397, 'learning_rate': 1.560468126329819e-06, 'epoch': 7.51}\n",
            "{'loss': 0.0567, 'learning_rate': 1.2442579346554764e-06, 'epoch': 7.57}\n",
            "{'loss': 0.1312, 'learning_rate': 9.634124028885213e-07, 'epoch': 7.62}\n",
            "{'loss': 0.1292, 'learning_rate': 7.181364496505816e-07, 'epoch': 7.68}\n",
            "{'loss': 0.1775, 'learning_rate': 5.086090402609291e-07, 'epoch': 7.73}\n",
            "{'loss': 0.1272, 'learning_rate': 3.349830561546151e-07, 'epoch': 7.79}\n",
            "{'loss': 0.063, 'learning_rate': 1.9738518333272899e-07, 'epoch': 7.85}\n",
            "{'loss': 0.2435, 'learning_rate': 9.591581992608696e-08, 'epoch': 7.9}\n",
            "{'loss': 0.1158, 'learning_rate': 3.0649002939852676e-08, 'epoch': 7.96}\n",
            "{'train_runtime': 147.5049, 'train_samples_per_second': 78.37, 'train_steps_per_second': 9.817, 'train_loss': 0.3428010452353493, 'epoch': 8.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 52/52 [00:01<00:00, 39.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 22:03:37,414] Trial 15 finished with value: 0.8997429305912596 and parameters: {'learning_rate': 9.9424622880478e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.112862050686657, 'num_train_epochs': 8, 'warmup_steps': 285, 'freeze_layers': 0, 'dropout': 0.16004110862844895, 'lr_scheduler_type': 'cosine'}. Best is trial 4 with value: 0.9168765743073047.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: cosine\n",
            " Warmup steps (True): 254\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "73744b56795c447ab5c0ccba865e820b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1086 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.6954, 'learning_rate': 2.1877297443651984e-06, 'epoch': 0.06}\n",
            "{'loss': 0.7164, 'learning_rate': 4.648925706776047e-06, 'epoch': 0.11}\n",
            "{'loss': 0.6825, 'learning_rate': 7.110121669186894e-06, 'epoch': 0.17}\n",
            "{'loss': 0.6725, 'learning_rate': 9.297851413552094e-06, 'epoch': 0.22}\n",
            "{'loss': 0.6871, 'learning_rate': 1.2032513594008591e-05, 'epoch': 0.28}\n",
            "{'loss': 0.6883, 'learning_rate': 1.476717577446509e-05, 'epoch': 0.33}\n",
            "{'loss': 0.6941, 'learning_rate': 1.7501837954921587e-05, 'epoch': 0.39}\n",
            "{'loss': 0.7137, 'learning_rate': 2.0236500135378083e-05, 'epoch': 0.44}\n",
            "{'loss': 0.6574, 'learning_rate': 2.2971162315834585e-05, 'epoch': 0.5}\n",
            "{'loss': 0.6372, 'learning_rate': 2.570582449629108e-05, 'epoch': 0.55}\n",
            "{'loss': 0.6536, 'learning_rate': 2.8440486676747576e-05, 'epoch': 0.61}\n",
            "{'loss': 0.6657, 'learning_rate': 3.1175148857204075e-05, 'epoch': 0.66}\n",
            "{'loss': 0.6014, 'learning_rate': 3.390981103766058e-05, 'epoch': 0.72}\n",
            "{'loss': 0.5787, 'learning_rate': 3.6644473218117066e-05, 'epoch': 0.77}\n",
            "{'loss': 0.5483, 'learning_rate': 3.937913539857357e-05, 'epoch': 0.83}\n",
            "{'loss': 0.4229, 'learning_rate': 4.211379757903007e-05, 'epoch': 0.88}\n",
            "{'loss': 0.3961, 'learning_rate': 4.4848459759486567e-05, 'epoch': 0.94}\n",
            "{'loss': 0.6821, 'learning_rate': 4.758312193994306e-05, 'epoch': 0.99}\n",
            "{'loss': 0.6184, 'learning_rate': 5.0317784120399565e-05, 'epoch': 1.05}\n",
            "{'loss': 0.4387, 'learning_rate': 5.305244630085606e-05, 'epoch': 1.1}\n",
            "{'loss': 0.5267, 'learning_rate': 5.5787108481312556e-05, 'epoch': 1.16}\n",
            "{'loss': 0.4492, 'learning_rate': 5.852177066176905e-05, 'epoch': 1.22}\n",
            "{'loss': 0.3468, 'learning_rate': 6.125643284222555e-05, 'epoch': 1.27}\n",
            "{'loss': 0.4878, 'learning_rate': 6.399109502268206e-05, 'epoch': 1.33}\n",
            "{'loss': 0.3898, 'learning_rate': 6.672575720313855e-05, 'epoch': 1.38}\n",
            "{'loss': 0.4784, 'learning_rate': 6.946041938359505e-05, 'epoch': 1.44}\n",
            "{'loss': 0.4713, 'learning_rate': 6.9435663473248e-05, 'epoch': 1.49}\n",
            "{'loss': 0.4795, 'learning_rate': 6.936143103454186e-05, 'epoch': 1.55}\n",
            "{'loss': 0.3575, 'learning_rate': 6.923782789416832e-05, 'epoch': 1.6}\n",
            "{'loss': 0.5122, 'learning_rate': 6.906503026230803e-05, 'epoch': 1.66}\n",
            "{'loss': 0.4857, 'learning_rate': 6.884328448142312e-05, 'epoch': 1.71}\n",
            "{'loss': 0.3926, 'learning_rate': 6.857290667506828e-05, 'epoch': 1.77}\n",
            "{'loss': 0.259, 'learning_rate': 6.825428229722105e-05, 'epoch': 1.82}\n",
            "{'loss': 0.3894, 'learning_rate': 6.788786558277395e-05, 'epoch': 1.88}\n",
            "{'loss': 0.7618, 'learning_rate': 6.747417889997136e-05, 'epoch': 1.93}\n",
            "{'loss': 0.5804, 'learning_rate': 6.701381200571496e-05, 'epoch': 1.99}\n",
            "{'loss': 0.2914, 'learning_rate': 6.650742120479892e-05, 'epoch': 2.04}\n",
            "{'loss': 0.0771, 'learning_rate': 6.595572841427347e-05, 'epoch': 2.1}\n",
            "{'loss': 0.499, 'learning_rate': 6.535952013427108e-05, 'epoch': 2.15}\n",
            "{'loss': 0.3404, 'learning_rate': 6.471964632676198e-05, 'epoch': 2.21}\n",
            "{'loss': 0.2921, 'learning_rate': 6.403701920383775e-05, 'epoch': 2.27}\n",
            "{'loss': 0.1849, 'learning_rate': 6.331261192725039e-05, 'epoch': 2.32}\n",
            "{'loss': 0.4452, 'learning_rate': 6.254745722106076e-05, 'epoch': 2.38}\n",
            "{'loss': 0.2693, 'learning_rate': 6.174264589937432e-05, 'epoch': 2.43}\n",
            "{'loss': 0.3263, 'learning_rate': 6.089932531126279e-05, 'epoch': 2.49}\n",
            "{'loss': 0.472, 'learning_rate': 6.0018697705089125e-05, 'epoch': 2.54}\n",
            "{'loss': 0.1578, 'learning_rate': 5.910201851456714e-05, 'epoch': 2.6}\n",
            "{'loss': 0.3285, 'learning_rate': 5.8150594568999555e-05, 'epoch': 2.65}\n",
            "{'loss': 0.3491, 'learning_rate': 5.716578223024585e-05, 'epoch': 2.71}\n",
            "{'loss': 0.1826, 'learning_rate': 5.61489854590758e-05, 'epoch': 2.76}\n",
            "{'loss': 0.3343, 'learning_rate': 5.510165381366549e-05, 'epoch': 2.82}\n",
            "{'loss': 0.7483, 'learning_rate': 5.402528038308912e-05, 'epoch': 2.87}\n",
            "{'loss': 0.3045, 'learning_rate': 5.2921399658752514e-05, 'epoch': 2.93}\n",
            "{'loss': 0.1833, 'learning_rate': 5.1791585346803023e-05, 'epoch': 2.98}\n",
            "{'loss': 0.1185, 'learning_rate': 5.063744812463441e-05, 'epoch': 3.04}\n",
            "{'loss': 0.0895, 'learning_rate': 4.9460633344685e-05, 'epoch': 3.09}\n",
            "{'loss': 0.0035, 'learning_rate': 4.826281868880274e-05, 'epoch': 3.15}\n",
            "{'loss': 0.2831, 'learning_rate': 4.704571177652096e-05, 'epoch': 3.2}\n",
            "{'loss': 0.0675, 'learning_rate': 4.581104773065469e-05, 'epoch': 3.26}\n",
            "{'loss': 0.2348, 'learning_rate': 4.456058670368785e-05, 'epoch': 3.31}\n",
            "{'loss': 0.3673, 'learning_rate': 4.329611136847792e-05, 'epoch': 3.37}\n",
            "{'loss': 0.1256, 'learning_rate': 4.2019424376855236e-05, 'epoch': 3.43}\n",
            "{'loss': 0.1596, 'learning_rate': 4.0732345789740045e-05, 'epoch': 3.48}\n",
            "{'loss': 0.4265, 'learning_rate': 3.94367104824409e-05, 'epoch': 3.54}\n",
            "{'loss': 0.1204, 'learning_rate': 3.813436552883352e-05, 'epoch': 3.59}\n",
            "{'loss': 0.1997, 'learning_rate': 3.6827167568149174e-05, 'epoch': 3.65}\n",
            "{'loss': 0.2826, 'learning_rate': 3.55169801581267e-05, 'epoch': 3.7}\n",
            "{'loss': 0.0762, 'learning_rate': 3.4205671118301166e-05, 'epoch': 3.76}\n",
            "{'loss': 0.1336, 'learning_rate': 3.2895109867217154e-05, 'epoch': 3.81}\n",
            "{'loss': 0.2662, 'learning_rate': 3.1587164757362254e-05, 'epoch': 3.87}\n",
            "{'loss': 0.2954, 'learning_rate': 3.0283700411620454e-05, 'epoch': 3.92}\n",
            "{'loss': 0.2005, 'learning_rate': 2.898657506504244e-05, 'epoch': 3.98}\n",
            "{'loss': 0.0581, 'learning_rate': 2.7697637915722547e-05, 'epoch': 4.03}\n",
            "{'loss': 0.0039, 'learning_rate': 2.6418726488558832e-05, 'epoch': 4.09}\n",
            "{'loss': 0.003, 'learning_rate': 2.5151664015654592e-05, 'epoch': 4.14}\n",
            "{'loss': 0.1054, 'learning_rate': 2.3898256837096e-05, 'epoch': 4.2}\n",
            "{'loss': 0.1818, 'learning_rate': 2.2660291825811027e-05, 'epoch': 4.25}\n",
            "{'loss': 0.0773, 'learning_rate': 2.1439533840181142e-05, 'epoch': 4.31}\n",
            "{'loss': 0.0031, 'learning_rate': 2.0237723208037117e-05, 'epoch': 4.36}\n",
            "{'loss': 0.0025, 'learning_rate': 1.9056573245625957e-05, 'epoch': 4.42}\n",
            "{'loss': 0.0675, 'learning_rate': 1.7897767815085866e-05, 'epoch': 4.48}\n",
            "{'loss': 0.222, 'learning_rate': 1.6762958923911318e-05, 'epoch': 4.53}\n",
            "{'loss': 0.2375, 'learning_rate': 1.565376436983062e-05, 'epoch': 4.59}\n",
            "{'loss': 0.1774, 'learning_rate': 1.4571765434453167e-05, 'epoch': 4.64}\n",
            "{'loss': 0.0027, 'learning_rate': 1.3518504628974688e-05, 'epoch': 4.7}\n",
            "{'loss': 0.0027, 'learning_rate': 1.2495483495154003e-05, 'epoch': 4.75}\n",
            "{'loss': 0.136, 'learning_rate': 1.1504160464696352e-05, 'epoch': 4.81}\n",
            "{'loss': 0.0112, 'learning_rate': 1.0545948780094922e-05, 'epoch': 4.86}\n",
            "{'loss': 0.076, 'learning_rate': 9.62221447989472e-06, 'epoch': 4.92}\n",
            "{'loss': 0.0849, 'learning_rate': 8.73427445125093e-06, 'epoch': 4.97}\n",
            "{'loss': 0.1333, 'learning_rate': 7.883394552558198e-06, 'epoch': 5.03}\n",
            "{'loss': 0.002, 'learning_rate': 7.070787808827016e-06, 'epoch': 5.08}\n",
            "{'loss': 0.0834, 'learning_rate': 6.297612682380177e-06, 'epoch': 5.14}\n",
            "{'loss': 0.0022, 'learning_rate': 5.564971421334385e-06, 'epoch': 5.19}\n",
            "{'loss': 0.0486, 'learning_rate': 4.873908488221586e-06, 'epoch': 5.25}\n",
            "{'loss': 0.0826, 'learning_rate': 4.225409070990177e-06, 'epoch': 5.3}\n",
            "{'loss': 0.0018, 'learning_rate': 3.620397678508663e-06, 'epoch': 5.36}\n",
            "{'loss': 0.0018, 'learning_rate': 3.059736822574368e-06, 'epoch': 5.41}\n",
            "{'loss': 0.0026, 'learning_rate': 2.5442257883058044e-06, 'epoch': 5.47}\n",
            "{'loss': 0.0706, 'learning_rate': 2.074599494671818e-06, 'epoch': 5.52}\n",
            "{'loss': 0.0018, 'learning_rate': 1.6515274467819302e-06, 'epoch': 5.58}\n",
            "{'loss': 0.0027, 'learning_rate': 1.2756127814315095e-06, 'epoch': 5.64}\n",
            "{'loss': 0.062, 'learning_rate': 9.473914072624022e-07, 'epoch': 5.69}\n",
            "{'loss': 0.0636, 'learning_rate': 6.673312407648983e-07, 'epoch': 5.75}\n",
            "{'loss': 0.0017, 'learning_rate': 4.358315392101224e-07, 'epoch': 5.8}\n",
            "{'loss': 0.0016, 'learning_rate': 2.5322233146388185e-07, 'epoch': 5.86}\n",
            "{'loss': 0.0018, 'learning_rate': 1.1976394749341734e-07, 'epoch': 5.91}\n",
            "{'loss': 0.0697, 'learning_rate': 3.564664723772219e-08, 'epoch': 5.97}\n",
            "{'train_runtime': 110.6148, 'train_samples_per_second': 78.38, 'train_steps_per_second': 9.818, 'train_loss': 0.2867701606195537, 'epoch': 6.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 52/52 [00:01<00:00, 40.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 22:05:31,819] Trial 16 finished with value: 0.8951406649616368 and parameters: {'learning_rate': 6.946041938359505e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.17706727872023129, 'num_train_epochs': 6, 'warmup_steps': 254, 'freeze_layers': 0, 'dropout': 0.19878395522296458, 'lr_scheduler_type': 'cosine'}. Best is trial 4 with value: 0.9168765743073047.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: linear\n",
            " Warmup steps (True): 244\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a580c371f4c41c1bb1b820c107df078",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/364 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7114, 'learning_rate': 4.748117888562756e-07, 'epoch': 0.11}\n",
            "{'loss': 0.7222, 'learning_rate': 1.06832652492662e-06, 'epoch': 0.22}\n",
            "{'loss': 0.6917, 'learning_rate': 1.60248978738993e-06, 'epoch': 0.33}\n",
            "{'loss': 0.7132, 'learning_rate': 2.13665304985324e-06, 'epoch': 0.44}\n",
            "{'loss': 0.6741, 'learning_rate': 2.7301677859235845e-06, 'epoch': 0.55}\n",
            "{'loss': 0.7148, 'learning_rate': 3.3236825219939293e-06, 'epoch': 0.66}\n",
            "{'loss': 0.6639, 'learning_rate': 3.917197258064274e-06, 'epoch': 0.77}\n",
            "{'loss': 0.7009, 'learning_rate': 4.510711994134618e-06, 'epoch': 0.88}\n",
            "{'loss': 0.6833, 'learning_rate': 5.104226730204963e-06, 'epoch': 0.99}\n",
            "{'loss': 0.6901, 'learning_rate': 5.697741466275307e-06, 'epoch': 1.1}\n",
            "{'loss': 0.652, 'learning_rate': 6.291256202345651e-06, 'epoch': 1.21}\n",
            "{'loss': 0.6577, 'learning_rate': 6.884770938415996e-06, 'epoch': 1.32}\n",
            "{'loss': 0.6625, 'learning_rate': 7.4782856744863404e-06, 'epoch': 1.43}\n",
            "{'loss': 0.6721, 'learning_rate': 8.071800410556684e-06, 'epoch': 1.54}\n",
            "{'loss': 0.6445, 'learning_rate': 8.665315146627028e-06, 'epoch': 1.65}\n",
            "{'loss': 0.635, 'learning_rate': 9.258829882697374e-06, 'epoch': 1.76}\n",
            "{'loss': 0.6175, 'learning_rate': 9.852344618767718e-06, 'epoch': 1.87}\n",
            "{'loss': 0.6025, 'learning_rate': 1.0445859354838064e-05, 'epoch': 1.98}\n",
            "{'loss': 0.5768, 'learning_rate': 1.0980022617301373e-05, 'epoch': 2.09}\n",
            "{'loss': 0.5943, 'learning_rate': 1.1573537353371718e-05, 'epoch': 2.2}\n",
            "{'loss': 0.5243, 'learning_rate': 1.216705208944206e-05, 'epoch': 2.31}\n",
            "{'loss': 0.5163, 'learning_rate': 1.2760566825512406e-05, 'epoch': 2.42}\n",
            "{'loss': 0.4695, 'learning_rate': 1.335408156158275e-05, 'epoch': 2.53}\n",
            "{'loss': 0.4668, 'learning_rate': 1.3947596297653096e-05, 'epoch': 2.64}\n",
            "{'loss': 0.404, 'learning_rate': 1.436107823044877e-05, 'epoch': 2.75}\n",
            "{'loss': 0.4448, 'learning_rate': 1.3154264933772401e-05, 'epoch': 2.86}\n",
            "{'loss': 0.457, 'learning_rate': 1.1947451637096034e-05, 'epoch': 2.97}\n",
            "{'loss': 0.3783, 'learning_rate': 1.0740638340419667e-05, 'epoch': 3.08}\n",
            "{'loss': 0.3191, 'learning_rate': 9.5338250437433e-06, 'epoch': 3.19}\n",
            "{'loss': 0.421, 'learning_rate': 8.327011747066932e-06, 'epoch': 3.3}\n",
            "{'loss': 0.3405, 'learning_rate': 7.120198450390565e-06, 'epoch': 3.41}\n",
            "{'loss': 0.3346, 'learning_rate': 5.9133851537141985e-06, 'epoch': 3.52}\n",
            "{'loss': 0.3248, 'learning_rate': 4.706571857037832e-06, 'epoch': 3.63}\n",
            "{'loss': 0.2942, 'learning_rate': 3.4997585603614645e-06, 'epoch': 3.74}\n",
            "{'loss': 0.3093, 'learning_rate': 2.2929452636850973e-06, 'epoch': 3.85}\n",
            "{'loss': 0.3367, 'learning_rate': 1.0861319670087302e-06, 'epoch': 3.96}\n",
            "{'train_runtime': 58.2509, 'train_samples_per_second': 99.226, 'train_steps_per_second': 6.249, 'train_loss': 0.541925480732551, 'epoch': 4.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 26/26 [00:01<00:00, 21.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 22:06:33,801] Trial 17 finished with value: 0.8333333333333334 and parameters: {'learning_rate': 1.4481759560116405e-05, 'per_device_train_batch_size': 16, 'weight_decay': 0.29289817793287287, 'num_train_epochs': 4, 'warmup_steps': 244, 'freeze_layers': 0, 'dropout': 0.10146357587673926, 'lr_scheduler_type': 'linear'}. Best is trial 4 with value: 0.9168765743073047.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: constant_with_warmup\n",
            " Warmup steps (True): 170\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "43538d08a17a461fab1173c7104325ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1448 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7007, 'learning_rate': 2.224130161790991e-06, 'epoch': 0.06}\n",
            "{'loss': 0.7216, 'learning_rate': 5.401458964349551e-06, 'epoch': 0.11}\n",
            "{'loss': 0.7028, 'learning_rate': 8.578787766908109e-06, 'epoch': 0.17}\n",
            "{'loss': 0.7043, 'learning_rate': 1.1756116569466669e-05, 'epoch': 0.22}\n",
            "{'loss': 0.69, 'learning_rate': 1.4297979611513515e-05, 'epoch': 0.28}\n",
            "{'loss': 0.6559, 'learning_rate': 1.7475308414072077e-05, 'epoch': 0.33}\n",
            "{'loss': 0.6559, 'learning_rate': 2.0652637216630632e-05, 'epoch': 0.39}\n",
            "{'loss': 0.6819, 'learning_rate': 2.3829966019189193e-05, 'epoch': 0.44}\n",
            "{'loss': 0.6273, 'learning_rate': 2.7007294821747752e-05, 'epoch': 0.5}\n",
            "{'loss': 0.5653, 'learning_rate': 3.018462362430631e-05, 'epoch': 0.55}\n",
            "{'loss': 0.617, 'learning_rate': 3.336195242686487e-05, 'epoch': 0.61}\n",
            "{'loss': 0.4451, 'learning_rate': 3.653928122942343e-05, 'epoch': 0.66}\n",
            "{'loss': 0.4156, 'learning_rate': 3.971661003198199e-05, 'epoch': 0.72}\n",
            "{'loss': 0.5382, 'learning_rate': 4.289393883454054e-05, 'epoch': 0.77}\n",
            "{'loss': 0.5392, 'learning_rate': 4.60712676370991e-05, 'epoch': 0.83}\n",
            "{'loss': 0.3981, 'learning_rate': 4.9248596439657666e-05, 'epoch': 0.88}\n",
            "{'loss': 0.3585, 'learning_rate': 5.2425925242216224e-05, 'epoch': 0.94}\n",
            "{'loss': 0.7223, 'learning_rate': 5.4014589643495503e-05, 'epoch': 0.99}\n",
            "{'loss': 0.5645, 'learning_rate': 5.4014589643495503e-05, 'epoch': 1.05}\n",
            "{'loss': 0.4048, 'learning_rate': 5.4014589643495503e-05, 'epoch': 1.1}\n",
            "{'loss': 0.4417, 'learning_rate': 5.4014589643495503e-05, 'epoch': 1.16}\n",
            "{'loss': 0.3976, 'learning_rate': 5.4014589643495503e-05, 'epoch': 1.22}\n",
            "{'loss': 0.4427, 'learning_rate': 5.4014589643495503e-05, 'epoch': 1.27}\n",
            "{'loss': 0.6915, 'learning_rate': 5.4014589643495503e-05, 'epoch': 1.33}\n",
            "{'loss': 0.4821, 'learning_rate': 5.4014589643495503e-05, 'epoch': 1.38}\n",
            "{'loss': 0.3531, 'learning_rate': 5.4014589643495503e-05, 'epoch': 1.44}\n",
            "{'loss': 0.2571, 'learning_rate': 5.4014589643495503e-05, 'epoch': 1.49}\n",
            "{'loss': 0.4373, 'learning_rate': 5.4014589643495503e-05, 'epoch': 1.55}\n",
            "{'loss': 0.4453, 'learning_rate': 5.4014589643495503e-05, 'epoch': 1.6}\n",
            "{'loss': 0.3654, 'learning_rate': 5.4014589643495503e-05, 'epoch': 1.66}\n",
            "{'loss': 0.3432, 'learning_rate': 5.4014589643495503e-05, 'epoch': 1.71}\n",
            "{'loss': 0.8996, 'learning_rate': 5.4014589643495503e-05, 'epoch': 1.77}\n",
            "{'loss': 0.2486, 'learning_rate': 5.4014589643495503e-05, 'epoch': 1.82}\n",
            "{'loss': 0.4673, 'learning_rate': 5.4014589643495503e-05, 'epoch': 1.88}\n",
            "{'loss': 0.3851, 'learning_rate': 5.4014589643495503e-05, 'epoch': 1.93}\n",
            "{'loss': 0.3491, 'learning_rate': 5.4014589643495503e-05, 'epoch': 1.99}\n",
            "{'loss': 0.2556, 'learning_rate': 5.4014589643495503e-05, 'epoch': 2.04}\n",
            "{'loss': 0.1209, 'learning_rate': 5.4014589643495503e-05, 'epoch': 2.1}\n",
            "{'loss': 0.4119, 'learning_rate': 5.4014589643495503e-05, 'epoch': 2.15}\n",
            "{'loss': 0.3169, 'learning_rate': 5.4014589643495503e-05, 'epoch': 2.21}\n",
            "{'loss': 0.2637, 'learning_rate': 5.4014589643495503e-05, 'epoch': 2.27}\n",
            "{'loss': 0.2941, 'learning_rate': 5.4014589643495503e-05, 'epoch': 2.32}\n",
            "{'loss': 0.3915, 'learning_rate': 5.4014589643495503e-05, 'epoch': 2.38}\n",
            "{'loss': 0.1821, 'learning_rate': 5.4014589643495503e-05, 'epoch': 2.43}\n",
            "{'loss': 0.2524, 'learning_rate': 5.4014589643495503e-05, 'epoch': 2.49}\n",
            "{'loss': 0.4818, 'learning_rate': 5.4014589643495503e-05, 'epoch': 2.54}\n",
            "{'loss': 0.4293, 'learning_rate': 5.4014589643495503e-05, 'epoch': 2.6}\n",
            "{'loss': 0.159, 'learning_rate': 5.4014589643495503e-05, 'epoch': 2.65}\n",
            "{'loss': 0.2163, 'learning_rate': 5.4014589643495503e-05, 'epoch': 2.71}\n",
            "{'loss': 0.2287, 'learning_rate': 5.4014589643495503e-05, 'epoch': 2.76}\n",
            "{'loss': 0.1832, 'learning_rate': 5.4014589643495503e-05, 'epoch': 2.82}\n",
            "{'loss': 0.3242, 'learning_rate': 5.4014589643495503e-05, 'epoch': 2.87}\n",
            "{'loss': 0.1957, 'learning_rate': 5.4014589643495503e-05, 'epoch': 2.93}\n",
            "{'loss': 0.2304, 'learning_rate': 5.4014589643495503e-05, 'epoch': 2.98}\n",
            "{'loss': 0.1544, 'learning_rate': 5.4014589643495503e-05, 'epoch': 3.04}\n",
            "{'loss': 0.0679, 'learning_rate': 5.4014589643495503e-05, 'epoch': 3.09}\n",
            "{'loss': 0.055, 'learning_rate': 5.4014589643495503e-05, 'epoch': 3.15}\n",
            "{'loss': 0.2491, 'learning_rate': 5.4014589643495503e-05, 'epoch': 3.2}\n",
            "{'loss': 0.1337, 'learning_rate': 5.4014589643495503e-05, 'epoch': 3.26}\n",
            "{'loss': 0.0819, 'learning_rate': 5.4014589643495503e-05, 'epoch': 3.31}\n",
            "{'loss': 0.3204, 'learning_rate': 5.4014589643495503e-05, 'epoch': 3.37}\n",
            "{'loss': 0.126, 'learning_rate': 5.4014589643495503e-05, 'epoch': 3.43}\n",
            "{'loss': 0.238, 'learning_rate': 5.4014589643495503e-05, 'epoch': 3.48}\n",
            "{'loss': 0.1925, 'learning_rate': 5.4014589643495503e-05, 'epoch': 3.54}\n",
            "{'loss': 0.2321, 'learning_rate': 5.4014589643495503e-05, 'epoch': 3.59}\n",
            "{'loss': 0.2532, 'learning_rate': 5.4014589643495503e-05, 'epoch': 3.65}\n",
            "{'loss': 0.1677, 'learning_rate': 5.4014589643495503e-05, 'epoch': 3.7}\n",
            "{'loss': 0.1109, 'learning_rate': 5.4014589643495503e-05, 'epoch': 3.76}\n",
            "{'loss': 0.1098, 'learning_rate': 5.4014589643495503e-05, 'epoch': 3.81}\n",
            "{'loss': 0.1655, 'learning_rate': 5.4014589643495503e-05, 'epoch': 3.87}\n",
            "{'loss': 0.1826, 'learning_rate': 5.4014589643495503e-05, 'epoch': 3.92}\n",
            "{'loss': 0.3989, 'learning_rate': 5.4014589643495503e-05, 'epoch': 3.98}\n",
            "{'loss': 0.1318, 'learning_rate': 5.4014589643495503e-05, 'epoch': 4.03}\n",
            "{'loss': 0.0238, 'learning_rate': 5.4014589643495503e-05, 'epoch': 4.09}\n",
            "{'loss': 0.0723, 'learning_rate': 5.4014589643495503e-05, 'epoch': 4.14}\n",
            "{'loss': 0.133, 'learning_rate': 5.4014589643495503e-05, 'epoch': 4.2}\n",
            "{'loss': 0.164, 'learning_rate': 5.4014589643495503e-05, 'epoch': 4.25}\n",
            "{'loss': 0.131, 'learning_rate': 5.4014589643495503e-05, 'epoch': 4.31}\n",
            "{'loss': 0.0997, 'learning_rate': 5.4014589643495503e-05, 'epoch': 4.36}\n",
            "{'loss': 0.0692, 'learning_rate': 5.4014589643495503e-05, 'epoch': 4.42}\n",
            "{'loss': 0.0736, 'learning_rate': 5.4014589643495503e-05, 'epoch': 4.48}\n",
            "{'loss': 0.2356, 'learning_rate': 5.4014589643495503e-05, 'epoch': 4.53}\n",
            "{'loss': 0.1339, 'learning_rate': 5.4014589643495503e-05, 'epoch': 4.59}\n",
            "{'loss': 0.1014, 'learning_rate': 5.4014589643495503e-05, 'epoch': 4.64}\n",
            "{'loss': 0.0805, 'learning_rate': 5.4014589643495503e-05, 'epoch': 4.7}\n",
            "{'loss': 0.0215, 'learning_rate': 5.4014589643495503e-05, 'epoch': 4.75}\n",
            "{'loss': 0.2208, 'learning_rate': 5.4014589643495503e-05, 'epoch': 4.81}\n",
            "{'loss': 0.1087, 'learning_rate': 5.4014589643495503e-05, 'epoch': 4.86}\n",
            "{'loss': 0.2077, 'learning_rate': 5.4014589643495503e-05, 'epoch': 4.92}\n",
            "{'loss': 0.1648, 'learning_rate': 5.4014589643495503e-05, 'epoch': 4.97}\n",
            "{'loss': 0.1079, 'learning_rate': 5.4014589643495503e-05, 'epoch': 5.03}\n",
            "{'loss': 0.0827, 'learning_rate': 5.4014589643495503e-05, 'epoch': 5.08}\n",
            "{'loss': 0.0029, 'learning_rate': 5.4014589643495503e-05, 'epoch': 5.14}\n",
            "{'loss': 0.0023, 'learning_rate': 5.4014589643495503e-05, 'epoch': 5.19}\n",
            "{'loss': 0.1673, 'learning_rate': 5.4014589643495503e-05, 'epoch': 5.25}\n",
            "{'loss': 0.1508, 'learning_rate': 5.4014589643495503e-05, 'epoch': 5.3}\n",
            "{'loss': 0.0042, 'learning_rate': 5.4014589643495503e-05, 'epoch': 5.36}\n",
            "{'loss': 0.1303, 'learning_rate': 5.4014589643495503e-05, 'epoch': 5.41}\n",
            "{'loss': 0.0759, 'learning_rate': 5.4014589643495503e-05, 'epoch': 5.47}\n",
            "{'loss': 0.0859, 'learning_rate': 5.4014589643495503e-05, 'epoch': 5.52}\n",
            "{'loss': 0.0018, 'learning_rate': 5.4014589643495503e-05, 'epoch': 5.58}\n",
            "{'loss': 0.0016, 'learning_rate': 5.4014589643495503e-05, 'epoch': 5.64}\n",
            "{'loss': 0.0012, 'learning_rate': 5.4014589643495503e-05, 'epoch': 5.69}\n",
            "{'loss': 0.1608, 'learning_rate': 5.4014589643495503e-05, 'epoch': 5.75}\n",
            "{'loss': 0.0832, 'learning_rate': 5.4014589643495503e-05, 'epoch': 5.8}\n",
            "{'loss': 0.0061, 'learning_rate': 5.4014589643495503e-05, 'epoch': 5.86}\n",
            "{'loss': 0.0015, 'learning_rate': 5.4014589643495503e-05, 'epoch': 5.91}\n",
            "{'loss': 0.0904, 'learning_rate': 5.4014589643495503e-05, 'epoch': 5.97}\n",
            "{'loss': 0.001, 'learning_rate': 5.4014589643495503e-05, 'epoch': 6.02}\n",
            "{'loss': 0.0014, 'learning_rate': 5.4014589643495503e-05, 'epoch': 6.08}\n",
            "{'loss': 0.001, 'learning_rate': 5.4014589643495503e-05, 'epoch': 6.13}\n",
            "{'loss': 0.0008, 'learning_rate': 5.4014589643495503e-05, 'epoch': 6.19}\n",
            "{'loss': 0.0006, 'learning_rate': 5.4014589643495503e-05, 'epoch': 6.24}\n",
            "{'loss': 0.0926, 'learning_rate': 5.4014589643495503e-05, 'epoch': 6.3}\n",
            "{'loss': 0.001, 'learning_rate': 5.4014589643495503e-05, 'epoch': 6.35}\n",
            "{'loss': 0.0008, 'learning_rate': 5.4014589643495503e-05, 'epoch': 6.41}\n",
            "{'loss': 0.0008, 'learning_rate': 5.4014589643495503e-05, 'epoch': 6.46}\n",
            "{'loss': 0.0006, 'learning_rate': 5.4014589643495503e-05, 'epoch': 6.52}\n",
            "{'loss': 0.0005, 'learning_rate': 5.4014589643495503e-05, 'epoch': 6.57}\n",
            "{'loss': 0.0005, 'learning_rate': 5.4014589643495503e-05, 'epoch': 6.63}\n",
            "{'loss': 0.0004, 'learning_rate': 5.4014589643495503e-05, 'epoch': 6.69}\n",
            "{'loss': 0.1001, 'learning_rate': 5.4014589643495503e-05, 'epoch': 6.74}\n",
            "{'loss': 0.0006, 'learning_rate': 5.4014589643495503e-05, 'epoch': 6.8}\n",
            "{'loss': 0.0007, 'learning_rate': 5.4014589643495503e-05, 'epoch': 6.85}\n",
            "{'loss': 0.1036, 'learning_rate': 5.4014589643495503e-05, 'epoch': 6.91}\n",
            "{'loss': 0.0009, 'learning_rate': 5.4014589643495503e-05, 'epoch': 6.96}\n",
            "{'loss': 0.0009, 'learning_rate': 5.4014589643495503e-05, 'epoch': 7.02}\n",
            "{'loss': 0.0007, 'learning_rate': 5.4014589643495503e-05, 'epoch': 7.07}\n",
            "{'loss': 0.0006, 'learning_rate': 5.4014589643495503e-05, 'epoch': 7.13}\n",
            "{'loss': 0.0005, 'learning_rate': 5.4014589643495503e-05, 'epoch': 7.18}\n",
            "{'loss': 0.0005, 'learning_rate': 5.4014589643495503e-05, 'epoch': 7.24}\n",
            "{'loss': 0.0004, 'learning_rate': 5.4014589643495503e-05, 'epoch': 7.29}\n",
            "{'loss': 0.0003, 'learning_rate': 5.4014589643495503e-05, 'epoch': 7.35}\n",
            "{'loss': 0.0003, 'learning_rate': 5.4014589643495503e-05, 'epoch': 7.4}\n",
            "{'loss': 0.0003, 'learning_rate': 5.4014589643495503e-05, 'epoch': 7.46}\n",
            "{'loss': 0.1066, 'learning_rate': 5.4014589643495503e-05, 'epoch': 7.51}\n",
            "{'loss': 0.0005, 'learning_rate': 5.4014589643495503e-05, 'epoch': 7.57}\n",
            "{'loss': 0.0992, 'learning_rate': 5.4014589643495503e-05, 'epoch': 7.62}\n",
            "{'loss': 0.001, 'learning_rate': 5.4014589643495503e-05, 'epoch': 7.68}\n",
            "{'loss': 0.0862, 'learning_rate': 5.4014589643495503e-05, 'epoch': 7.73}\n",
            "{'loss': 0.0017, 'learning_rate': 5.4014589643495503e-05, 'epoch': 7.79}\n",
            "{'loss': 0.0818, 'learning_rate': 5.4014589643495503e-05, 'epoch': 7.85}\n",
            "{'loss': 0.0698, 'learning_rate': 5.4014589643495503e-05, 'epoch': 7.9}\n",
            "{'loss': 0.0011, 'learning_rate': 5.4014589643495503e-05, 'epoch': 7.96}\n",
            "{'train_runtime': 146.4635, 'train_samples_per_second': 78.927, 'train_steps_per_second': 9.886, 'train_loss': 0.21398260853560744, 'epoch': 8.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 52/52 [00:01<00:00, 41.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 22:09:04,058] Trial 18 finished with value: 0.912718204488778 and parameters: {'learning_rate': 5.4014589643495503e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.2516180360065601, 'num_train_epochs': 8, 'warmup_steps': 170, 'freeze_layers': 0, 'dropout': 0.23851589467221906, 'lr_scheduler_type': 'constant_with_warmup'}. Best is trial 4 with value: 0.9168765743073047.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: cosine\n",
            " Warmup steps (True): 113\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d659ae8b4c548368c4ab32b51abab5e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1629 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.6961, 'learning_rate': 5.952988962153732e-06, 'epoch': 0.06}\n",
            "{'loss': 0.7249, 'learning_rate': 1.1905977924307464e-05, 'epoch': 0.11}\n",
            "{'loss': 0.7036, 'learning_rate': 1.934721412699963e-05, 'epoch': 0.17}\n",
            "{'loss': 0.7129, 'learning_rate': 2.6788450329691795e-05, 'epoch': 0.22}\n",
            "{'loss': 0.6831, 'learning_rate': 3.422968653238396e-05, 'epoch': 0.28}\n",
            "{'loss': 0.683, 'learning_rate': 4.1670922735076125e-05, 'epoch': 0.33}\n",
            "{'loss': 0.6719, 'learning_rate': 4.9112158937768295e-05, 'epoch': 0.39}\n",
            "{'loss': 0.7091, 'learning_rate': 5.655339514046046e-05, 'epoch': 0.44}\n",
            "{'loss': 0.5794, 'learning_rate': 6.399463134315261e-05, 'epoch': 0.5}\n",
            "{'loss': 0.5453, 'learning_rate': 7.143586754584478e-05, 'epoch': 0.55}\n",
            "{'loss': 0.6095, 'learning_rate': 7.887710374853695e-05, 'epoch': 0.61}\n",
            "{'loss': 0.4717, 'learning_rate': 8.408515662292446e-05, 'epoch': 0.66}\n",
            "{'loss': 0.476, 'learning_rate': 8.407071362984661e-05, 'epoch': 0.72}\n",
            "{'loss': 0.5208, 'learning_rate': 8.403822294251758e-05, 'epoch': 0.77}\n",
            "{'loss': 0.5298, 'learning_rate': 8.398769851320185e-05, 'epoch': 0.83}\n",
            "{'loss': 0.3895, 'learning_rate': 8.391916203827635e-05, 'epoch': 0.88}\n",
            "{'loss': 0.4378, 'learning_rate': 8.383264294891358e-05, 'epoch': 0.94}\n",
            "{'loss': 1.0976, 'learning_rate': 8.372817839844318e-05, 'epoch': 0.99}\n",
            "{'loss': 0.5763, 'learning_rate': 8.360581324639734e-05, 'epoch': 1.05}\n",
            "{'loss': 0.5804, 'learning_rate': 8.346560003924717e-05, 'epoch': 1.1}\n",
            "{'loss': 0.52, 'learning_rate': 8.330759898783792e-05, 'epoch': 1.16}\n",
            "{'loss': 0.2708, 'learning_rate': 8.313187794153309e-05, 'epoch': 1.22}\n",
            "{'loss': 0.3202, 'learning_rate': 8.293851235907824e-05, 'epoch': 1.27}\n",
            "{'loss': 0.7324, 'learning_rate': 8.272758527619738e-05, 'epoch': 1.33}\n",
            "{'loss': 0.4697, 'learning_rate': 8.249918726993529e-05, 'epoch': 1.38}\n",
            "{'loss': 0.4581, 'learning_rate': 8.225341641976179e-05, 'epoch': 1.44}\n",
            "{'loss': 0.3894, 'learning_rate': 8.199037826545396e-05, 'epoch': 1.49}\n",
            "{'loss': 0.6813, 'learning_rate': 8.171018576177497e-05, 'epoch': 1.55}\n",
            "{'loss': 0.3715, 'learning_rate': 8.141295922996862e-05, 'epoch': 1.6}\n",
            "{'loss': 0.3991, 'learning_rate': 8.10988263060906e-05, 'epoch': 1.66}\n",
            "{'loss': 0.7684, 'learning_rate': 8.076792188619855e-05, 'epoch': 1.71}\n",
            "{'loss': 0.4773, 'learning_rate': 8.042038806842447e-05, 'epoch': 1.77}\n",
            "{'loss': 0.3391, 'learning_rate': 8.005637409195454e-05, 'epoch': 1.82}\n",
            "{'loss': 0.4371, 'learning_rate': 7.967603627294225e-05, 'epoch': 1.88}\n",
            "{'loss': 0.4485, 'learning_rate': 7.92795379373826e-05, 'epoch': 1.93}\n",
            "{'loss': 0.3017, 'learning_rate': 7.886704935097603e-05, 'epoch': 1.99}\n",
            "{'loss': 0.4948, 'learning_rate': 7.84387476460124e-05, 'epoch': 2.04}\n",
            "{'loss': 0.1557, 'learning_rate': 7.799481674530615e-05, 'epoch': 2.1}\n",
            "{'loss': 0.2076, 'learning_rate': 7.753544728321557e-05, 'epoch': 2.15}\n",
            "{'loss': 0.3887, 'learning_rate': 7.706083652377994e-05, 'epoch': 2.21}\n",
            "{'loss': 0.3292, 'learning_rate': 7.657118827600965e-05, 'epoch': 2.27}\n",
            "{'loss': 0.3749, 'learning_rate': 7.606671280636591e-05, 'epoch': 2.32}\n",
            "{'loss': 0.3745, 'learning_rate': 7.554762674846731e-05, 'epoch': 2.38}\n",
            "{'loss': 0.2942, 'learning_rate': 7.50141530100623e-05, 'epoch': 2.43}\n",
            "{'loss': 0.2284, 'learning_rate': 7.446652067730738e-05, 'epoch': 2.49}\n",
            "{'loss': 0.3728, 'learning_rate': 7.390496491639206e-05, 'epoch': 2.54}\n",
            "{'loss': 0.4176, 'learning_rate': 7.332972687255308e-05, 'epoch': 2.6}\n",
            "{'loss': 0.3771, 'learning_rate': 7.274105356652082e-05, 'epoch': 2.65}\n",
            "{'loss': 0.154, 'learning_rate': 7.213919778844298e-05, 'epoch': 2.71}\n",
            "{'loss': 0.3906, 'learning_rate': 7.152441798933042e-05, 'epoch': 2.76}\n",
            "{'loss': 0.4373, 'learning_rate': 7.089697817007224e-05, 'epoch': 2.82}\n",
            "{'loss': 0.2921, 'learning_rate': 7.025714776806764e-05, 'epoch': 2.87}\n",
            "{'loss': 0.1654, 'learning_rate': 6.960520154152318e-05, 'epoch': 2.93}\n",
            "{'loss': 0.2144, 'learning_rate': 6.894141945146507e-05, 'epoch': 2.98}\n",
            "{'loss': 0.1772, 'learning_rate': 6.826608654151744e-05, 'epoch': 3.04}\n",
            "{'loss': 0.2755, 'learning_rate': 6.757949281549777e-05, 'epoch': 3.09}\n",
            "{'loss': 0.1256, 'learning_rate': 6.688193311288257e-05, 'epoch': 3.15}\n",
            "{'loss': 0.3855, 'learning_rate': 6.617370698219638e-05, 'epoch': 3.2}\n",
            "{'loss': 0.0703, 'learning_rate': 6.545511855237845e-05, 'epoch': 3.26}\n",
            "{'loss': 0.2063, 'learning_rate': 6.472647640218273e-05, 'epoch': 3.31}\n",
            "{'loss': 0.3066, 'learning_rate': 6.398809342766701e-05, 'epoch': 3.37}\n",
            "{'loss': 0.2092, 'learning_rate': 6.324028670782776e-05, 'epoch': 3.43}\n",
            "{'loss': 0.2439, 'learning_rate': 6.248337736843915e-05, 'epoch': 3.48}\n",
            "{'loss': 0.3732, 'learning_rate': 6.171769044415406e-05, 'epoch': 3.54}\n",
            "{'loss': 0.1655, 'learning_rate': 6.094355473892648e-05, 'epoch': 3.59}\n",
            "{'loss': 0.4465, 'learning_rate': 6.016130268481547e-05, 'epoch': 3.65}\n",
            "{'loss': 0.3139, 'learning_rate': 5.937127019923099e-05, 'epoch': 3.7}\n",
            "{'loss': 0.0676, 'learning_rate': 5.857379654068303e-05, 'epoch': 3.76}\n",
            "{'loss': 0.112, 'learning_rate': 5.776922416309611e-05, 'epoch': 3.81}\n",
            "{'loss': 0.4212, 'learning_rate': 5.695789856875143e-05, 'epoch': 3.87}\n",
            "{'loss': 0.2612, 'learning_rate': 5.614016815992018e-05, 'epoch': 3.92}\n",
            "{'loss': 0.203, 'learning_rate': 5.5316384089251313e-05, 'epoch': 3.98}\n",
            "{'loss': 0.2297, 'learning_rate': 5.4486900108978434e-05, 'epoch': 4.03}\n",
            "{'loss': 0.072, 'learning_rate': 5.365207241901023e-05, 'epoch': 4.09}\n",
            "{'loss': 0.0881, 'learning_rate': 5.2812259513969865e-05, 'epoch': 4.14}\n",
            "{'loss': 0.3698, 'learning_rate': 5.196782202924897e-05, 'epoch': 4.2}\n",
            "{'loss': 0.1527, 'learning_rate': 5.1119122586142385e-05, 'epoch': 4.25}\n",
            "{'loss': 0.0472, 'learning_rate': 5.0266525636129955e-05, 'epoch': 4.31}\n",
            "{'loss': 0.0056, 'learning_rate': 4.941039730437258e-05, 'epoch': 4.36}\n",
            "{'loss': 0.1916, 'learning_rate': 4.855110523248945e-05, 'epoch': 4.42}\n",
            "{'loss': 0.1776, 'learning_rate': 4.768901842068408e-05, 'epoch': 4.48}\n",
            "{'loss': 0.2961, 'learning_rate': 4.6824507069286995e-05, 'epoch': 4.53}\n",
            "{'loss': 0.1426, 'learning_rate': 4.5957942419782926e-05, 'epoch': 4.59}\n",
            "{'loss': 0.1883, 'learning_rate': 4.5089696595391106e-05, 'epoch': 4.64}\n",
            "{'loss': 0.1614, 'learning_rate': 4.422014244126672e-05, 'epoch': 4.7}\n",
            "{'loss': 0.2342, 'learning_rate': 4.334965336439254e-05, 'epoch': 4.75}\n",
            "{'loss': 0.0993, 'learning_rate': 4.247860317322904e-05, 'epoch': 4.81}\n",
            "{'loss': 0.1939, 'learning_rate': 4.160736591719243e-05, 'epoch': 4.86}\n",
            "{'loss': 0.1135, 'learning_rate': 4.073631572602895e-05, 'epoch': 4.92}\n",
            "{'loss': 0.069, 'learning_rate': 3.9865826649154746e-05, 'epoch': 4.97}\n",
            "{'loss': 0.2153, 'learning_rate': 3.899627249503036e-05, 'epoch': 5.03}\n",
            "{'loss': 0.0662, 'learning_rate': 3.8128026670638556e-05, 'epoch': 5.08}\n",
            "{'loss': 0.007, 'learning_rate': 3.726146202113449e-05, 'epoch': 5.14}\n",
            "{'loss': 0.0511, 'learning_rate': 3.639695066973739e-05, 'epoch': 5.19}\n",
            "{'loss': 0.073, 'learning_rate': 3.553486385793202e-05, 'epoch': 5.25}\n",
            "{'loss': 0.1504, 'learning_rate': 3.46755717860489e-05, 'epoch': 5.3}\n",
            "{'loss': 0.138, 'learning_rate': 3.381944345429151e-05, 'epoch': 5.36}\n",
            "{'loss': 0.3519, 'learning_rate': 3.29668465042791e-05, 'epoch': 5.41}\n",
            "{'loss': 0.0449, 'learning_rate': 3.21181470611725e-05, 'epoch': 5.47}\n",
            "{'loss': 0.1376, 'learning_rate': 3.127370957645161e-05, 'epoch': 5.52}\n",
            "{'loss': 0.1872, 'learning_rate': 3.0433896671411256e-05, 'epoch': 5.58}\n",
            "{'loss': 0.1258, 'learning_rate': 2.9599068981443037e-05, 'epoch': 5.64}\n",
            "{'loss': 0.1925, 'learning_rate': 2.876958500117015e-05, 'epoch': 5.69}\n",
            "{'loss': 0.0559, 'learning_rate': 2.7945800930501305e-05, 'epoch': 5.75}\n",
            "{'loss': 0.1921, 'learning_rate': 2.712807052167004e-05, 'epoch': 5.8}\n",
            "{'loss': 0.0657, 'learning_rate': 2.6316744927325367e-05, 'epoch': 5.86}\n",
            "{'loss': 0.0067, 'learning_rate': 2.5512172549738436e-05, 'epoch': 5.91}\n",
            "{'loss': 0.246, 'learning_rate': 2.4714698891190483e-05, 'epoch': 5.97}\n",
            "{'loss': 0.0058, 'learning_rate': 2.3924666405605994e-05, 'epoch': 6.02}\n",
            "{'loss': 0.004, 'learning_rate': 2.3142414351495e-05, 'epoch': 6.08}\n",
            "{'loss': 0.1273, 'learning_rate': 2.2368278646267413e-05, 'epoch': 6.13}\n",
            "{'loss': 0.0037, 'learning_rate': 2.160259172198231e-05, 'epoch': 6.19}\n",
            "{'loss': 0.0729, 'learning_rate': 2.084568238259372e-05, 'epoch': 6.24}\n",
            "{'loss': 0.1195, 'learning_rate': 2.0097875662754463e-05, 'epoch': 6.3}\n",
            "{'loss': 0.0031, 'learning_rate': 1.9359492688238723e-05, 'epoch': 6.35}\n",
            "{'loss': 0.0807, 'learning_rate': 1.8630850538043037e-05, 'epoch': 6.41}\n",
            "{'loss': 0.254, 'learning_rate': 1.7912262108225085e-05, 'epoch': 6.46}\n",
            "{'loss': 0.0499, 'learning_rate': 1.7204035977538873e-05, 'epoch': 6.52}\n",
            "{'loss': 0.0033, 'learning_rate': 1.6506476274923706e-05, 'epoch': 6.57}\n",
            "{'loss': 0.0661, 'learning_rate': 1.5819882548904036e-05, 'epoch': 6.63}\n",
            "{'loss': 0.0726, 'learning_rate': 1.5144549638956384e-05, 'epoch': 6.69}\n",
            "{'loss': 0.0692, 'learning_rate': 1.448076754889829e-05, 'epoch': 6.74}\n",
            "{'loss': 0.0913, 'learning_rate': 1.382882132235382e-05, 'epoch': 6.8}\n",
            "{'loss': 0.0838, 'learning_rate': 1.3188990920349237e-05, 'epoch': 6.85}\n",
            "{'loss': 0.2005, 'learning_rate': 1.256155110109106e-05, 'epoch': 6.91}\n",
            "{'loss': 0.0043, 'learning_rate': 1.1946771301978485e-05, 'epoch': 6.96}\n",
            "{'loss': 0.0774, 'learning_rate': 1.1344915523900642e-05, 'epoch': 7.02}\n",
            "{'loss': 0.1353, 'learning_rate': 1.0756242217868408e-05, 'epoch': 7.07}\n",
            "{'loss': 0.0038, 'learning_rate': 1.018100417402941e-05, 'epoch': 7.13}\n",
            "{'loss': 0.088, 'learning_rate': 9.6194484131141e-06, 'epoch': 7.18}\n",
            "{'loss': 0.0669, 'learning_rate': 9.071816080359185e-06, 'epoch': 7.24}\n",
            "{'loss': 0.0647, 'learning_rate': 8.538342341954173e-06, 'epoch': 7.29}\n",
            "{'loss': 0.0724, 'learning_rate': 8.019256284055566e-06, 'epoch': 7.35}\n",
            "{'loss': 0.0037, 'learning_rate': 7.514780814411824e-06, 'epoch': 7.4}\n",
            "{'loss': 0.1147, 'learning_rate': 7.025132566641532e-06, 'epoch': 7.46}\n",
            "{'loss': 0.07, 'learning_rate': 6.55052180720589e-06, 'epoch': 7.51}\n",
            "{'loss': 0.0032, 'learning_rate': 6.091152345115323e-06, 'epoch': 7.57}\n",
            "{'loss': 0.0034, 'learning_rate': 5.647221444409069e-06, 'epoch': 7.62}\n",
            "{'loss': 0.0032, 'learning_rate': 5.218919739445427e-06, 'epoch': 7.68}\n",
            "{'loss': 0.0038, 'learning_rate': 4.806431153038869e-06, 'epoch': 7.73}\n",
            "{'loss': 0.1592, 'learning_rate': 4.409932817479212e-06, 'epoch': 7.79}\n",
            "{'loss': 0.003, 'learning_rate': 4.029594998466927e-06, 'epoch': 7.85}\n",
            "{'loss': 0.0034, 'learning_rate': 3.665581021997009e-06, 'epoch': 7.9}\n",
            "{'loss': 0.1385, 'learning_rate': 3.318047204222924e-06, 'epoch': 7.96}\n",
            "{'loss': 0.0042, 'learning_rate': 2.9871427843308616e-06, 'epoch': 8.01}\n",
            "{'loss': 0.0693, 'learning_rate': 2.6730098604528457e-06, 'epoch': 8.07}\n",
            "{'loss': 0.1407, 'learning_rate': 2.375783328646512e-06, 'epoch': 8.12}\n",
            "{'loss': 0.0029, 'learning_rate': 2.0955908249675137e-06, 'epoch': 8.18}\n",
            "{'loss': 0.0691, 'learning_rate': 1.832552670659686e-06, 'epoch': 8.23}\n",
            "{'loss': 0.0047, 'learning_rate': 1.5867818204861737e-06, 'epoch': 8.29}\n",
            "{'loss': 0.1339, 'learning_rate': 1.358383814224098e-06, 'epoch': 8.34}\n",
            "{'loss': 0.0029, 'learning_rate': 1.1474567313432312e-06, 'epoch': 8.4}\n",
            "{'loss': 0.1544, 'learning_rate': 9.54091148888396e-07, 'epoch': 8.45}\n",
            "{'loss': 0.0689, 'learning_rate': 7.783701025835484e-07, 'epoch': 8.51}\n",
            "{'loss': 0.0684, 'learning_rate': 6.203690511743003e-07, 'epoch': 8.56}\n",
            "{'loss': 0.0034, 'learning_rate': 4.801558440241235e-07, 'epoch': 8.62}\n",
            "{'loss': 0.0031, 'learning_rate': 3.5779069197829123e-07, 'epoch': 8.67}\n",
            "{'loss': 0.0797, 'learning_rate': 2.53326141507884e-07, 'epoch': 8.73}\n",
            "{'loss': 0.0032, 'learning_rate': 1.6680705214512297e-07, 'epoch': 8.78}\n",
            "{'loss': 0.134, 'learning_rate': 9.827057721962293e-08, 'epoch': 8.84}\n",
            "{'loss': 0.0088, 'learning_rate': 4.774614790388799e-08, 'epoch': 8.9}\n",
            "{'loss': 0.0029, 'learning_rate': 1.5255460574859276e-08, 'epoch': 8.95}\n",
            "{'train_runtime': 163.9222, 'train_samples_per_second': 79.336, 'train_steps_per_second': 9.938, 'train_loss': 0.2347479489265482, 'epoch': 9.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 52/52 [00:01<00:00, 39.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 22:11:51,821] Trial 19 finished with value: 0.9289340101522843 and parameters: {'learning_rate': 8.408596909042147e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.19146450882672536, 'num_train_epochs': 9, 'warmup_steps': 113, 'freeze_layers': 6, 'dropout': 0.1411689003855268, 'lr_scheduler_type': 'cosine'}. Best is trial 19 with value: 0.9289340101522843.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: cosine\n",
            " Warmup steps (True): 48\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a8d3e095c17e464694c28fe2eaf00a62",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/819 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7341, 'learning_rate': 5.133655897700733e-06, 'epoch': 0.11}\n",
            "{'loss': 0.699, 'learning_rate': 1.1550725769826649e-05, 'epoch': 0.22}\n",
            "{'loss': 0.6917, 'learning_rate': 1.668438166752738e-05, 'epoch': 0.33}\n",
            "{'loss': 0.6673, 'learning_rate': 2.2459744552440704e-05, 'epoch': 0.44}\n",
            "{'loss': 0.6135, 'learning_rate': 2.8876814424566624e-05, 'epoch': 0.55}\n",
            "{'loss': 0.6872, 'learning_rate': 3.079567104161013e-05, 'epoch': 0.66}\n",
            "{'loss': 0.5475, 'learning_rate': 3.0765000804707274e-05, 'epoch': 0.77}\n",
            "{'loss': 0.5038, 'learning_rate': 3.070882493317768e-05, 'epoch': 0.88}\n",
            "{'loss': 0.4841, 'learning_rate': 3.0627236683866316e-05, 'epoch': 0.99}\n",
            "{'loss': 0.4631, 'learning_rate': 3.0520371500381096e-05, 'epoch': 1.1}\n",
            "{'loss': 0.6145, 'learning_rate': 3.0388406788244685e-05, 'epoch': 1.21}\n",
            "{'loss': 0.4772, 'learning_rate': 3.023156162038585e-05, 'epoch': 1.32}\n",
            "{'loss': 0.373, 'learning_rate': 3.005009637345928e-05, 'epoch': 1.43}\n",
            "{'loss': 0.3235, 'learning_rate': 2.9844312295597688e-05, 'epoch': 1.54}\n",
            "{'loss': 0.3054, 'learning_rate': 2.9614551006313586e-05, 'epoch': 1.65}\n",
            "{'loss': 0.3314, 'learning_rate': 2.9361193929381138e-05, 'epoch': 1.76}\n",
            "{'loss': 0.3031, 'learning_rate': 2.9084661659639443e-05, 'epoch': 1.87}\n",
            "{'loss': 0.3429, 'learning_rate': 2.8785413264768397e-05, 'epoch': 1.98}\n",
            "{'loss': 0.2572, 'learning_rate': 2.846394552319635e-05, 'epoch': 2.09}\n",
            "{'loss': 0.3371, 'learning_rate': 2.812079209940458e-05, 'epoch': 2.2}\n",
            "{'loss': 0.3128, 'learning_rate': 2.775652265799772e-05, 'epoch': 2.31}\n",
            "{'loss': 0.3358, 'learning_rate': 2.7371741918010852e-05, 'epoch': 2.42}\n",
            "{'loss': 0.3046, 'learning_rate': 2.6967088649023175e-05, 'epoch': 2.53}\n",
            "{'loss': 0.2745, 'learning_rate': 2.6543234610744816e-05, 'epoch': 2.64}\n",
            "{'loss': 0.2446, 'learning_rate': 2.6100883437837107e-05, 'epoch': 2.75}\n",
            "{'loss': 0.2592, 'learning_rate': 2.5640769471817744e-05, 'epoch': 2.86}\n",
            "{'loss': 0.1927, 'learning_rate': 2.516365654198979e-05, 'epoch': 2.97}\n",
            "{'loss': 0.1582, 'learning_rate': 2.467033669741845e-05, 'epoch': 3.08}\n",
            "{'loss': 0.1753, 'learning_rate': 2.4161628892060564e-05, 'epoch': 3.19}\n",
            "{'loss': 0.2018, 'learning_rate': 2.3638377625229632e-05, 'epoch': 3.3}\n",
            "{'loss': 0.2345, 'learning_rate': 2.3101451539653298e-05, 'epoch': 3.41}\n",
            "{'loss': 0.3855, 'learning_rate': 2.25517419794507e-05, 'epoch': 3.52}\n",
            "{'loss': 0.3329, 'learning_rate': 2.199016151042351e-05, 'epoch': 3.63}\n",
            "{'loss': 0.1134, 'learning_rate': 2.141764240511712e-05, 'epoch': 3.74}\n",
            "{'loss': 0.1256, 'learning_rate': 2.083513509516695e-05, 'epoch': 3.85}\n",
            "{'loss': 0.186, 'learning_rate': 2.0243606593499032e-05, 'epoch': 3.96}\n",
            "{'loss': 0.2541, 'learning_rate': 1.9644038889004254e-05, 'epoch': 4.07}\n",
            "{'loss': 0.1247, 'learning_rate': 1.903742731635117e-05, 'epoch': 4.18}\n",
            "{'loss': 0.1093, 'learning_rate': 1.8424778903643676e-05, 'epoch': 4.29}\n",
            "{'loss': 0.0348, 'learning_rate': 1.7807110700666523e-05, 'epoch': 4.4}\n",
            "{'loss': 0.0129, 'learning_rate': 1.718544809049402e-05, 'epoch': 4.51}\n",
            "{'loss': 0.3693, 'learning_rate': 1.6560823087264704e-05, 'epoch': 4.62}\n",
            "{'loss': 0.165, 'learning_rate': 1.5934272622947892e-05, 'epoch': 4.73}\n",
            "{'loss': 0.128, 'learning_rate': 1.53068368259462e-05, 'epoch': 4.84}\n",
            "{'loss': 0.113, 'learning_rate': 1.4679557294391701e-05, 'epoch': 4.95}\n",
            "{'loss': 0.1199, 'learning_rate': 1.4053475367002176e-05, 'epoch': 5.05}\n",
            "{'loss': 0.0266, 'learning_rate': 1.342963039436811e-05, 'epoch': 5.16}\n",
            "{'loss': 0.1463, 'learning_rate': 1.2809058013539995e-05, 'epoch': 5.27}\n",
            "{'loss': 0.0443, 'learning_rate': 1.219278842878062e-05, 'epoch': 5.38}\n",
            "{'loss': 0.1043, 'learning_rate': 1.1581844701336074e-05, 'epoch': 5.49}\n",
            "{'loss': 0.0575, 'learning_rate': 1.0977241051064958e-05, 'epoch': 5.6}\n",
            "{'loss': 0.0303, 'learning_rate': 1.0379981172744916e-05, 'epoch': 5.71}\n",
            "{'loss': 0.1253, 'learning_rate': 9.791056569851818e-06, 'epoch': 5.82}\n",
            "{'loss': 0.0542, 'learning_rate': 9.211444908577555e-06, 'epoch': 5.93}\n",
            "{'loss': 0.0504, 'learning_rate': 8.642108394818865e-06, 'epoch': 6.04}\n",
            "{'loss': 0.0742, 'learning_rate': 8.083992176831698e-06, 'epoch': 6.15}\n",
            "{'loss': 0.0509, 'learning_rate': 7.538022776202648e-06, 'epoch': 6.26}\n",
            "{'loss': 0.0191, 'learning_rate': 7.0051065497423736e-06, 'epoch': 6.37}\n",
            "{'loss': 0.0296, 'learning_rate': 6.486128184854248e-06, 'epoch': 6.48}\n",
            "{'loss': 0.0601, 'learning_rate': 5.9819492308761145e-06, 'epoch': 6.59}\n",
            "{'loss': 0.1081, 'learning_rate': 5.493406668833286e-06, 'epoch': 6.7}\n",
            "{'loss': 0.0923, 'learning_rate': 5.021311521977052e-06, 'epoch': 6.81}\n",
            "{'loss': 0.0395, 'learning_rate': 4.56644750941537e-06, 'epoch': 6.92}\n",
            "{'loss': 0.0886, 'learning_rate': 4.129569745070788e-06, 'epoch': 7.03}\n",
            "{'loss': 0.0755, 'learning_rate': 3.711403484125529e-06, 'epoch': 7.14}\n",
            "{'loss': 0.031, 'learning_rate': 3.312642919034627e-06, 'epoch': 7.25}\n",
            "{'loss': 0.0347, 'learning_rate': 2.9339500271059095e-06, 'epoch': 7.36}\n",
            "{'loss': 0.1037, 'learning_rate': 2.5759534715599784e-06, 'epoch': 7.47}\n",
            "{'loss': 0.0354, 'learning_rate': 2.2392475578944267e-06, 'epoch': 7.58}\n",
            "{'loss': 0.0709, 'learning_rate': 1.9243912472848867e-06, 'epoch': 7.69}\n",
            "{'loss': 0.0165, 'learning_rate': 1.6319072286607606e-06, 'epoch': 7.8}\n",
            "{'loss': 0.0345, 'learning_rate': 1.3622810509960025e-06, 'epoch': 7.91}\n",
            "{'loss': 0.0011, 'learning_rate': 1.1159603172554968e-06, 'epoch': 8.02}\n",
            "{'loss': 0.0804, 'learning_rate': 8.933539413351041e-07, 'epoch': 8.13}\n",
            "{'loss': 0.0086, 'learning_rate': 6.948314692289397e-07, 'epoch': 8.24}\n",
            "{'loss': 0.0014, 'learning_rate': 5.207224655507901e-07, 'epoch': 8.35}\n",
            "{'loss': 0.0605, 'learning_rate': 3.713159664281396e-07, 'epoch': 8.46}\n",
            "{'loss': 0.0243, 'learning_rate': 2.4685999967697893e-07, 'epoch': 8.57}\n",
            "{'loss': 0.0051, 'learning_rate': 1.4756117305400645e-07, 'epoch': 8.68}\n",
            "{'loss': 0.001, 'learning_rate': 7.35843312697449e-08, 'epoch': 8.79}\n",
            "{'loss': 0.0009, 'learning_rate': 2.5052282331941348e-08, 'epoch': 8.9}\n",
            "{'train_runtime': 129.0831, 'train_samples_per_second': 100.749, 'train_steps_per_second': 6.345, 'train_loss': 0.20528551690867206, 'epoch': 9.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 26/26 [00:01<00:00, 23.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 22:14:04,584] Trial 20 finished with value: 0.8956743002544529 and parameters: {'learning_rate': 3.08019353862044e-05, 'per_device_train_batch_size': 16, 'weight_decay': 0.12826734235776555, 'num_train_epochs': 9, 'warmup_steps': 48, 'freeze_layers': 6, 'dropout': 0.14091372104000105, 'lr_scheduler_type': 'cosine'}. Best is trial 19 with value: 0.9289340101522843.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: cosine\n",
            " Warmup steps (True): 113\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4ae6fcc23654518bf83f840cd0778e2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1810 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7125, 'learning_rate': 4.9835433772987815e-06, 'epoch': 0.06}\n",
            "{'loss': 0.7154, 'learning_rate': 1.2102891059154185e-05, 'epoch': 0.11}\n",
            "{'loss': 0.7269, 'learning_rate': 1.9222238741009587e-05, 'epoch': 0.17}\n",
            "{'loss': 0.7151, 'learning_rate': 2.634158642286499e-05, 'epoch': 0.22}\n",
            "{'loss': 0.6676, 'learning_rate': 3.3460934104720394e-05, 'epoch': 0.28}\n",
            "{'loss': 0.6767, 'learning_rate': 4.05802817865758e-05, 'epoch': 0.33}\n",
            "{'loss': 0.7192, 'learning_rate': 4.76996294684312e-05, 'epoch': 0.39}\n",
            "{'loss': 0.755, 'learning_rate': 5.48189771502866e-05, 'epoch': 0.44}\n",
            "{'loss': 0.6728, 'learning_rate': 6.122639006395646e-05, 'epoch': 0.5}\n",
            "{'loss': 0.6801, 'learning_rate': 6.763380297762632e-05, 'epoch': 0.55}\n",
            "{'loss': 0.8317, 'learning_rate': 7.475315065948172e-05, 'epoch': 0.61}\n",
            "{'loss': 0.7009, 'learning_rate': 8.044835309389151e-05, 'epoch': 0.66}\n",
            "{'loss': 0.7979, 'learning_rate': 8.043870360313838e-05, 'epoch': 0.72}\n",
            "{'loss': 0.6667, 'learning_rate': 8.04152723380595e-05, 'epoch': 0.77}\n",
            "{'loss': 0.6938, 'learning_rate': 8.037806732872604e-05, 'epoch': 0.83}\n",
            "{'loss': 0.767, 'learning_rate': 8.032710132557516e-05, 'epoch': 0.88}\n",
            "{'loss': 0.7154, 'learning_rate': 8.026239179504035e-05, 'epoch': 0.94}\n",
            "{'loss': 0.713, 'learning_rate': 8.01839609135655e-05, 'epoch': 0.99}\n",
            "{'loss': 0.7085, 'learning_rate': 8.009183556000495e-05, 'epoch': 1.05}\n",
            "{'loss': 0.6848, 'learning_rate': 7.99860473064118e-05, 'epoch': 1.1}\n",
            "{'loss': 0.7541, 'learning_rate': 7.986663240721803e-05, 'epoch': 1.16}\n",
            "{'loss': 0.792, 'learning_rate': 7.973363178680979e-05, 'epoch': 1.22}\n",
            "{'loss': 0.824, 'learning_rate': 7.958709102550226e-05, 'epoch': 1.27}\n",
            "{'loss': 0.7474, 'learning_rate': 7.942706034391903e-05, 'epoch': 1.33}\n",
            "{'loss': 0.689, 'learning_rate': 7.925359458578101e-05, 'epoch': 1.38}\n",
            "{'loss': 0.6372, 'learning_rate': 7.906675319911115e-05, 'epoch': 1.44}\n",
            "{'loss': 0.5726, 'learning_rate': 7.886660021586113e-05, 'epoch': 1.49}\n",
            "{'loss': 0.6201, 'learning_rate': 7.86532042299671e-05, 'epoch': 1.55}\n",
            "{'loss': 0.6121, 'learning_rate': 7.84266383738421e-05, 'epoch': 1.6}\n",
            "{'loss': 0.6738, 'learning_rate': 7.81869802933129e-05, 'epoch': 1.66}\n",
            "{'loss': 0.7898, 'learning_rate': 7.796016195933092e-05, 'epoch': 1.71}\n",
            "{'loss': 0.6595, 'learning_rate': 7.769585861351748e-05, 'epoch': 1.77}\n",
            "{'loss': 0.6736, 'learning_rate': 7.741871348703253e-05, 'epoch': 1.82}\n",
            "{'loss': 0.5889, 'learning_rate': 7.712882155960009e-05, 'epoch': 1.88}\n",
            "{'loss': 0.7132, 'learning_rate': 7.6826282179369e-05, 'epoch': 1.93}\n",
            "{'loss': 0.5781, 'learning_rate': 7.651119902886546e-05, 'epoch': 1.99}\n",
            "{'loss': 0.5523, 'learning_rate': 7.618368008946036e-05, 'epoch': 2.04}\n",
            "{'loss': 0.4566, 'learning_rate': 7.584383760436313e-05, 'epoch': 2.1}\n",
            "{'loss': 0.437, 'learning_rate': 7.549178804015524e-05, 'epoch': 2.15}\n",
            "{'loss': 0.5485, 'learning_rate': 7.51276520468762e-05, 'epoch': 2.21}\n",
            "{'loss': 0.5331, 'learning_rate': 7.475155441667585e-05, 'epoch': 2.27}\n",
            "{'loss': 0.5447, 'learning_rate': 7.436362404104717e-05, 'epoch': 2.32}\n",
            "{'loss': 0.5303, 'learning_rate': 7.396399386665423e-05, 'epoch': 2.38}\n",
            "{'loss': 0.4161, 'learning_rate': 7.35528008497703e-05, 'epoch': 2.43}\n",
            "{'loss': 0.3966, 'learning_rate': 7.313018590934196e-05, 'epoch': 2.49}\n",
            "{'loss': 0.8242, 'learning_rate': 7.269629387869507e-05, 'epoch': 2.54}\n",
            "{'loss': 0.5145, 'learning_rate': 7.225127345589933e-05, 'epoch': 2.6}\n",
            "{'loss': 0.6622, 'learning_rate': 7.17952771528083e-05, 'epoch': 2.65}\n",
            "{'loss': 0.5249, 'learning_rate': 7.132846124279249e-05, 'epoch': 2.71}\n",
            "{'loss': 0.4053, 'learning_rate': 7.085098570718322e-05, 'epoch': 2.76}\n",
            "{'loss': 0.4341, 'learning_rate': 7.036301418044591e-05, 'epoch': 2.82}\n",
            "{'loss': 0.5504, 'learning_rate': 6.98647138941012e-05, 'epoch': 2.87}\n",
            "{'loss': 0.5883, 'learning_rate': 6.935625561941357e-05, 'epoch': 2.93}\n",
            "{'loss': 0.4329, 'learning_rate': 6.883781360886662e-05, 'epoch': 2.98}\n",
            "{'loss': 0.4864, 'learning_rate': 6.830956553644553e-05, 'epoch': 3.04}\n",
            "{'loss': 0.5279, 'learning_rate': 6.777169243674679e-05, 'epoch': 3.09}\n",
            "{'loss': 0.2091, 'learning_rate': 6.72243786429363e-05, 'epoch': 3.15}\n",
            "{'loss': 0.4496, 'learning_rate': 6.6667811723577e-05, 'epoch': 3.2}\n",
            "{'loss': 0.553, 'learning_rate': 6.610218241834769e-05, 'epoch': 3.26}\n",
            "{'loss': 0.499, 'learning_rate': 6.552768457267513e-05, 'epoch': 3.31}\n",
            "{'loss': 0.5369, 'learning_rate': 6.494451507130178e-05, 'epoch': 3.37}\n",
            "{'loss': 0.3733, 'learning_rate': 6.435287377081182e-05, 'epoch': 3.43}\n",
            "{'loss': 0.659, 'learning_rate': 6.375296343113887e-05, 'epoch': 3.48}\n",
            "{'loss': 0.6389, 'learning_rate': 6.314498964607863e-05, 'epoch': 3.54}\n",
            "{'loss': 0.413, 'learning_rate': 6.252916077283032e-05, 'epoch': 3.59}\n",
            "{'loss': 0.4598, 'learning_rate': 6.190568786059106e-05, 'epoch': 3.65}\n",
            "{'loss': 0.6685, 'learning_rate': 6.127478457822781e-05, 'epoch': 3.7}\n",
            "{'loss': 0.3018, 'learning_rate': 6.0636667141051306e-05, 'epoch': 3.76}\n",
            "{'loss': 0.3003, 'learning_rate': 5.99915542367176e-05, 'epoch': 3.81}\n",
            "{'loss': 0.516, 'learning_rate': 5.933966695028201e-05, 'epoch': 3.87}\n",
            "{'loss': 0.4456, 'learning_rate': 5.868122868843173e-05, 'epoch': 3.92}\n",
            "{'loss': 0.3708, 'learning_rate': 5.801646510292256e-05, 'epoch': 3.98}\n",
            "{'loss': 0.3356, 'learning_rate': 5.734560401324642e-05, 'epoch': 4.03}\n",
            "{'loss': 0.2993, 'learning_rate': 5.666887532855586e-05, 'epoch': 4.09}\n",
            "{'loss': 0.2955, 'learning_rate': 5.598651096887251e-05, 'epoch': 4.14}\n",
            "{'loss': 0.5118, 'learning_rate': 5.529874478560625e-05, 'epoch': 4.2}\n",
            "{'loss': 0.1873, 'learning_rate': 5.4605812481412644e-05, 'epoch': 4.25}\n",
            "{'loss': 0.2757, 'learning_rate': 5.390795152941588e-05, 'epoch': 4.31}\n",
            "{'loss': 0.2677, 'learning_rate': 5.320540109182483e-05, 'epoch': 4.36}\n",
            "{'loss': 0.2223, 'learning_rate': 5.249840193797049e-05, 'epoch': 4.42}\n",
            "{'loss': 0.4174, 'learning_rate': 5.1787196361792424e-05, 'epoch': 4.48}\n",
            "{'loss': 0.3607, 'learning_rate': 5.1072028098802854e-05, 'epoch': 4.53}\n",
            "{'loss': 0.6938, 'learning_rate': 5.03531422425566e-05, 'epoch': 4.59}\n",
            "{'loss': 0.7083, 'learning_rate': 4.96307851606558e-05, 'epoch': 4.64}\n",
            "{'loss': 0.4834, 'learning_rate': 4.8905204410317706e-05, 'epoch': 4.7}\n",
            "{'loss': 0.3251, 'learning_rate': 4.817664865353509e-05, 'epoch': 4.75}\n",
            "{'loss': 0.4409, 'learning_rate': 4.7445367571857836e-05, 'epoch': 4.81}\n",
            "{'loss': 0.3648, 'learning_rate': 4.671161178082523e-05, 'epoch': 4.86}\n",
            "{'loss': 0.3366, 'learning_rate': 4.59756327440781e-05, 'epoch': 4.92}\n",
            "{'loss': 0.2494, 'learning_rate': 4.523768268718037e-05, 'epoch': 4.97}\n",
            "{'loss': 0.3242, 'learning_rate': 4.4498014511179354e-05, 'epoch': 5.03}\n",
            "{'loss': 0.1938, 'learning_rate': 4.3756881705934825e-05, 'epoch': 5.08}\n",
            "{'loss': 0.4251, 'learning_rate': 4.301453826324598e-05, 'epoch': 5.14}\n",
            "{'loss': 0.3065, 'learning_rate': 4.22712385898066e-05, 'epoch': 5.19}\n",
            "{'loss': 0.2474, 'learning_rate': 4.152723742001797e-05, 'epoch': 5.25}\n",
            "{'loss': 0.2277, 'learning_rate': 4.078278972868945e-05, 'epoch': 5.3}\n",
            "{'loss': 0.3094, 'learning_rate': 4.003815064365672e-05, 'epoch': 5.36}\n",
            "{'loss': 0.1521, 'learning_rate': 3.929357535834748e-05, 'epoch': 5.41}\n",
            "{'loss': 0.1293, 'learning_rate': 3.854931904432482e-05, 'epoch': 5.47}\n",
            "{'loss': 0.3741, 'learning_rate': 3.7805636763837955e-05, 'epoch': 5.52}\n",
            "{'loss': 0.4335, 'learning_rate': 3.7062783382410494e-05, 'epoch': 5.58}\n",
            "{'loss': 0.1927, 'learning_rate': 3.632101348149605e-05, 'epoch': 5.64}\n",
            "{'loss': 0.2825, 'learning_rate': 3.5580581271231365e-05, 'epoch': 5.69}\n",
            "{'loss': 0.2558, 'learning_rate': 3.484174050331643e-05, 'epoch': 5.75}\n",
            "{'loss': 0.2611, 'learning_rate': 3.410474438405201e-05, 'epoch': 5.8}\n",
            "{'loss': 0.3607, 'learning_rate': 3.336984548756383e-05, 'epoch': 5.86}\n",
            "{'loss': 0.126, 'learning_rate': 3.2637295669243604e-05, 'epoch': 5.91}\n",
            "{'loss': 0.4554, 'learning_rate': 3.19073459794362e-05, 'epoch': 5.97}\n",
            "{'loss': 0.2861, 'learning_rate': 3.118024657740289e-05, 'epoch': 6.02}\n",
            "{'loss': 0.0355, 'learning_rate': 3.0456246645589794e-05, 'epoch': 6.08}\n",
            "{'loss': 0.2237, 'learning_rate': 2.9735594304231267e-05, 'epoch': 6.13}\n",
            "{'loss': 0.1387, 'learning_rate': 2.9018536526317144e-05, 'epoch': 6.19}\n",
            "{'loss': 0.1178, 'learning_rate': 2.8305319052953305e-05, 'epoch': 6.24}\n",
            "{'loss': 0.2365, 'learning_rate': 2.7596186309144275e-05, 'epoch': 6.3}\n",
            "{'loss': 0.2274, 'learning_rate': 2.6891381320027018e-05, 'epoch': 6.35}\n",
            "{'loss': 0.2888, 'learning_rate': 2.6191145627584275e-05, 'epoch': 6.41}\n",
            "{'loss': 0.1999, 'learning_rate': 2.5495719207866414e-05, 'epoch': 6.46}\n",
            "{'loss': 0.2175, 'learning_rate': 2.4805340388749804e-05, 'epoch': 6.52}\n",
            "{'loss': 0.1995, 'learning_rate': 2.4120245768259984e-05, 'epoch': 6.57}\n",
            "{'loss': 0.2979, 'learning_rate': 2.3440670133487834e-05, 'epoch': 6.63}\n",
            "{'loss': 0.2428, 'learning_rate': 2.2766846380126218e-05, 'epoch': 6.69}\n",
            "{'loss': 0.2364, 'learning_rate': 2.2099005432654865e-05, 'epoch': 6.74}\n",
            "{'loss': 0.2825, 'learning_rate': 2.143737616520084e-05, 'epoch': 6.8}\n",
            "{'loss': 0.3172, 'learning_rate': 2.078218532310162e-05, 'epoch': 6.85}\n",
            "{'loss': 0.3951, 'learning_rate': 2.013365744519782e-05, 'epoch': 6.91}\n",
            "{'loss': 0.2835, 'learning_rate': 1.949201478688196e-05, 'epoch': 6.96}\n",
            "{'loss': 0.1399, 'learning_rate': 1.8857477243929918e-05, 'epoch': 7.02}\n",
            "{'loss': 0.1966, 'learning_rate': 1.823026227714095e-05, 'epoch': 7.07}\n",
            "{'loss': 0.1186, 'learning_rate': 1.7610584837812333e-05, 'epoch': 7.13}\n",
            "{'loss': 0.0204, 'learning_rate': 1.6998657294073793e-05, 'epoch': 7.18}\n",
            "{'loss': 0.176, 'learning_rate': 1.6394689358107435e-05, 'epoch': 7.24}\n",
            "{'loss': 0.1751, 'learning_rate': 1.579888801427778e-05, 'epoch': 7.29}\n",
            "{'loss': 0.2473, 'learning_rate': 1.5211457448196705e-05, 'epoch': 7.35}\n",
            "{'loss': 0.2428, 'learning_rate': 1.4632598976747368e-05, 'epoch': 7.4}\n",
            "{'loss': 0.1747, 'learning_rate': 1.4062510979091528e-05, 'epoch': 7.46}\n",
            "{'loss': 0.2481, 'learning_rate': 1.3501388828683484e-05, 'epoch': 7.51}\n",
            "{'loss': 0.1752, 'learning_rate': 1.2949424826314044e-05, 'epoch': 7.57}\n",
            "{'loss': 0.3522, 'learning_rate': 1.2406808134207683e-05, 'epoch': 7.62}\n",
            "{'loss': 0.1826, 'learning_rate': 1.1873724711195148e-05, 'epoch': 7.68}\n",
            "{'loss': 0.28, 'learning_rate': 1.1350357248984069e-05, 'epoch': 7.73}\n",
            "{'loss': 0.367, 'learning_rate': 1.0836885109549e-05, 'epoch': 7.79}\n",
            "{'loss': 0.0455, 'learning_rate': 1.0333484263662825e-05, 'epoch': 7.85}\n",
            "{'loss': 0.1721, 'learning_rate': 9.840327230590188e-06, 'epoch': 7.9}\n",
            "{'loss': 0.0682, 'learning_rate': 9.357583018963884e-06, 'epoch': 7.96}\n",
            "{'loss': 0.2748, 'learning_rate': 8.885417068864283e-06, 'epoch': 8.01}\n",
            "{'loss': 0.2987, 'learning_rate': 8.423991195121784e-06, 'epoch': 8.07}\n",
            "{'loss': 0.3868, 'learning_rate': 7.973463531861698e-06, 'epoch': 8.12}\n",
            "{'loss': 0.1902, 'learning_rate': 7.533988478310402e-06, 'epoch': 8.18}\n",
            "{'loss': 0.115, 'learning_rate': 7.105716645881629e-06, 'epoch': 8.23}\n",
            "{'loss': 0.1841, 'learning_rate': 6.6887948065607665e-06, 'epoch': 8.29}\n",
            "{'loss': 0.2169, 'learning_rate': 6.28336584260505e-06, 'epoch': 8.34}\n",
            "{'loss': 0.2254, 'learning_rate': 5.889568697576626e-06, 'epoch': 8.4}\n",
            "{'loss': 0.2277, 'learning_rate': 5.5075383287256535e-06, 'epoch': 8.45}\n",
            "{'loss': 0.2535, 'learning_rate': 5.137405660739373e-06, 'epoch': 8.51}\n",
            "{'loss': 0.0175, 'learning_rate': 4.779297540873281e-06, 'epoch': 8.56}\n",
            "{'loss': 0.0272, 'learning_rate': 4.43333669547956e-06, 'epoch': 8.62}\n",
            "{'loss': 0.27, 'learning_rate': 4.099641687947862e-06, 'epoch': 8.67}\n",
            "{'loss': 0.1741, 'learning_rate': 3.778326878072764e-06, 'epoch': 8.73}\n",
            "{'loss': 0.1249, 'learning_rate': 3.4695023828617615e-06, 'epoch': 8.78}\n",
            "{'loss': 0.0658, 'learning_rate': 3.173274038797359e-06, 'epoch': 8.84}\n",
            "{'loss': 0.063, 'learning_rate': 2.8897433655661125e-06, 'epoch': 8.9}\n",
            "{'loss': 0.1176, 'learning_rate': 2.619007531267082e-06, 'epoch': 8.95}\n",
            "{'loss': 0.0715, 'learning_rate': 2.361159319111546e-06, 'epoch': 9.01}\n",
            "{'loss': 0.1146, 'learning_rate': 2.116287095625545e-06, 'epoch': 9.06}\n",
            "{'loss': 0.2223, 'learning_rate': 1.884474780365972e-06, 'epoch': 9.12}\n",
            "{'loss': 0.2865, 'learning_rate': 1.665801817160736e-06, 'epoch': 9.17}\n",
            "{'loss': 0.0135, 'learning_rate': 1.4603431468827426e-06, 'epoch': 9.23}\n",
            "{'loss': 0.2789, 'learning_rate': 1.268169181767095e-06, 'epoch': 9.28}\n",
            "{'loss': 0.1799, 'learning_rate': 1.0893457812802962e-06, 'epoch': 9.34}\n",
            "{'loss': 0.143, 'learning_rate': 9.239342295497091e-07, 'epoch': 9.39}\n",
            "{'loss': 0.1706, 'learning_rate': 7.719912143610295e-07, 'epoch': 9.45}\n",
            "{'loss': 0.3345, 'learning_rate': 6.335688077309481e-07, 'epoch': 9.5}\n",
            "{'loss': 0.2282, 'learning_rate': 5.087144480616875e-07, 'epoch': 9.56}\n",
            "{'loss': 0.0915, 'learning_rate': 3.974709238834851e-07, 'epoch': 9.61}\n",
            "{'loss': 0.1725, 'learning_rate': 2.998763591906614e-07, 'epoch': 9.67}\n",
            "{'loss': 0.1218, 'learning_rate': 2.1596420037622792e-07, 'epoch': 9.72}\n",
            "{'loss': 0.2256, 'learning_rate': 1.4576320476956475e-07, 'epoch': 9.78}\n",
            "{'loss': 0.2298, 'learning_rate': 8.929743078106466e-08, 'epoch': 9.83}\n",
            "{'loss': 0.1201, 'learning_rate': 4.658622965712199e-08, 'epoch': 9.89}\n",
            "{'loss': 0.1806, 'learning_rate': 1.7644238848327044e-08, 'epoch': 9.94}\n",
            "{'loss': 0.1215, 'learning_rate': 2.4813769931090696e-09, 'epoch': 10.0}\n",
            "{'train_runtime': 202.0675, 'train_samples_per_second': 71.511, 'train_steps_per_second': 8.957, 'train_loss': 0.38115783587345103, 'epoch': 10.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 52/52 [00:01<00:00, 36.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 22:17:30,680] Trial 21 finished with value: 0.8940568475452196 and parameters: {'learning_rate': 8.044862880496605e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.18276025743006552, 'num_train_epochs': 10, 'warmup_steps': 113, 'freeze_layers': 6, 'dropout': 0.1627147677006455, 'lr_scheduler_type': 'cosine'}. Best is trial 19 with value: 0.9289340101522843.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: cosine\n",
            " Warmup steps (True): 102\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "428c11f13ee84139a803c1301bff4c4b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1629 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7591, 'learning_rate': 6.841308807502984e-06, 'epoch': 0.06}\n",
            "{'loss': 0.7224, 'learning_rate': 1.5637277274292532e-05, 'epoch': 0.11}\n",
            "{'loss': 0.7392, 'learning_rate': 2.5410575570725364e-05, 'epoch': 0.17}\n",
            "{'loss': 0.7605, 'learning_rate': 3.420654403751491e-05, 'epoch': 0.22}\n",
            "{'loss': 0.6874, 'learning_rate': 4.3979842333947744e-05, 'epoch': 0.28}\n",
            "{'loss': 0.6461, 'learning_rate': 5.3753140630380576e-05, 'epoch': 0.33}\n",
            "{'loss': 0.6121, 'learning_rate': 6.352643892681341e-05, 'epoch': 0.39}\n",
            "{'loss': 0.8322, 'learning_rate': 7.329973722324625e-05, 'epoch': 0.44}\n",
            "{'loss': 0.7178, 'learning_rate': 8.307303551967909e-05, 'epoch': 0.5}\n",
            "{'loss': 0.6089, 'learning_rate': 9.284633381611192e-05, 'epoch': 0.55}\n",
            "{'loss': 0.5591, 'learning_rate': 9.968669323474326e-05, 'epoch': 0.61}\n",
            "{'loss': 0.3539, 'learning_rate': 9.966981621645426e-05, 'epoch': 0.66}\n",
            "{'loss': 0.4194, 'learning_rate': 9.963184989006078e-05, 'epoch': 0.72}\n",
            "{'loss': 0.4607, 'learning_rate': 9.95728103251577e-05, 'epoch': 0.77}\n",
            "{'loss': 0.6866, 'learning_rate': 9.949272251078096e-05, 'epoch': 0.83}\n",
            "{'loss': 0.3528, 'learning_rate': 9.939162034483053e-05, 'epoch': 0.88}\n",
            "{'loss': 0.7204, 'learning_rate': 9.926954661972294e-05, 'epoch': 0.94}\n",
            "{'loss': 0.6955, 'learning_rate': 9.912655300427899e-05, 'epoch': 0.99}\n",
            "{'loss': 0.5246, 'learning_rate': 9.896270002185433e-05, 'epoch': 1.05}\n",
            "{'loss': 0.6662, 'learning_rate': 9.87780570247226e-05, 'epoch': 1.1}\n",
            "{'loss': 0.4461, 'learning_rate': 9.857270216472123e-05, 'epoch': 1.16}\n",
            "{'loss': 0.5767, 'learning_rate': 9.834672236017313e-05, 'epoch': 1.22}\n",
            "{'loss': 0.5357, 'learning_rate': 9.810021325909762e-05, 'epoch': 1.27}\n",
            "{'loss': 0.4091, 'learning_rate': 9.783327919872657e-05, 'epoch': 1.33}\n",
            "{'loss': 0.3509, 'learning_rate': 9.754603316134268e-05, 'epoch': 1.38}\n",
            "{'loss': 0.4274, 'learning_rate': 9.723859672645874e-05, 'epoch': 1.44}\n",
            "{'loss': 0.391, 'learning_rate': 9.691110001935793e-05, 'epoch': 1.49}\n",
            "{'loss': 0.4308, 'learning_rate': 9.656368165601719e-05, 'epoch': 1.55}\n",
            "{'loss': 0.3418, 'learning_rate': 9.619648868443664e-05, 'epoch': 1.6}\n",
            "{'loss': 0.2942, 'learning_rate': 9.580967652240024e-05, 'epoch': 1.66}\n",
            "{'loss': 0.3664, 'learning_rate': 9.540340889169377e-05, 'epoch': 1.71}\n",
            "{'loss': 0.3945, 'learning_rate': 9.497785774880809e-05, 'epoch': 1.77}\n",
            "{'loss': 0.3164, 'learning_rate': 9.453320321215692e-05, 'epoch': 1.82}\n",
            "{'loss': 1.7509, 'learning_rate': 9.406963348584022e-05, 'epoch': 1.88}\n",
            "{'loss': 0.798, 'learning_rate': 9.358734477998494e-05, 'epoch': 1.93}\n",
            "{'loss': 0.3713, 'learning_rate': 9.308654122769737e-05, 'epoch': 1.99}\n",
            "{'loss': 0.3477, 'learning_rate': 9.256743479866185e-05, 'epoch': 2.04}\n",
            "{'loss': 0.2561, 'learning_rate': 9.203024520942279e-05, 'epoch': 2.1}\n",
            "{'loss': 0.3628, 'learning_rate': 9.147519983038755e-05, 'epoch': 2.15}\n",
            "{'loss': 0.4094, 'learning_rate': 9.090253358958984e-05, 'epoch': 2.21}\n",
            "{'loss': 0.3453, 'learning_rate': 9.031248887325423e-05, 'epoch': 2.27}\n",
            "{'loss': 0.5406, 'learning_rate': 8.970531542320415e-05, 'epoch': 2.32}\n",
            "{'loss': 0.4207, 'learning_rate': 8.908127023115616e-05, 'epoch': 2.38}\n",
            "{'loss': 0.3154, 'learning_rate': 8.844061742994596e-05, 'epoch': 2.43}\n",
            "{'loss': 0.3173, 'learning_rate': 8.778362818173174e-05, 'epoch': 2.49}\n",
            "{'loss': 0.4242, 'learning_rate': 8.711058056322235e-05, 'epoch': 2.54}\n",
            "{'loss': 0.2857, 'learning_rate': 8.649134310945455e-05, 'epoch': 2.6}\n",
            "{'loss': 0.5925, 'learning_rate': 8.578857493452452e-05, 'epoch': 2.65}\n",
            "{'loss': 0.5476, 'learning_rate': 8.507059281383506e-05, 'epoch': 2.71}\n",
            "{'loss': 0.3863, 'learning_rate': 8.433770063988616e-05, 'epoch': 2.76}\n",
            "{'loss': 0.4447, 'learning_rate': 8.359020861599423e-05, 'epoch': 2.82}\n",
            "{'loss': 0.508, 'learning_rate': 8.282843312499579e-05, 'epoch': 2.87}\n",
            "{'loss': 0.4912, 'learning_rate': 8.205269659533534e-05, 'epoch': 2.93}\n",
            "{'loss': 0.6712, 'learning_rate': 8.126332736459481e-05, 'epoch': 2.98}\n",
            "{'loss': 0.9001, 'learning_rate': 8.046065954052148e-05, 'epoch': 3.04}\n",
            "{'loss': 0.7011, 'learning_rate': 7.964503285961396e-05, 'epoch': 3.09}\n",
            "{'loss': 0.7135, 'learning_rate': 7.881679254332552e-05, 'epoch': 3.15}\n",
            "{'loss': 0.5888, 'learning_rate': 7.797628915194599e-05, 'epoch': 3.2}\n",
            "{'loss': 0.5178, 'learning_rate': 7.712387843622391e-05, 'epoch': 3.26}\n",
            "{'loss': 0.4835, 'learning_rate': 7.625992118679173e-05, 'epoch': 3.31}\n",
            "{'loss': 0.4708, 'learning_rate': 7.538478308145795e-05, 'epoch': 3.37}\n",
            "{'loss': 0.4067, 'learning_rate': 7.44988345304306e-05, 'epoch': 3.43}\n",
            "{'loss': 0.5183, 'learning_rate': 7.360245051953772e-05, 'epoch': 3.48}\n",
            "{'loss': 0.4835, 'learning_rate': 7.269601045151117e-05, 'epoch': 3.54}\n",
            "{'loss': 0.3655, 'learning_rate': 7.177989798540104e-05, 'epoch': 3.59}\n",
            "{'loss': 0.5612, 'learning_rate': 7.08545008741883e-05, 'epoch': 3.65}\n",
            "{'loss': 0.4819, 'learning_rate': 6.992021080066495e-05, 'epoch': 3.7}\n",
            "{'loss': 0.5305, 'learning_rate': 6.897742321165062e-05, 'epoch': 3.76}\n",
            "{'loss': 0.5284, 'learning_rate': 6.802653715061606e-05, 'epoch': 3.81}\n",
            "{'loss': 0.5059, 'learning_rate': 6.706795508878444e-05, 'epoch': 3.87}\n",
            "{'loss': 0.5059, 'learning_rate': 6.610208275478162e-05, 'epoch': 3.92}\n",
            "{'loss': 0.5682, 'learning_rate': 6.512932896290786e-05, 'epoch': 3.98}\n",
            "{'loss': 0.6588, 'learning_rate': 6.424830713868063e-05, 'epoch': 4.03}\n",
            "{'loss': 0.5153, 'learning_rate': 6.326361515145723e-05, 'epoch': 4.09}\n",
            "{'loss': 0.5748, 'learning_rate': 6.227324311373963e-05, 'epoch': 4.14}\n",
            "{'loss': 0.5274, 'learning_rate': 6.127761020955177e-05, 'epoch': 4.2}\n",
            "{'loss': 0.6267, 'learning_rate': 6.027713784962744e-05, 'epoch': 4.25}\n",
            "{'loss': 0.5077, 'learning_rate': 5.9272249493044345e-05, 'epoch': 4.31}\n",
            "{'loss': 0.5695, 'learning_rate': 5.8263370467991206e-05, 'epoch': 4.36}\n",
            "{'loss': 0.5873, 'learning_rate': 5.725092779174363e-05, 'epoch': 4.42}\n",
            "{'loss': 0.6123, 'learning_rate': 5.623534998992522e-05, 'epoch': 4.48}\n",
            "{'loss': 0.7044, 'learning_rate': 5.5217066915130124e-05, 'epoch': 4.53}\n",
            "{'loss': 0.5107, 'learning_rate': 5.419650956498406e-05, 'epoch': 4.59}\n",
            "{'loss': 0.7122, 'learning_rate': 5.3174109899720566e-05, 'epoch': 4.64}\n",
            "{'loss': 0.6364, 'learning_rate': 5.21503006593499e-05, 'epoch': 4.7}\n",
            "{'loss': 0.4885, 'learning_rate': 5.112551518049789e-05, 'epoch': 4.75}\n",
            "{'loss': 0.5986, 'learning_rate': 5.010018721299223e-05, 'epoch': 4.81}\n",
            "{'loss': 0.3974, 'learning_rate': 4.9074750736273906e-05, 'epoch': 4.86}\n",
            "{'loss': 0.5338, 'learning_rate': 4.804963977571142e-05, 'epoch': 4.92}\n",
            "{'loss': 0.3382, 'learning_rate': 4.702528821889555e-05, 'epoch': 4.97}\n",
            "{'loss': 0.4249, 'learning_rate': 4.600212963199253e-05, 'epoch': 5.03}\n",
            "{'loss': 0.5218, 'learning_rate': 4.498059707623316e-05, 'epoch': 5.08}\n",
            "{'loss': 0.501, 'learning_rate': 4.396112292461567e-05, 'epoch': 5.14}\n",
            "{'loss': 0.3818, 'learning_rate': 4.294413867889993e-05, 'epoch': 5.19}\n",
            "{'loss': 0.4828, 'learning_rate': 4.193007478697033e-05, 'epoch': 5.25}\n",
            "{'loss': 0.5677, 'learning_rate': 4.091936046064486e-05, 'epoch': 5.3}\n",
            "{'loss': 0.4072, 'learning_rate': 3.9912423494007156e-05, 'epoch': 5.36}\n",
            "{'loss': 0.4213, 'learning_rate': 3.890969008233888e-05, 'epoch': 5.41}\n",
            "{'loss': 0.3783, 'learning_rate': 3.791158464172858e-05, 'epoch': 5.47}\n",
            "{'loss': 0.494, 'learning_rate': 3.69185296294337e-05, 'epoch': 5.52}\n",
            "{'loss': 0.5822, 'learning_rate': 3.5930945365071744e-05, 'epoch': 5.58}\n",
            "{'loss': 0.455, 'learning_rate': 3.494924985271607e-05, 'epoch': 5.64}\n",
            "{'loss': 0.516, 'learning_rate': 3.397385860397194e-05, 'epoch': 5.69}\n",
            "{'loss': 0.5075, 'learning_rate': 3.300518446210729e-05, 'epoch': 5.75}\n",
            "{'loss': 0.5419, 'learning_rate': 3.204363742731322e-05, 'epoch': 5.8}\n",
            "{'loss': 0.4928, 'learning_rate': 3.1089624483167516e-05, 'epoch': 5.86}\n",
            "{'loss': 0.557, 'learning_rate': 3.0143549424375224e-05, 'epoch': 5.91}\n",
            "{'loss': 0.6209, 'learning_rate': 2.920581268585871e-05, 'epoch': 5.97}\n",
            "{'loss': 0.4221, 'learning_rate': 2.8276811173270137e-05, 'epoch': 6.02}\n",
            "{'loss': 0.3569, 'learning_rate': 2.7356938094997333e-05, 'epoch': 6.08}\n",
            "{'loss': 0.3315, 'learning_rate': 2.644658279573479e-05, 'epoch': 6.13}\n",
            "{'loss': 0.4481, 'learning_rate': 2.554613059168998e-05, 'epoch': 6.19}\n",
            "{'loss': 0.329, 'learning_rate': 2.4655962607494783e-05, 'epoch': 6.24}\n",
            "{'loss': 0.5176, 'learning_rate': 2.3776455614890905e-05, 'epoch': 6.3}\n",
            "{'loss': 0.3966, 'learning_rate': 2.2907981873257853e-05, 'epoch': 6.35}\n",
            "{'loss': 0.5232, 'learning_rate': 2.2050908972050776e-05, 'epoch': 6.41}\n",
            "{'loss': 0.3579, 'learning_rate': 2.1205599675214794e-05, 'epoch': 6.46}\n",
            "{'loss': 0.4381, 'learning_rate': 2.0372411767641862e-05, 'epoch': 6.52}\n",
            "{'loss': 0.4266, 'learning_rate': 1.9551697903735108e-05, 'epoch': 6.57}\n",
            "{'loss': 0.4698, 'learning_rate': 1.874380545814451e-05, 'epoch': 6.63}\n",
            "{'loss': 0.4693, 'learning_rate': 1.794907637873756e-05, 'epoch': 6.69}\n",
            "{'loss': 0.5755, 'learning_rate': 1.7167847041866474e-05, 'epoch': 6.74}\n",
            "{'loss': 0.4814, 'learning_rate': 1.6400448109994066e-05, 'epoch': 6.8}\n",
            "{'loss': 0.481, 'learning_rate': 1.5647204391737714e-05, 'epoch': 6.85}\n",
            "{'loss': 0.3605, 'learning_rate': 1.490843470439108e-05, 'epoch': 6.91}\n",
            "{'loss': 0.474, 'learning_rate': 1.4184451738981939e-05, 'epoch': 6.96}\n",
            "{'loss': 0.3964, 'learning_rate': 1.347556192792269e-05, 'epoch': 7.02}\n",
            "{'loss': 0.4282, 'learning_rate': 1.2782065315310134e-05, 'epoch': 7.07}\n",
            "{'loss': 0.3284, 'learning_rate': 1.2104255429929015e-05, 'epoch': 7.13}\n",
            "{'loss': 0.4321, 'learning_rate': 1.1442419161013253e-05, 'epoch': 7.18}\n",
            "{'loss': 0.4247, 'learning_rate': 1.0796836636817552e-05, 'epoch': 7.24}\n",
            "{'loss': 0.4367, 'learning_rate': 1.0167781106050447e-05, 'epoch': 7.29}\n",
            "{'loss': 0.5358, 'learning_rate': 9.555518822219328e-06, 'epoch': 7.35}\n",
            "{'loss': 0.327, 'learning_rate': 8.960308930936243e-06, 'epoch': 7.4}\n",
            "{'loss': 0.4047, 'learning_rate': 8.382403360232087e-06, 'epoch': 7.46}\n",
            "{'loss': 0.4314, 'learning_rate': 7.82204671392578e-06, 'epoch': 7.51}\n",
            "{'loss': 0.4658, 'learning_rate': 7.279476168093505e-06, 'epoch': 7.57}\n",
            "{'loss': 0.4423, 'learning_rate': 6.754921370681692e-06, 'epoch': 7.62}\n",
            "{'loss': 0.4042, 'learning_rate': 6.248604344306505e-06, 'epoch': 7.68}\n",
            "{'loss': 0.5506, 'learning_rate': 5.760739392280628e-06, 'epoch': 7.73}\n",
            "{'loss': 0.5457, 'learning_rate': 5.29153300790755e-06, 'epoch': 7.79}\n",
            "{'loss': 0.3696, 'learning_rate': 4.841183787081334e-06, 'epoch': 7.85}\n",
            "{'loss': 0.4065, 'learning_rate': 4.4098823442290235e-06, 'epoch': 7.9}\n",
            "{'loss': 0.5532, 'learning_rate': 3.997811231631477e-06, 'epoch': 7.96}\n",
            "{'loss': 0.3269, 'learning_rate': 3.605144862156321e-06, 'epoch': 8.01}\n",
            "{'loss': 0.5277, 'learning_rate': 3.232049435436183e-06, 'epoch': 8.07}\n",
            "{'loss': 0.5714, 'learning_rate': 2.8786828675231477e-06, 'epoch': 8.12}\n",
            "{'loss': 0.3569, 'learning_rate': 2.545194724049342e-06, 'epoch': 8.18}\n",
            "{'loss': 0.4956, 'learning_rate': 2.2317261569219316e-06, 'epoch': 8.23}\n",
            "{'loss': 0.5037, 'learning_rate': 1.9384098445792694e-06, 'epoch': 8.29}\n",
            "{'loss': 0.4343, 'learning_rate': 1.665369935833519e-06, 'epoch': 8.34}\n",
            "{'loss': 0.5877, 'learning_rate': 1.4127219973235858e-06, 'epoch': 8.4}\n",
            "{'loss': 0.3899, 'learning_rate': 1.1805729646004228e-06, 'epoch': 8.45}\n",
            "{'loss': 0.4762, 'learning_rate': 9.690210968656042e-07, 'epoch': 8.51}\n",
            "{'loss': 0.4767, 'learning_rate': 7.781559353822325e-07, 'epoch': 8.56}\n",
            "{'loss': 0.3754, 'learning_rate': 6.080582655757519e-07, 'epoch': 8.62}\n",
            "{'loss': 0.4161, 'learning_rate': 4.588000828408141e-07, 'epoch': 8.67}\n",
            "{'loss': 0.2781, 'learning_rate': 3.304445620685233e-07, 'epoch': 8.73}\n",
            "{'loss': 0.3661, 'learning_rate': 2.230460309071265e-07, 'epoch': 8.78}\n",
            "{'loss': 0.3146, 'learning_rate': 1.366499467673157e-07, 'epoch': 8.84}\n",
            "{'loss': 0.4214, 'learning_rate': 7.129287758197014e-08, 'epoch': 8.9}\n",
            "{'loss': 0.3341, 'learning_rate': 2.700248632844539e-08, 'epoch': 8.95}\n",
            "{'train_runtime': 165.9809, 'train_samples_per_second': 78.352, 'train_steps_per_second': 9.814, 'train_loss': 0.4969738863083832, 'epoch': 9.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 52/52 [00:01<00:00, 38.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 22:20:20,675] Trial 22 finished with value: 0.8043478260869564 and parameters: {'learning_rate': 9.96876426236149e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.18612200745793037, 'num_train_epochs': 9, 'warmup_steps': 102, 'freeze_layers': 6, 'dropout': 0.19583089448229488, 'lr_scheduler_type': 'cosine'}. Best is trial 19 with value: 0.9289340101522843.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: cosine\n",
            " Warmup steps (True): 131\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bc240ae7dc9f402aa48096051a23d943",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1810 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7126, 'learning_rate': 3.904917304877443e-06, 'epoch': 0.06}\n",
            "{'loss': 0.7091, 'learning_rate': 9.483370597559504e-06, 'epoch': 0.11}\n",
            "{'loss': 0.7072, 'learning_rate': 1.5061823890241568e-05, 'epoch': 0.17}\n",
            "{'loss': 0.7468, 'learning_rate': 2.064027718292363e-05, 'epoch': 0.22}\n",
            "{'loss': 0.6814, 'learning_rate': 2.621873047560569e-05, 'epoch': 0.28}\n",
            "{'loss': 0.6375, 'learning_rate': 3.123933843901954e-05, 'epoch': 0.33}\n",
            "{'loss': 0.669, 'learning_rate': 3.6817791731701606e-05, 'epoch': 0.39}\n",
            "{'loss': 0.7091, 'learning_rate': 4.239624502438367e-05, 'epoch': 0.44}\n",
            "{'loss': 0.6209, 'learning_rate': 4.797469831706573e-05, 'epoch': 0.5}\n",
            "{'loss': 0.5171, 'learning_rate': 5.3553151609747794e-05, 'epoch': 0.55}\n",
            "{'loss': 0.4602, 'learning_rate': 5.9131604902429857e-05, 'epoch': 0.61}\n",
            "{'loss': 0.4407, 'learning_rate': 6.471005819511192e-05, 'epoch': 0.66}\n",
            "{'loss': 0.4609, 'learning_rate': 7.028851148779399e-05, 'epoch': 0.72}\n",
            "{'loss': 0.5543, 'learning_rate': 7.30761390905568e-05, 'epoch': 0.77}\n",
            "{'loss': 0.535, 'learning_rate': 7.306334758166248e-05, 'epoch': 0.83}\n",
            "{'loss': 0.3587, 'learning_rate': 7.303776904211486e-05, 'epoch': 0.88}\n",
            "{'loss': 0.4524, 'learning_rate': 7.299941242682805e-05, 'epoch': 0.94}\n",
            "{'loss': 1.1951, 'learning_rate': 7.294829116425428e-05, 'epoch': 0.99}\n",
            "{'loss': 0.7352, 'learning_rate': 7.28844231516827e-05, 'epoch': 1.05}\n",
            "{'loss': 0.4673, 'learning_rate': 7.280783074897351e-05, 'epoch': 1.1}\n",
            "{'loss': 0.4787, 'learning_rate': 7.271854077073001e-05, 'epoch': 1.16}\n",
            "{'loss': 0.3228, 'learning_rate': 7.261658447691084e-05, 'epoch': 1.22}\n",
            "{'loss': 0.348, 'learning_rate': 7.25140235226241e-05, 'epoch': 1.27}\n",
            "{'loss': 0.506, 'learning_rate': 7.238810322219681e-05, 'epoch': 1.33}\n",
            "{'loss': 0.3346, 'learning_rate': 7.224963229066723e-05, 'epoch': 1.38}\n",
            "{'loss': 0.4333, 'learning_rate': 7.209865920599091e-05, 'epoch': 1.44}\n",
            "{'loss': 0.4075, 'learning_rate': 7.193523682306246e-05, 'epoch': 1.49}\n",
            "{'loss': 0.4402, 'learning_rate': 7.175942235521125e-05, 'epoch': 1.55}\n",
            "{'loss': 0.3505, 'learning_rate': 7.157127735417138e-05, 'epoch': 1.6}\n",
            "{'loss': 0.3888, 'learning_rate': 7.137086768853271e-05, 'epoch': 1.66}\n",
            "{'loss': 0.4269, 'learning_rate': 7.115826352068066e-05, 'epoch': 1.71}\n",
            "{'loss': 0.3896, 'learning_rate': 7.093353928223263e-05, 'epoch': 1.77}\n",
            "{'loss': 0.3607, 'learning_rate': 7.069677364797996e-05, 'epoch': 1.82}\n",
            "{'loss': 0.3688, 'learning_rate': 7.044804950834426e-05, 'epoch': 1.88}\n",
            "{'loss': 0.6705, 'learning_rate': 7.018745394035786e-05, 'epoch': 1.93}\n",
            "{'loss': 0.283, 'learning_rate': 6.991507817717872e-05, 'epoch': 1.99}\n",
            "{'loss': 0.2149, 'learning_rate': 6.963101757614999e-05, 'epoch': 2.04}\n",
            "{'loss': 0.1883, 'learning_rate': 6.933537158541611e-05, 'epoch': 2.1}\n",
            "{'loss': 0.637, 'learning_rate': 6.902824370910631e-05, 'epoch': 2.15}\n",
            "{'loss': 0.4967, 'learning_rate': 6.870974147109853e-05, 'epoch': 2.21}\n",
            "{'loss': 0.4007, 'learning_rate': 6.837997637737578e-05, 'epoch': 2.27}\n",
            "{'loss': 0.2609, 'learning_rate': 6.803906387698847e-05, 'epoch': 2.32}\n",
            "{'loss': 0.4637, 'learning_rate': 6.768712332163635e-05, 'epoch': 2.38}\n",
            "{'loss': 0.3671, 'learning_rate': 6.732427792388404e-05, 'epoch': 2.43}\n",
            "{'loss': 0.2139, 'learning_rate': 6.695065471402498e-05, 'epoch': 2.49}\n",
            "{'loss': 0.2904, 'learning_rate': 6.656638449560877e-05, 'epoch': 2.54}\n",
            "{'loss': 0.4001, 'learning_rate': 6.617160179964755e-05, 'epoch': 2.6}\n",
            "{'loss': 0.4048, 'learning_rate': 6.576644483751735e-05, 'epoch': 2.65}\n",
            "{'loss': 0.1779, 'learning_rate': 6.535105545257105e-05, 'epoch': 2.71}\n",
            "{'loss': 0.1724, 'learning_rate': 6.492557907047971e-05, 'epoch': 2.76}\n",
            "{'loss': 0.3829, 'learning_rate': 6.449016464831983e-05, 'epoch': 2.82}\n",
            "{'loss': 0.4179, 'learning_rate': 6.404496462242421e-05, 'epoch': 2.87}\n",
            "{'loss': 0.3641, 'learning_rate': 6.359013485501487e-05, 'epoch': 2.93}\n",
            "{'loss': 0.1279, 'learning_rate': 6.312583457963636e-05, 'epoch': 2.98}\n",
            "{'loss': 0.1252, 'learning_rate': 6.265222634540905e-05, 'epoch': 3.04}\n",
            "{'loss': 0.2025, 'learning_rate': 6.216947596012142e-05, 'epoch': 3.09}\n",
            "{'loss': 0.1892, 'learning_rate': 6.167775243218169e-05, 'epoch': 3.15}\n",
            "{'loss': 0.2845, 'learning_rate': 6.117722791144883e-05, 'epoch': 3.2}\n",
            "{'loss': 0.1797, 'learning_rate': 6.0668077628963766e-05, 'epoch': 3.26}\n",
            "{'loss': 0.1499, 'learning_rate': 6.0150479835601874e-05, 'epoch': 3.31}\n",
            "{'loss': 0.4224, 'learning_rate': 5.96246157396684e-05, 'epoch': 3.37}\n",
            "{'loss': 0.1254, 'learning_rate': 5.9090669443458206e-05, 'epoch': 3.43}\n",
            "{'loss': 0.1827, 'learning_rate': 5.854882787880262e-05, 'epoch': 3.48}\n",
            "{'loss': 0.1631, 'learning_rate': 5.799928074162553e-05, 'epoch': 3.54}\n",
            "{'loss': 0.1299, 'learning_rate': 5.744222042553185e-05, 'epoch': 3.59}\n",
            "{'loss': 0.1289, 'learning_rate': 5.6877841954451475e-05, 'epoch': 3.65}\n",
            "{'loss': 0.1097, 'learning_rate': 5.6306342914362446e-05, 'epoch': 3.7}\n",
            "{'loss': 0.28, 'learning_rate': 5.5727923384117124e-05, 'epoch': 3.76}\n",
            "{'loss': 0.6097, 'learning_rate': 5.514278586539558e-05, 'epoch': 3.81}\n",
            "{'loss': 0.2254, 'learning_rate': 5.45511352118109e-05, 'epoch': 3.87}\n",
            "{'loss': 0.2432, 'learning_rate': 5.395317855719086e-05, 'epoch': 3.92}\n",
            "{'loss': 0.2865, 'learning_rate': 5.334912524306155e-05, 'epoch': 3.98}\n",
            "{'loss': 0.0695, 'learning_rate': 5.273918674535797e-05, 'epoch': 4.03}\n",
            "{'loss': 0.1881, 'learning_rate': 5.2123576600387407e-05, 'epoch': 4.09}\n",
            "{'loss': 0.0493, 'learning_rate': 5.150251033007142e-05, 'epoch': 4.14}\n",
            "{'loss': 0.2759, 'learning_rate': 5.087620536649279e-05, 'epoch': 4.2}\n",
            "{'loss': 0.2689, 'learning_rate': 5.024488097577369e-05, 'epoch': 4.25}\n",
            "{'loss': 0.1891, 'learning_rate': 4.960875818131173e-05, 'epoch': 4.31}\n",
            "{'loss': 0.0657, 'learning_rate': 4.896805968640072e-05, 'epoch': 4.36}\n",
            "{'loss': 0.1178, 'learning_rate': 4.832300979626358e-05, 'epoch': 4.42}\n",
            "{'loss': 0.0909, 'learning_rate': 4.767383433952412e-05, 'epoch': 4.48}\n",
            "{'loss': 0.197, 'learning_rate': 4.7020760589145614e-05, 'epoch': 4.53}\n",
            "{'loss': 0.1336, 'learning_rate': 4.6364017182863766e-05, 'epoch': 4.59}\n",
            "{'loss': 0.3709, 'learning_rate': 4.5703834043141774e-05, 'epoch': 4.64}\n",
            "{'loss': 0.2377, 'learning_rate': 4.5040442296675714e-05, 'epoch': 4.7}\n",
            "{'loss': 0.1394, 'learning_rate': 4.4374074193478244e-05, 'epoch': 4.75}\n",
            "{'loss': 0.183, 'learning_rate': 4.370496302556906e-05, 'epoch': 4.81}\n",
            "{'loss': 0.178, 'learning_rate': 4.303334304530065e-05, 'epoch': 4.86}\n",
            "{'loss': 0.1281, 'learning_rate': 4.235944938334768e-05, 'epoch': 4.92}\n",
            "{'loss': 0.2283, 'learning_rate': 4.168351796638898e-05, 'epoch': 4.97}\n",
            "{'loss': 0.1136, 'learning_rate': 4.100578543451088e-05, 'epoch': 5.03}\n",
            "{'loss': 0.2244, 'learning_rate': 4.0326489058360676e-05, 'epoch': 5.08}\n",
            "{'loss': 0.2672, 'learning_rate': 3.9645866656079466e-05, 'epoch': 5.14}\n",
            "{'loss': 0.0635, 'learning_rate': 3.896415651004322e-05, 'epoch': 5.19}\n",
            "{'loss': 0.0809, 'learning_rate': 3.828159728344134e-05, 'epoch': 5.25}\n",
            "{'loss': 0.1358, 'learning_rate': 3.7598427936721955e-05, 'epoch': 5.3}\n",
            "{'loss': 0.2089, 'learning_rate': 3.6914887643933073e-05, 'epoch': 5.36}\n",
            "{'loss': 0.0464, 'learning_rate': 3.6231215708989014e-05, 'epoch': 5.41}\n",
            "{'loss': 0.2046, 'learning_rate': 3.55476514818913e-05, 'epoch': 5.47}\n",
            "{'loss': 0.1899, 'learning_rate': 3.4864434274933556e-05, 'epoch': 5.52}\n",
            "{'loss': 0.2952, 'learning_rate': 3.41818032789194e-05, 'epoch': 5.58}\n",
            "{'loss': 0.0958, 'learning_rate': 3.349999747942303e-05, 'epoch': 5.64}\n",
            "{'loss': 0.1877, 'learning_rate': 3.2819255573121685e-05, 'epoch': 5.69}\n",
            "{'loss': 0.0892, 'learning_rate': 3.2139815884229045e-05, 'epoch': 5.75}\n",
            "{'loss': 0.1514, 'learning_rate': 3.1461916281059235e-05, 'epoch': 5.8}\n",
            "{'loss': 0.0084, 'learning_rate': 3.0785794092750375e-05, 'epoch': 5.86}\n",
            "{'loss': 0.0367, 'learning_rate': 3.0111686026176842e-05, 'epoch': 5.91}\n",
            "{'loss': 0.2668, 'learning_rate': 2.9439828083079406e-05, 'epoch': 5.97}\n",
            "{'loss': 0.0647, 'learning_rate': 2.8770455477442317e-05, 'epoch': 6.02}\n",
            "{'loss': 0.0066, 'learning_rate': 2.810380255314603e-05, 'epoch': 6.08}\n",
            "{'loss': 0.0054, 'learning_rate': 2.7440102701924617e-05, 'epoch': 6.13}\n",
            "{'loss': 0.0049, 'learning_rate': 2.677958828165666e-05, 'epoch': 6.19}\n",
            "{'loss': 0.0033, 'learning_rate': 2.6122490535017802e-05, 'epoch': 6.24}\n",
            "{'loss': 0.2325, 'learning_rate': 2.5469039508523975e-05, 'epoch': 6.3}\n",
            "{'loss': 0.1027, 'learning_rate': 2.481946397199329e-05, 'epoch': 6.35}\n",
            "{'loss': 0.2163, 'learning_rate': 2.4173991338454892e-05, 'epoch': 6.41}\n",
            "{'loss': 0.1274, 'learning_rate': 2.353284758453287e-05, 'epoch': 6.46}\n",
            "{'loss': 0.0644, 'learning_rate': 2.2896257171332978e-05, 'epoch': 6.52}\n",
            "{'loss': 0.0959, 'learning_rate': 2.226444296585997e-05, 'epoch': 6.57}\n",
            "{'loss': 0.1699, 'learning_rate': 2.1637626162993058e-05, 'epoch': 6.63}\n",
            "{'loss': 0.1363, 'learning_rate': 2.101602620804667e-05, 'epoch': 6.69}\n",
            "{'loss': 0.1228, 'learning_rate': 2.0399860719943807e-05, 'epoch': 6.74}\n",
            "{'loss': 0.0079, 'learning_rate': 1.978934541502885e-05, 'epoch': 6.8}\n",
            "{'loss': 0.212, 'learning_rate': 1.918469403154622e-05, 'epoch': 6.85}\n",
            "{'loss': 0.1267, 'learning_rate': 1.8586118254811916e-05, 'epoch': 6.91}\n",
            "{'loss': 0.0066, 'learning_rate': 1.7993827643103485e-05, 'epoch': 6.96}\n",
            "{'loss': 0.2087, 'learning_rate': 1.7408029554294748e-05, 'epoch': 7.02}\n",
            "{'loss': 0.1318, 'learning_rate': 1.6828929073260903e-05, 'epoch': 7.07}\n",
            "{'loss': 0.0056, 'learning_rate': 1.6256728940079415e-05, 'epoch': 7.13}\n",
            "{'loss': 0.1703, 'learning_rate': 1.5691629479051677e-05, 'epoch': 7.18}\n",
            "{'loss': 0.0056, 'learning_rate': 1.5133828528570576e-05, 'epoch': 7.24}\n",
            "{'loss': 0.0055, 'learning_rate': 1.4583521371858283e-05, 'epoch': 7.29}\n",
            "{'loss': 0.0742, 'learning_rate': 1.4040900668598589e-05, 'epoch': 7.35}\n",
            "{'loss': 0.0694, 'learning_rate': 1.3506156387487769e-05, 'epoch': 7.4}\n",
            "{'loss': 0.0052, 'learning_rate': 1.297947573972755e-05, 'epoch': 7.46}\n",
            "{'loss': 0.0683, 'learning_rate': 1.2461043113483356e-05, 'epoch': 7.51}\n",
            "{'loss': 0.0034, 'learning_rate': 1.1951040009331077e-05, 'epoch': 7.57}\n",
            "{'loss': 0.199, 'learning_rate': 1.144964497671456e-05, 'epoch': 7.62}\n",
            "{'loss': 0.1255, 'learning_rate': 1.0957033551436428e-05, 'epoch': 7.68}\n",
            "{'loss': 0.1829, 'learning_rate': 1.0473378194203898e-05, 'epoch': 7.73}\n",
            "{'loss': 0.1034, 'learning_rate': 9.998848230251168e-06, 'epoch': 7.79}\n",
            "{'loss': 0.2121, 'learning_rate': 9.533609790059532e-06, 'epoch': 7.85}\n",
            "{'loss': 0.1467, 'learning_rate': 9.077825751195995e-06, 'epoch': 7.9}\n",
            "{'loss': 0.1544, 'learning_rate': 8.631655681290625e-06, 'epoch': 7.96}\n",
            "{'loss': 0.1145, 'learning_rate': 8.195255782172768e-06, 'epoch': 8.01}\n",
            "{'loss': 0.0206, 'learning_rate': 7.768778835185644e-06, 'epoch': 8.07}\n",
            "{'loss': 0.2769, 'learning_rate': 7.352374147698334e-06, 'epoch': 8.12}\n",
            "{'loss': 0.0508, 'learning_rate': 6.946187500834038e-06, 'epoch': 8.18}\n",
            "{'loss': 0.0138, 'learning_rate': 6.55036109843294e-06, 'epoch': 8.23}\n",
            "{'loss': 0.0164, 'learning_rate': 6.1650335172672785e-06, 'epoch': 8.29}\n",
            "{'loss': 0.0854, 'learning_rate': 5.790339658526401e-06, 'epoch': 8.34}\n",
            "{'loss': 0.0748, 'learning_rate': 5.426410700588556e-06, 'epoch': 8.4}\n",
            "{'loss': 0.1405, 'learning_rate': 5.073374053095972e-06, 'epoch': 8.45}\n",
            "{'loss': 0.1243, 'learning_rate': 4.731353312349477e-06, 'epoch': 8.51}\n",
            "{'loss': 0.0044, 'learning_rate': 4.4004682180379904e-06, 'epoch': 8.56}\n",
            "{'loss': 0.0112, 'learning_rate': 4.080834611318334e-06, 'epoch': 8.62}\n",
            "{'loss': 0.1467, 'learning_rate': 3.772564394259858e-06, 'epoch': 8.67}\n",
            "{'loss': 0.0608, 'learning_rate': 3.4757654906680534e-06, 'epoch': 8.73}\n",
            "{'loss': 0.0093, 'learning_rate': 3.2185404137835382e-06, 'epoch': 8.78}\n",
            "{'loss': 0.0712, 'learning_rate': 2.9438199230515407e-06, 'epoch': 8.84}\n",
            "{'loss': 0.0121, 'learning_rate': 2.6808608849309176e-06, 'epoch': 8.9}\n",
            "{'loss': 0.0743, 'learning_rate': 2.4297553600182195e-06, 'epoch': 8.95}\n",
            "{'loss': 0.0035, 'learning_rate': 2.1905912590564713e-06, 'epoch': 9.01}\n",
            "{'loss': 0.0785, 'learning_rate': 1.963452312158033e-06, 'epoch': 9.06}\n",
            "{'loss': 0.003, 'learning_rate': 1.748418039491151e-06, 'epoch': 9.12}\n",
            "{'loss': 0.0531, 'learning_rate': 1.5455637234403471e-06, 'epoch': 9.17}\n",
            "{'loss': 0.0029, 'learning_rate': 1.354960382250455e-06, 'epoch': 9.23}\n",
            "{'loss': 0.084, 'learning_rate': 1.1766747451634882e-06, 'epoch': 9.28}\n",
            "{'loss': 0.1559, 'learning_rate': 1.0107692290571012e-06, 'epoch': 9.34}\n",
            "{'loss': 0.1481, 'learning_rate': 8.573019165927306e-07, 'epoch': 9.39}\n",
            "{'loss': 0.0535, 'learning_rate': 7.163265358811895e-07, 'epoch': 9.45}\n",
            "{'loss': 0.1177, 'learning_rate': 5.878924416727099e-07, 'epoch': 9.5}\n",
            "{'loss': 0.0702, 'learning_rate': 4.720445980781109e-07, 'epoch': 9.56}\n",
            "{'loss': 0.003, 'learning_rate': 3.68823562827093e-07, 'epoch': 9.61}\n",
            "{'loss': 0.0723, 'learning_rate': 2.782654730691999e-07, 'epoch': 9.67}\n",
            "{'loss': 0.0031, 'learning_rate': 2.0040203272236384e-07, 'epoch': 9.72}\n",
            "{'loss': 0.0557, 'learning_rate': 1.352605013735536e-07, 'epoch': 9.78}\n",
            "{'loss': 0.0049, 'learning_rate': 8.286368473533097e-08, 'epoch': 9.83}\n",
            "{'loss': 0.0754, 'learning_rate': 4.322992666166176e-08, 'epoch': 9.89}\n",
            "{'loss': 0.0029, 'learning_rate': 1.6373102725869893e-08, 'epoch': 9.94}\n",
            "{'loss': 0.0037, 'learning_rate': 2.3026153628318206e-09, 'epoch': 10.0}\n",
            "{'train_runtime': 180.0294, 'train_samples_per_second': 80.265, 'train_steps_per_second': 10.054, 'train_loss': 0.2240611494246109, 'epoch': 10.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 52/52 [00:01<00:00, 41.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 22:23:24,705] Trial 23 finished with value: 0.9269521410579344 and parameters: {'learning_rate': 7.307773813413501e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.23330034465291838, 'num_train_epochs': 10, 'warmup_steps': 131, 'freeze_layers': 9, 'dropout': 0.1295662057386814, 'lr_scheduler_type': 'cosine'}. Best is trial 19 with value: 0.9289340101522843.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: constant_with_warmup\n",
            " Warmup steps (True): 133\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4324318cc7414fe6a5813ab89f469292",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1810 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7609, 'learning_rate': 2.279456365995015e-06, 'epoch': 0.06}\n",
            "{'loss': 0.6887, 'learning_rate': 6.078550309320041e-06, 'epoch': 0.11}\n",
            "{'loss': 0.7231, 'learning_rate': 9.497734858312563e-06, 'epoch': 0.17}\n",
            "{'loss': 0.7293, 'learning_rate': 1.3296828801637588e-05, 'epoch': 0.22}\n",
            "{'loss': 0.6817, 'learning_rate': 1.7095922744962614e-05, 'epoch': 0.28}\n",
            "{'loss': 0.6735, 'learning_rate': 2.089501668828764e-05, 'epoch': 0.33}\n",
            "{'loss': 0.6656, 'learning_rate': 2.4694110631612664e-05, 'epoch': 0.39}\n",
            "{'loss': 0.695, 'learning_rate': 2.8493204574937692e-05, 'epoch': 0.44}\n",
            "{'loss': 0.6511, 'learning_rate': 3.2292298518262716e-05, 'epoch': 0.5}\n",
            "{'loss': 0.5431, 'learning_rate': 3.609139246158774e-05, 'epoch': 0.55}\n",
            "{'loss': 0.594, 'learning_rate': 3.989048640491277e-05, 'epoch': 0.61}\n",
            "{'loss': 0.4509, 'learning_rate': 4.36895803482378e-05, 'epoch': 0.66}\n",
            "{'loss': 0.3849, 'learning_rate': 4.748867429156282e-05, 'epoch': 0.72}\n",
            "{'loss': 0.615, 'learning_rate': 5.052794944622284e-05, 'epoch': 0.77}\n",
            "{'loss': 0.5725, 'learning_rate': 5.052794944622284e-05, 'epoch': 0.83}\n",
            "{'loss': 0.3948, 'learning_rate': 5.052794944622284e-05, 'epoch': 0.88}\n",
            "{'loss': 0.4472, 'learning_rate': 5.052794944622284e-05, 'epoch': 0.94}\n",
            "{'loss': 0.9887, 'learning_rate': 5.052794944622284e-05, 'epoch': 0.99}\n",
            "{'loss': 0.4549, 'learning_rate': 5.052794944622284e-05, 'epoch': 1.05}\n",
            "{'loss': 0.4129, 'learning_rate': 5.052794944622284e-05, 'epoch': 1.1}\n",
            "{'loss': 0.949, 'learning_rate': 5.052794944622284e-05, 'epoch': 1.16}\n",
            "{'loss': 0.4475, 'learning_rate': 5.052794944622284e-05, 'epoch': 1.22}\n",
            "{'loss': 0.3889, 'learning_rate': 5.052794944622284e-05, 'epoch': 1.27}\n",
            "{'loss': 0.5323, 'learning_rate': 5.052794944622284e-05, 'epoch': 1.33}\n",
            "{'loss': 0.5218, 'learning_rate': 5.052794944622284e-05, 'epoch': 1.38}\n",
            "{'loss': 0.3446, 'learning_rate': 5.052794944622284e-05, 'epoch': 1.44}\n",
            "{'loss': 0.331, 'learning_rate': 5.052794944622284e-05, 'epoch': 1.49}\n",
            "{'loss': 0.6067, 'learning_rate': 5.052794944622284e-05, 'epoch': 1.55}\n",
            "{'loss': 0.4098, 'learning_rate': 5.052794944622284e-05, 'epoch': 1.6}\n",
            "{'loss': 0.3653, 'learning_rate': 5.052794944622284e-05, 'epoch': 1.66}\n",
            "{'loss': 0.3438, 'learning_rate': 5.052794944622284e-05, 'epoch': 1.71}\n",
            "{'loss': 0.3506, 'learning_rate': 5.052794944622284e-05, 'epoch': 1.77}\n",
            "{'loss': 0.43, 'learning_rate': 5.052794944622284e-05, 'epoch': 1.82}\n",
            "{'loss': 0.3848, 'learning_rate': 5.052794944622284e-05, 'epoch': 1.88}\n",
            "{'loss': 0.3574, 'learning_rate': 5.052794944622284e-05, 'epoch': 1.93}\n",
            "{'loss': 0.4611, 'learning_rate': 5.052794944622284e-05, 'epoch': 1.99}\n",
            "{'loss': 0.2024, 'learning_rate': 5.052794944622284e-05, 'epoch': 2.04}\n",
            "{'loss': 0.1609, 'learning_rate': 5.052794944622284e-05, 'epoch': 2.1}\n",
            "{'loss': 0.3785, 'learning_rate': 5.052794944622284e-05, 'epoch': 2.15}\n",
            "{'loss': 0.1969, 'learning_rate': 5.052794944622284e-05, 'epoch': 2.21}\n",
            "{'loss': 0.0759, 'learning_rate': 5.052794944622284e-05, 'epoch': 2.27}\n",
            "{'loss': 0.7679, 'learning_rate': 5.052794944622284e-05, 'epoch': 2.32}\n",
            "{'loss': 0.4801, 'learning_rate': 5.052794944622284e-05, 'epoch': 2.38}\n",
            "{'loss': 0.3013, 'learning_rate': 5.052794944622284e-05, 'epoch': 2.43}\n",
            "{'loss': 0.209, 'learning_rate': 5.052794944622284e-05, 'epoch': 2.49}\n",
            "{'loss': 0.4686, 'learning_rate': 5.052794944622284e-05, 'epoch': 2.54}\n",
            "{'loss': 0.4213, 'learning_rate': 5.052794944622284e-05, 'epoch': 2.6}\n",
            "{'loss': 0.4745, 'learning_rate': 5.052794944622284e-05, 'epoch': 2.65}\n",
            "{'loss': 0.2566, 'learning_rate': 5.052794944622284e-05, 'epoch': 2.71}\n",
            "{'loss': 0.2914, 'learning_rate': 5.052794944622284e-05, 'epoch': 2.76}\n",
            "{'loss': 0.1702, 'learning_rate': 5.052794944622284e-05, 'epoch': 2.82}\n",
            "{'loss': 0.1975, 'learning_rate': 5.052794944622284e-05, 'epoch': 2.87}\n",
            "{'loss': 0.1582, 'learning_rate': 5.052794944622284e-05, 'epoch': 2.93}\n",
            "{'loss': 0.1851, 'learning_rate': 5.052794944622284e-05, 'epoch': 2.98}\n",
            "{'loss': 0.1838, 'learning_rate': 5.052794944622284e-05, 'epoch': 3.04}\n",
            "{'loss': 0.0902, 'learning_rate': 5.052794944622284e-05, 'epoch': 3.09}\n",
            "{'loss': 0.2079, 'learning_rate': 5.052794944622284e-05, 'epoch': 3.15}\n",
            "{'loss': 0.2231, 'learning_rate': 5.052794944622284e-05, 'epoch': 3.2}\n",
            "{'loss': 0.1321, 'learning_rate': 5.052794944622284e-05, 'epoch': 3.26}\n",
            "{'loss': 0.0427, 'learning_rate': 5.052794944622284e-05, 'epoch': 3.31}\n",
            "{'loss': 0.3401, 'learning_rate': 5.052794944622284e-05, 'epoch': 3.37}\n",
            "{'loss': 0.1836, 'learning_rate': 5.052794944622284e-05, 'epoch': 3.43}\n",
            "{'loss': 0.3061, 'learning_rate': 5.052794944622284e-05, 'epoch': 3.48}\n",
            "{'loss': 0.1723, 'learning_rate': 5.052794944622284e-05, 'epoch': 3.54}\n",
            "{'loss': 0.2644, 'learning_rate': 5.052794944622284e-05, 'epoch': 3.59}\n",
            "{'loss': 0.3671, 'learning_rate': 5.052794944622284e-05, 'epoch': 3.65}\n",
            "{'loss': 0.3384, 'learning_rate': 5.052794944622284e-05, 'epoch': 3.7}\n",
            "{'loss': 0.0362, 'learning_rate': 5.052794944622284e-05, 'epoch': 3.76}\n",
            "{'loss': 0.3941, 'learning_rate': 5.052794944622284e-05, 'epoch': 3.81}\n",
            "{'loss': 0.2927, 'learning_rate': 5.052794944622284e-05, 'epoch': 3.87}\n",
            "{'loss': 0.232, 'learning_rate': 5.052794944622284e-05, 'epoch': 3.92}\n",
            "{'loss': 0.3976, 'learning_rate': 5.052794944622284e-05, 'epoch': 3.98}\n",
            "{'loss': 0.1742, 'learning_rate': 5.052794944622284e-05, 'epoch': 4.03}\n",
            "{'loss': 0.0797, 'learning_rate': 5.052794944622284e-05, 'epoch': 4.09}\n",
            "{'loss': 0.0679, 'learning_rate': 5.052794944622284e-05, 'epoch': 4.14}\n",
            "{'loss': 0.4069, 'learning_rate': 5.052794944622284e-05, 'epoch': 4.2}\n",
            "{'loss': 0.114, 'learning_rate': 5.052794944622284e-05, 'epoch': 4.25}\n",
            "{'loss': 0.1261, 'learning_rate': 5.052794944622284e-05, 'epoch': 4.31}\n",
            "{'loss': 0.0648, 'learning_rate': 5.052794944622284e-05, 'epoch': 4.36}\n",
            "{'loss': 0.0667, 'learning_rate': 5.052794944622284e-05, 'epoch': 4.42}\n",
            "{'loss': 0.2092, 'learning_rate': 5.052794944622284e-05, 'epoch': 4.48}\n",
            "{'loss': 0.3595, 'learning_rate': 5.052794944622284e-05, 'epoch': 4.53}\n",
            "{'loss': 0.4292, 'learning_rate': 5.052794944622284e-05, 'epoch': 4.59}\n",
            "{'loss': 0.6252, 'learning_rate': 5.052794944622284e-05, 'epoch': 4.64}\n",
            "{'loss': 0.5992, 'learning_rate': 5.052794944622284e-05, 'epoch': 4.7}\n",
            "{'loss': 0.2458, 'learning_rate': 5.052794944622284e-05, 'epoch': 4.75}\n",
            "{'loss': 0.2651, 'learning_rate': 5.052794944622284e-05, 'epoch': 4.81}\n",
            "{'loss': 0.1446, 'learning_rate': 5.052794944622284e-05, 'epoch': 4.86}\n",
            "{'loss': 0.3329, 'learning_rate': 5.052794944622284e-05, 'epoch': 4.92}\n",
            "{'loss': 0.2167, 'learning_rate': 5.052794944622284e-05, 'epoch': 4.97}\n",
            "{'loss': 0.174, 'learning_rate': 5.052794944622284e-05, 'epoch': 5.03}\n",
            "{'loss': 0.1149, 'learning_rate': 5.052794944622284e-05, 'epoch': 5.08}\n",
            "{'loss': 0.0653, 'learning_rate': 5.052794944622284e-05, 'epoch': 5.14}\n",
            "{'loss': 0.0713, 'learning_rate': 5.052794944622284e-05, 'epoch': 5.19}\n",
            "{'loss': 0.1813, 'learning_rate': 5.052794944622284e-05, 'epoch': 5.25}\n",
            "{'loss': 0.1182, 'learning_rate': 5.052794944622284e-05, 'epoch': 5.3}\n",
            "{'loss': 0.1375, 'learning_rate': 5.052794944622284e-05, 'epoch': 5.36}\n",
            "{'loss': 0.147, 'learning_rate': 5.052794944622284e-05, 'epoch': 5.41}\n",
            "{'loss': 0.1986, 'learning_rate': 5.052794944622284e-05, 'epoch': 5.47}\n",
            "{'loss': 0.3852, 'learning_rate': 5.052794944622284e-05, 'epoch': 5.52}\n",
            "{'loss': 0.1231, 'learning_rate': 5.052794944622284e-05, 'epoch': 5.58}\n",
            "{'loss': 0.0739, 'learning_rate': 5.052794944622284e-05, 'epoch': 5.64}\n",
            "{'loss': 0.0672, 'learning_rate': 5.052794944622284e-05, 'epoch': 5.69}\n",
            "{'loss': 0.2791, 'learning_rate': 5.052794944622284e-05, 'epoch': 5.75}\n",
            "{'loss': 0.4056, 'learning_rate': 5.052794944622284e-05, 'epoch': 5.8}\n",
            "{'loss': 0.1218, 'learning_rate': 5.052794944622284e-05, 'epoch': 5.86}\n",
            "{'loss': 0.1241, 'learning_rate': 5.052794944622284e-05, 'epoch': 5.91}\n",
            "{'loss': 0.2255, 'learning_rate': 5.052794944622284e-05, 'epoch': 5.97}\n",
            "{'loss': 0.1376, 'learning_rate': 5.052794944622284e-05, 'epoch': 6.02}\n",
            "{'loss': 0.0085, 'learning_rate': 5.052794944622284e-05, 'epoch': 6.08}\n",
            "{'loss': 0.1716, 'learning_rate': 5.052794944622284e-05, 'epoch': 6.13}\n",
            "{'loss': 0.0065, 'learning_rate': 5.052794944622284e-05, 'epoch': 6.19}\n",
            "{'loss': 0.1399, 'learning_rate': 5.052794944622284e-05, 'epoch': 6.24}\n",
            "{'loss': 0.261, 'learning_rate': 5.052794944622284e-05, 'epoch': 6.3}\n",
            "{'loss': 0.1267, 'learning_rate': 5.052794944622284e-05, 'epoch': 6.35}\n",
            "{'loss': 0.1815, 'learning_rate': 5.052794944622284e-05, 'epoch': 6.41}\n",
            "{'loss': 0.1248, 'learning_rate': 5.052794944622284e-05, 'epoch': 6.46}\n",
            "{'loss': 0.1765, 'learning_rate': 5.052794944622284e-05, 'epoch': 6.52}\n",
            "{'loss': 0.1302, 'learning_rate': 5.052794944622284e-05, 'epoch': 6.57}\n",
            "{'loss': 0.104, 'learning_rate': 5.052794944622284e-05, 'epoch': 6.63}\n",
            "{'loss': 0.0799, 'learning_rate': 5.052794944622284e-05, 'epoch': 6.69}\n",
            "{'loss': 0.0757, 'learning_rate': 5.052794944622284e-05, 'epoch': 6.74}\n",
            "{'loss': 0.0049, 'learning_rate': 5.052794944622284e-05, 'epoch': 6.8}\n",
            "{'loss': 0.3468, 'learning_rate': 5.052794944622284e-05, 'epoch': 6.85}\n",
            "{'loss': 0.3051, 'learning_rate': 5.052794944622284e-05, 'epoch': 6.91}\n",
            "{'loss': 0.0693, 'learning_rate': 5.052794944622284e-05, 'epoch': 6.96}\n",
            "{'loss': 0.0726, 'learning_rate': 5.052794944622284e-05, 'epoch': 7.02}\n",
            "{'loss': 0.081, 'learning_rate': 5.052794944622284e-05, 'epoch': 7.07}\n",
            "{'loss': 0.0141, 'learning_rate': 5.052794944622284e-05, 'epoch': 7.13}\n",
            "{'loss': 0.1929, 'learning_rate': 5.052794944622284e-05, 'epoch': 7.18}\n",
            "{'loss': 0.1564, 'learning_rate': 5.052794944622284e-05, 'epoch': 7.24}\n",
            "{'loss': 0.19, 'learning_rate': 5.052794944622284e-05, 'epoch': 7.29}\n",
            "{'loss': 0.4451, 'learning_rate': 5.052794944622284e-05, 'epoch': 7.35}\n",
            "{'loss': 0.1442, 'learning_rate': 5.052794944622284e-05, 'epoch': 7.4}\n",
            "{'loss': 0.1842, 'learning_rate': 5.052794944622284e-05, 'epoch': 7.46}\n",
            "{'loss': 0.1163, 'learning_rate': 5.052794944622284e-05, 'epoch': 7.51}\n",
            "{'loss': 0.1197, 'learning_rate': 5.052794944622284e-05, 'epoch': 7.57}\n",
            "{'loss': 0.1684, 'learning_rate': 5.052794944622284e-05, 'epoch': 7.62}\n",
            "{'loss': 0.0924, 'learning_rate': 5.052794944622284e-05, 'epoch': 7.68}\n",
            "{'loss': 0.1976, 'learning_rate': 5.052794944622284e-05, 'epoch': 7.73}\n",
            "{'loss': 0.0893, 'learning_rate': 5.052794944622284e-05, 'epoch': 7.79}\n",
            "{'loss': 0.0068, 'learning_rate': 5.052794944622284e-05, 'epoch': 7.85}\n",
            "{'loss': 0.0335, 'learning_rate': 5.052794944622284e-05, 'epoch': 7.9}\n",
            "{'loss': 0.0714, 'learning_rate': 5.052794944622284e-05, 'epoch': 7.96}\n",
            "{'loss': 0.1256, 'learning_rate': 5.052794944622284e-05, 'epoch': 8.01}\n",
            "{'loss': 0.0881, 'learning_rate': 5.052794944622284e-05, 'epoch': 8.07}\n",
            "{'loss': 0.0022, 'learning_rate': 5.052794944622284e-05, 'epoch': 8.12}\n",
            "{'loss': 0.0175, 'learning_rate': 5.052794944622284e-05, 'epoch': 8.18}\n",
            "{'loss': 0.2025, 'learning_rate': 5.052794944622284e-05, 'epoch': 8.23}\n",
            "{'loss': 0.083, 'learning_rate': 5.052794944622284e-05, 'epoch': 8.29}\n",
            "{'loss': 0.0744, 'learning_rate': 5.052794944622284e-05, 'epoch': 8.34}\n",
            "{'loss': 0.2013, 'learning_rate': 5.052794944622284e-05, 'epoch': 8.4}\n",
            "{'loss': 0.1263, 'learning_rate': 5.052794944622284e-05, 'epoch': 8.45}\n",
            "{'loss': 0.1552, 'learning_rate': 5.052794944622284e-05, 'epoch': 8.51}\n",
            "{'loss': 0.0046, 'learning_rate': 5.052794944622284e-05, 'epoch': 8.56}\n",
            "{'loss': 0.1557, 'learning_rate': 5.052794944622284e-05, 'epoch': 8.62}\n",
            "{'loss': 0.1463, 'learning_rate': 5.052794944622284e-05, 'epoch': 8.67}\n",
            "{'loss': 0.0726, 'learning_rate': 5.052794944622284e-05, 'epoch': 8.73}\n",
            "{'loss': 0.0716, 'learning_rate': 5.052794944622284e-05, 'epoch': 8.78}\n",
            "{'loss': 0.0835, 'learning_rate': 5.052794944622284e-05, 'epoch': 8.84}\n",
            "{'loss': 0.3176, 'learning_rate': 5.052794944622284e-05, 'epoch': 8.9}\n",
            "{'loss': 0.1868, 'learning_rate': 5.052794944622284e-05, 'epoch': 8.95}\n",
            "{'loss': 0.0052, 'learning_rate': 5.052794944622284e-05, 'epoch': 9.01}\n",
            "{'loss': 0.0765, 'learning_rate': 5.052794944622284e-05, 'epoch': 9.06}\n",
            "{'loss': 0.0456, 'learning_rate': 5.052794944622284e-05, 'epoch': 9.12}\n",
            "{'loss': 0.1727, 'learning_rate': 5.052794944622284e-05, 'epoch': 9.17}\n",
            "{'loss': 0.0393, 'learning_rate': 5.052794944622284e-05, 'epoch': 9.23}\n",
            "{'loss': 0.1616, 'learning_rate': 5.052794944622284e-05, 'epoch': 9.28}\n",
            "{'loss': 0.3337, 'learning_rate': 5.052794944622284e-05, 'epoch': 9.34}\n",
            "{'loss': 0.2038, 'learning_rate': 5.052794944622284e-05, 'epoch': 9.39}\n",
            "{'loss': 0.0775, 'learning_rate': 5.052794944622284e-05, 'epoch': 9.45}\n",
            "{'loss': 0.1404, 'learning_rate': 5.052794944622284e-05, 'epoch': 9.5}\n",
            "{'loss': 0.1941, 'learning_rate': 5.052794944622284e-05, 'epoch': 9.56}\n",
            "{'loss': 0.2733, 'learning_rate': 5.052794944622284e-05, 'epoch': 9.61}\n",
            "{'loss': 0.3606, 'learning_rate': 5.052794944622284e-05, 'epoch': 9.67}\n",
            "{'loss': 0.424, 'learning_rate': 5.052794944622284e-05, 'epoch': 9.72}\n",
            "{'loss': 0.1066, 'learning_rate': 5.052794944622284e-05, 'epoch': 9.78}\n",
            "{'loss': 0.1746, 'learning_rate': 5.052794944622284e-05, 'epoch': 9.83}\n",
            "{'loss': 0.0684, 'learning_rate': 5.052794944622284e-05, 'epoch': 9.89}\n",
            "{'loss': 0.0049, 'learning_rate': 5.052794944622284e-05, 'epoch': 9.94}\n",
            "{'loss': 0.0751, 'learning_rate': 5.052794944622284e-05, 'epoch': 10.0}\n",
            "{'train_runtime': 182.4586, 'train_samples_per_second': 79.196, 'train_steps_per_second': 9.92, 'train_loss': 0.25620954672893437, 'epoch': 10.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 52/52 [00:01<00:00, 35.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 22:26:31,134] Trial 24 finished with value: 0.8861386138613861 and parameters: {'learning_rate': 5.052794944622284e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.2715289812035702, 'num_train_epochs': 10, 'warmup_steps': 133, 'freeze_layers': 9, 'dropout': 0.13399567924466288, 'lr_scheduler_type': 'constant_with_warmup'}. Best is trial 19 with value: 0.9289340101522843.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: cosine\n",
            " Warmup steps (True): 86\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ddd45cc01185485c9d1a90b070d3fe33",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1810 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7595, 'learning_rate': 4.540797630594951e-06, 'epoch': 0.06}\n",
            "{'loss': 0.7206, 'learning_rate': 1.2108793681586536e-05, 'epoch': 0.11}\n",
            "{'loss': 0.7326, 'learning_rate': 1.967678973257812e-05, 'epoch': 0.17}\n",
            "{'loss': 0.7508, 'learning_rate': 2.7244785783569708e-05, 'epoch': 0.22}\n",
            "{'loss': 0.6459, 'learning_rate': 3.481278183456129e-05, 'epoch': 0.28}\n",
            "{'loss': 0.676, 'learning_rate': 4.238077788555288e-05, 'epoch': 0.33}\n",
            "{'loss': 0.6466, 'learning_rate': 4.994877393654446e-05, 'epoch': 0.39}\n",
            "{'loss': 0.6581, 'learning_rate': 5.751676998753605e-05, 'epoch': 0.44}\n",
            "{'loss': 0.6157, 'learning_rate': 6.508476603852763e-05, 'epoch': 0.5}\n",
            "{'loss': 0.4776, 'learning_rate': 6.507936306846476e-05, 'epoch': 0.55}\n",
            "{'loss': 0.5972, 'learning_rate': 6.50631559523725e-05, 'epoch': 0.61}\n",
            "{'loss': 0.4241, 'learning_rate': 6.50361500719442e-05, 'epoch': 0.66}\n",
            "{'loss': 0.3403, 'learning_rate': 6.499835439468317e-05, 'epoch': 0.72}\n",
            "{'loss': 0.5006, 'learning_rate': 6.494978147092491e-05, 'epoch': 0.77}\n",
            "{'loss': 0.577, 'learning_rate': 6.489044742966973e-05, 'epoch': 0.83}\n",
            "{'loss': 0.3503, 'learning_rate': 6.482037197322699e-05, 'epoch': 0.88}\n",
            "{'loss': 0.4074, 'learning_rate': 6.473957837067277e-05, 'epoch': 0.94}\n",
            "{'loss': 0.976, 'learning_rate': 6.464809345012326e-05, 'epoch': 0.99}\n",
            "{'loss': 0.798, 'learning_rate': 6.454594758982617e-05, 'epoch': 1.05}\n",
            "{'loss': 0.5276, 'learning_rate': 6.443317470807355e-05, 'epoch': 1.1}\n",
            "{'loss': 0.405, 'learning_rate': 6.430981225193887e-05, 'epoch': 1.16}\n",
            "{'loss': 0.4389, 'learning_rate': 6.417590118484249e-05, 'epoch': 1.22}\n",
            "{'loss': 0.3566, 'learning_rate': 6.40314859729494e-05, 'epoch': 1.27}\n",
            "{'loss': 0.703, 'learning_rate': 6.387661457040398e-05, 'epoch': 1.33}\n",
            "{'loss': 0.3773, 'learning_rate': 6.371133840340639e-05, 'epoch': 1.38}\n",
            "{'loss': 0.3891, 'learning_rate': 6.353571235313614e-05, 'epoch': 1.44}\n",
            "{'loss': 0.4063, 'learning_rate': 6.334979473752844e-05, 'epoch': 1.49}\n",
            "{'loss': 0.5865, 'learning_rate': 6.315364729190921e-05, 'epoch': 1.55}\n",
            "{'loss': 0.4969, 'learning_rate': 6.29473351484955e-05, 'epoch': 1.6}\n",
            "{'loss': 0.4834, 'learning_rate': 6.273092681476775e-05, 'epoch': 1.66}\n",
            "{'loss': 0.4169, 'learning_rate': 6.250449415072145e-05, 'epoch': 1.71}\n",
            "{'loss': 0.3278, 'learning_rate': 6.226811234500548e-05, 'epoch': 1.77}\n",
            "{'loss': 0.5586, 'learning_rate': 6.202185988995513e-05, 'epoch': 1.82}\n",
            "{'loss': 0.6023, 'learning_rate': 6.176581855552818e-05, 'epoch': 1.88}\n",
            "{'loss': 0.566, 'learning_rate': 6.150007336215254e-05, 'epoch': 1.93}\n",
            "{'loss': 0.2352, 'learning_rate': 6.122471255249458e-05, 'epoch': 1.99}\n",
            "{'loss': 0.2755, 'learning_rate': 6.093982756215755e-05, 'epoch': 2.04}\n",
            "{'loss': 0.2617, 'learning_rate': 6.064551298931967e-05, 'epoch': 2.1}\n",
            "{'loss': 0.2594, 'learning_rate': 6.034186656332207e-05, 'epoch': 2.15}\n",
            "{'loss': 0.4378, 'learning_rate': 6.002898911221714e-05, 'epoch': 2.21}\n",
            "{'loss': 0.5595, 'learning_rate': 5.97069845292877e-05, 'epoch': 2.27}\n",
            "{'loss': 0.3138, 'learning_rate': 5.940946501758626e-05, 'epoch': 2.32}\n",
            "{'loss': 0.5761, 'learning_rate': 5.907041593615583e-05, 'epoch': 2.38}\n",
            "{'loss': 0.4303, 'learning_rate': 5.872255802424782e-05, 'epoch': 2.43}\n",
            "{'loss': 0.2562, 'learning_rate': 5.8366006790667024e-05, 'epoch': 2.49}\n",
            "{'loss': 0.3876, 'learning_rate': 5.800088063090032e-05, 'epoch': 2.54}\n",
            "{'loss': 0.5407, 'learning_rate': 5.7627300787802565e-05, 'epoch': 2.6}\n",
            "{'loss': 0.4225, 'learning_rate': 5.7245391311336976e-05, 'epoch': 2.65}\n",
            "{'loss': 0.2633, 'learning_rate': 5.685527901738344e-05, 'epoch': 2.71}\n",
            "{'loss': 0.2123, 'learning_rate': 5.6457093445628336e-05, 'epoch': 2.76}\n",
            "{'loss': 0.1935, 'learning_rate': 5.6050966816549976e-05, 'epoch': 2.82}\n",
            "{'loss': 0.1372, 'learning_rate': 5.563703398751373e-05, 'epoch': 2.87}\n",
            "{'loss': 0.4629, 'learning_rate': 5.5215432407991675e-05, 'epoch': 2.93}\n",
            "{'loss': 0.163, 'learning_rate': 5.4786302073921514e-05, 'epoch': 2.98}\n",
            "{'loss': 0.2724, 'learning_rate': 5.4349785481219826e-05, 'epoch': 3.04}\n",
            "{'loss': 0.3348, 'learning_rate': 5.390602757846526e-05, 'epoch': 3.09}\n",
            "{'loss': 0.2262, 'learning_rate': 5.345517571876729e-05, 'epoch': 3.15}\n",
            "{'loss': 0.4121, 'learning_rate': 5.29973796108365e-05, 'epoch': 3.2}\n",
            "{'loss': 0.2556, 'learning_rate': 5.2532791269272745e-05, 'epoch': 3.26}\n",
            "{'loss': 0.1794, 'learning_rate': 5.2061564964087484e-05, 'epoch': 3.31}\n",
            "{'loss': 0.3619, 'learning_rate': 5.158385716947734e-05, 'epoch': 3.37}\n",
            "{'loss': 0.1194, 'learning_rate': 5.109982651186572e-05, 'epoch': 3.43}\n",
            "{'loss': 0.2952, 'learning_rate': 5.060963371722961e-05, 'epoch': 3.48}\n",
            "{'loss': 0.2296, 'learning_rate': 5.011344155772942e-05, 'epoch': 3.54}\n",
            "{'loss': 0.138, 'learning_rate': 4.961141479765925e-05, 'epoch': 3.59}\n",
            "{'loss': 0.3059, 'learning_rate': 4.9103720138735686e-05, 'epoch': 3.65}\n",
            "{'loss': 0.283, 'learning_rate': 4.859052616474323e-05, 'epoch': 3.7}\n",
            "{'loss': 0.1425, 'learning_rate': 4.807200328555484e-05, 'epoch': 3.76}\n",
            "{'loss': 0.2831, 'learning_rate': 4.754832368054604e-05, 'epoch': 3.81}\n",
            "{'loss': 0.4578, 'learning_rate': 4.701966124142149e-05, 'epoch': 3.87}\n",
            "{'loss': 0.2119, 'learning_rate': 4.648619151447295e-05, 'epoch': 3.92}\n",
            "{'loss': 0.2754, 'learning_rate': 4.5948091642287794e-05, 'epoch': 3.98}\n",
            "{'loss': 0.2123, 'learning_rate': 4.54055403049276e-05, 'epoch': 4.03}\n",
            "{'loss': 0.1717, 'learning_rate': 4.485871766059597e-05, 'epoch': 4.09}\n",
            "{'loss': 0.1014, 'learning_rate': 4.4307805285815774e-05, 'epoch': 4.14}\n",
            "{'loss': 0.2107, 'learning_rate': 4.375298611513526e-05, 'epoch': 4.2}\n",
            "{'loss': 0.0609, 'learning_rate': 4.3194444380383274e-05, 'epoch': 4.25}\n",
            "{'loss': 0.217, 'learning_rate': 4.263236554949374e-05, 'epoch': 4.31}\n",
            "{'loss': 0.0727, 'learning_rate': 4.2066936264919645e-05, 'epoch': 4.36}\n",
            "{'loss': 0.2639, 'learning_rate': 4.1498344281657e-05, 'epoch': 4.42}\n",
            "{'loss': 0.1909, 'learning_rate': 4.0926778404899444e-05, 'epoch': 4.48}\n",
            "{'loss': 0.2484, 'learning_rate': 4.035242842734404e-05, 'epoch': 4.53}\n",
            "{'loss': 0.1688, 'learning_rate': 3.977548506616922e-05, 'epoch': 4.59}\n",
            "{'loss': 0.3584, 'learning_rate': 3.91961398997057e-05, 'epoch': 4.64}\n",
            "{'loss': 0.1232, 'learning_rate': 3.861458530382152e-05, 'epoch': 4.7}\n",
            "{'loss': 0.1639, 'learning_rate': 3.8031014388042165e-05, 'epoch': 4.75}\n",
            "{'loss': 0.222, 'learning_rate': 3.7445620931427116e-05, 'epoch': 4.81}\n",
            "{'loss': 0.1185, 'learning_rate': 3.6858599318224095e-05, 'epoch': 4.86}\n",
            "{'loss': 0.2768, 'learning_rate': 3.627014447332232e-05, 'epoch': 4.92}\n",
            "{'loss': 0.2081, 'learning_rate': 3.568045179752623e-05, 'epoch': 4.97}\n",
            "{'loss': 0.3018, 'learning_rate': 3.508971710267123e-05, 'epoch': 5.03}\n",
            "{'loss': 0.15, 'learning_rate': 3.4498136546602896e-05, 'epoch': 5.08}\n",
            "{'loss': 0.1942, 'learning_rate': 3.3905906568041294e-05, 'epoch': 5.14}\n",
            "{'loss': 0.0739, 'learning_rate': 3.3313223821352075e-05, 'epoch': 5.19}\n",
            "{'loss': 0.0675, 'learning_rate': 3.27202851112459e-05, 'epoch': 5.25}\n",
            "{'loss': 0.0621, 'learning_rate': 3.212728732742794e-05, 'epoch': 5.3}\n",
            "{'loss': 0.1879, 'learning_rate': 3.153442737921933e-05, 'epoch': 5.36}\n",
            "{'loss': 0.1254, 'learning_rate': 3.094190213017179e-05, 'epoch': 5.41}\n",
            "{'loss': 0.1698, 'learning_rate': 3.0349908332697697e-05, 'epoch': 5.47}\n",
            "{'loss': 0.2259, 'learning_rate': 2.9758642562737036e-05, 'epoch': 5.52}\n",
            "{'loss': 0.0078, 'learning_rate': 2.9168301154482803e-05, 'epoch': 5.58}\n",
            "{'loss': 0.0657, 'learning_rate': 2.8579080135186822e-05, 'epoch': 5.64}\n",
            "{'loss': 0.1909, 'learning_rate': 2.7991175160067457e-05, 'epoch': 5.69}\n",
            "{'loss': 0.2996, 'learning_rate': 2.7404781447340804e-05, 'epoch': 5.75}\n",
            "{'loss': 0.1118, 'learning_rate': 2.6820093713397052e-05, 'epoch': 5.8}\n",
            "{'loss': 0.2621, 'learning_rate': 2.623730610814348e-05, 'epoch': 5.86}\n",
            "{'loss': 0.0605, 'learning_rate': 2.5656612150535492e-05, 'epoch': 5.91}\n",
            "{'loss': 0.2983, 'learning_rate': 2.5078204664317225e-05, 'epoch': 5.97}\n",
            "{'loss': 0.1621, 'learning_rate': 2.4502275713993012e-05, 'epoch': 6.02}\n",
            "{'loss': 0.0132, 'learning_rate': 2.3929016541050922e-05, 'epoch': 6.08}\n",
            "{'loss': 0.0628, 'learning_rate': 2.3358617500459615e-05, 'epoch': 6.13}\n",
            "{'loss': 0.0611, 'learning_rate': 2.279126799745952e-05, 'epoch': 6.19}\n",
            "{'loss': 0.0795, 'learning_rate': 2.2227156424669468e-05, 'epoch': 6.24}\n",
            "{'loss': 0.1238, 'learning_rate': 2.1666470099529496e-05, 'epoch': 6.3}\n",
            "{'loss': 0.1819, 'learning_rate': 2.11093952021007e-05, 'epoch': 6.35}\n",
            "{'loss': 0.1814, 'learning_rate': 2.0556116713242774e-05, 'epoch': 6.41}\n",
            "{'loss': 0.1188, 'learning_rate': 2.0006818353189705e-05, 'epoch': 6.46}\n",
            "{'loss': 0.1138, 'learning_rate': 1.9461682520544173e-05, 'epoch': 6.52}\n",
            "{'loss': 0.1729, 'learning_rate': 1.892089023171067e-05, 'epoch': 6.57}\n",
            "{'loss': 0.1644, 'learning_rate': 1.8384621060787686e-05, 'epoch': 6.63}\n",
            "{'loss': 0.1853, 'learning_rate': 1.785305307993882e-05, 'epoch': 6.69}\n",
            "{'loss': 0.0105, 'learning_rate': 1.732636280026252e-05, 'epoch': 6.74}\n",
            "{'loss': 0.1172, 'learning_rate': 1.680472511318036e-05, 'epoch': 6.8}\n",
            "{'loss': 0.2549, 'learning_rate': 1.6288313232362977e-05, 'epoch': 6.85}\n",
            "{'loss': 0.14, 'learning_rate': 1.5777298636213193e-05, 'epoch': 6.91}\n",
            "{'loss': 0.113, 'learning_rate': 1.5271851010925337e-05, 'epoch': 6.96}\n",
            "{'loss': 0.1715, 'learning_rate': 1.4772138194139715e-05, 'epoch': 7.02}\n",
            "{'loss': 0.1173, 'learning_rate': 1.4278326119210856e-05, 'epoch': 7.07}\n",
            "{'loss': 0.173, 'learning_rate': 1.3790578760108059e-05, 'epoch': 7.13}\n",
            "{'loss': 0.0083, 'learning_rate': 1.3309058076966709e-05, 'epoch': 7.18}\n",
            "{'loss': 0.1104, 'learning_rate': 1.283392396230815e-05, 'epoch': 7.24}\n",
            "{'loss': 0.0086, 'learning_rate': 1.2365334187946177e-05, 'epoch': 7.29}\n",
            "{'loss': 0.0909, 'learning_rate': 1.1949327450050079e-05, 'epoch': 7.35}\n",
            "{'loss': 0.1805, 'learning_rate': 1.149359875900475e-05, 'epoch': 7.4}\n",
            "{'loss': 0.1779, 'learning_rate': 1.1044859473200625e-05, 'epoch': 7.46}\n",
            "{'loss': 0.0069, 'learning_rate': 1.0603258599852447e-05, 'epoch': 7.51}\n",
            "{'loss': 0.0078, 'learning_rate': 1.0168942775812023e-05, 'epoch': 7.57}\n",
            "{'loss': 0.1227, 'learning_rate': 9.742056218876423e-06, 'epoch': 7.62}\n",
            "{'loss': 0.1212, 'learning_rate': 9.322740679899368e-06, 'epoch': 7.68}\n",
            "{'loss': 0.121, 'learning_rate': 8.911135395721773e-06, 'epoch': 7.73}\n",
            "{'loss': 0.0626, 'learning_rate': 8.50737704293717e-06, 'epoch': 7.79}\n",
            "{'loss': 0.1758, 'learning_rate': 8.111599692507213e-06, 'epoch': 7.85}\n",
            "{'loss': 0.0054, 'learning_rate': 7.723934765242372e-06, 'epoch': 7.9}\n",
            "{'loss': 0.0548, 'learning_rate': 7.344510988162757e-06, 'epoch': 7.96}\n",
            "{'loss': 0.0668, 'learning_rate': 6.97345435175331e-06, 'epoch': 8.01}\n",
            "{'loss': 0.187, 'learning_rate': 6.610888068127697e-06, 'epoch': 8.07}\n",
            "{'loss': 0.0662, 'learning_rate': 6.25693253011489e-06, 'epoch': 8.12}\n",
            "{'loss': 0.2326, 'learning_rate': 5.9117052712817535e-06, 'epoch': 8.18}\n",
            "{'loss': 0.0074, 'learning_rate': 5.575320926905193e-06, 'epoch': 8.23}\n",
            "{'loss': 0.0607, 'learning_rate': 5.247891195906666e-06, 'epoch': 8.29}\n",
            "{'loss': 0.1017, 'learning_rate': 4.929524803761703e-06, 'epoch': 8.34}\n",
            "{'loss': 0.1197, 'learning_rate': 4.620327466396793e-06, 'epoch': 8.4}\n",
            "{'loss': 0.2911, 'learning_rate': 4.320401855085673e-06, 'epoch': 8.45}\n",
            "{'loss': 0.0637, 'learning_rate': 4.02984756235653e-06, 'epoch': 8.51}\n",
            "{'loss': 0.0644, 'learning_rate': 3.7487610689215526e-06, 'epoch': 8.56}\n",
            "{'loss': 0.0647, 'learning_rate': 3.4772357116398372e-06, 'epoch': 8.62}\n",
            "{'loss': 0.0634, 'learning_rate': 3.2153616525241617e-06, 'epoch': 8.67}\n",
            "{'loss': 0.1216, 'learning_rate': 2.9632258488020013e-06, 'epoch': 8.73}\n",
            "{'loss': 0.1198, 'learning_rate': 2.7209120240407826e-06, 'epoch': 8.78}\n",
            "{'loss': 0.007, 'learning_rate': 2.4885006403468123e-06, 'epoch': 8.84}\n",
            "{'loss': 0.1181, 'learning_rate': 2.2660688716472484e-06, 'epoch': 8.9}\n",
            "{'loss': 0.0075, 'learning_rate': 2.053690578063926e-06, 'epoch': 8.95}\n",
            "{'loss': 0.0052, 'learning_rate': 1.8514362813875603e-06, 'epoch': 9.01}\n",
            "{'loss': 0.065, 'learning_rate': 1.6593731416604411e-06, 'epoch': 9.06}\n",
            "{'loss': 0.061, 'learning_rate': 1.4775649348754675e-06, 'epoch': 9.12}\n",
            "{'loss': 0.0057, 'learning_rate': 1.3060720317988469e-06, 'epoch': 9.17}\n",
            "{'loss': 0.0066, 'learning_rate': 1.1449513779235107e-06, 'epoch': 9.23}\n",
            "{'loss': 0.1247, 'learning_rate': 9.942564745599858e-07, 'epoch': 9.28}\n",
            "{'loss': 0.1183, 'learning_rate': 8.540373610708454e-07, 'epoch': 9.34}\n",
            "{'loss': 0.0629, 'learning_rate': 7.243405982547821e-07, 'epoch': 9.39}\n",
            "{'loss': 0.2315, 'learning_rate': 6.052092528857547e-07, 'epoch': 9.45}\n",
            "{'loss': 0.1225, 'learning_rate': 4.966828834123387e-07, 'epoch': 9.5}\n",
            "{'loss': 0.115, 'learning_rate': 3.987975268220474e-07, 'epoch': 9.56}\n",
            "{'loss': 0.0057, 'learning_rate': 3.1158568667498877e-07, 'epoch': 9.61}\n",
            "{'loss': 0.1207, 'learning_rate': 2.3507632231081788e-07, 'epoch': 9.67}\n",
            "{'loss': 0.0062, 'learning_rate': 1.692948392325581e-07, 'epoch': 9.72}\n",
            "{'loss': 0.0066, 'learning_rate': 1.1426308067053159e-07, 'epoch': 9.78}\n",
            "{'loss': 0.1875, 'learning_rate': 6.999932032914902e-08, 'epoch': 9.83}\n",
            "{'loss': 0.0644, 'learning_rate': 3.6518256318985744e-08, 'epoch': 9.89}\n",
            "{'loss': 0.0651, 'learning_rate': 1.383100627616831e-08, 'epoch': 9.94}\n",
            "{'loss': 0.0661, 'learning_rate': 1.9451036706714075e-09, 'epoch': 10.0}\n",
            "{'train_runtime': 181.1218, 'train_samples_per_second': 79.781, 'train_steps_per_second': 9.993, 'train_loss': 0.24249558950985334, 'epoch': 10.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 52/52 [00:01<00:00, 38.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 22:29:36,307] Trial 25 finished with value: 0.9086294416243655 and parameters: {'learning_rate': 6.508476603852763e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.2328960833487708, 'num_train_epochs': 10, 'warmup_steps': 86, 'freeze_layers': 9, 'dropout': 0.10143727922040138, 'lr_scheduler_type': 'cosine'}. Best is trial 19 with value: 0.9289340101522843.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: linear\n",
            " Warmup steps (True): 172\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2675a37369c54bd7ada3beefabc47473",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1629 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.761, 'learning_rate': 2.4897323406570016e-06, 'epoch': 0.06}\n",
            "{'loss': 0.6889, 'learning_rate': 6.639286241752004e-06, 'epoch': 0.11}\n",
            "{'loss': 0.707, 'learning_rate': 9.958929362628006e-06, 'epoch': 0.17}\n",
            "{'loss': 0.7359, 'learning_rate': 1.4108483263723007e-05, 'epoch': 0.22}\n",
            "{'loss': 0.6901, 'learning_rate': 1.825803716481801e-05, 'epoch': 0.28}\n",
            "{'loss': 0.6773, 'learning_rate': 2.2407591065913015e-05, 'epoch': 0.33}\n",
            "{'loss': 0.6608, 'learning_rate': 2.6557144967008016e-05, 'epoch': 0.39}\n",
            "{'loss': 0.6646, 'learning_rate': 3.070669886810302e-05, 'epoch': 0.44}\n",
            "{'loss': 0.6561, 'learning_rate': 3.485625276919802e-05, 'epoch': 0.5}\n",
            "{'loss': 0.5394, 'learning_rate': 3.900580667029302e-05, 'epoch': 0.55}\n",
            "{'loss': 0.6256, 'learning_rate': 4.3155360571388024e-05, 'epoch': 0.61}\n",
            "{'loss': 0.4739, 'learning_rate': 4.730491447248302e-05, 'epoch': 0.66}\n",
            "{'loss': 0.4036, 'learning_rate': 5.1454468373578026e-05, 'epoch': 0.72}\n",
            "{'loss': 0.4788, 'learning_rate': 5.560402227467304e-05, 'epoch': 0.77}\n",
            "{'loss': 0.4944, 'learning_rate': 5.9338620785658535e-05, 'epoch': 0.83}\n",
            "{'loss': 0.3828, 'learning_rate': 6.348817468675353e-05, 'epoch': 0.88}\n",
            "{'loss': 0.5409, 'learning_rate': 6.763772858784854e-05, 'epoch': 0.94}\n",
            "{'loss': 0.6967, 'learning_rate': 7.132334128751021e-05, 'epoch': 0.99}\n",
            "{'loss': 0.5163, 'learning_rate': 7.083348317427181e-05, 'epoch': 1.05}\n",
            "{'loss': 0.6527, 'learning_rate': 7.034362506103341e-05, 'epoch': 1.1}\n",
            "{'loss': 0.4998, 'learning_rate': 6.985376694779502e-05, 'epoch': 1.16}\n",
            "{'loss': 0.5615, 'learning_rate': 6.936390883455662e-05, 'epoch': 1.22}\n",
            "{'loss': 0.5447, 'learning_rate': 6.887405072131822e-05, 'epoch': 1.27}\n",
            "{'loss': 0.6602, 'learning_rate': 6.838419260807984e-05, 'epoch': 1.33}\n",
            "{'loss': 0.3522, 'learning_rate': 6.789433449484144e-05, 'epoch': 1.38}\n",
            "{'loss': 0.5974, 'learning_rate': 6.740447638160305e-05, 'epoch': 1.44}\n",
            "{'loss': 0.4196, 'learning_rate': 6.691461826836466e-05, 'epoch': 1.49}\n",
            "{'loss': 0.5858, 'learning_rate': 6.642476015512626e-05, 'epoch': 1.55}\n",
            "{'loss': 0.4585, 'learning_rate': 6.593490204188786e-05, 'epoch': 1.6}\n",
            "{'loss': 0.4511, 'learning_rate': 6.544504392864948e-05, 'epoch': 1.66}\n",
            "{'loss': 0.4282, 'learning_rate': 6.495518581541108e-05, 'epoch': 1.71}\n",
            "{'loss': 0.4764, 'learning_rate': 6.446532770217268e-05, 'epoch': 1.77}\n",
            "{'loss': 0.2726, 'learning_rate': 6.397546958893429e-05, 'epoch': 1.82}\n",
            "{'loss': 0.4963, 'learning_rate': 6.348561147569589e-05, 'epoch': 1.88}\n",
            "{'loss': 0.6187, 'learning_rate': 6.29957533624575e-05, 'epoch': 1.93}\n",
            "{'loss': 0.4781, 'learning_rate': 6.25058952492191e-05, 'epoch': 1.99}\n",
            "{'loss': 0.4873, 'learning_rate': 6.201603713598072e-05, 'epoch': 2.04}\n",
            "{'loss': 0.4271, 'learning_rate': 6.152617902274232e-05, 'epoch': 2.1}\n",
            "{'loss': 0.4012, 'learning_rate': 6.103632090950393e-05, 'epoch': 2.15}\n",
            "{'loss': 0.4393, 'learning_rate': 6.054646279626553e-05, 'epoch': 2.21}\n",
            "{'loss': 0.3755, 'learning_rate': 6.0056604683027136e-05, 'epoch': 2.27}\n",
            "{'loss': 0.3654, 'learning_rate': 5.956674656978874e-05, 'epoch': 2.32}\n",
            "{'loss': 0.3714, 'learning_rate': 5.907688845655034e-05, 'epoch': 2.38}\n",
            "{'loss': 0.456, 'learning_rate': 5.863601615463579e-05, 'epoch': 2.43}\n",
            "{'loss': 0.3656, 'learning_rate': 5.81461580413974e-05, 'epoch': 2.49}\n",
            "{'loss': 0.4699, 'learning_rate': 5.7656299928159e-05, 'epoch': 2.54}\n",
            "{'loss': 0.4989, 'learning_rate': 5.7166441814920615e-05, 'epoch': 2.6}\n",
            "{'loss': 0.5438, 'learning_rate': 5.6676583701682214e-05, 'epoch': 2.65}\n",
            "{'loss': 0.3574, 'learning_rate': 5.618672558844382e-05, 'epoch': 2.71}\n",
            "{'loss': 0.2691, 'learning_rate': 5.569686747520542e-05, 'epoch': 2.76}\n",
            "{'loss': 0.3781, 'learning_rate': 5.5207009361967034e-05, 'epoch': 2.82}\n",
            "{'loss': 0.3896, 'learning_rate': 5.4717151248728634e-05, 'epoch': 2.87}\n",
            "{'loss': 0.6453, 'learning_rate': 5.422729313549024e-05, 'epoch': 2.93}\n",
            "{'loss': 0.6073, 'learning_rate': 5.373743502225185e-05, 'epoch': 2.98}\n",
            "{'loss': 0.6449, 'learning_rate': 5.3247576909013454e-05, 'epoch': 3.04}\n",
            "{'loss': 0.4959, 'learning_rate': 5.275771879577506e-05, 'epoch': 3.09}\n",
            "{'loss': 0.2817, 'learning_rate': 5.226786068253667e-05, 'epoch': 3.15}\n",
            "{'loss': 0.3618, 'learning_rate': 5.1778002569298274e-05, 'epoch': 3.2}\n",
            "{'loss': 0.4063, 'learning_rate': 5.1288144456059874e-05, 'epoch': 3.26}\n",
            "{'loss': 0.4164, 'learning_rate': 5.079828634282149e-05, 'epoch': 3.31}\n",
            "{'loss': 0.3572, 'learning_rate': 5.030842822958309e-05, 'epoch': 3.37}\n",
            "{'loss': 0.3287, 'learning_rate': 4.9818570116344694e-05, 'epoch': 3.43}\n",
            "{'loss': 0.3605, 'learning_rate': 4.93287120031063e-05, 'epoch': 3.48}\n",
            "{'loss': 0.3167, 'learning_rate': 4.883885388986791e-05, 'epoch': 3.54}\n",
            "{'loss': 0.2862, 'learning_rate': 4.834899577662951e-05, 'epoch': 3.59}\n",
            "{'loss': 0.3723, 'learning_rate': 4.785913766339112e-05, 'epoch': 3.65}\n",
            "{'loss': 0.5019, 'learning_rate': 4.736927955015273e-05, 'epoch': 3.7}\n",
            "{'loss': 0.2901, 'learning_rate': 4.687942143691433e-05, 'epoch': 3.76}\n",
            "{'loss': 0.3066, 'learning_rate': 4.638956332367594e-05, 'epoch': 3.81}\n",
            "{'loss': 0.3113, 'learning_rate': 4.589970521043754e-05, 'epoch': 3.87}\n",
            "{'loss': 0.3768, 'learning_rate': 4.540984709719915e-05, 'epoch': 3.92}\n",
            "{'loss': 0.396, 'learning_rate': 4.4919988983960754e-05, 'epoch': 3.98}\n",
            "{'loss': 0.4457, 'learning_rate': 4.443013087072236e-05, 'epoch': 4.03}\n",
            "{'loss': 0.3698, 'learning_rate': 4.394027275748396e-05, 'epoch': 4.09}\n",
            "{'loss': 0.1831, 'learning_rate': 4.3450414644245574e-05, 'epoch': 4.14}\n",
            "{'loss': 0.4305, 'learning_rate': 4.2960556531007173e-05, 'epoch': 4.2}\n",
            "{'loss': 0.4176, 'learning_rate': 4.247069841776878e-05, 'epoch': 4.25}\n",
            "{'loss': 0.117, 'learning_rate': 4.198084030453039e-05, 'epoch': 4.31}\n",
            "{'loss': 0.2906, 'learning_rate': 4.1490982191291993e-05, 'epoch': 4.36}\n",
            "{'loss': 0.3382, 'learning_rate': 4.10011240780536e-05, 'epoch': 4.42}\n",
            "{'loss': 0.4808, 'learning_rate': 4.051126596481521e-05, 'epoch': 4.48}\n",
            "{'loss': 0.3233, 'learning_rate': 4.002140785157681e-05, 'epoch': 4.53}\n",
            "{'loss': 0.3429, 'learning_rate': 3.953154973833841e-05, 'epoch': 4.59}\n",
            "{'loss': 0.3097, 'learning_rate': 3.904169162510003e-05, 'epoch': 4.64}\n",
            "{'loss': 0.2653, 'learning_rate': 3.8551833511861627e-05, 'epoch': 4.7}\n",
            "{'loss': 0.2008, 'learning_rate': 3.806197539862323e-05, 'epoch': 4.75}\n",
            "{'loss': 0.2957, 'learning_rate': 3.757211728538483e-05, 'epoch': 4.81}\n",
            "{'loss': 0.4126, 'learning_rate': 3.7082259172146446e-05, 'epoch': 4.86}\n",
            "{'loss': 0.3045, 'learning_rate': 3.6592401058908046e-05, 'epoch': 4.92}\n",
            "{'loss': 0.2122, 'learning_rate': 3.610254294566966e-05, 'epoch': 4.97}\n",
            "{'loss': 0.3984, 'learning_rate': 3.561268483243126e-05, 'epoch': 5.03}\n",
            "{'loss': 0.337, 'learning_rate': 3.5122826719192866e-05, 'epoch': 5.08}\n",
            "{'loss': 0.2921, 'learning_rate': 3.463296860595447e-05, 'epoch': 5.14}\n",
            "{'loss': 0.1839, 'learning_rate': 3.414311049271608e-05, 'epoch': 5.19}\n",
            "{'loss': 0.3111, 'learning_rate': 3.3653252379477686e-05, 'epoch': 5.25}\n",
            "{'loss': 0.387, 'learning_rate': 3.3163394266239286e-05, 'epoch': 5.3}\n",
            "{'loss': 0.2072, 'learning_rate': 3.267353615300089e-05, 'epoch': 5.36}\n",
            "{'loss': 0.3683, 'learning_rate': 3.2183678039762506e-05, 'epoch': 5.41}\n",
            "{'loss': 0.2093, 'learning_rate': 3.1693819926524106e-05, 'epoch': 5.47}\n",
            "{'loss': 0.2994, 'learning_rate': 3.120396181328571e-05, 'epoch': 5.52}\n",
            "{'loss': 0.4429, 'learning_rate': 3.071410370004732e-05, 'epoch': 5.58}\n",
            "{'loss': 0.2671, 'learning_rate': 3.0224245586808926e-05, 'epoch': 5.64}\n",
            "{'loss': 0.2079, 'learning_rate': 2.9734387473570533e-05, 'epoch': 5.69}\n",
            "{'loss': 0.1406, 'learning_rate': 2.9244529360332136e-05, 'epoch': 5.75}\n",
            "{'loss': 0.2455, 'learning_rate': 2.8754671247093743e-05, 'epoch': 5.8}\n",
            "{'loss': 0.2589, 'learning_rate': 2.8264813133855346e-05, 'epoch': 5.86}\n",
            "{'loss': 0.128, 'learning_rate': 2.7774955020616952e-05, 'epoch': 5.91}\n",
            "{'loss': 0.5173, 'learning_rate': 2.728509690737856e-05, 'epoch': 5.97}\n",
            "{'loss': 0.3592, 'learning_rate': 2.6795238794140162e-05, 'epoch': 6.02}\n",
            "{'loss': 0.1096, 'learning_rate': 2.6305380680901772e-05, 'epoch': 6.08}\n",
            "{'loss': 0.2368, 'learning_rate': 2.581552256766338e-05, 'epoch': 6.13}\n",
            "{'loss': 0.2017, 'learning_rate': 2.5325664454424982e-05, 'epoch': 6.19}\n",
            "{'loss': 0.2766, 'learning_rate': 2.483580634118659e-05, 'epoch': 6.24}\n",
            "{'loss': 0.2751, 'learning_rate': 2.4345948227948196e-05, 'epoch': 6.3}\n",
            "{'loss': 0.2103, 'learning_rate': 2.38560901147098e-05, 'epoch': 6.35}\n",
            "{'loss': 0.3202, 'learning_rate': 2.3366232001471406e-05, 'epoch': 6.41}\n",
            "{'loss': 0.2325, 'learning_rate': 2.2876373888233012e-05, 'epoch': 6.46}\n",
            "{'loss': 0.0256, 'learning_rate': 2.2386515774994615e-05, 'epoch': 6.52}\n",
            "{'loss': 0.1486, 'learning_rate': 2.1896657661756222e-05, 'epoch': 6.57}\n",
            "{'loss': 0.3358, 'learning_rate': 2.140679954851783e-05, 'epoch': 6.63}\n",
            "{'loss': 0.1457, 'learning_rate': 2.0916941435279432e-05, 'epoch': 6.69}\n",
            "{'loss': 0.4111, 'learning_rate': 2.042708332204104e-05, 'epoch': 6.74}\n",
            "{'loss': 0.2665, 'learning_rate': 1.993722520880265e-05, 'epoch': 6.8}\n",
            "{'loss': 0.2504, 'learning_rate': 1.9447367095564252e-05, 'epoch': 6.85}\n",
            "{'loss': 0.1916, 'learning_rate': 1.895750898232586e-05, 'epoch': 6.91}\n",
            "{'loss': 0.2306, 'learning_rate': 1.8467650869087465e-05, 'epoch': 6.96}\n",
            "{'loss': 0.2302, 'learning_rate': 1.797779275584907e-05, 'epoch': 7.02}\n",
            "{'loss': 0.3448, 'learning_rate': 1.7487934642610675e-05, 'epoch': 7.07}\n",
            "{'loss': 0.1713, 'learning_rate': 1.6998076529372282e-05, 'epoch': 7.13}\n",
            "{'loss': 0.0937, 'learning_rate': 1.6508218416133885e-05, 'epoch': 7.18}\n",
            "{'loss': 0.2609, 'learning_rate': 1.6018360302895492e-05, 'epoch': 7.24}\n",
            "{'loss': 0.0846, 'learning_rate': 1.55285021896571e-05, 'epoch': 7.29}\n",
            "{'loss': 0.2667, 'learning_rate': 1.5038644076418703e-05, 'epoch': 7.35}\n",
            "{'loss': 0.1577, 'learning_rate': 1.454878596318031e-05, 'epoch': 7.4}\n",
            "{'loss': 0.4018, 'learning_rate': 1.4058927849941915e-05, 'epoch': 7.46}\n",
            "{'loss': 0.1093, 'learning_rate': 1.356906973670352e-05, 'epoch': 7.51}\n",
            "{'loss': 0.0578, 'learning_rate': 1.3079211623465125e-05, 'epoch': 7.57}\n",
            "{'loss': 0.213, 'learning_rate': 1.2589353510226733e-05, 'epoch': 7.62}\n",
            "{'loss': 0.2609, 'learning_rate': 1.2099495396988338e-05, 'epoch': 7.68}\n",
            "{'loss': 0.2112, 'learning_rate': 1.1609637283749943e-05, 'epoch': 7.73}\n",
            "{'loss': 0.2659, 'learning_rate': 1.111977917051155e-05, 'epoch': 7.79}\n",
            "{'loss': 0.1285, 'learning_rate': 1.0629921057273155e-05, 'epoch': 7.85}\n",
            "{'loss': 0.1554, 'learning_rate': 1.014006294403476e-05, 'epoch': 7.9}\n",
            "{'loss': 0.0132, 'learning_rate': 9.650204830796368e-06, 'epoch': 7.96}\n",
            "{'loss': 0.1057, 'learning_rate': 9.160346717557973e-06, 'epoch': 8.01}\n",
            "{'loss': 0.1671, 'learning_rate': 8.670488604319578e-06, 'epoch': 8.07}\n",
            "{'loss': 0.2363, 'learning_rate': 8.180630491081185e-06, 'epoch': 8.12}\n",
            "{'loss': 0.2066, 'learning_rate': 7.69077237784279e-06, 'epoch': 8.18}\n",
            "{'loss': 0.2344, 'learning_rate': 7.200914264604395e-06, 'epoch': 8.23}\n",
            "{'loss': 0.4025, 'learning_rate': 6.711056151366001e-06, 'epoch': 8.29}\n",
            "{'loss': 0.2165, 'learning_rate': 6.221198038127607e-06, 'epoch': 8.34}\n",
            "{'loss': 0.2466, 'learning_rate': 5.731339924889213e-06, 'epoch': 8.4}\n",
            "{'loss': 0.2018, 'learning_rate': 5.2414818116508185e-06, 'epoch': 8.45}\n",
            "{'loss': 0.153, 'learning_rate': 4.7516236984124235e-06, 'epoch': 8.51}\n",
            "{'loss': 0.0591, 'learning_rate': 4.26176558517403e-06, 'epoch': 8.56}\n",
            "{'loss': 0.2083, 'learning_rate': 3.7719074719356355e-06, 'epoch': 8.62}\n",
            "{'loss': 0.2468, 'learning_rate': 3.2820493586972417e-06, 'epoch': 8.67}\n",
            "{'loss': 0.1991, 'learning_rate': 2.792191245458847e-06, 'epoch': 8.73}\n",
            "{'loss': 0.1094, 'learning_rate': 2.302333132220453e-06, 'epoch': 8.78}\n",
            "{'loss': 0.1743, 'learning_rate': 1.812475018982059e-06, 'epoch': 8.84}\n",
            "{'loss': 0.0578, 'learning_rate': 1.3226169057436645e-06, 'epoch': 8.9}\n",
            "{'loss': 0.0668, 'learning_rate': 8.327587925052702e-07, 'epoch': 8.95}\n",
            "{'train_runtime': 185.3044, 'train_samples_per_second': 70.182, 'train_steps_per_second': 8.791, 'train_loss': 0.3480696525582512, 'epoch': 9.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 52/52 [00:01<00:00, 36.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 22:32:45,813] Trial 26 finished with value: 0.9067357512953368 and parameters: {'learning_rate': 7.137232709883404e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.23565305559192157, 'num_train_epochs': 9, 'warmup_steps': 172, 'freeze_layers': 9, 'dropout': 0.25942886620747807, 'lr_scheduler_type': 'linear'}. Best is trial 19 with value: 0.9289340101522843.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: cosine_with_restarts\n",
            " Warmup steps (True): 27\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "83d96bdb29c34833ab067d887ecec69a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1448 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7101, 'learning_rate': 1.1544942571618206e-05, 'epoch': 0.06}\n",
            "{'loss': 0.7576, 'learning_rate': 2.638844016369876e-05, 'epoch': 0.11}\n",
            "{'loss': 0.7319, 'learning_rate': 4.288121526601048e-05, 'epoch': 0.17}\n",
            "{'loss': 0.7418, 'learning_rate': 4.452608540341574e-05, 'epoch': 0.22}\n",
            "{'loss': 0.7079, 'learning_rate': 4.4510852280691645e-05, 'epoch': 0.28}\n",
            "{'loss': 0.6404, 'learning_rate': 4.448474643959707e-05, 'epoch': 0.33}\n",
            "{'loss': 0.6203, 'learning_rate': 4.4447780639571326e-05, 'epoch': 0.39}\n",
            "{'loss': 0.6582, 'learning_rate': 4.439997294794575e-05, 'epoch': 0.44}\n",
            "{'loss': 0.5747, 'learning_rate': 4.434134673111324e-05, 'epoch': 0.5}\n",
            "{'loss': 0.4982, 'learning_rate': 4.427193064310765e-05, 'epoch': 0.55}\n",
            "{'loss': 0.5185, 'learning_rate': 4.4191758611598965e-05, 'epoch': 0.61}\n",
            "{'loss': 0.3988, 'learning_rate': 4.4100869821310866e-05, 'epoch': 0.66}\n",
            "{'loss': 0.3231, 'learning_rate': 4.399930869486886e-05, 'epoch': 0.72}\n",
            "{'loss': 0.5615, 'learning_rate': 4.388712487108837e-05, 'epoch': 0.77}\n",
            "{'loss': 0.6611, 'learning_rate': 4.376437318071341e-05, 'epoch': 0.83}\n",
            "{'loss': 0.3864, 'learning_rate': 4.3631113619617556e-05, 'epoch': 0.88}\n",
            "{'loss': 0.3158, 'learning_rate': 4.3487411319480516e-05, 'epoch': 0.94}\n",
            "{'loss': 0.9475, 'learning_rate': 4.3333336515954506e-05, 'epoch': 0.99}\n",
            "{'loss': 0.4715, 'learning_rate': 4.316896451433598e-05, 'epoch': 1.05}\n",
            "{'loss': 0.4109, 'learning_rate': 4.2994375652759586e-05, 'epoch': 1.1}\n",
            "{'loss': 0.345, 'learning_rate': 4.280965526293227e-05, 'epoch': 1.16}\n",
            "{'loss': 0.2387, 'learning_rate': 4.2614893628426664e-05, 'epoch': 1.22}\n",
            "{'loss': 0.2162, 'learning_rate': 4.241018594055435e-05, 'epoch': 1.27}\n",
            "{'loss': 0.5377, 'learning_rate': 4.219563225184026e-05, 'epoch': 1.33}\n",
            "{'loss': 0.6048, 'learning_rate': 4.197133742712127e-05, 'epoch': 1.38}\n",
            "{'loss': 0.3362, 'learning_rate': 4.17374110922926e-05, 'epoch': 1.44}\n",
            "{'loss': 0.4106, 'learning_rate': 4.149396758072735e-05, 'epoch': 1.49}\n",
            "{'loss': 0.4707, 'learning_rate': 4.124112587739508e-05, 'epoch': 1.55}\n",
            "{'loss': 0.3007, 'learning_rate': 4.0979009560707025e-05, 'epoch': 1.6}\n",
            "{'loss': 0.3326, 'learning_rate': 4.070774674211607e-05, 'epoch': 1.66}\n",
            "{'loss': 0.3316, 'learning_rate': 4.0427470003501326e-05, 'epoch': 1.71}\n",
            "{'loss': 0.4264, 'learning_rate': 4.013831633236762e-05, 'epoch': 1.77}\n",
            "{'loss': 0.2343, 'learning_rate': 3.9840427054891793e-05, 'epoch': 1.82}\n",
            "{'loss': 0.3098, 'learning_rate': 3.953394776684835e-05, 'epoch': 1.88}\n",
            "{'loss': 0.4619, 'learning_rate': 3.92190282624484e-05, 'epoch': 1.93}\n",
            "{'loss': 0.2082, 'learning_rate': 3.889582246112652e-05, 'epoch': 1.99}\n",
            "{'loss': 0.1959, 'learning_rate': 3.8564488332311395e-05, 'epoch': 2.04}\n",
            "{'loss': 0.1647, 'learning_rate': 3.822518781821697e-05, 'epoch': 2.1}\n",
            "{'loss': 0.2647, 'learning_rate': 3.7878086754691944e-05, 'epoch': 2.15}\n",
            "{'loss': 0.2304, 'learning_rate': 3.7523354790166125e-05, 'epoch': 2.21}\n",
            "{'loss': 0.1386, 'learning_rate': 3.7161165302733394e-05, 'epoch': 2.27}\n",
            "{'loss': 0.2054, 'learning_rate': 3.6791695315411836e-05, 'epoch': 2.32}\n",
            "{'loss': 0.3251, 'learning_rate': 3.6415125409622224e-05, 'epoch': 2.38}\n",
            "{'loss': 0.2685, 'learning_rate': 3.603163963692747e-05, 'epoch': 2.43}\n",
            "{'loss': 0.172, 'learning_rate': 3.564142542907594e-05, 'epoch': 2.49}\n",
            "{'loss': 0.2329, 'learning_rate': 3.524467350639265e-05, 'epoch': 2.54}\n",
            "{'loss': 0.1899, 'learning_rate': 3.484157778456319e-05, 'epoch': 2.6}\n",
            "{'loss': 0.3026, 'learning_rate': 3.443233527985591e-05, 'epoch': 2.65}\n",
            "{'loss': 0.121, 'learning_rate': 3.401714601282859e-05, 'epoch': 2.71}\n",
            "{'loss': 0.2733, 'learning_rate': 3.35962129105668e-05, 'epoch': 2.76}\n",
            "{'loss': 0.227, 'learning_rate': 3.3169741707501705e-05, 'epoch': 2.82}\n",
            "{'loss': 0.3001, 'learning_rate': 3.273794084485564e-05, 'epoch': 2.87}\n",
            "{'loss': 0.4179, 'learning_rate': 3.230102136876483e-05, 'epoch': 2.93}\n",
            "{'loss': 0.1988, 'learning_rate': 3.18591968271289e-05, 'epoch': 2.98}\n",
            "{'loss': 0.1233, 'learning_rate': 3.141268316523761e-05, 'epoch': 3.04}\n",
            "{'loss': 0.013, 'learning_rate': 3.0961698620225855e-05, 'epoch': 3.09}\n",
            "{'loss': 0.0019, 'learning_rate': 3.0506463614408568e-05, 'epoch': 3.15}\n",
            "{'loss': 0.0793, 'learning_rate': 3.0047200647547455e-05, 'epoch': 3.2}\n",
            "{'loss': 0.1502, 'learning_rate': 2.9584134188102528e-05, 'epoch': 3.26}\n",
            "{'loss': 0.0012, 'learning_rate': 2.9117490563521333e-05, 'epoch': 3.31}\n",
            "{'loss': 0.3305, 'learning_rate': 2.8647497849619547e-05, 'epoch': 3.37}\n",
            "{'loss': 0.1248, 'learning_rate': 2.817438575910713e-05, 'epoch': 3.43}\n",
            "{'loss': 0.206, 'learning_rate': 2.7698385529314407e-05, 'epoch': 3.48}\n",
            "{'loss': 0.3532, 'learning_rate': 2.7219729809172928e-05, 'epoch': 3.54}\n",
            "{'loss': 0.1633, 'learning_rate': 2.6738652545506485e-05, 'epoch': 3.59}\n",
            "{'loss': 0.3164, 'learning_rate': 2.6255388868687653e-05, 'epoch': 3.65}\n",
            "{'loss': 0.1529, 'learning_rate': 2.577017497771603e-05, 'epoch': 3.7}\n",
            "{'loss': 0.0252, 'learning_rate': 2.5283248024774003e-05, 'epoch': 3.76}\n",
            "{'loss': 0.1244, 'learning_rate': 2.4794845999316733e-05, 'epoch': 3.81}\n",
            "{'loss': 0.1964, 'learning_rate': 2.4305207611752915e-05, 'epoch': 3.87}\n",
            "{'loss': 0.1094, 'learning_rate': 2.381457217677316e-05, 'epoch': 3.92}\n",
            "{'loss': 0.2065, 'learning_rate': 2.3323179496382988e-05, 'epoch': 3.98}\n",
            "{'loss': 0.0295, 'learning_rate': 2.2831269742697687e-05, 'epoch': 4.03}\n",
            "{'loss': 0.0036, 'learning_rate': 2.233908334055628e-05, 'epoch': 4.09}\n",
            "{'loss': 0.0018, 'learning_rate': 2.1846860850011928e-05, 'epoch': 4.14}\n",
            "{'loss': 0.0015, 'learning_rate': 2.1354842848756293e-05, 'epoch': 4.2}\n",
            "{'loss': 0.0534, 'learning_rate': 2.0863269814535267e-05, 'epoch': 4.25}\n",
            "{'loss': 0.0681, 'learning_rate': 2.0372382007613514e-05, 'epoch': 4.31}\n",
            "{'loss': 0.0009, 'learning_rate': 1.9882419353345377e-05, 'epoch': 4.36}\n",
            "{'loss': 0.101, 'learning_rate': 1.9393621324909415e-05, 'epoch': 4.42}\n",
            "{'loss': 0.0006, 'learning_rate': 1.890622682626395e-05, 'epoch': 4.48}\n",
            "{'loss': 0.1331, 'learning_rate': 1.8420474075380857e-05, 'epoch': 4.53}\n",
            "{'loss': 0.0566, 'learning_rate': 1.7936600487814647e-05, 'epoch': 4.59}\n",
            "{'loss': 0.0117, 'learning_rate': 1.7454842560663663e-05, 'epoch': 4.64}\n",
            "{'loss': 0.0006, 'learning_rate': 1.697543575698025e-05, 'epoch': 4.7}\n",
            "{'loss': 0.0004, 'learning_rate': 1.6498614390686273e-05, 'epoch': 4.75}\n",
            "{'loss': 0.0956, 'learning_rate': 1.602461151205036e-05, 'epoch': 4.81}\n",
            "{'loss': 0.0005, 'learning_rate': 1.5553658793782664e-05, 'epoch': 4.86}\n",
            "{'loss': 0.0007, 'learning_rate': 1.5085986417802985e-05, 'epoch': 4.92}\n",
            "{'loss': 0.1623, 'learning_rate': 1.4621822962737527e-05, 'epoch': 4.97}\n",
            "{'loss': 0.0023, 'learning_rate': 1.4161395292199209e-05, 'epoch': 5.03}\n",
            "{'loss': 0.0008, 'learning_rate': 1.3704928443906318e-05, 'epoch': 5.08}\n",
            "{'loss': 0.0007, 'learning_rate': 1.3252645519693474e-05, 'epoch': 5.14}\n",
            "{'loss': 0.0007, 'learning_rate': 1.2804767576468841e-05, 'epoch': 5.19}\n",
            "{'loss': 0.0752, 'learning_rate': 1.2361513518170775e-05, 'epoch': 5.25}\n",
            "{'loss': 0.0965, 'learning_rate': 1.1923099988776772e-05, 'epoch': 5.3}\n",
            "{'loss': 0.0816, 'learning_rate': 1.1489741266416995e-05, 'epoch': 5.36}\n",
            "{'loss': 0.001, 'learning_rate': 1.1061649158644094e-05, 'epoch': 5.41}\n",
            "{'loss': 0.0008, 'learning_rate': 1.0639032898910625e-05, 'epoch': 5.47}\n",
            "{'loss': 0.0007, 'learning_rate': 1.022209904430441e-05, 'epoch': 5.52}\n",
            "{'loss': 0.0281, 'learning_rate': 9.811051374592236e-06, 'epoch': 5.58}\n",
            "{'loss': 0.0005, 'learning_rate': 9.406090792620768e-06, 'epoch': 5.64}\n",
            "{'loss': 0.0005, 'learning_rate': 9.00741522612368e-06, 'epoch': 5.69}\n",
            "{'loss': 0.0005, 'learning_rate': 8.615219530982953e-06, 'epoch': 5.75}\n",
            "{'loss': 0.0005, 'learning_rate': 8.229695395991386e-06, 'epoch': 5.8}\n",
            "{'loss': 0.0007, 'learning_rate': 7.85103124916328e-06, 'epoch': 5.86}\n",
            "{'loss': 0.0005, 'learning_rate': 7.47941216563865e-06, 'epoch': 5.91}\n",
            "{'loss': 0.0069, 'learning_rate': 7.115019777226301e-06, 'epoch': 5.97}\n",
            "{'loss': 0.0004, 'learning_rate': 6.758032183629834e-06, 'epoch': 6.02}\n",
            "{'loss': 0.0541, 'learning_rate': 6.4086238653999355e-06, 'epoch': 6.08}\n",
            "{'loss': 0.0356, 'learning_rate': 6.066965598655665e-06, 'epoch': 6.13}\n",
            "{'loss': 0.0005, 'learning_rate': 5.7332243716162444e-06, 'epoch': 6.19}\n",
            "{'loss': 0.0004, 'learning_rate': 5.407563302984199e-06, 'epoch': 6.24}\n",
            "{'loss': 0.0006, 'learning_rate': 5.090141562219808e-06, 'epoch': 6.3}\n",
            "{'loss': 0.0717, 'learning_rate': 4.781114291745741e-06, 'epoch': 6.35}\n",
            "{'loss': 0.0005, 'learning_rate': 4.480632531119959e-06, 'epoch': 6.41}\n",
            "{'loss': 0.0003, 'learning_rate': 4.188843143213932e-06, 'epoch': 6.46}\n",
            "{'loss': 0.0003, 'learning_rate': 3.90588874243221e-06, 'epoch': 6.52}\n",
            "{'loss': 0.0003, 'learning_rate': 3.6319076250084766e-06, 'epoch': 6.57}\n",
            "{'loss': 0.0003, 'learning_rate': 3.367033701412216e-06, 'epoch': 6.63}\n",
            "{'loss': 0.0003, 'learning_rate': 3.11139643089883e-06, 'epoch': 6.69}\n",
            "{'loss': 0.0019, 'learning_rate': 2.8651207582354117e-06, 'epoch': 6.74}\n",
            "{'loss': 0.0004, 'learning_rate': 2.6283270526330176e-06, 'epoch': 6.8}\n",
            "{'loss': 0.0003, 'learning_rate': 2.401131048915187e-06, 'epoch': 6.85}\n",
            "{'loss': 0.1006, 'learning_rate': 2.1836437909516864e-06, 'epoch': 6.91}\n",
            "{'loss': 0.0004, 'learning_rate': 1.9759715773848777e-06, 'epoch': 6.96}\n",
            "{'loss': 0.0004, 'learning_rate': 1.7782159096754224e-06, 'epoch': 7.02}\n",
            "{'loss': 0.0008, 'learning_rate': 1.5904734424926444e-06, 'epoch': 7.07}\n",
            "{'loss': 0.0004, 'learning_rate': 1.412835936473742e-06, 'epoch': 7.13}\n",
            "{'loss': 0.0004, 'learning_rate': 1.2453902133750807e-06, 'epoch': 7.18}\n",
            "{'loss': 0.0004, 'learning_rate': 1.0882181136373537e-06, 'epoch': 7.24}\n",
            "{'loss': 0.0003, 'learning_rate': 9.413964563853965e-07, 'epoch': 7.29}\n",
            "{'loss': 0.0006, 'learning_rate': 8.049970018822326e-07, 'epoch': 7.35}\n",
            "{'loss': 0.0003, 'learning_rate': 6.790864164556669e-07, 'epoch': 7.4}\n",
            "{'loss': 0.0003, 'learning_rate': 5.637262399145878e-07, 'epoch': 7.46}\n",
            "{'loss': 0.1006, 'learning_rate': 4.5897285547088983e-07, 'epoch': 7.51}\n",
            "{'loss': 0.0003, 'learning_rate': 3.6487746218171713e-07, 'epoch': 7.57}\n",
            "{'loss': 0.0124, 'learning_rate': 2.814860499255316e-07, 'epoch': 7.62}\n",
            "{'loss': 0.0003, 'learning_rate': 2.088393769241715e-07, 'epoch': 7.68}\n",
            "{'loss': 0.0003, 'learning_rate': 1.4697294982195818e-07, 'epoch': 7.73}\n",
            "{'loss': 0.0942, 'learning_rate': 9.59170063315278e-08, 'epoch': 7.79}\n",
            "{'loss': 0.0003, 'learning_rate': 5.569650045491939e-08, 'epoch': 7.85}\n",
            "{'loss': 0.0003, 'learning_rate': 2.6331090287092525e-08, 'epoch': 7.9}\n",
            "{'loss': 0.0004, 'learning_rate': 7.835128407883848e-09, 'epoch': 7.96}\n",
            "{'train_runtime': 144.7658, 'train_samples_per_second': 79.853, 'train_steps_per_second': 10.002, 'train_loss': 0.17825535623512992, 'epoch': 8.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 52/52 [00:01<00:00, 39.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 22:35:14,384] Trial 27 finished with value: 0.9162303664921465 and parameters: {'learning_rate': 4.4530492776241655e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.27695787612251693, 'num_train_epochs': 8, 'warmup_steps': 27, 'freeze_layers': 6, 'dropout': 0.1556092548578853, 'lr_scheduler_type': 'cosine_with_restarts'}. Best is trial 19 with value: 0.9289340101522843.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: constant_with_warmup\n",
            " Warmup steps (True): 122\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4513944df6304bac8dfe52a53ad42f6c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/910 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.6916, 'learning_rate': 5.052164598913648e-06, 'epoch': 0.11}\n",
            "{'loss': 0.6945, 'learning_rate': 1.07358497726915e-05, 'epoch': 0.22}\n",
            "{'loss': 0.6798, 'learning_rate': 1.6419534946469354e-05, 'epoch': 0.33}\n",
            "{'loss': 0.6827, 'learning_rate': 2.2734740695111415e-05, 'epoch': 0.44}\n",
            "{'loss': 0.6497, 'learning_rate': 2.9049946443753473e-05, 'epoch': 0.55}\n",
            "{'loss': 0.687, 'learning_rate': 3.536515219239553e-05, 'epoch': 0.66}\n",
            "{'loss': 0.6128, 'learning_rate': 4.1680357941037596e-05, 'epoch': 0.77}\n",
            "{'loss': 0.6031, 'learning_rate': 4.7995563689679654e-05, 'epoch': 0.88}\n",
            "{'loss': 0.5322, 'learning_rate': 5.431076943832171e-05, 'epoch': 0.99}\n",
            "{'loss': 0.5193, 'learning_rate': 6.062597518696377e-05, 'epoch': 1.1}\n",
            "{'loss': 0.5731, 'learning_rate': 6.694118093560583e-05, 'epoch': 1.21}\n",
            "{'loss': 0.4995, 'learning_rate': 7.325638668424789e-05, 'epoch': 1.32}\n",
            "{'loss': 0.3882, 'learning_rate': 7.704551013343313e-05, 'epoch': 1.43}\n",
            "{'loss': 0.3348, 'learning_rate': 7.704551013343313e-05, 'epoch': 1.54}\n",
            "{'loss': 0.3982, 'learning_rate': 7.704551013343313e-05, 'epoch': 1.65}\n",
            "{'loss': 0.4814, 'learning_rate': 7.704551013343313e-05, 'epoch': 1.76}\n",
            "{'loss': 0.2943, 'learning_rate': 7.704551013343313e-05, 'epoch': 1.87}\n",
            "{'loss': 0.3846, 'learning_rate': 7.704551013343313e-05, 'epoch': 1.98}\n",
            "{'loss': 0.1801, 'learning_rate': 7.704551013343313e-05, 'epoch': 2.09}\n",
            "{'loss': 0.3392, 'learning_rate': 7.704551013343313e-05, 'epoch': 2.2}\n",
            "{'loss': 0.225, 'learning_rate': 7.704551013343313e-05, 'epoch': 2.31}\n",
            "{'loss': 0.3338, 'learning_rate': 7.704551013343313e-05, 'epoch': 2.42}\n",
            "{'loss': 0.1947, 'learning_rate': 7.704551013343313e-05, 'epoch': 2.53}\n",
            "{'loss': 0.3001, 'learning_rate': 7.704551013343313e-05, 'epoch': 2.64}\n",
            "{'loss': 0.1479, 'learning_rate': 7.704551013343313e-05, 'epoch': 2.75}\n",
            "{'loss': 0.2713, 'learning_rate': 7.704551013343313e-05, 'epoch': 2.86}\n",
            "{'loss': 0.475, 'learning_rate': 7.704551013343313e-05, 'epoch': 2.97}\n",
            "{'loss': 0.1651, 'learning_rate': 7.704551013343313e-05, 'epoch': 3.08}\n",
            "{'loss': 0.1649, 'learning_rate': 7.704551013343313e-05, 'epoch': 3.19}\n",
            "{'loss': 0.1995, 'learning_rate': 7.704551013343313e-05, 'epoch': 3.3}\n",
            "{'loss': 0.1397, 'learning_rate': 7.704551013343313e-05, 'epoch': 3.41}\n",
            "{'loss': 0.4925, 'learning_rate': 7.704551013343313e-05, 'epoch': 3.52}\n",
            "{'loss': 0.3445, 'learning_rate': 7.704551013343313e-05, 'epoch': 3.63}\n",
            "{'loss': 0.1292, 'learning_rate': 7.704551013343313e-05, 'epoch': 3.74}\n",
            "{'loss': 0.1449, 'learning_rate': 7.704551013343313e-05, 'epoch': 3.85}\n",
            "{'loss': 0.1635, 'learning_rate': 7.704551013343313e-05, 'epoch': 3.96}\n",
            "{'loss': 0.1022, 'learning_rate': 7.704551013343313e-05, 'epoch': 4.07}\n",
            "{'loss': 0.0095, 'learning_rate': 7.704551013343313e-05, 'epoch': 4.18}\n",
            "{'loss': 0.0431, 'learning_rate': 7.704551013343313e-05, 'epoch': 4.29}\n",
            "{'loss': 0.072, 'learning_rate': 7.704551013343313e-05, 'epoch': 4.4}\n",
            "{'loss': 0.0938, 'learning_rate': 7.704551013343313e-05, 'epoch': 4.51}\n",
            "{'loss': 0.1309, 'learning_rate': 7.704551013343313e-05, 'epoch': 4.62}\n",
            "{'loss': 0.1143, 'learning_rate': 7.704551013343313e-05, 'epoch': 4.73}\n",
            "{'loss': 0.1355, 'learning_rate': 7.704551013343313e-05, 'epoch': 4.84}\n",
            "{'loss': 0.1687, 'learning_rate': 7.704551013343313e-05, 'epoch': 4.95}\n",
            "{'loss': 0.0972, 'learning_rate': 7.704551013343313e-05, 'epoch': 5.05}\n",
            "{'loss': 0.0425, 'learning_rate': 7.704551013343313e-05, 'epoch': 5.16}\n",
            "{'loss': 0.1809, 'learning_rate': 7.704551013343313e-05, 'epoch': 5.27}\n",
            "{'loss': 0.1295, 'learning_rate': 7.704551013343313e-05, 'epoch': 5.38}\n",
            "{'loss': 0.1111, 'learning_rate': 7.704551013343313e-05, 'epoch': 5.49}\n",
            "{'loss': 0.2042, 'learning_rate': 7.704551013343313e-05, 'epoch': 5.6}\n",
            "{'loss': 0.0221, 'learning_rate': 7.704551013343313e-05, 'epoch': 5.71}\n",
            "{'loss': 0.1258, 'learning_rate': 7.704551013343313e-05, 'epoch': 5.82}\n",
            "{'loss': 0.1247, 'learning_rate': 7.704551013343313e-05, 'epoch': 5.93}\n",
            "{'loss': 0.1499, 'learning_rate': 7.704551013343313e-05, 'epoch': 6.04}\n",
            "{'loss': 0.153, 'learning_rate': 7.704551013343313e-05, 'epoch': 6.15}\n",
            "{'loss': 0.0916, 'learning_rate': 7.704551013343313e-05, 'epoch': 6.26}\n",
            "{'loss': 0.1714, 'learning_rate': 7.704551013343313e-05, 'epoch': 6.37}\n",
            "{'loss': 0.0971, 'learning_rate': 7.704551013343313e-05, 'epoch': 6.48}\n",
            "{'loss': 0.1322, 'learning_rate': 7.704551013343313e-05, 'epoch': 6.59}\n",
            "{'loss': 0.0879, 'learning_rate': 7.704551013343313e-05, 'epoch': 6.7}\n",
            "{'loss': 0.1672, 'learning_rate': 7.704551013343313e-05, 'epoch': 6.81}\n",
            "{'loss': 0.1328, 'learning_rate': 7.704551013343313e-05, 'epoch': 6.92}\n",
            "{'loss': 0.0934, 'learning_rate': 7.704551013343313e-05, 'epoch': 7.03}\n",
            "{'loss': 0.0428, 'learning_rate': 7.704551013343313e-05, 'epoch': 7.14}\n",
            "{'loss': 0.0672, 'learning_rate': 7.704551013343313e-05, 'epoch': 7.25}\n",
            "{'loss': 0.0617, 'learning_rate': 7.704551013343313e-05, 'epoch': 7.36}\n",
            "{'loss': 0.1159, 'learning_rate': 7.704551013343313e-05, 'epoch': 7.47}\n",
            "{'loss': 0.0547, 'learning_rate': 7.704551013343313e-05, 'epoch': 7.58}\n",
            "{'loss': 0.0991, 'learning_rate': 7.704551013343313e-05, 'epoch': 7.69}\n",
            "{'loss': 0.0416, 'learning_rate': 7.704551013343313e-05, 'epoch': 7.8}\n",
            "{'loss': 0.0515, 'learning_rate': 7.704551013343313e-05, 'epoch': 7.91}\n",
            "{'loss': 0.0461, 'learning_rate': 7.704551013343313e-05, 'epoch': 8.02}\n",
            "{'loss': 0.0502, 'learning_rate': 7.704551013343313e-05, 'epoch': 8.13}\n",
            "{'loss': 0.0544, 'learning_rate': 7.704551013343313e-05, 'epoch': 8.24}\n",
            "{'loss': 0.0943, 'learning_rate': 7.704551013343313e-05, 'epoch': 8.35}\n",
            "{'loss': 0.0024, 'learning_rate': 7.704551013343313e-05, 'epoch': 8.46}\n",
            "{'loss': 0.0397, 'learning_rate': 7.704551013343313e-05, 'epoch': 8.57}\n",
            "{'loss': 0.0696, 'learning_rate': 7.704551013343313e-05, 'epoch': 8.68}\n",
            "{'loss': 0.0489, 'learning_rate': 7.704551013343313e-05, 'epoch': 8.79}\n",
            "{'loss': 0.0712, 'learning_rate': 7.704551013343313e-05, 'epoch': 8.9}\n",
            "{'loss': 0.0019, 'learning_rate': 7.704551013343313e-05, 'epoch': 9.01}\n",
            "{'loss': 0.0307, 'learning_rate': 7.704551013343313e-05, 'epoch': 9.12}\n",
            "{'loss': 0.0012, 'learning_rate': 7.704551013343313e-05, 'epoch': 9.23}\n",
            "{'loss': 0.0577, 'learning_rate': 7.704551013343313e-05, 'epoch': 9.34}\n",
            "{'loss': 0.0888, 'learning_rate': 7.704551013343313e-05, 'epoch': 9.45}\n",
            "{'loss': 0.0416, 'learning_rate': 7.704551013343313e-05, 'epoch': 9.56}\n",
            "{'loss': 0.08, 'learning_rate': 7.704551013343313e-05, 'epoch': 9.67}\n",
            "{'loss': 0.0616, 'learning_rate': 7.704551013343313e-05, 'epoch': 9.78}\n",
            "{'loss': 0.0478, 'learning_rate': 7.704551013343313e-05, 'epoch': 9.89}\n",
            "{'loss': 0.0345, 'learning_rate': 7.704551013343313e-05, 'epoch': 10.0}\n",
            "{'train_runtime': 145.4616, 'train_samples_per_second': 99.339, 'train_steps_per_second': 6.256, 'train_loss': 0.20614555581667265, 'epoch': 10.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 26/26 [00:01<00:00, 24.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 22:37:43,306] Trial 28 finished with value: 0.9081364829396325 and parameters: {'learning_rate': 7.704551013343313e-05, 'per_device_train_batch_size': 16, 'weight_decay': 0.20331602815049013, 'num_train_epochs': 10, 'warmup_steps': 122, 'freeze_layers': 9, 'dropout': 0.12496704634292015, 'lr_scheduler_type': 'constant_with_warmup'}. Best is trial 19 with value: 0.9289340101522843.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: cosine\n",
            " Warmup steps (True): 66\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a2f48dc8171249f28358e34e081bffba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1629 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7609, 'learning_rate': 2.493265119131855e-06, 'epoch': 0.06}\n",
            "{'loss': 0.6834, 'learning_rate': 6.233162797829637e-06, 'epoch': 0.11}\n",
            "{'loss': 0.7233, 'learning_rate': 1.0388604663049395e-05, 'epoch': 0.17}\n",
            "{'loss': 0.7479, 'learning_rate': 1.4544046528269153e-05, 'epoch': 0.22}\n",
            "{'loss': 0.6932, 'learning_rate': 1.869948839348891e-05, 'epoch': 0.28}\n",
            "{'loss': 0.6746, 'learning_rate': 2.2854930258708672e-05, 'epoch': 0.33}\n",
            "{'loss': 0.6739, 'learning_rate': 2.701037212392843e-05, 'epoch': 0.39}\n",
            "{'loss': 0.6861, 'learning_rate': 2.742367265523082e-05, 'epoch': 0.44}\n",
            "{'loss': 0.6425, 'learning_rate': 2.7415917752617403e-05, 'epoch': 0.5}\n",
            "{'loss': 0.5624, 'learning_rate': 2.7402627035295193e-05, 'epoch': 0.55}\n",
            "{'loss': 0.5866, 'learning_rate': 2.7383805872538465e-05, 'epoch': 0.61}\n",
            "{'loss': 0.4828, 'learning_rate': 2.7359461867848404e-05, 'epoch': 0.66}\n",
            "{'loss': 0.3756, 'learning_rate': 2.732960485588141e-05, 'epoch': 0.72}\n",
            "{'loss': 0.5311, 'learning_rate': 2.729424689847601e-05, 'epoch': 0.77}\n",
            "{'loss': 0.5227, 'learning_rate': 2.7253402279780035e-05, 'epoch': 0.83}\n",
            "{'loss': 0.4167, 'learning_rate': 2.720708750048003e-05, 'epoch': 0.88}\n",
            "{'loss': 0.3215, 'learning_rate': 2.7155321271135167e-05, 'epoch': 0.94}\n",
            "{'loss': 0.6634, 'learning_rate': 2.7098124504618455e-05, 'epoch': 0.99}\n",
            "{'loss': 0.3237, 'learning_rate': 2.703552030766819e-05, 'epoch': 1.05}\n",
            "{'loss': 0.3497, 'learning_rate': 2.6967533971553163e-05, 'epoch': 1.1}\n",
            "{'loss': 0.4739, 'learning_rate': 2.6894192961855296e-05, 'epoch': 1.16}\n",
            "{'loss': 0.4008, 'learning_rate': 2.6815526907373927e-05, 'epoch': 1.22}\n",
            "{'loss': 0.3703, 'learning_rate': 2.673156758815616e-05, 'epoch': 1.27}\n",
            "{'loss': 0.4975, 'learning_rate': 2.6642348922658155e-05, 'epoch': 1.33}\n",
            "{'loss': 0.412, 'learning_rate': 2.6547906954042496e-05, 'epoch': 1.38}\n",
            "{'loss': 0.282, 'learning_rate': 2.6448279835617255e-05, 'epoch': 1.44}\n",
            "{'loss': 0.3403, 'learning_rate': 2.6343507815422547e-05, 'epoch': 1.49}\n",
            "{'loss': 0.424, 'learning_rate': 2.6233633219970854e-05, 'epoch': 1.55}\n",
            "{'loss': 0.3674, 'learning_rate': 2.6118700437147685e-05, 'epoch': 1.6}\n",
            "{'loss': 0.3545, 'learning_rate': 2.5998755898279426e-05, 'epoch': 1.66}\n",
            "{'loss': 0.3911, 'learning_rate': 2.5873848059375733e-05, 'epoch': 1.71}\n",
            "{'loss': 0.4617, 'learning_rate': 2.5744027381553933e-05, 'epoch': 1.77}\n",
            "{'loss': 0.1782, 'learning_rate': 2.5609346310653367e-05, 'epoch': 1.82}\n",
            "{'loss': 0.4905, 'learning_rate': 2.5469859256048024e-05, 'epoch': 1.88}\n",
            "{'loss': 0.3846, 'learning_rate': 2.532562256866582e-05, 'epoch': 1.93}\n",
            "{'loss': 0.3166, 'learning_rate': 2.517669451822359e-05, 'epoch': 1.99}\n",
            "{'loss': 0.2962, 'learning_rate': 2.5023135269686888e-05, 'epoch': 2.04}\n",
            "{'loss': 0.166, 'learning_rate': 2.4865006858964145e-05, 'epoch': 2.1}\n",
            "{'loss': 0.464, 'learning_rate': 2.4702373167844957e-05, 'epoch': 2.15}\n",
            "{'loss': 0.2239, 'learning_rate': 2.4535299898192717e-05, 'epoch': 2.21}\n",
            "{'loss': 0.2918, 'learning_rate': 2.4363854545401902e-05, 'epoch': 2.27}\n",
            "{'loss': 0.3389, 'learning_rate': 2.418810637113084e-05, 'epoch': 2.32}\n",
            "{'loss': 0.2805, 'learning_rate': 2.4008126375320915e-05, 'epoch': 2.38}\n",
            "{'loss': 0.2905, 'learning_rate': 2.3823987267513522e-05, 'epoch': 2.43}\n",
            "{'loss': 0.265, 'learning_rate': 2.363576343747638e-05, 'epoch': 2.49}\n",
            "{'loss': 0.3529, 'learning_rate': 2.3443530925151037e-05, 'epoch': 2.54}\n",
            "{'loss': 0.2577, 'learning_rate': 2.324736738993375e-05, 'epoch': 2.6}\n",
            "{'loss': 0.3658, 'learning_rate': 2.3047352079302102e-05, 'epoch': 2.65}\n",
            "{'loss': 0.1741, 'learning_rate': 2.2843565796800082e-05, 'epoch': 2.71}\n",
            "{'loss': 0.2065, 'learning_rate': 2.263609086939452e-05, 'epoch': 2.76}\n",
            "{'loss': 0.2778, 'learning_rate': 2.242501111421605e-05, 'epoch': 2.82}\n",
            "{'loss': 0.3898, 'learning_rate': 2.221041180469814e-05, 'epoch': 2.87}\n",
            "{'loss': 0.2901, 'learning_rate': 2.1992379636127722e-05, 'epoch': 2.93}\n",
            "{'loss': 0.0876, 'learning_rate': 2.177100269062145e-05, 'epoch': 2.98}\n",
            "{'loss': 0.0759, 'learning_rate': 2.154637040154169e-05, 'epoch': 3.04}\n",
            "{'loss': 0.2134, 'learning_rate': 2.1318573517366615e-05, 'epoch': 3.09}\n",
            "{'loss': 0.0369, 'learning_rate': 2.1087704065029026e-05, 'epoch': 3.15}\n",
            "{'loss': 0.01, 'learning_rate': 2.0853855312738676e-05, 'epoch': 3.2}\n",
            "{'loss': 0.0898, 'learning_rate': 2.0617121732303172e-05, 'epoch': 3.26}\n",
            "{'loss': 0.0442, 'learning_rate': 2.037759896096257e-05, 'epoch': 3.31}\n",
            "{'loss': 0.2708, 'learning_rate': 2.013538376275323e-05, 'epoch': 3.37}\n",
            "{'loss': 0.0708, 'learning_rate': 1.9890573989416413e-05, 'epoch': 3.43}\n",
            "{'loss': 0.186, 'learning_rate': 1.964326854086745e-05, 'epoch': 3.48}\n",
            "{'loss': 0.1827, 'learning_rate': 1.9393567325241512e-05, 'epoch': 3.54}\n",
            "{'loss': 0.1838, 'learning_rate': 1.9141571218532028e-05, 'epoch': 3.59}\n",
            "{'loss': 0.4167, 'learning_rate': 1.88873820238381e-05, 'epoch': 3.65}\n",
            "{'loss': 0.1696, 'learning_rate': 1.8631102430237454e-05, 'epoch': 3.7}\n",
            "{'loss': 0.0353, 'learning_rate': 1.8372835971301314e-05, 'epoch': 3.76}\n",
            "{'loss': 0.1156, 'learning_rate': 1.8112686983268295e-05, 'epoch': 3.81}\n",
            "{'loss': 0.2584, 'learning_rate': 1.7850760562893908e-05, 'epoch': 3.87}\n",
            "{'loss': 0.0994, 'learning_rate': 1.758716252499283e-05, 'epoch': 3.92}\n",
            "{'loss': 0.2855, 'learning_rate': 1.7321999359691164e-05, 'epoch': 3.98}\n",
            "{'loss': 0.0064, 'learning_rate': 1.705537818940581e-05, 'epoch': 4.03}\n",
            "{'loss': 0.0015, 'learning_rate': 1.678740672556841e-05, 'epoch': 4.09}\n",
            "{'loss': 0.1551, 'learning_rate': 1.6518193225111398e-05, 'epoch': 4.14}\n",
            "{'loss': 0.1047, 'learning_rate': 1.6247846446733572e-05, 'epoch': 4.2}\n",
            "{'loss': 0.1448, 'learning_rate': 1.5976475606963055e-05, 'epoch': 4.25}\n",
            "{'loss': 0.0803, 'learning_rate': 1.5704190336035247e-05, 'epoch': 4.31}\n",
            "{'loss': 0.0509, 'learning_rate': 1.543110063360366e-05, 'epoch': 4.36}\n",
            "{'loss': 0.1236, 'learning_rate': 1.515731682430151e-05, 'epoch': 4.42}\n",
            "{'loss': 0.0247, 'learning_rate': 1.4882949513172018e-05, 'epoch': 4.48}\n",
            "{'loss': 0.1755, 'learning_rate': 1.4608109540985443e-05, 'epoch': 4.53}\n",
            "{'loss': 0.1374, 'learning_rate': 1.4332907939460866e-05, 'epoch': 4.59}\n",
            "{'loss': 0.3603, 'learning_rate': 1.405745588641084e-05, 'epoch': 4.64}\n",
            "{'loss': 0.0036, 'learning_rate': 1.3781864660827036e-05, 'epoch': 4.7}\n",
            "{'loss': 0.0574, 'learning_rate': 1.3506245597924987e-05, 'epoch': 4.75}\n",
            "{'loss': 0.0804, 'learning_rate': 1.323071004416613e-05, 'epoch': 4.81}\n",
            "{'loss': 0.0697, 'learning_rate': 1.2955369312275316e-05, 'epoch': 4.86}\n",
            "{'loss': 0.0044, 'learning_rate': 1.2680334636271935e-05, 'epoch': 4.92}\n",
            "{'loss': 0.1747, 'learning_rate': 1.2405717126532838e-05, 'epoch': 4.97}\n",
            "{'loss': 0.0848, 'learning_rate': 1.2131627724905212e-05, 'epoch': 5.03}\n",
            "{'loss': 0.072, 'learning_rate': 1.185817715988755e-05, 'epoch': 5.08}\n",
            "{'loss': 0.0039, 'learning_rate': 1.1585475901896778e-05, 'epoch': 5.14}\n",
            "{'loss': 0.0018, 'learning_rate': 1.1313634118639698e-05, 'epoch': 5.19}\n",
            "{'loss': 0.1582, 'learning_rate': 1.1042761630606651e-05, 'epoch': 5.25}\n",
            "{'loss': 0.0972, 'learning_rate': 1.0772967866705514e-05, 'epoch': 5.3}\n",
            "{'loss': 0.0573, 'learning_rate': 1.0504361820053873e-05, 'epoch': 5.36}\n",
            "{'loss': 0.101, 'learning_rate': 1.023705200394721e-05, 'epoch': 5.41}\n",
            "{'loss': 0.0876, 'learning_rate': 9.971146408021011e-06, 'epoch': 5.47}\n",
            "{'loss': 0.0127, 'learning_rate': 9.70675245462433e-06, 'epoch': 5.52}\n",
            "{'loss': 0.0853, 'learning_rate': 9.44397695542261e-06, 'epoch': 5.58}\n",
            "{'loss': 0.0011, 'learning_rate': 9.182926068247187e-06, 'epoch': 5.64}\n",
            "{'loss': 0.0012, 'learning_rate': 8.92370525420889e-06, 'epoch': 5.69}\n",
            "{'loss': 0.15, 'learning_rate': 8.666419235093196e-06, 'epoch': 5.75}\n",
            "{'loss': 0.0705, 'learning_rate': 8.41117195105397e-06, 'epoch': 5.8}\n",
            "{'loss': 0.0015, 'learning_rate': 8.158066518623018e-06, 'epoch': 5.86}\n",
            "{'loss': 0.0008, 'learning_rate': 7.907205189052414e-06, 'epoch': 5.91}\n",
            "{'loss': 0.1363, 'learning_rate': 7.65868930700629e-06, 'epoch': 5.97}\n",
            "{'loss': 0.001, 'learning_rate': 7.412619269618963e-06, 'epoch': 6.02}\n",
            "{'loss': 0.0012, 'learning_rate': 7.169094485935805e-06, 'epoch': 6.08}\n",
            "{'loss': 0.0009, 'learning_rate': 6.928213336753298e-06, 'epoch': 6.13}\n",
            "{'loss': 0.0127, 'learning_rate': 6.690073134874523e-06, 'epoch': 6.19}\n",
            "{'loss': 0.0009, 'learning_rate': 6.45477008579602e-06, 'epoch': 6.24}\n",
            "{'loss': 0.2581, 'learning_rate': 6.2223992488420945e-06, 'epoch': 6.3}\n",
            "{'loss': 0.0076, 'learning_rate': 5.993054498762051e-06, 'epoch': 6.35}\n",
            "{'loss': 0.0012, 'learning_rate': 5.7668284878060705e-06, 'epoch': 6.41}\n",
            "{'loss': 0.0287, 'learning_rate': 5.54381260829493e-06, 'epoch': 6.46}\n",
            "{'loss': 0.001, 'learning_rate': 5.324096955698676e-06, 'epoch': 6.52}\n",
            "{'loss': 0.0882, 'learning_rate': 5.10777029223929e-06, 'epoch': 6.57}\n",
            "{'loss': 0.0029, 'learning_rate': 4.894920011031872e-06, 'epoch': 6.63}\n",
            "{'loss': 0.0012, 'learning_rate': 4.685632100779015e-06, 'epoch': 6.69}\n",
            "{'loss': 0.08, 'learning_rate': 4.479991111032502e-06, 'epoch': 6.74}\n",
            "{'loss': 0.0012, 'learning_rate': 4.278080118036381e-06, 'epoch': 6.8}\n",
            "{'loss': 0.0865, 'learning_rate': 4.079980691165284e-06, 'epoch': 6.85}\n",
            "{'loss': 0.1023, 'learning_rate': 3.885772859971463e-06, 'epoch': 6.91}\n",
            "{'loss': 0.0274, 'learning_rate': 3.695535081853896e-06, 'epoch': 6.96}\n",
            "{'loss': 0.0008, 'learning_rate': 3.509344210362574e-06, 'epoch': 7.02}\n",
            "{'loss': 0.0014, 'learning_rate': 3.3272754641506345e-06, 'epoch': 7.07}\n",
            "{'loss': 0.0007, 'learning_rate': 3.149402396587058e-06, 'epoch': 7.13}\n",
            "{'loss': 0.0006, 'learning_rate': 2.975796866042054e-06, 'epoch': 7.18}\n",
            "{'loss': 0.0005, 'learning_rate': 2.806529006857232e-06, 'epoch': 7.24}\n",
            "{'loss': 0.0006, 'learning_rate': 2.641667201012265e-06, 'epoch': 7.29}\n",
            "{'loss': 0.0021, 'learning_rate': 2.4812780504994556e-06, 'epoch': 7.35}\n",
            "{'loss': 0.0006, 'learning_rate': 2.3254263504174347e-06, 'epoch': 7.4}\n",
            "{'loss': 0.0006, 'learning_rate': 2.1741750627947725e-06, 'epoch': 7.46}\n",
            "{'loss': 0.0976, 'learning_rate': 2.027585291154163e-06, 'epoch': 7.51}\n",
            "{'loss': 0.0005, 'learning_rate': 1.8857162558274068e-06, 'epoch': 7.57}\n",
            "{'loss': 0.172, 'learning_rate': 1.7486252700311749e-06, 'epoch': 7.62}\n",
            "{'loss': 0.0006, 'learning_rate': 1.6163677167132389e-06, 'epoch': 7.68}\n",
            "{'loss': 0.0859, 'learning_rate': 1.488997026178475e-06, 'epoch': 7.73}\n",
            "{'loss': 0.001, 'learning_rate': 1.3665646545037306e-06, 'epoch': 7.79}\n",
            "{'loss': 0.0009, 'learning_rate': 1.2491200627502577e-06, 'epoch': 7.85}\n",
            "{'loss': 0.0006, 'learning_rate': 1.1367106969820865e-06, 'epoch': 7.9}\n",
            "{'loss': 0.0007, 'learning_rate': 1.0293819690984553e-06, 'epoch': 7.96}\n",
            "{'loss': 0.0006, 'learning_rate': 9.27177238487985e-07, 'epoch': 8.01}\n",
            "{'loss': 0.0006, 'learning_rate': 8.301377945120729e-07, 'epoch': 8.07}\n",
            "{'loss': 0.0482, 'learning_rate': 7.383028398245303e-07, 'epoch': 8.12}\n",
            "{'loss': 0.0069, 'learning_rate': 6.517094745342292e-07, 'epoch': 8.18}\n",
            "{'loss': 0.0006, 'learning_rate': 5.703926812171517e-07, 'epoch': 8.23}\n",
            "{'loss': 0.0005, 'learning_rate': 4.943853107838854e-07, 'epoch': 8.29}\n",
            "{'loss': 0.0971, 'learning_rate': 4.237180692082883e-07, 'epoch': 8.34}\n",
            "{'loss': 0.0798, 'learning_rate': 3.5841950512269077e-07, 'epoch': 8.4}\n",
            "{'loss': 0.069, 'learning_rate': 2.9851599828461285e-07, 'epoch': 8.45}\n",
            "{'loss': 0.0008, 'learning_rate': 2.4403174891970296e-07, 'epoch': 8.51}\n",
            "{'loss': 0.0005, 'learning_rate': 1.949887679451559e-07, 'epoch': 8.56}\n",
            "{'loss': 0.0011, 'learning_rate': 1.5140686807759563e-07, 'epoch': 8.62}\n",
            "{'loss': 0.0006, 'learning_rate': 1.1330365582900633e-07, 'epoch': 8.67}\n",
            "{'loss': 0.0005, 'learning_rate': 8.069452439392175e-08, 'epoch': 8.73}\n",
            "{'loss': 0.0009, 'learning_rate': 5.3592647430790414e-08, 'epoch': 8.78}\n",
            "{'loss': 0.0008, 'learning_rate': 3.200897373998259e-08, 'epoch': 8.84}\n",
            "{'loss': 0.0006, 'learning_rate': 1.5952222840625624e-08, 'epoch': 8.9}\n",
            "{'loss': 0.0099, 'learning_rate': 5.428881448027398e-09, 'epoch': 8.95}\n",
            "{'train_runtime': 163.7979, 'train_samples_per_second': 79.397, 'train_steps_per_second': 9.945, 'train_loss': 0.18170683668581042, 'epoch': 9.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 52/52 [00:01<00:00, 38.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 22:40:30,878] Trial 29 finished with value: 0.8944723618090453 and parameters: {'learning_rate': 2.7425916310450404e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.21789238248525802, 'num_train_epochs': 9, 'warmup_steps': 66, 'freeze_layers': 9, 'dropout': 0.2163456240607394, 'lr_scheduler_type': 'cosine'}. Best is trial 19 with value: 0.9289340101522843.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: cosine\n",
            " Warmup steps (True): 174\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c3ded56ecc14442182c0361ec791aced",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/910 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.734, 'learning_rate': 9.36321332846728e-07, 'epoch': 0.11}\n",
            "{'loss': 0.6955, 'learning_rate': 1.7686069620438197e-06, 'epoch': 0.22}\n",
            "{'loss': 0.703, 'learning_rate': 2.808963998540184e-06, 'epoch': 0.33}\n",
            "{'loss': 0.6873, 'learning_rate': 3.745285331386912e-06, 'epoch': 0.44}\n",
            "{'loss': 0.6722, 'learning_rate': 4.785642367883277e-06, 'epoch': 0.55}\n",
            "{'loss': 0.7282, 'learning_rate': 5.825999404379641e-06, 'epoch': 0.66}\n",
            "{'loss': 0.6649, 'learning_rate': 6.866356440876005e-06, 'epoch': 0.77}\n",
            "{'loss': 0.6898, 'learning_rate': 7.90671347737237e-06, 'epoch': 0.88}\n",
            "{'loss': 0.6904, 'learning_rate': 8.947070513868735e-06, 'epoch': 0.99}\n",
            "{'loss': 0.6657, 'learning_rate': 9.9874275503651e-06, 'epoch': 1.1}\n",
            "{'loss': 0.646, 'learning_rate': 1.1027784586861464e-05, 'epoch': 1.21}\n",
            "{'loss': 0.6394, 'learning_rate': 1.2068141623357827e-05, 'epoch': 1.32}\n",
            "{'loss': 0.6124, 'learning_rate': 1.3108498659854193e-05, 'epoch': 1.43}\n",
            "{'loss': 0.5927, 'learning_rate': 1.4148855696350558e-05, 'epoch': 1.54}\n",
            "{'loss': 0.5381, 'learning_rate': 1.518921273284692e-05, 'epoch': 1.65}\n",
            "{'loss': 0.5257, 'learning_rate': 1.6229569769343285e-05, 'epoch': 1.76}\n",
            "{'loss': 0.4846, 'learning_rate': 1.726992680583965e-05, 'epoch': 1.87}\n",
            "{'loss': 0.5442, 'learning_rate': 1.810188261796137e-05, 'epoch': 1.98}\n",
            "{'loss': 0.4171, 'learning_rate': 1.8090341543979355e-05, 'epoch': 2.09}\n",
            "{'loss': 0.4741, 'learning_rate': 1.806233364504276e-05, 'epoch': 2.2}\n",
            "{'loss': 0.4008, 'learning_rate': 1.8017909943295874e-05, 'epoch': 2.31}\n",
            "{'loss': 0.4452, 'learning_rate': 1.7957151365641708e-05, 'epoch': 2.42}\n",
            "{'loss': 0.3439, 'learning_rate': 1.7880168596316986e-05, 'epoch': 2.53}\n",
            "{'loss': 0.4098, 'learning_rate': 1.7787101875258078e-05, 'epoch': 2.64}\n",
            "{'loss': 0.3343, 'learning_rate': 1.767812074262512e-05, 'epoch': 2.75}\n",
            "{'loss': 0.3678, 'learning_rate': 1.755342372994978e-05, 'epoch': 2.86}\n",
            "{'loss': 0.3155, 'learning_rate': 1.7413237998469244e-05, 'epoch': 2.97}\n",
            "{'loss': 0.2319, 'learning_rate': 1.7257818925305377e-05, 'epoch': 3.08}\n",
            "{'loss': 0.1921, 'learning_rate': 1.7087449638242764e-05, 'epoch': 3.19}\n",
            "{'loss': 0.4244, 'learning_rate': 1.6902440499953298e-05, 'epoch': 3.3}\n",
            "{'loss': 0.3087, 'learning_rate': 1.670312854260674e-05, 'epoch': 3.41}\n",
            "{'loss': 0.4407, 'learning_rate': 1.6489876853897415e-05, 'epoch': 3.52}\n",
            "{'loss': 0.4946, 'learning_rate': 1.6263073915605282e-05, 'epoch': 3.63}\n",
            "{'loss': 0.1912, 'learning_rate': 1.6023132895896594e-05, 'epoch': 3.74}\n",
            "{'loss': 0.2216, 'learning_rate': 1.5770490896653117e-05, 'epoch': 3.85}\n",
            "{'loss': 0.2586, 'learning_rate': 1.550560815720124e-05, 'epoch': 3.96}\n",
            "{'loss': 0.1791, 'learning_rate': 1.522896721589144e-05, 'epoch': 4.07}\n",
            "{'loss': 0.157, 'learning_rate': 1.4941072031055514e-05, 'epoch': 4.18}\n",
            "{'loss': 0.1463, 'learning_rate': 1.4642447062942896e-05, 'epoch': 4.29}\n",
            "{'loss': 0.1032, 'learning_rate': 1.4333636318308506e-05, 'epoch': 4.4}\n",
            "{'loss': 0.1815, 'learning_rate': 1.4015202359392664e-05, 'epoch': 4.51}\n",
            "{'loss': 0.3653, 'learning_rate': 1.368772527909833e-05, 'epoch': 4.62}\n",
            "{'loss': 0.1688, 'learning_rate': 1.3351801644232656e-05, 'epoch': 4.73}\n",
            "{'loss': 0.2288, 'learning_rate': 1.300804340873795e-05, 'epoch': 4.84}\n",
            "{'loss': 0.1579, 'learning_rate': 1.2657076798891783e-05, 'epoch': 4.95}\n",
            "{'loss': 0.179, 'learning_rate': 1.2299541172507123e-05, 'epoch': 5.05}\n",
            "{'loss': 0.1719, 'learning_rate': 1.1936087854210674e-05, 'epoch': 5.16}\n",
            "{'loss': 0.2463, 'learning_rate': 1.1567378948921207e-05, 'epoch': 5.27}\n",
            "{'loss': 0.1053, 'learning_rate': 1.119408613568936e-05, 'epoch': 5.38}\n",
            "{'loss': 0.1099, 'learning_rate': 1.0816889444096213e-05, 'epoch': 5.49}\n",
            "{'loss': 0.2078, 'learning_rate': 1.043647601543962e-05, 'epoch': 5.6}\n",
            "{'loss': 0.0676, 'learning_rate': 1.0053538850965139e-05, 'epoch': 5.71}\n",
            "{'loss': 0.1787, 'learning_rate': 9.668775549421804e-06, 'epoch': 5.82}\n",
            "{'loss': 0.1443, 'learning_rate': 9.282887036242647e-06, 'epoch': 5.93}\n",
            "{'loss': 0.0681, 'learning_rate': 8.896576286664955e-06, 'epoch': 6.04}\n",
            "{'loss': 0.0633, 'learning_rate': 8.510547045116395e-06, 'epoch': 6.15}\n",
            "{'loss': 0.0648, 'learning_rate': 8.1255025431999e-06, 'epoch': 6.26}\n",
            "{'loss': 0.102, 'learning_rate': 7.742144218612775e-06, 'epoch': 6.37}\n",
            "{'loss': 0.0961, 'learning_rate': 7.361170437333765e-06, 'epoch': 6.48}\n",
            "{'loss': 0.1489, 'learning_rate': 6.9832752214058875e-06, 'epoch': 6.59}\n",
            "{'loss': 0.2191, 'learning_rate': 6.6091469846326465e-06, 'epoch': 6.7}\n",
            "{'loss': 0.1361, 'learning_rate': 6.239467278490805e-06, 'epoch': 6.81}\n",
            "{'loss': 0.0468, 'learning_rate': 5.874909550544275e-06, 'epoch': 6.92}\n",
            "{'loss': 0.1083, 'learning_rate': 5.516137917620991e-06, 'epoch': 7.03}\n",
            "{'loss': 0.076, 'learning_rate': 5.163805955987601e-06, 'epoch': 7.14}\n",
            "{'loss': 0.0905, 'learning_rate': 4.8185555107259704e-06, 'epoch': 7.25}\n",
            "{'loss': 0.0573, 'learning_rate': 4.481015526480453e-06, 'epoch': 7.36}\n",
            "{'loss': 0.0974, 'learning_rate': 4.15180090170595e-06, 'epoch': 7.47}\n",
            "{'loss': 0.0447, 'learning_rate': 3.831511368504001e-06, 'epoch': 7.58}\n",
            "{'loss': 0.0881, 'learning_rate': 3.5207304000874987e-06, 'epoch': 7.69}\n",
            "{'loss': 0.0326, 'learning_rate': 3.2200241478643125e-06, 'epoch': 7.8}\n",
            "{'loss': 0.0446, 'learning_rate': 2.9299404100761368e-06, 'epoch': 7.91}\n",
            "{'loss': 0.0275, 'learning_rate': 2.651007633871409e-06, 'epoch': 8.02}\n",
            "{'loss': 0.1324, 'learning_rate': 2.3837339526302197e-06, 'epoch': 8.13}\n",
            "{'loss': 0.1163, 'learning_rate': 2.128606260294923e-06, 'epoch': 8.24}\n",
            "{'loss': 0.0687, 'learning_rate': 1.8860893243927512e-06, 'epoch': 8.35}\n",
            "{'loss': 0.1288, 'learning_rate': 1.6566249393662413e-06, 'epoch': 8.46}\n",
            "{'loss': 0.0784, 'learning_rate': 1.4406311217538593e-06, 'epoch': 8.57}\n",
            "{'loss': 0.0664, 'learning_rate': 1.2385013486869606e-06, 'epoch': 8.68}\n",
            "{'loss': 0.0178, 'learning_rate': 1.0506038410903227e-06, 'epoch': 8.79}\n",
            "{'loss': 0.0239, 'learning_rate': 8.772808928920542e-07, 'epoch': 8.9}\n",
            "{'loss': 0.0023, 'learning_rate': 7.188482474648557e-07, 'epoch': 9.01}\n",
            "{'loss': 0.0495, 'learning_rate': 5.755945224345663e-07, 'epoch': 9.12}\n",
            "{'loss': 0.0371, 'learning_rate': 4.4778068390384625e-07, 'epoch': 9.23}\n",
            "{'loss': 0.0596, 'learning_rate': 3.356395710487824e-07, 'epoch': 9.34}\n",
            "{'loss': 0.043, 'learning_rate': 2.3937547195446944e-07, 'epoch': 9.45}\n",
            "{'loss': 0.0363, 'learning_rate': 1.5916375146228714e-07, 'epoch': 9.56}\n",
            "{'loss': 0.0022, 'learning_rate': 9.515053170679117e-08, 'epoch': 9.67}\n",
            "{'loss': 0.0466, 'learning_rate': 4.745242592421281e-08, 'epoch': 9.78}\n",
            "{'loss': 0.1083, 'learning_rate': 1.6156326017488773e-08, 'epoch': 9.89}\n",
            "{'loss': 0.0383, 'learning_rate': 1.319244264793483e-09, 'epoch': 10.0}\n",
            "{'train_runtime': 141.7906, 'train_samples_per_second': 101.911, 'train_steps_per_second': 6.418, 'train_loss': 0.2588263514073013, 'epoch': 10.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 26/26 [00:01<00:00, 22.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 22:42:56,367] Trial 30 finished with value: 0.896551724137931 and parameters: {'learning_rate': 1.8102212435036742e-05, 'per_device_train_batch_size': 16, 'weight_decay': 0.14008504618951317, 'num_train_epochs': 10, 'warmup_steps': 174, 'freeze_layers': 6, 'dropout': 0.1720673551849773, 'lr_scheduler_type': 'cosine'}. Best is trial 19 with value: 0.9289340101522843.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: cosine_with_restarts\n",
            " Warmup steps (True): 5\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "045bdae4a24443d68322cdfa7824f15b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1448 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7694, 'learning_rate': 4.644633120712237e-05, 'epoch': 0.06}\n",
            "{'loss': 0.6697, 'learning_rate': 4.6438626374432247e-05, 'epoch': 0.11}\n",
            "{'loss': 0.6318, 'learning_rate': 4.641991818540551e-05, 'epoch': 0.17}\n",
            "{'loss': 0.6633, 'learning_rate': 4.639021550714363e-05, 'epoch': 0.22}\n",
            "{'loss': 0.8149, 'learning_rate': 4.6349532417795045e-05, 'epoch': 0.28}\n",
            "{'loss': 0.7512, 'learning_rate': 4.6297888199882554e-05, 'epoch': 0.33}\n",
            "{'loss': 0.7151, 'learning_rate': 4.6235307331163984e-05, 'epoch': 0.39}\n",
            "{'loss': 0.7125, 'learning_rate': 4.616181947303051e-05, 'epoch': 0.44}\n",
            "{'loss': 0.6975, 'learning_rate': 4.60774594564481e-05, 'epoch': 0.5}\n",
            "{'loss': 0.6537, 'learning_rate': 4.598226726544864e-05, 'epoch': 0.55}\n",
            "{'loss': 0.7667, 'learning_rate': 4.5876288018178825e-05, 'epoch': 0.61}\n",
            "{'loss': 0.7051, 'learning_rate': 4.575957194551552e-05, 'epoch': 0.66}\n",
            "{'loss': 0.6892, 'learning_rate': 4.563217436725786e-05, 'epoch': 0.72}\n",
            "{'loss': 0.6732, 'learning_rate': 4.550843366152646e-05, 'epoch': 0.77}\n",
            "{'loss': 0.6773, 'learning_rate': 4.537613728777957e-05, 'epoch': 0.83}\n",
            "{'loss': 0.5527, 'learning_rate': 4.521916877782581e-05, 'epoch': 0.88}\n",
            "{'loss': 0.473, 'learning_rate': 4.5051774896621634e-05, 'epoch': 0.94}\n",
            "{'loss': 0.6307, 'learning_rate': 4.487403498367596e-05, 'epoch': 0.99}\n",
            "{'loss': 0.525, 'learning_rate': 4.468603328219592e-05, 'epoch': 1.05}\n",
            "{'loss': 0.5245, 'learning_rate': 4.4487858899158206e-05, 'epoch': 1.1}\n",
            "{'loss': 0.507, 'learning_rate': 4.427960576307512e-05, 'epoch': 1.16}\n",
            "{'loss': 0.465, 'learning_rate': 4.406137257947535e-05, 'epoch': 1.22}\n",
            "{'loss': 0.3543, 'learning_rate': 4.383326278412068e-05, 'epoch': 1.27}\n",
            "{'loss': 0.4968, 'learning_rate': 4.359538449398056e-05, 'epoch': 1.33}\n",
            "{'loss': 0.369, 'learning_rate': 4.334785045598805e-05, 'epoch': 1.38}\n",
            "{'loss': 0.3651, 'learning_rate': 4.309077799360131e-05, 'epoch': 1.44}\n",
            "{'loss': 0.3377, 'learning_rate': 4.2824288951195845e-05, 'epoch': 1.49}\n",
            "{'loss': 0.5073, 'learning_rate': 4.25485096363141e-05, 'epoch': 1.55}\n",
            "{'loss': 0.4028, 'learning_rate': 4.22635707597996e-05, 'epoch': 1.6}\n",
            "{'loss': 0.4032, 'learning_rate': 4.1969607373844034e-05, 'epoch': 1.66}\n",
            "{'loss': 0.4558, 'learning_rate': 4.166675880797673e-05, 'epoch': 1.71}\n",
            "{'loss': 0.4381, 'learning_rate': 4.135516860302677e-05, 'epoch': 1.77}\n",
            "{'loss': 0.3147, 'learning_rate': 4.103498444308909e-05, 'epoch': 1.82}\n",
            "{'loss': 0.5245, 'learning_rate': 4.0706358085526806e-05, 'epoch': 1.88}\n",
            "{'loss': 0.5895, 'learning_rate': 4.036944528904289e-05, 'epoch': 1.93}\n",
            "{'loss': 0.4215, 'learning_rate': 4.002440573985543e-05, 'epoch': 1.99}\n",
            "{'loss': 0.5156, 'learning_rate': 3.9671402976011304e-05, 'epoch': 2.04}\n",
            "{'loss': 0.3811, 'learning_rate': 3.9310604309874177e-05, 'epoch': 2.1}\n",
            "{'loss': 0.392, 'learning_rate': 3.894218074882365e-05, 'epoch': 2.15}\n",
            "{'loss': 0.4092, 'learning_rate': 3.85663069142031e-05, 'epoch': 2.21}\n",
            "{'loss': 0.288, 'learning_rate': 3.8183160958554526e-05, 'epoch': 2.27}\n",
            "{'loss': 0.2992, 'learning_rate': 3.779292448117979e-05, 'epoch': 2.32}\n",
            "{'loss': 0.5125, 'learning_rate': 3.73957824420682e-05, 'epoch': 2.38}\n",
            "{'loss': 0.5483, 'learning_rate': 3.699192307423116e-05, 'epoch': 2.43}\n",
            "{'loss': 0.3173, 'learning_rate': 3.6581537794485615e-05, 'epoch': 2.49}\n",
            "{'loss': 0.4891, 'learning_rate': 3.6164821112728376e-05, 'epoch': 2.54}\n",
            "{'loss': 0.4027, 'learning_rate': 3.574197053974448e-05, 'epoch': 2.6}\n",
            "{'loss': 0.3567, 'learning_rate': 3.5313186493593204e-05, 'epoch': 2.65}\n",
            "{'loss': 0.3241, 'learning_rate': 3.4878672204616094e-05, 'epoch': 2.71}\n",
            "{'loss': 0.2086, 'learning_rate': 3.443863361911213e-05, 'epoch': 2.76}\n",
            "{'loss': 0.3831, 'learning_rate': 3.399327930172552e-05, 'epoch': 2.82}\n",
            "{'loss': 0.3904, 'learning_rate': 3.354282033659255e-05, 'epoch': 2.87}\n",
            "{'loss': 0.2427, 'learning_rate': 3.308747022729427e-05, 'epoch': 2.93}\n",
            "{'loss': 0.2959, 'learning_rate': 3.262744479566234e-05, 'epoch': 2.98}\n",
            "{'loss': 0.2117, 'learning_rate': 3.216296207948629e-05, 'epoch': 3.04}\n",
            "{'loss': 0.3462, 'learning_rate': 3.1694242229170273e-05, 'epoch': 3.09}\n",
            "{'loss': 0.2839, 'learning_rate': 3.1221507403388624e-05, 'epoch': 3.15}\n",
            "{'loss': 0.2612, 'learning_rate': 3.074498166378957e-05, 'epoch': 3.2}\n",
            "{'loss': 0.2863, 'learning_rate': 3.026489086879693e-05, 'epoch': 3.26}\n",
            "{'loss': 0.1587, 'learning_rate': 2.9781462566560208e-05, 'epoch': 3.31}\n",
            "{'loss': 0.4402, 'learning_rate': 2.9294925887103875e-05, 'epoch': 3.37}\n",
            "{'loss': 0.2061, 'learning_rate': 2.8805511433726803e-05, 'epoch': 3.43}\n",
            "{'loss': 0.2077, 'learning_rate': 2.8313451173703467e-05, 'epoch': 3.48}\n",
            "{'loss': 0.3965, 'learning_rate': 2.7818978328338636e-05, 'epoch': 3.54}\n",
            "{'loss': 0.2019, 'learning_rate': 2.732232726242774e-05, 'epoch': 3.59}\n",
            "{'loss': 0.247, 'learning_rate': 2.682373337317518e-05, 'epoch': 3.65}\n",
            "{'loss': 0.3171, 'learning_rate': 2.63234329786234e-05, 'epoch': 3.7}\n",
            "{'loss': 0.2095, 'learning_rate': 2.5821663205645413e-05, 'epoch': 3.76}\n",
            "{'loss': 0.6364, 'learning_rate': 2.531866187755405e-05, 'epoch': 3.81}\n",
            "{'loss': 0.2809, 'learning_rate': 2.4814667401381088e-05, 'epoch': 3.87}\n",
            "{'loss': 0.2611, 'learning_rate': 2.4309918654879683e-05, 'epoch': 3.92}\n",
            "{'loss': 0.473, 'learning_rate': 2.3804654873303745e-05, 'epoch': 3.98}\n",
            "{'loss': 0.1305, 'learning_rate': 2.3299115536017838e-05, 'epoch': 4.03}\n",
            "{'loss': 0.1089, 'learning_rate': 2.2793540252991388e-05, 'epoch': 4.09}\n",
            "{'loss': 0.161, 'learning_rate': 2.2288168651230975e-05, 'epoch': 4.14}\n",
            "{'loss': 0.2561, 'learning_rate': 2.1783240261204586e-05, 'epoch': 4.2}\n",
            "{'loss': 0.1608, 'learning_rate': 2.1278994403311598e-05, 'epoch': 4.25}\n",
            "{'loss': 0.0652, 'learning_rate': 2.0775670074452315e-05, 'epoch': 4.31}\n",
            "{'loss': 0.1521, 'learning_rate': 2.0273505834750836e-05, 'epoch': 4.36}\n",
            "{'loss': 0.0938, 'learning_rate': 1.9772739694485005e-05, 'epoch': 4.42}\n",
            "{'loss': 0.2199, 'learning_rate': 1.927360900127687e-05, 'epoch': 4.48}\n",
            "{'loss': 0.3185, 'learning_rate': 1.8776350327597275e-05, 'epoch': 4.53}\n",
            "{'loss': 0.3242, 'learning_rate': 1.8281199358637898e-05, 'epoch': 4.59}\n",
            "{'loss': 0.287, 'learning_rate': 1.7788390780603704e-05, 'epoch': 4.64}\n",
            "{'loss': 0.1827, 'learning_rate': 1.729815816947898e-05, 'epoch': 4.7}\n",
            "{'loss': 0.1708, 'learning_rate': 1.6810733880319633e-05, 'epoch': 4.75}\n",
            "{'loss': 0.1952, 'learning_rate': 1.6326348937124e-05, 'epoch': 4.81}\n",
            "{'loss': 0.0563, 'learning_rate': 1.5845232923334678e-05, 'epoch': 4.86}\n",
            "{'loss': 0.1891, 'learning_rate': 1.5367613873023124e-05, 'epoch': 4.92}\n",
            "{'loss': 0.2039, 'learning_rate': 1.4893718162808522e-05, 'epoch': 4.97}\n",
            "{'loss': 0.2382, 'learning_rate': 1.4423770404562294e-05, 'epoch': 5.03}\n",
            "{'loss': 0.1687, 'learning_rate': 1.3957993338949097e-05, 'epoch': 5.08}\n",
            "{'loss': 0.1593, 'learning_rate': 1.349660772985458e-05, 'epoch': 5.14}\n",
            "{'loss': 0.0952, 'learning_rate': 1.3039832259750152e-05, 'epoch': 5.19}\n",
            "{'loss': 0.1952, 'learning_rate': 1.258788342604438e-05, 'epoch': 5.25}\n",
            "{'loss': 0.1047, 'learning_rate': 1.2140975438469756e-05, 'epoch': 5.3}\n",
            "{'loss': 0.1621, 'learning_rate': 1.1699320117554078e-05, 'epoch': 5.36}\n",
            "{'loss': 0.1833, 'learning_rate': 1.126312679422402e-05, 'epoch': 5.41}\n",
            "{'loss': 0.1116, 'learning_rate': 1.0832602210588748e-05, 'epoch': 5.47}\n",
            "{'loss': 0.1972, 'learning_rate': 1.0407950421950622e-05, 'epoch': 5.52}\n",
            "{'loss': 0.1555, 'learning_rate': 9.989372700089282e-06, 'epoch': 5.58}\n",
            "{'loss': 0.0525, 'learning_rate': 9.577067437865071e-06, 'epoch': 5.64}\n",
            "{'loss': 0.0822, 'learning_rate': 9.171230055186943e-06, 'epoch': 5.69}\n",
            "{'loss': 0.1199, 'learning_rate': 8.772052906389544e-06, 'epoch': 5.75}\n",
            "{'loss': 0.1242, 'learning_rate': 8.37972518906318e-06, 'epoch': 5.8}\n",
            "{'loss': 0.0617, 'learning_rate': 7.994432854380021e-06, 'epoch': 5.86}\n",
            "{'loss': 0.0381, 'learning_rate': 7.61635851895905e-06, 'epoch': 5.91}\n",
            "{'loss': 0.1258, 'learning_rate': 7.245681378311415e-06, 'epoch': 5.97}\n",
            "{'loss': 0.0837, 'learning_rate': 6.882577121907308e-06, 'epoch': 6.02}\n",
            "{'loss': 0.0668, 'learning_rate': 6.527217849904661e-06, 'epoch': 6.08}\n",
            "{'loss': 0.0667, 'learning_rate': 6.179771991578919e-06, 'epoch': 6.13}\n",
            "{'loss': 0.0123, 'learning_rate': 5.840404225492864e-06, 'epoch': 6.19}\n",
            "{'loss': 0.0528, 'learning_rate': 5.509275401444052e-06, 'epoch': 6.24}\n",
            "{'loss': 0.2242, 'learning_rate': 5.186542464226975e-06, 'epoch': 6.3}\n",
            "{'loss': 0.0575, 'learning_rate': 4.872358379246143e-06, 'epoch': 6.35}\n",
            "{'loss': 0.1232, 'learning_rate': 4.5668720600151874e-06, 'epoch': 6.41}\n",
            "{'loss': 0.0759, 'learning_rate': 4.270228297576496e-06, 'epoch': 6.46}\n",
            "{'loss': 0.0056, 'learning_rate': 3.982567691874722e-06, 'epoch': 6.52}\n",
            "{'loss': 0.1261, 'learning_rate': 3.704026585116802e-06, 'epoch': 6.57}\n",
            "{'loss': 0.0504, 'learning_rate': 3.434736997149965e-06, 'epoch': 6.63}\n",
            "{'loss': 0.1527, 'learning_rate': 3.1748265628883932e-06, 'epoch': 6.69}\n",
            "{'loss': 0.0627, 'learning_rate': 2.9244184718182966e-06, 'epoch': 6.74}\n",
            "{'loss': 0.067, 'learning_rate': 2.6836314096098264e-06, 'epoch': 6.8}\n",
            "{'loss': 0.2529, 'learning_rate': 2.452579501863828e-06, 'epoch': 6.85}\n",
            "{'loss': 0.1333, 'learning_rate': 2.2313722600198054e-06, 'epoch': 6.91}\n",
            "{'loss': 0.0588, 'learning_rate': 2.0201145294508867e-06, 'epoch': 6.96}\n",
            "{'loss': 0.246, 'learning_rate': 1.8189064397704021e-06, 'epoch': 7.02}\n",
            "{'loss': 0.1873, 'learning_rate': 1.6278433573735315e-06, 'epoch': 7.07}\n",
            "{'loss': 0.0681, 'learning_rate': 1.4470158402365775e-06, 'epoch': 7.13}\n",
            "{'loss': 0.0786, 'learning_rate': 1.2765095949953233e-06, 'epoch': 7.18}\n",
            "{'loss': 0.119, 'learning_rate': 1.116405436322723e-06, 'epoch': 7.24}\n",
            "{'loss': 0.0071, 'learning_rate': 9.667792486252659e-07, 'epoch': 7.29}\n",
            "{'loss': 0.1157, 'learning_rate': 8.277019500760998e-07, 'epoch': 7.35}\n",
            "{'loss': 0.0653, 'learning_rate': 6.992394590020442e-07, 'epoch': 7.4}\n",
            "{'loss': 0.1234, 'learning_rate': 5.814526626403329e-07, 'epoch': 7.46}\n",
            "{'loss': 0.0971, 'learning_rate': 4.7439738827994006e-07, 'epoch': 7.51}\n",
            "{'loss': 0.0062, 'learning_rate': 3.781243768012041e-07, 'epoch': 7.57}\n",
            "{'loss': 0.1299, 'learning_rate': 2.9267925862619897e-07, 'epoch': 7.62}\n",
            "{'loss': 0.0673, 'learning_rate': 2.1810253209134027e-07, 'epoch': 7.68}\n",
            "{'loss': 0.0624, 'learning_rate': 1.5442954425243308e-07, 'epoch': 7.73}\n",
            "{'loss': 0.1181, 'learning_rate': 1.0169047413125268e-07, 'epoch': 7.79}\n",
            "{'loss': 0.0057, 'learning_rate': 5.991031841163048e-08, 'epoch': 7.85}\n",
            "{'loss': 0.0048, 'learning_rate': 2.910887959180258e-08, 'epoch': 7.9}\n",
            "{'loss': 0.0055, 'learning_rate': 9.30075659863933e-09, 'epoch': 7.96}\n",
            "{'train_runtime': 143.1234, 'train_samples_per_second': 80.769, 'train_steps_per_second': 10.117, 'train_loss': 0.2858104698812764, 'epoch': 8.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 52/52 [00:01<00:00, 39.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 22:45:23,461] Trial 31 finished with value: 0.8866498740554156 and parameters: {'learning_rate': 4.64465513577208e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.2749464551685909, 'num_train_epochs': 8, 'warmup_steps': 5, 'freeze_layers': 6, 'dropout': 0.14958881394312135, 'lr_scheduler_type': 'cosine_with_restarts'}. Best is trial 19 with value: 0.9289340101522843.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: cosine_with_restarts\n",
            " Warmup steps (True): 34\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1eb319943734402fb0185ca94ec82ad6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1448 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.6941, 'learning_rate': 9.414570956385535e-06, 'epoch': 0.06}\n",
            "{'loss': 0.7107, 'learning_rate': 2.0005963282319263e-05, 'epoch': 0.11}\n",
            "{'loss': 0.6913, 'learning_rate': 3.059735560825299e-05, 'epoch': 0.17}\n",
            "{'loss': 0.7312, 'learning_rate': 4.0011729054372056e-05, 'epoch': 0.22}\n",
            "{'loss': 0.7311, 'learning_rate': 4.000481660452316e-05, 'epoch': 0.28}\n",
            "{'loss': 0.6779, 'learning_rate': 3.9988032540872494e-05, 'epoch': 0.33}\n",
            "{'loss': 0.6376, 'learning_rate': 3.996138514818476e-05, 'epoch': 0.39}\n",
            "{'loss': 0.6924, 'learning_rate': 3.9924887579852564e-05, 'epoch': 0.44}\n",
            "{'loss': 0.5979, 'learning_rate': 3.9878557851403777e-05, 'epoch': 0.5}\n",
            "{'loss': 0.4892, 'learning_rate': 3.982241883160889e-05, 'epoch': 0.55}\n",
            "{'loss': 0.5169, 'learning_rate': 3.975649823119281e-05, 'epoch': 0.61}\n",
            "{'loss': 0.551, 'learning_rate': 3.9680828589156556e-05, 'epoch': 0.66}\n",
            "{'loss': 0.4475, 'learning_rate': 3.959544725671575e-05, 'epoch': 0.72}\n",
            "{'loss': 0.5806, 'learning_rate': 3.950039637886373e-05, 'epoch': 0.77}\n",
            "{'loss': 0.6749, 'learning_rate': 3.939572287356836e-05, 'epoch': 0.83}\n",
            "{'loss': 0.381, 'learning_rate': 3.9281478408612935e-05, 'epoch': 0.88}\n",
            "{'loss': 0.4268, 'learning_rate': 3.915771937609248e-05, 'epoch': 0.94}\n",
            "{'loss': 0.87, 'learning_rate': 3.9024506864578125e-05, 'epoch': 0.99}\n",
            "{'loss': 0.4426, 'learning_rate': 3.8881906628963205e-05, 'epoch': 1.05}\n",
            "{'loss': 0.3969, 'learning_rate': 3.87299890580061e-05, 'epoch': 1.1}\n",
            "{'loss': 0.8268, 'learning_rate': 3.8568829139585644e-05, 'epoch': 1.16}\n",
            "{'loss': 0.5226, 'learning_rate': 3.839850642368651e-05, 'epoch': 1.22}\n",
            "{'loss': 0.4635, 'learning_rate': 3.8219104983132574e-05, 'epoch': 1.27}\n",
            "{'loss': 0.3955, 'learning_rate': 3.8030713372087815e-05, 'epoch': 1.33}\n",
            "{'loss': 0.2498, 'learning_rate': 3.78334245823452e-05, 'epoch': 1.38}\n",
            "{'loss': 0.3277, 'learning_rate': 3.76273359974251e-05, 'epoch': 1.44}\n",
            "{'loss': 0.4392, 'learning_rate': 3.7412549344505886e-05, 'epoch': 1.49}\n",
            "{'loss': 0.5068, 'learning_rate': 3.718917064421051e-05, 'epoch': 1.55}\n",
            "{'loss': 0.3369, 'learning_rate': 3.695731015827374e-05, 'epoch': 1.6}\n",
            "{'loss': 0.621, 'learning_rate': 3.671708233511601e-05, 'epoch': 1.66}\n",
            "{'loss': 0.4119, 'learning_rate': 3.646860575335063e-05, 'epoch': 1.71}\n",
            "{'loss': 0.4012, 'learning_rate': 3.62120030632523e-05, 'epoch': 1.77}\n",
            "{'loss': 0.1911, 'learning_rate': 3.594740092621588e-05, 'epoch': 1.82}\n",
            "{'loss': 0.3114, 'learning_rate': 3.567492995223514e-05, 'epoch': 1.88}\n",
            "{'loss': 0.4924, 'learning_rate': 3.539472463543253e-05, 'epoch': 1.93}\n",
            "{'loss': 0.1962, 'learning_rate': 3.510692328767163e-05, 'epoch': 1.99}\n",
            "{'loss': 0.1836, 'learning_rate': 3.4811667970285207e-05, 'epoch': 2.04}\n",
            "{'loss': 0.1647, 'learning_rate': 3.4509104423952454e-05, 'epoch': 2.1}\n",
            "{'loss': 0.1536, 'learning_rate': 3.419938199676006e-05, 'epoch': 2.15}\n",
            "{'loss': 0.2634, 'learning_rate': 3.38826535704827e-05, 'epoch': 2.21}\n",
            "{'loss': 0.2285, 'learning_rate': 3.3559075485119154e-05, 'epoch': 2.27}\n",
            "{'loss': 0.3172, 'learning_rate': 3.3228807461721524e-05, 'epoch': 2.32}\n",
            "{'loss': 0.291, 'learning_rate': 3.289201252355547e-05, 'epoch': 2.38}\n",
            "{'loss': 0.4242, 'learning_rate': 3.2548856915630475e-05, 'epoch': 2.43}\n",
            "{'loss': 0.2326, 'learning_rate': 3.219951002263978e-05, 'epoch': 2.49}\n",
            "{'loss': 0.1632, 'learning_rate': 3.18441442853506e-05, 'epoch': 2.54}\n",
            "{'loss': 0.228, 'learning_rate': 3.148293511548583e-05, 'epoch': 2.6}\n",
            "{'loss': 0.1986, 'learning_rate': 3.111606080913921e-05, 'epoch': 2.65}\n",
            "{'loss': 0.2271, 'learning_rate': 3.074370245876676e-05, 'epoch': 2.71}\n",
            "{'loss': 0.1852, 'learning_rate': 3.0366043863797963e-05, 'epoch': 2.76}\n",
            "{'loss': 0.228, 'learning_rate': 2.9983271439910683e-05, 'epoch': 2.82}\n",
            "{'loss': 0.2389, 'learning_rate': 2.9595574127014702e-05, 'epoch': 2.87}\n",
            "{'loss': 0.1955, 'learning_rate': 2.9203143295989303e-05, 'epoch': 2.93}\n",
            "{'loss': 0.2265, 'learning_rate': 2.8806172654220878e-05, 'epoch': 2.98}\n",
            "{'loss': 0.1053, 'learning_rate': 2.840485814998721e-05, 'epoch': 3.04}\n",
            "{'loss': 0.0658, 'learning_rate': 2.7999397875735655e-05, 'epoch': 3.09}\n",
            "{'loss': 0.0099, 'learning_rate': 2.758999197030291e-05, 'epoch': 3.15}\n",
            "{'loss': 0.1342, 'learning_rate': 2.7176842520124713e-05, 'epoch': 3.2}\n",
            "{'loss': 0.1014, 'learning_rate': 2.6760153459484142e-05, 'epoch': 3.26}\n",
            "{'loss': 0.0022, 'learning_rate': 2.6340130469847815e-05, 'epoch': 3.31}\n",
            "{'loss': 0.4677, 'learning_rate': 2.5916980878339683e-05, 'epoch': 3.37}\n",
            "{'loss': 0.0743, 'learning_rate': 2.5490913555402484e-05, 'epoch': 3.43}\n",
            "{'loss': 0.1842, 'learning_rate': 2.5062138811697425e-05, 'epoch': 3.48}\n",
            "{'loss': 0.1655, 'learning_rate': 2.4630868294292962e-05, 'epoch': 3.54}\n",
            "{'loss': 0.0492, 'learning_rate': 2.419731488219385e-05, 'epoch': 3.59}\n",
            "{'loss': 0.1405, 'learning_rate': 2.3761692581262223e-05, 'epoch': 3.65}\n",
            "{'loss': 0.0476, 'learning_rate': 2.332421641858233e-05, 'epoch': 3.7}\n",
            "{'loss': 0.126, 'learning_rate': 2.288510233632125e-05, 'epoch': 3.76}\n",
            "{'loss': 0.0744, 'learning_rate': 2.2444567085137895e-05, 'epoch': 3.81}\n",
            "{'loss': 0.2605, 'learning_rate': 2.2002828117192923e-05, 'epoch': 3.87}\n",
            "{'loss': 0.1471, 'learning_rate': 2.1560103478812423e-05, 'epoch': 3.92}\n",
            "{'loss': 0.2217, 'learning_rate': 2.1116611702858257e-05, 'epoch': 3.98}\n",
            "{'loss': 0.0191, 'learning_rate': 2.0672571700858303e-05, 'epoch': 4.03}\n",
            "{'loss': 0.0666, 'learning_rate': 2.0228202654949744e-05, 'epoch': 4.09}\n",
            "{'loss': 0.0921, 'learning_rate': 1.9783723909688785e-05, 'epoch': 4.14}\n",
            "{'loss': 0.113, 'learning_rate': 1.9339354863780226e-05, 'epoch': 4.2}\n",
            "{'loss': 0.0722, 'learning_rate': 1.889531486178027e-05, 'epoch': 4.25}\n",
            "{'loss': 0.0741, 'learning_rate': 1.8451823085826106e-05, 'epoch': 4.31}\n",
            "{'loss': 0.0029, 'learning_rate': 1.8009098447445606e-05, 'epoch': 4.36}\n",
            "{'loss': 0.0026, 'learning_rate': 1.7567359479500637e-05, 'epoch': 4.42}\n",
            "{'loss': 0.0731, 'learning_rate': 1.712682422831728e-05, 'epoch': 4.48}\n",
            "{'loss': 0.3045, 'learning_rate': 1.6687710146056195e-05, 'epoch': 4.53}\n",
            "{'loss': 0.1941, 'learning_rate': 1.6250233983376303e-05, 'epoch': 4.59}\n",
            "{'loss': 0.2238, 'learning_rate': 1.5814611682444677e-05, 'epoch': 4.64}\n",
            "{'loss': 0.1014, 'learning_rate': 1.5381058270345574e-05, 'epoch': 4.7}\n",
            "{'loss': 0.0059, 'learning_rate': 1.4949787752941102e-05, 'epoch': 4.75}\n",
            "{'loss': 0.258, 'learning_rate': 1.4521013009236045e-05, 'epoch': 4.81}\n",
            "{'loss': 0.0742, 'learning_rate': 1.4094945686298843e-05, 'epoch': 4.86}\n",
            "{'loss': 0.0658, 'learning_rate': 1.3671796094790711e-05, 'epoch': 4.92}\n",
            "{'loss': 0.1591, 'learning_rate': 1.3251773105154389e-05, 'epoch': 4.97}\n",
            "{'loss': 0.0644, 'learning_rate': 1.2835084044513816e-05, 'epoch': 5.03}\n",
            "{'loss': 0.0728, 'learning_rate': 1.242193459433562e-05, 'epoch': 5.08}\n",
            "{'loss': 0.0769, 'learning_rate': 1.2012528688902874e-05, 'epoch': 5.14}\n",
            "{'loss': 0.0034, 'learning_rate': 1.1607068414651319e-05, 'epoch': 5.19}\n",
            "{'loss': 0.0693, 'learning_rate': 1.1205753910417651e-05, 'epoch': 5.25}\n",
            "{'loss': 0.1632, 'learning_rate': 1.0808783268649219e-05, 'epoch': 5.3}\n",
            "{'loss': 0.0879, 'learning_rate': 1.0416352437623825e-05, 'epoch': 5.36}\n",
            "{'loss': 0.0038, 'learning_rate': 1.0028655124727839e-05, 'epoch': 5.41}\n",
            "{'loss': 0.0698, 'learning_rate': 9.64588270084056e-06, 'epoch': 5.47}\n",
            "{'loss': 0.0818, 'learning_rate': 9.268224105871769e-06, 'epoch': 5.52}\n",
            "{'loss': 0.067, 'learning_rate': 8.895865755499324e-06, 'epoch': 5.58}\n",
            "{'loss': 0.0028, 'learning_rate': 8.528991449152693e-06, 'epoch': 5.64}\n",
            "{'loss': 0.0026, 'learning_rate': 8.167782279287927e-06, 'epoch': 5.69}\n",
            "{'loss': 0.0781, 'learning_rate': 7.812416541998746e-06, 'epoch': 5.75}\n",
            "{'loss': 0.0513, 'learning_rate': 7.463069649008058e-06, 'epoch': 5.8}\n",
            "{'loss': 0.0688, 'learning_rate': 7.119914041083053e-06, 'epoch': 5.86}\n",
            "{'loss': 0.0025, 'learning_rate': 6.783119102917006e-06, 'epoch': 5.91}\n",
            "{'loss': 0.1523, 'learning_rate': 6.452851079519372e-06, 'epoch': 5.97}\n",
            "{'loss': 0.002, 'learning_rate': 6.129272994155827e-06, 'epoch': 6.02}\n",
            "{'loss': 0.0025, 'learning_rate': 5.812544567878465e-06, 'epoch': 6.08}\n",
            "{'loss': 0.002, 'learning_rate': 5.502822140686079e-06, 'epoch': 6.13}\n",
            "{'loss': 0.0017, 'learning_rate': 5.200258594353318e-06, 'epoch': 6.19}\n",
            "{'loss': 0.0018, 'learning_rate': 4.9050032769669e-06, 'epoch': 6.24}\n",
            "{'loss': 0.1511, 'learning_rate': 4.617201929205994e-06, 'epoch': 6.3}\n",
            "{'loss': 0.0018, 'learning_rate': 4.33699661240339e-06, 'epoch': 6.35}\n",
            "{'loss': 0.0043, 'learning_rate': 4.064525638422651e-06, 'epoch': 6.41}\n",
            "{'loss': 0.0017, 'learning_rate': 3.7999235013862316e-06, 'epoch': 6.46}\n",
            "{'loss': 0.0016, 'learning_rate': 3.543320811287903e-06, 'epoch': 6.52}\n",
            "{'loss': 0.078, 'learning_rate': 3.294844229522517e-06, 'epoch': 6.57}\n",
            "{'loss': 0.0015, 'learning_rate': 3.054616406364789e-06, 'epoch': 6.63}\n",
            "{'loss': 0.0907, 'learning_rate': 2.8227559204280202e-06, 'epoch': 6.69}\n",
            "{'loss': 0.0351, 'learning_rate': 2.5993772201326407e-06, 'epoch': 6.74}\n",
            "{'loss': 0.1527, 'learning_rate': 2.3845905672134254e-06, 'epoch': 6.8}\n",
            "{'loss': 0.2305, 'learning_rate': 2.1785019822933235e-06, 'epoch': 6.85}\n",
            "{'loss': 0.0874, 'learning_rate': 1.9812131925507135e-06, 'epoch': 6.91}\n",
            "{'loss': 0.0052, 'learning_rate': 1.7928215815059542e-06, 'epoch': 6.96}\n",
            "{'loss': 0.0779, 'learning_rate': 1.6134201409520111e-06, 'epoch': 7.02}\n",
            "{'loss': 0.1304, 'learning_rate': 1.443097425052882e-06, 'epoch': 7.07}\n",
            "{'loss': 0.0776, 'learning_rate': 1.281937506632429e-06, 'epoch': 7.13}\n",
            "{'loss': 0.0018, 'learning_rate': 1.1300199356753203e-06, 'epoch': 7.18}\n",
            "{'loss': 0.0018, 'learning_rate': 9.87419700060403e-07, 'epoch': 7.24}\n",
            "{'loss': 0.0019, 'learning_rate': 8.542071885460462e-07, 'epoch': 7.29}\n",
            "{'loss': 0.0891, 'learning_rate': 7.30448156025593e-07, 'epoch': 7.35}\n",
            "{'loss': 0.0029, 'learning_rate': 6.162036910701657e-07, 'epoch': 7.4}\n",
            "{'loss': 0.0017, 'learning_rate': 5.115301857747957e-07, 'epoch': 7.46}\n",
            "{'loss': 0.0907, 'learning_rate': 4.164793079227742e-07, 'epoch': 7.51}\n",
            "{'loss': 0.0017, 'learning_rate': 3.3109797548197255e-07, 'epoch': 7.57}\n",
            "{'loss': 0.0818, 'learning_rate': 2.5542833344571604e-07, 'epoch': 7.62}\n",
            "{'loss': 0.0646, 'learning_rate': 1.8950773302963023e-07, 'epoch': 7.68}\n",
            "{'loss': 0.0791, 'learning_rate': 1.3336871323474885e-07, 'epoch': 7.73}\n",
            "{'loss': 0.069, 'learning_rate': 8.703898478596151e-08, 'epoch': 7.79}\n",
            "{'loss': 0.0627, 'learning_rate': 5.0541416453770237e-08, 'epoch': 7.85}\n",
            "{'loss': 0.0016, 'learning_rate': 2.3894023766031798e-08, 'epoch': 7.9}\n",
            "{'loss': 0.0018, 'learning_rate': 7.109960115360416e-09, 'epoch': 7.96}\n",
            "{'train_runtime': 150.6639, 'train_samples_per_second': 76.727, 'train_steps_per_second': 9.611, 'train_loss': 0.20631924332299614, 'epoch': 8.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 52/52 [00:01<00:00, 36.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 22:47:58,372] Trial 32 finished with value: 0.8934010152284264 and parameters: {'learning_rate': 4.0011926564638526e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.2717995259113486, 'num_train_epochs': 8, 'warmup_steps': 34, 'freeze_layers': 6, 'dropout': 0.11817938357939443, 'lr_scheduler_type': 'cosine_with_restarts'}. Best is trial 19 with value: 0.9289340101522843.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: cosine_with_restarts\n",
            " Warmup steps (True): 87\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "068053b13cab4cd8af33f8352bebd582",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1629 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.6961, 'learning_rate': 4.939522843749662e-06, 'epoch': 0.06}\n",
            "{'loss': 0.7227, 'learning_rate': 1.0496486042968033e-05, 'epoch': 0.11}\n",
            "{'loss': 0.7054, 'learning_rate': 1.667088959765511e-05, 'epoch': 0.17}\n",
            "{'loss': 0.7193, 'learning_rate': 2.222785279687348e-05, 'epoch': 0.22}\n",
            "{'loss': 0.6674, 'learning_rate': 2.8402256351560558e-05, 'epoch': 0.28}\n",
            "{'loss': 0.6966, 'learning_rate': 3.4576659906247637e-05, 'epoch': 0.33}\n",
            "{'loss': 0.665, 'learning_rate': 4.075106346093471e-05, 'epoch': 0.39}\n",
            "{'loss': 0.7182, 'learning_rate': 4.6925467015621794e-05, 'epoch': 0.44}\n",
            "{'loss': 0.6647, 'learning_rate': 5.309987057030887e-05, 'epoch': 0.5}\n",
            "{'loss': 0.5713, 'learning_rate': 5.371279592196526e-05, 'epoch': 0.55}\n",
            "{'loss': 0.882, 'learning_rate': 5.3697190450208295e-05, 'epoch': 0.61}\n",
            "{'loss': 0.6488, 'learning_rate': 5.3670445245459486e-05, 'epoch': 0.66}\n",
            "{'loss': 0.4819, 'learning_rate': 5.363257140871371e-05, 'epoch': 0.72}\n",
            "{'loss': 0.6012, 'learning_rate': 5.358358466007004e-05, 'epoch': 0.77}\n",
            "{'loss': 0.4985, 'learning_rate': 5.352350533220685e-05, 'epoch': 0.83}\n",
            "{'loss': 0.3415, 'learning_rate': 5.3452358361942445e-05, 'epoch': 0.88}\n",
            "{'loss': 0.2658, 'learning_rate': 5.337017327988469e-05, 'epoch': 0.94}\n",
            "{'loss': 0.9054, 'learning_rate': 5.327698419817383e-05, 'epoch': 0.99}\n",
            "{'loss': 0.529, 'learning_rate': 5.3172829796323815e-05, 'epoch': 1.05}\n",
            "{'loss': 0.3998, 'learning_rate': 5.305775330516773e-05, 'epoch': 1.1}\n",
            "{'loss': 0.4795, 'learning_rate': 5.293180248891424e-05, 'epoch': 1.16}\n",
            "{'loss': 0.3661, 'learning_rate': 5.279502962532231e-05, 'epoch': 1.22}\n",
            "{'loss': 0.2145, 'learning_rate': 5.264749148400256e-05, 'epoch': 1.27}\n",
            "{'loss': 0.3974, 'learning_rate': 5.2505553365559375e-05, 'epoch': 1.33}\n",
            "{'loss': 0.365, 'learning_rate': 5.233773357955682e-05, 'epoch': 1.38}\n",
            "{'loss': 0.3805, 'learning_rate': 5.2159338323349486e-05, 'epoch': 1.44}\n",
            "{'loss': 0.3538, 'learning_rate': 5.197044164254092e-05, 'epoch': 1.49}\n",
            "{'loss': 0.5425, 'learning_rate': 5.177112194150707e-05, 'epoch': 1.55}\n",
            "{'loss': 0.3589, 'learning_rate': 5.1561461950853414e-05, 'epoch': 1.6}\n",
            "{'loss': 0.5169, 'learning_rate': 5.134154869307637e-05, 'epoch': 1.66}\n",
            "{'loss': 0.3878, 'learning_rate': 5.1111473446443344e-05, 'epoch': 1.71}\n",
            "{'loss': 0.2834, 'learning_rate': 5.0871331707106276e-05, 'epoch': 1.77}\n",
            "{'loss': 0.1887, 'learning_rate': 5.062122314946461e-05, 'epoch': 1.82}\n",
            "{'loss': 0.2942, 'learning_rate': 5.036125158479389e-05, 'epoch': 1.88}\n",
            "{'loss': 0.3987, 'learning_rate': 5.00915249181574e-05, 'epoch': 1.93}\n",
            "{'loss': 0.355, 'learning_rate': 4.981215510361853e-05, 'epoch': 1.99}\n",
            "{'loss': 0.2774, 'learning_rate': 4.9523258097772565e-05, 'epoch': 2.04}\n",
            "{'loss': 0.2205, 'learning_rate': 4.92249538116172e-05, 'epoch': 2.1}\n",
            "{'loss': 0.1773, 'learning_rate': 4.891736606078173e-05, 'epoch': 2.15}\n",
            "{'loss': 0.4762, 'learning_rate': 4.860062251413545e-05, 'epoch': 2.21}\n",
            "{'loss': 0.2539, 'learning_rate': 4.827485464079686e-05, 'epoch': 2.27}\n",
            "{'loss': 0.3046, 'learning_rate': 4.794019765556544e-05, 'epoch': 2.32}\n",
            "{'loss': 0.2521, 'learning_rate': 4.75967904627987e-05, 'epoch': 2.38}\n",
            "{'loss': 0.318, 'learning_rate': 4.7244775598757904e-05, 'epoch': 2.43}\n",
            "{'loss': 0.2967, 'learning_rate': 4.688429917244627e-05, 'epoch': 2.49}\n",
            "{'loss': 0.2358, 'learning_rate': 4.651551080496424e-05, 'epoch': 2.54}\n",
            "{'loss': 0.4029, 'learning_rate': 4.6138563567407006e-05, 'epoch': 2.6}\n",
            "{'loss': 0.1811, 'learning_rate': 4.575361391733011e-05, 'epoch': 2.65}\n",
            "{'loss': 0.2258, 'learning_rate': 4.5360821633809417e-05, 'epoch': 2.71}\n",
            "{'loss': 0.1478, 'learning_rate': 4.4960349751122354e-05, 'epoch': 2.76}\n",
            "{'loss': 0.063, 'learning_rate': 4.4552364491078205e-05, 'epoch': 2.82}\n",
            "{'loss': 0.4166, 'learning_rate': 4.413703519402524e-05, 'epoch': 2.87}\n",
            "{'loss': 0.2914, 'learning_rate': 4.3714534248563454e-05, 'epoch': 2.93}\n",
            "{'loss': 0.1765, 'learning_rate': 4.328503701999218e-05, 'epoch': 2.98}\n",
            "{'loss': 0.0111, 'learning_rate': 4.284872177752204e-05, 'epoch': 3.04}\n",
            "{'loss': 0.1225, 'learning_rate': 4.240576962028175e-05, 'epoch': 3.09}\n",
            "{'loss': 0.0048, 'learning_rate': 4.195636440215012e-05, 'epoch': 3.15}\n",
            "{'loss': 0.0672, 'learning_rate': 4.1500692655444874e-05, 'epoch': 3.2}\n",
            "{'loss': 0.1216, 'learning_rate': 4.1038943513499584e-05, 'epoch': 3.26}\n",
            "{'loss': 0.0422, 'learning_rate': 4.0618331465533606e-05, 'epoch': 3.31}\n",
            "{'loss': 0.3515, 'learning_rate': 4.014556530525981e-05, 'epoch': 3.37}\n",
            "{'loss': 0.0691, 'learning_rate': 3.966728421550119e-05, 'epoch': 3.43}\n",
            "{'loss': 0.2467, 'learning_rate': 3.918368671393534e-05, 'epoch': 3.48}\n",
            "{'loss': 0.2559, 'learning_rate': 3.869497352489556e-05, 'epoch': 3.54}\n",
            "{'loss': 0.1388, 'learning_rate': 3.820134749605735e-05, 'epoch': 3.59}\n",
            "{'loss': 0.2097, 'learning_rate': 3.770301351424338e-05, 'epoch': 3.65}\n",
            "{'loss': 0.1511, 'learning_rate': 3.720017842038225e-05, 'epoch': 3.7}\n",
            "{'loss': 0.0358, 'learning_rate': 3.669305092365597e-05, 'epoch': 3.76}\n",
            "{'loss': 0.1416, 'learning_rate': 3.618184151487224e-05, 'epoch': 3.81}\n",
            "{'loss': 0.1872, 'learning_rate': 3.566676237909703e-05, 'epoch': 3.87}\n",
            "{'loss': 0.1161, 'learning_rate': 3.5148027307584006e-05, 'epoch': 3.92}\n",
            "{'loss': 0.2906, 'learning_rate': 3.462585160903737e-05, 'epoch': 3.98}\n",
            "{'loss': 0.0065, 'learning_rate': 3.410045202024471e-05, 'epoch': 4.03}\n",
            "{'loss': 0.0219, 'learning_rate': 3.357204661611718e-05, 'epoch': 4.09}\n",
            "{'loss': 0.0814, 'learning_rate': 3.304085471917429e-05, 'epoch': 4.14}\n",
            "{'loss': 0.2433, 'learning_rate': 3.250709680851083e-05, 'epoch': 4.2}\n",
            "{'loss': 0.0818, 'learning_rate': 3.1970994428283744e-05, 'epoch': 4.25}\n",
            "{'loss': 0.0813, 'learning_rate': 3.14327700957569e-05, 'epoch': 4.31}\n",
            "{'loss': 0.003, 'learning_rate': 3.089264720894204e-05, 'epoch': 4.36}\n",
            "{'loss': 0.0025, 'learning_rate': 3.035084995387408e-05, 'epoch': 4.42}\n",
            "{'loss': 0.0789, 'learning_rate': 2.980760321155938e-05, 'epoch': 4.48}\n",
            "{'loss': 0.0721, 'learning_rate': 2.926313246463555e-05, 'epoch': 4.53}\n",
            "{'loss': 0.0277, 'learning_rate': 2.8717663703781478e-05, 'epoch': 4.59}\n",
            "{'loss': 0.2308, 'learning_rate': 2.8171423333916585e-05, 'epoch': 4.64}\n",
            "{'loss': 0.1367, 'learning_rate': 2.762463808022812e-05, 'epoch': 4.7}\n",
            "{'loss': 0.0009, 'learning_rate': 2.7077534894065393e-05, 'epoch': 4.75}\n",
            "{'loss': 0.1304, 'learning_rate': 2.6530340858740388e-05, 'epoch': 4.81}\n",
            "{'loss': 0.0012, 'learning_rate': 2.598328309527333e-05, 'epoch': 4.86}\n",
            "{'loss': 0.0861, 'learning_rate': 2.543658866812281e-05, 'epoch': 4.92}\n",
            "{'loss': 0.1289, 'learning_rate': 2.489048449093929e-05, 'epoch': 4.97}\n",
            "{'loss': 0.002, 'learning_rate': 2.434519723238118e-05, 'epoch': 5.03}\n",
            "{'loss': 0.0017, 'learning_rate': 2.3800953222032668e-05, 'epoch': 5.08}\n",
            "{'loss': 0.0105, 'learning_rate': 2.325797835646229e-05, 'epoch': 5.14}\n",
            "{'loss': 0.0022, 'learning_rate': 2.2716498005461136e-05, 'epoch': 5.19}\n",
            "{'loss': 0.0893, 'learning_rate': 2.217673691849984e-05, 'epoch': 5.25}\n",
            "{'loss': 0.092, 'learning_rate': 2.1638919131442907e-05, 'epoch': 5.3}\n",
            "{'loss': 0.0021, 'learning_rate': 2.110326787355933e-05, 'epoch': 5.36}\n",
            "{'loss': 0.0018, 'learning_rate': 2.057000547486796e-05, 'epoch': 5.41}\n",
            "{'loss': 0.0013, 'learning_rate': 2.0039353273856104e-05, 'epoch': 5.47}\n",
            "{'loss': 0.0013, 'learning_rate': 1.951153152560974e-05, 'epoch': 5.52}\n",
            "{'loss': 0.0009, 'learning_rate': 1.8986759310393337e-05, 'epoch': 5.58}\n",
            "{'loss': 0.0008, 'learning_rate': 1.8465254442717316e-05, 'epoch': 5.64}\n",
            "{'loss': 0.0401, 'learning_rate': 1.7947233380930934e-05, 'epoch': 5.69}\n",
            "{'loss': 0.1003, 'learning_rate': 1.7432911137378018e-05, 'epoch': 5.75}\n",
            "{'loss': 0.0007, 'learning_rate': 1.69225011891529e-05, 'epoch': 5.8}\n",
            "{'loss': 0.0008, 'learning_rate': 1.641621538949355e-05, 'epoch': 5.86}\n",
            "{'loss': 0.0008, 'learning_rate': 1.591426387984876e-05, 'epoch': 5.91}\n",
            "{'loss': 0.0879, 'learning_rate': 1.5416855002655823e-05, 'epoch': 5.97}\n",
            "{'loss': 0.0008, 'learning_rate': 1.492419521486485e-05, 'epoch': 6.02}\n",
            "{'loss': 0.0009, 'learning_rate': 1.4436489002245833e-05, 'epoch': 6.08}\n",
            "{'loss': 0.0009, 'learning_rate': 1.3953938794513727e-05, 'epoch': 6.13}\n",
            "{'loss': 0.0007, 'learning_rate': 1.3476744881306983e-05, 'epoch': 6.19}\n",
            "{'loss': 0.0007, 'learning_rate': 1.3005105329054354e-05, 'epoch': 6.24}\n",
            "{'loss': 0.0836, 'learning_rate': 1.2539215898764544e-05, 'epoch': 6.3}\n",
            "{'loss': 0.0012, 'learning_rate': 1.20792699647726e-05, 'epoch': 6.35}\n",
            "{'loss': 0.0007, 'learning_rate': 1.1625458434477072e-05, 'epoch': 6.41}\n",
            "{'loss': 0.0007, 'learning_rate': 1.1177969669101041e-05, 'epoch': 6.46}\n",
            "{'loss': 0.0007, 'learning_rate': 1.0736989405510014e-05, 'epoch': 6.52}\n",
            "{'loss': 0.0006, 'learning_rate': 1.0302700679119066e-05, 'epoch': 6.57}\n",
            "{'loss': 0.0008, 'learning_rate': 9.87528374792124e-06, 'epoch': 6.63}\n",
            "{'loss': 0.0005, 'learning_rate': 9.454916017668828e-06, 'epoch': 6.69}\n",
            "{'loss': 0.0922, 'learning_rate': 9.041771968238452e-06, 'epoch': 6.74}\n",
            "{'loss': 0.0006, 'learning_rate': 8.636023081210601e-06, 'epoch': 6.8}\n",
            "{'loss': 0.0826, 'learning_rate': 8.23783776869368e-06, 'epoch': 6.85}\n",
            "{'loss': 0.1007, 'learning_rate': 7.847381303421998e-06, 'epoch': 6.91}\n",
            "{'loss': 0.0156, 'learning_rate': 7.464815750156937e-06, 'epoch': 6.96}\n",
            "{'loss': 0.001, 'learning_rate': 7.090299898419498e-06, 'epoch': 7.02}\n",
            "{'loss': 0.0008, 'learning_rate': 6.723989196582381e-06, 'epoch': 7.07}\n",
            "{'loss': 0.0008, 'learning_rate': 6.366035687348839e-06, 'epoch': 7.13}\n",
            "{'loss': 0.0007, 'learning_rate': 6.016587944645061e-06, 'epoch': 7.18}\n",
            "{'loss': 0.0006, 'learning_rate': 5.675791011952378e-06, 'epoch': 7.24}\n",
            "{'loss': 0.0007, 'learning_rate': 5.343786342104786e-06, 'epoch': 7.29}\n",
            "{'loss': 0.0006, 'learning_rate': 5.020711738576888e-06, 'epoch': 7.35}\n",
            "{'loss': 0.0006, 'learning_rate': 4.706701298286476e-06, 'epoch': 7.4}\n",
            "{'loss': 0.0006, 'learning_rate': 4.401885355935612e-06, 'epoch': 7.46}\n",
            "{'loss': 0.0979, 'learning_rate': 4.106390429913287e-06, 'epoch': 7.51}\n",
            "{'loss': 0.0006, 'learning_rate': 3.820339169782065e-06, 'epoch': 7.57}\n",
            "{'loss': 0.1691, 'learning_rate': 3.543850305370596e-06, 'epoch': 7.62}\n",
            "{'loss': 0.0007, 'learning_rate': 3.2770385974929895e-06, 'epoch': 7.68}\n",
            "{'loss': 0.0007, 'learning_rate': 3.020014790315643e-06, 'epoch': 7.73}\n",
            "{'loss': 0.0007, 'learning_rate': 2.772885565391273e-06, 'epoch': 7.79}\n",
            "{'loss': 0.0594, 'learning_rate': 2.5357534973790728e-06, 'epoch': 7.85}\n",
            "{'loss': 0.0006, 'learning_rate': 2.3087170114696577e-06, 'epoch': 7.9}\n",
            "{'loss': 0.0007, 'learning_rate': 2.091870342532158e-06, 'epoch': 7.96}\n",
            "{'loss': 0.0007, 'learning_rate': 1.8853034960006772e-06, 'epoch': 8.01}\n",
            "{'loss': 0.0007, 'learning_rate': 1.6891022105161758e-06, 'epoch': 8.07}\n",
            "{'loss': 0.0855, 'learning_rate': 1.5033479223393875e-06, 'epoch': 8.12}\n",
            "{'loss': 0.033, 'learning_rate': 1.3281177315494913e-06, 'epoch': 8.18}\n",
            "{'loss': 0.0007, 'learning_rate': 1.163484370042557e-06, 'epoch': 8.23}\n",
            "{'loss': 0.0006, 'learning_rate': 1.009516171343115e-06, 'epoch': 8.29}\n",
            "{'loss': 0.0964, 'learning_rate': 8.662770422412848e-07, 'epoch': 8.34}\n",
            "{'loss': 0.0007, 'learning_rate': 7.338264362673343e-07, 'epoch': 8.4}\n",
            "{'loss': 0.0007, 'learning_rate': 6.122193290146e-07, 'epoch': 8.45}\n",
            "{'loss': 0.0006, 'learning_rate': 5.015061953210503e-07, 'epoch': 8.51}\n",
            "{'loss': 0.0006, 'learning_rate': 4.0173298831894345e-07, 'epoch': 8.56}\n",
            "{'loss': 0.0006, 'learning_rate': 3.1294112036130914e-07, 'epoch': 8.62}\n",
            "{'loss': 0.0007, 'learning_rate': 2.3516744583314145e-07, 'epoch': 8.67}\n",
            "{'loss': 0.0006, 'learning_rate': 1.6844424585441639e-07, 'epoch': 8.73}\n",
            "{'loss': 0.0028, 'learning_rate': 1.1279921488135154e-07, 'epoch': 8.78}\n",
            "{'loss': 0.0007, 'learning_rate': 6.82554492114033e-08, 'epoch': 8.84}\n",
            "{'loss': 0.0646, 'learning_rate': 3.4831437396805594e-08, 'epoch': 8.9}\n",
            "{'loss': 0.0007, 'learning_rate': 1.254105257062518e-08, 'epoch': 8.95}\n",
            "{'train_runtime': 161.9112, 'train_samples_per_second': 80.322, 'train_steps_per_second': 10.061, 'train_loss': 0.17448960669496497, 'epoch': 9.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 52/52 [00:01<00:00, 36.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 22:50:44,265] Trial 33 finished with value: 0.9086294416243655 and parameters: {'learning_rate': 5.371731092577758e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.24401789101231425, 'num_train_epochs': 9, 'warmup_steps': 87, 'freeze_layers': 6, 'dropout': 0.1428009166800228, 'lr_scheduler_type': 'cosine_with_restarts'}. Best is trial 19 with value: 0.9289340101522843.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: cosine_with_restarts\n",
            " Warmup steps (True): 38\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "422c41b72ba84a3bb5e09aa6ec2dfdcf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1629 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7127, 'learning_rate': 1.5444850760988683e-05, 'epoch': 0.06}\n",
            "{'loss': 0.7088, 'learning_rate': 3.75089232766868e-05, 'epoch': 0.11}\n",
            "{'loss': 0.6931, 'learning_rate': 5.9572995792384916e-05, 'epoch': 0.17}\n",
            "{'loss': 0.7251, 'learning_rate': 8.163706830808303e-05, 'epoch': 0.22}\n",
            "{'loss': 0.7446, 'learning_rate': 8.383685579946924e-05, 'epoch': 0.28}\n",
            "{'loss': 0.6137, 'learning_rate': 8.381397536187523e-05, 'epoch': 0.33}\n",
            "{'loss': 0.5118, 'learning_rate': 8.377476144023114e-05, 'epoch': 0.39}\n",
            "{'loss': 0.5434, 'learning_rate': 8.371922932376481e-05, 'epoch': 0.44}\n",
            "{'loss': 0.5476, 'learning_rate': 8.364740066405157e-05, 'epoch': 0.5}\n",
            "{'loss': 0.4603, 'learning_rate': 8.355930346657253e-05, 'epoch': 0.55}\n",
            "{'loss': 0.6605, 'learning_rate': 8.345497207979539e-05, 'epoch': 0.61}\n",
            "{'loss': 0.553, 'learning_rate': 8.333444718178224e-05, 'epoch': 0.66}\n",
            "{'loss': 0.3422, 'learning_rate': 8.319777576432952e-05, 'epoch': 0.72}\n",
            "{'loss': 0.7545, 'learning_rate': 8.304501111464614e-05, 'epoch': 0.77}\n",
            "{'loss': 0.5654, 'learning_rate': 8.287621279457729e-05, 'epoch': 0.83}\n",
            "{'loss': 0.4238, 'learning_rate': 8.269144661738163e-05, 'epoch': 0.88}\n",
            "{'loss': 0.2808, 'learning_rate': 8.249078462207124e-05, 'epoch': 0.94}\n",
            "{'loss': 0.7102, 'learning_rate': 8.227430504532403e-05, 'epoch': 0.99}\n",
            "{'loss': 0.4997, 'learning_rate': 8.206601902699109e-05, 'epoch': 1.05}\n",
            "{'loss': 0.5553, 'learning_rate': 8.181972364877198e-05, 'epoch': 1.1}\n",
            "{'loss': 0.973, 'learning_rate': 8.158475461773241e-05, 'epoch': 1.16}\n",
            "{'loss': 0.901, 'learning_rate': 8.130899007263975e-05, 'epoch': 1.22}\n",
            "{'loss': 0.702, 'learning_rate': 8.10178687193594e-05, 'epoch': 1.27}\n",
            "{'loss': 0.6268, 'learning_rate': 8.071150406402653e-05, 'epoch': 1.33}\n",
            "{'loss': 0.583, 'learning_rate': 8.039001555603078e-05, 'epoch': 1.38}\n",
            "{'loss': 0.5961, 'learning_rate': 8.005352854144393e-05, 'epoch': 1.44}\n",
            "{'loss': 0.6602, 'learning_rate': 7.970217421414822e-05, 'epoch': 1.49}\n",
            "{'loss': 0.5976, 'learning_rate': 7.933608956468496e-05, 'epoch': 1.55}\n",
            "{'loss': 0.55, 'learning_rate': 7.89554173268427e-05, 'epoch': 1.6}\n",
            "{'loss': 0.4999, 'learning_rate': 7.856030592200654e-05, 'epoch': 1.66}\n",
            "{'loss': 0.5399, 'learning_rate': 7.815090940128953e-05, 'epoch': 1.71}\n",
            "{'loss': 0.3794, 'learning_rate': 7.772738738546935e-05, 'epoch': 1.77}\n",
            "{'loss': 0.3817, 'learning_rate': 7.728990500275325e-05, 'epoch': 1.82}\n",
            "{'loss': 0.4087, 'learning_rate': 7.68386328243958e-05, 'epoch': 1.88}\n",
            "{'loss': 0.6331, 'learning_rate': 7.637374679819434e-05, 'epoch': 1.93}\n",
            "{'loss': 0.5348, 'learning_rate': 7.589542817988813e-05, 'epoch': 1.99}\n",
            "{'loss': 0.4162, 'learning_rate': 7.540386346248817e-05, 'epoch': 2.04}\n",
            "{'loss': 0.4772, 'learning_rate': 7.48992443035648e-05, 'epoch': 2.1}\n",
            "{'loss': 0.4262, 'learning_rate': 7.43817674505218e-05, 'epoch': 2.15}\n",
            "{'loss': 0.4221, 'learning_rate': 7.385163466388604e-05, 'epoch': 2.21}\n",
            "{'loss': 0.3644, 'learning_rate': 7.330905263864243e-05, 'epoch': 2.27}\n",
            "{'loss': 0.3885, 'learning_rate': 7.275423292364504e-05, 'epoch': 2.32}\n",
            "{'loss': 0.5729, 'learning_rate': 7.218739183913573e-05, 'epoch': 2.38}\n",
            "{'loss': 0.4387, 'learning_rate': 7.16087503924024e-05, 'epoch': 2.43}\n",
            "{'loss': 0.4351, 'learning_rate': 7.10185341916099e-05, 'epoch': 2.49}\n",
            "{'loss': 0.4861, 'learning_rate': 7.04169733578369e-05, 'epoch': 2.54}\n",
            "{'loss': 0.4512, 'learning_rate': 6.980430243535344e-05, 'epoch': 2.6}\n",
            "{'loss': 0.519, 'learning_rate': 6.918076030017373e-05, 'epoch': 2.65}\n",
            "{'loss': 0.2447, 'learning_rate': 6.854659006692016e-05, 'epoch': 2.71}\n",
            "{'loss': 0.7498, 'learning_rate': 6.790203899403455e-05, 'epoch': 2.76}\n",
            "{'loss': 0.5329, 'learning_rate': 6.724735838737392e-05, 'epoch': 2.82}\n",
            "{'loss': 0.389, 'learning_rate': 6.658280350222814e-05, 'epoch': 2.87}\n",
            "{'loss': 0.2532, 'learning_rate': 6.590863344379769e-05, 'epoch': 2.93}\n",
            "{'loss': 0.2198, 'learning_rate': 6.522511106617038e-05, 'epoch': 2.98}\n",
            "{'loss': 0.5165, 'learning_rate': 6.453250286983645e-05, 'epoch': 3.04}\n",
            "{'loss': 0.3132, 'learning_rate': 6.383107889778192e-05, 'epoch': 3.09}\n",
            "{'loss': 0.2288, 'learning_rate': 6.312111263020077e-05, 'epoch': 3.15}\n",
            "{'loss': 0.1729, 'learning_rate': 6.240288087786695e-05, 'epoch': 3.2}\n",
            "{'loss': 0.4217, 'learning_rate': 6.167666367420783e-05, 'epoch': 3.26}\n",
            "{'loss': 0.175, 'learning_rate': 6.094274416612123e-05, 'epoch': 3.31}\n",
            "{'loss': 0.4499, 'learning_rate': 6.0201408503578364e-05, 'epoch': 3.37}\n",
            "{'loss': 0.3737, 'learning_rate': 5.94529457280561e-05, 'epoch': 3.43}\n",
            "{'loss': 0.469, 'learning_rate': 5.869764765984173e-05, 'epoch': 3.48}\n",
            "{'loss': 0.3556, 'learning_rate': 5.793580878425431e-05, 'epoch': 3.54}\n",
            "{'loss': 0.1902, 'learning_rate': 5.716772613682694e-05, 'epoch': 3.59}\n",
            "{'loss': 0.6082, 'learning_rate': 5.6393699187494726e-05, 'epoch': 3.65}\n",
            "{'loss': 0.6344, 'learning_rate': 5.561402972383366e-05, 'epoch': 3.7}\n",
            "{'loss': 0.3263, 'learning_rate': 5.482902173339568e-05, 'epoch': 3.76}\n",
            "{'loss': 0.5078, 'learning_rate': 5.40389812851862e-05, 'epoch': 3.81}\n",
            "{'loss': 0.3279, 'learning_rate': 5.324421641032996e-05, 'epoch': 3.87}\n",
            "{'loss': 0.3553, 'learning_rate': 5.2445036981971844e-05, 'epoch': 3.92}\n",
            "{'loss': 0.262, 'learning_rate': 5.164175459445966e-05, 'epoch': 3.98}\n",
            "{'loss': 0.2868, 'learning_rate': 5.083468244185562e-05, 'epoch': 4.03}\n",
            "{'loss': 0.3212, 'learning_rate': 5.002413519582428e-05, 'epoch': 4.09}\n",
            "{'loss': 0.273, 'learning_rate': 4.921042888294427e-05, 'epoch': 4.14}\n",
            "{'loss': 0.3935, 'learning_rate': 4.8393880761491865e-05, 'epoch': 4.2}\n",
            "{'loss': 0.3215, 'learning_rate': 4.75748091977441e-05, 'epoch': 4.25}\n",
            "{'loss': 0.1216, 'learning_rate': 4.6753533541850225e-05, 'epoch': 4.31}\n",
            "{'loss': 0.212, 'learning_rate': 4.593037400331919e-05, 'epoch': 4.36}\n",
            "{'loss': 0.2793, 'learning_rate': 4.510565152617236e-05, 'epoch': 4.42}\n",
            "{'loss': 0.2905, 'learning_rate': 4.4279687663809685e-05, 'epoch': 4.48}\n",
            "{'loss': 0.4618, 'learning_rate': 4.345280445363838e-05, 'epoch': 4.53}\n",
            "{'loss': 0.3101, 'learning_rate': 4.262532429151271e-05, 'epoch': 4.59}\n",
            "{'loss': 0.2889, 'learning_rate': 4.179756980603432e-05, 'epoch': 4.64}\n",
            "{'loss': 0.3247, 'learning_rate': 4.096986373276156e-05, 'epoch': 4.7}\n",
            "{'loss': 0.3006, 'learning_rate': 4.014252878837717e-05, 'epoch': 4.75}\n",
            "{'loss': 0.4052, 'learning_rate': 3.931588754486341e-05, 'epoch': 4.81}\n",
            "{'loss': 0.2375, 'learning_rate': 3.8490262303733536e-05, 'epoch': 4.86}\n",
            "{'loss': 0.2475, 'learning_rate': 3.766597497036872e-05, 'epoch': 4.92}\n",
            "{'loss': 0.3989, 'learning_rate': 3.6843346928509486e-05, 'epoch': 4.97}\n",
            "{'loss': 0.4398, 'learning_rate': 3.602269891495042e-05, 'epoch': 5.03}\n",
            "{'loss': 0.4047, 'learning_rate': 3.520435089448724e-05, 'epoch': 5.08}\n",
            "{'loss': 0.3854, 'learning_rate': 3.438862193516479e-05, 'epoch': 5.14}\n",
            "{'loss': 0.321, 'learning_rate': 3.357583008387473e-05, 'epoch': 5.19}\n",
            "{'loss': 0.3736, 'learning_rate': 3.276629224235121e-05, 'epoch': 5.25}\n",
            "{'loss': 0.2788, 'learning_rate': 3.1960324043613305e-05, 'epoch': 5.3}\n",
            "{'loss': 0.3523, 'learning_rate': 3.115823972890183e-05, 'epoch': 5.36}\n",
            "{'loss': 0.3645, 'learning_rate': 3.0360352025159003e-05, 'epoch': 5.41}\n",
            "{'loss': 0.2785, 'learning_rate': 2.9566972023098375e-05, 'epoch': 5.47}\n",
            "{'loss': 0.3819, 'learning_rate': 2.877840905591289e-05, 'epoch': 5.52}\n",
            "{'loss': 0.2775, 'learning_rate': 2.7994970578667942e-05, 'epoch': 5.58}\n",
            "{'loss': 0.3901, 'learning_rate': 2.721696204842701e-05, 'epoch': 5.64}\n",
            "{'loss': 0.4679, 'learning_rate': 2.644468680515595e-05, 'epoch': 5.69}\n",
            "{'loss': 0.2372, 'learning_rate': 2.567844595345305e-05, 'epoch': 5.75}\n",
            "{'loss': 0.1826, 'learning_rate': 2.4918538245150447e-05, 'epoch': 5.8}\n",
            "{'loss': 0.3305, 'learning_rate': 2.4165259962832937e-05, 'epoch': 5.86}\n",
            "{'loss': 0.2189, 'learning_rate': 2.3418904804319486e-05, 'epoch': 5.91}\n",
            "{'loss': 0.4442, 'learning_rate': 2.267976376815253e-05, 'epoch': 5.97}\n",
            "{'loss': 0.4877, 'learning_rate': 2.1948125040139823e-05, 'epoch': 6.02}\n",
            "{'loss': 0.1633, 'learning_rate': 2.1224273880992767e-05, 'epoch': 6.08}\n",
            "{'loss': 0.3019, 'learning_rate': 2.050849251510529e-05, 'epoch': 6.13}\n",
            "{'loss': 0.1566, 'learning_rate': 1.9801060020516595e-05, 'epoch': 6.19}\n",
            "{'loss': 0.3826, 'learning_rate': 1.9102252220100675e-05, 'epoch': 6.24}\n",
            "{'loss': 0.3457, 'learning_rate': 1.8412341574024872e-05, 'epoch': 6.3}\n",
            "{'loss': 0.2914, 'learning_rate': 1.773159707351965e-05, 'epoch': 6.35}\n",
            "{'loss': 0.3415, 'learning_rate': 1.7060284136000795e-05, 'epoch': 6.41}\n",
            "{'loss': 0.1152, 'learning_rate': 1.6398664501585113e-05, 'epoch': 6.46}\n",
            "{'loss': 0.315, 'learning_rate': 1.574699613103978e-05, 'epoch': 6.52}\n",
            "{'loss': 0.264, 'learning_rate': 1.5169213007742965e-05, 'epoch': 6.57}\n",
            "{'loss': 0.3485, 'learning_rate': 1.453714874465294e-05, 'epoch': 6.63}\n",
            "{'loss': 0.3534, 'learning_rate': 1.3915761537123565e-05, 'epoch': 6.69}\n",
            "{'loss': 0.3285, 'learning_rate': 1.3305293659586315e-05, 'epoch': 6.74}\n",
            "{'loss': 0.4509, 'learning_rate': 1.270598312910391e-05, 'epoch': 6.8}\n",
            "{'loss': 0.3041, 'learning_rate': 1.2118063612569219e-05, 'epoch': 6.85}\n",
            "{'loss': 0.246, 'learning_rate': 1.154176433560018e-05, 'epoch': 6.91}\n",
            "{'loss': 0.4317, 'learning_rate': 1.0977309993166341e-05, 'epoch': 6.96}\n",
            "{'loss': 0.3006, 'learning_rate': 1.0424920661981936e-05, 'epoch': 7.02}\n",
            "{'loss': 0.3901, 'learning_rate': 9.88481171469954e-06, 'epoch': 7.07}\n",
            "{'loss': 0.3449, 'learning_rate': 9.357193735937813e-06, 'epoch': 7.13}\n",
            "{'loss': 0.2158, 'learning_rate': 8.84227244017606e-06, 'epoch': 7.18}\n",
            "{'loss': 0.2862, 'learning_rate': 8.340248591547595e-06, 'epoch': 7.24}\n",
            "{'loss': 0.1251, 'learning_rate': 7.851317925563275e-06, 'epoch': 7.29}\n",
            "{'loss': 0.2054, 'learning_rate': 7.375671072795625e-06, 'epoch': 7.35}\n",
            "{'loss': 0.1607, 'learning_rate': 6.913493484553343e-06, 'epoch': 7.4}\n",
            "{'loss': 0.4232, 'learning_rate': 6.4649653605750994e-06, 'epoch': 7.46}\n",
            "{'loss': 0.378, 'learning_rate': 6.030261578771046e-06, 'epoch': 7.51}\n",
            "{'loss': 0.0772, 'learning_rate': 5.6095516270390935e-06, 'epoch': 7.57}\n",
            "{'loss': 0.4505, 'learning_rate': 5.202999537182805e-06, 'epoch': 7.62}\n",
            "{'loss': 0.1549, 'learning_rate': 4.8107638209566e-06, 'epoch': 7.68}\n",
            "{'loss': 0.3648, 'learning_rate': 4.432997408263102e-06, 'epoch': 7.73}\n",
            "{'loss': 0.3697, 'learning_rate': 4.069847587526922e-06, 'epoch': 7.79}\n",
            "{'loss': 0.2683, 'learning_rate': 3.7214559482679116e-06, 'epoch': 7.85}\n",
            "{'loss': 0.3599, 'learning_rate': 3.3879583258964462e-06, 'epoch': 7.9}\n",
            "{'loss': 0.1555, 'learning_rate': 3.0694847487521222e-06, 'epoch': 7.96}\n",
            "{'loss': 0.1462, 'learning_rate': 2.7661593874067046e-06, 'epoch': 8.01}\n",
            "{'loss': 0.4805, 'learning_rate': 2.4781005062508606e-06, 'epoch': 8.07}\n",
            "{'loss': 0.5306, 'learning_rate': 2.2054204173837533e-06, 'epoch': 8.12}\n",
            "{'loss': 0.192, 'learning_rate': 1.9482254368233035e-06, 'epoch': 8.18}\n",
            "{'loss': 0.0889, 'learning_rate': 1.706615843054403e-06, 'epoch': 8.23}\n",
            "{'loss': 0.3821, 'learning_rate': 1.4806858379309786e-06, 'epoch': 8.29}\n",
            "{'loss': 0.3098, 'learning_rate': 1.2705235099474339e-06, 'epoch': 8.34}\n",
            "{'loss': 0.2534, 'learning_rate': 1.0762107998935101e-06, 'epoch': 8.4}\n",
            "{'loss': 0.2199, 'learning_rate': 8.978234689062093e-07, 'epoch': 8.45}\n",
            "{'loss': 0.3949, 'learning_rate': 7.354310689310309e-07, 'epoch': 8.51}\n",
            "{'loss': 0.2275, 'learning_rate': 5.890969156041978e-07, 'epoch': 8.56}\n",
            "{'loss': 0.0729, 'learning_rate': 4.588780635663029e-07, 'epoch': 8.62}\n",
            "{'loss': 0.3457, 'learning_rate': 3.4482528421714403e-07, 'epoch': 8.67}\n",
            "{'loss': 0.2762, 'learning_rate': 2.4698304592031987e-07, 'epoch': 8.73}\n",
            "{'loss': 0.1918, 'learning_rate': 1.6538949666530465e-07, 'epoch': 8.78}\n",
            "{'loss': 0.1147, 'learning_rate': 1.0007644919384963e-07, 'epoch': 8.84}\n",
            "{'loss': 0.1963, 'learning_rate': 5.1069368596398714e-08, 'epoch': 8.9}\n",
            "{'loss': 0.2033, 'learning_rate': 1.8387362383451373e-08, 'epoch': 8.95}\n",
            "{'train_runtime': 165.4854, 'train_samples_per_second': 78.587, 'train_steps_per_second': 9.844, 'train_loss': 0.38502394377343707, 'epoch': 9.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 52/52 [00:01<00:00, 37.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 22:53:33,878] Trial 34 finished with value: 0.8563829787234041 and parameters: {'learning_rate': 8.384347555965284e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.20098075881599528, 'num_train_epochs': 9, 'warmup_steps': 38, 'freeze_layers': 6, 'dropout': 0.1767587401524868, 'lr_scheduler_type': 'cosine_with_restarts'}. Best is trial 19 with value: 0.9289340101522843.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: constant_with_warmup\n",
            " Warmup steps (True): 102\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "33d8f1909e1a49d495d71d967331f3cb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/368 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7032, 'learning_rate': 4.748535693868422e-06, 'epoch': 0.22}\n",
            "{'loss': 0.707, 'learning_rate': 1.068420531120395e-05, 'epoch': 0.43}\n",
            "{'loss': 0.675, 'learning_rate': 1.6619874928539477e-05, 'epoch': 0.65}\n",
            "{'loss': 0.6468, 'learning_rate': 2.2555544545875006e-05, 'epoch': 0.87}\n",
            "{'loss': 0.6185, 'learning_rate': 2.849121416321053e-05, 'epoch': 1.09}\n",
            "{'loss': 0.5452, 'learning_rate': 3.442688378054606e-05, 'epoch': 1.3}\n",
            "{'loss': 0.4851, 'learning_rate': 3.976898643614803e-05, 'epoch': 1.52}\n",
            "{'loss': 0.4625, 'learning_rate': 4.570465605348356e-05, 'epoch': 1.74}\n",
            "{'loss': 0.5305, 'learning_rate': 5.164032567081909e-05, 'epoch': 1.96}\n",
            "{'loss': 0.412, 'learning_rate': 5.698242832642106e-05, 'epoch': 2.17}\n",
            "{'loss': 0.3827, 'learning_rate': 6.054383009682238e-05, 'epoch': 2.39}\n",
            "{'loss': 0.313, 'learning_rate': 6.054383009682238e-05, 'epoch': 2.61}\n",
            "{'loss': 0.3045, 'learning_rate': 6.054383009682238e-05, 'epoch': 2.83}\n",
            "{'loss': 0.1779, 'learning_rate': 6.054383009682238e-05, 'epoch': 3.04}\n",
            "{'loss': 0.1847, 'learning_rate': 6.054383009682238e-05, 'epoch': 3.26}\n",
            "{'loss': 0.1669, 'learning_rate': 6.054383009682238e-05, 'epoch': 3.48}\n",
            "{'loss': 0.26, 'learning_rate': 6.054383009682238e-05, 'epoch': 3.7}\n",
            "{'loss': 0.1796, 'learning_rate': 6.054383009682238e-05, 'epoch': 3.91}\n",
            "{'loss': 0.1158, 'learning_rate': 6.054383009682238e-05, 'epoch': 4.13}\n",
            "{'loss': 0.1054, 'learning_rate': 6.054383009682238e-05, 'epoch': 4.35}\n",
            "{'loss': 0.2878, 'learning_rate': 6.054383009682238e-05, 'epoch': 4.57}\n",
            "{'loss': 0.1627, 'learning_rate': 6.054383009682238e-05, 'epoch': 4.78}\n",
            "{'loss': 0.1172, 'learning_rate': 6.054383009682238e-05, 'epoch': 5.0}\n",
            "{'loss': 0.0796, 'learning_rate': 6.054383009682238e-05, 'epoch': 5.22}\n",
            "{'loss': 0.1016, 'learning_rate': 6.054383009682238e-05, 'epoch': 5.43}\n",
            "{'loss': 0.0815, 'learning_rate': 6.054383009682238e-05, 'epoch': 5.65}\n",
            "{'loss': 0.1269, 'learning_rate': 6.054383009682238e-05, 'epoch': 5.87}\n",
            "{'loss': 0.0342, 'learning_rate': 6.054383009682238e-05, 'epoch': 6.09}\n",
            "{'loss': 0.0316, 'learning_rate': 6.054383009682238e-05, 'epoch': 6.3}\n",
            "{'loss': 0.052, 'learning_rate': 6.054383009682238e-05, 'epoch': 6.52}\n",
            "{'loss': 0.0406, 'learning_rate': 6.054383009682238e-05, 'epoch': 6.74}\n",
            "{'loss': 0.0499, 'learning_rate': 6.054383009682238e-05, 'epoch': 6.96}\n",
            "{'loss': 0.0196, 'learning_rate': 6.054383009682238e-05, 'epoch': 7.17}\n",
            "{'loss': 0.0505, 'learning_rate': 6.054383009682238e-05, 'epoch': 7.39}\n",
            "{'loss': 0.0842, 'learning_rate': 6.054383009682238e-05, 'epoch': 7.61}\n",
            "{'loss': 0.0787, 'learning_rate': 6.054383009682238e-05, 'epoch': 7.83}\n",
            "{'train_runtime': 104.6876, 'train_samples_per_second': 110.424, 'train_steps_per_second': 3.515, 'train_loss': 0.25569349681229697, 'epoch': 8.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 13/13 [00:00<00:00, 13.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 22:55:22,222] Trial 35 finished with value: 0.9230769230769231 and parameters: {'learning_rate': 6.054383009682238e-05, 'per_device_train_batch_size': 32, 'weight_decay': 0.2670343187898195, 'num_train_epochs': 8, 'warmup_steps': 102, 'freeze_layers': 9, 'dropout': 0.2585721892750704, 'lr_scheduler_type': 'constant_with_warmup'}. Best is trial 19 with value: 0.9289340101522843.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: constant_with_warmup\n",
            " Warmup steps (True): 162\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "55bf7e0382ac4beaaf082cb2c946f206",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/322 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7113, 'learning_rate': 3.0876036008898524e-06, 'epoch': 0.22}\n",
            "{'loss': 0.7027, 'learning_rate': 6.561157651890936e-06, 'epoch': 0.43}\n",
            "{'loss': 0.6858, 'learning_rate': 1.0420662153003252e-05, 'epoch': 0.65}\n",
            "{'loss': 0.6715, 'learning_rate': 1.4280166654115567e-05, 'epoch': 0.87}\n",
            "{'loss': 0.6699, 'learning_rate': 1.8139671155227884e-05, 'epoch': 1.09}\n",
            "{'loss': 0.6314, 'learning_rate': 2.19991756563402e-05, 'epoch': 1.3}\n",
            "{'loss': 0.5831, 'learning_rate': 2.5858680157452517e-05, 'epoch': 1.52}\n",
            "{'loss': 0.4957, 'learning_rate': 2.9718184658564832e-05, 'epoch': 1.74}\n",
            "{'loss': 0.4644, 'learning_rate': 3.357768915967715e-05, 'epoch': 1.96}\n",
            "{'loss': 0.3884, 'learning_rate': 3.7437193660789466e-05, 'epoch': 2.17}\n",
            "{'loss': 0.4444, 'learning_rate': 4.1296698161901784e-05, 'epoch': 2.39}\n",
            "{'loss': 0.3692, 'learning_rate': 4.5156202663014096e-05, 'epoch': 2.61}\n",
            "{'loss': 0.3702, 'learning_rate': 4.9015707164126415e-05, 'epoch': 2.83}\n",
            "{'loss': 0.2238, 'learning_rate': 5.2875211665238726e-05, 'epoch': 3.04}\n",
            "{'loss': 0.2666, 'learning_rate': 5.6734716166351045e-05, 'epoch': 3.26}\n",
            "{'loss': 0.3712, 'learning_rate': 6.0594220667463356e-05, 'epoch': 3.48}\n",
            "{'loss': 0.312, 'learning_rate': 6.252397291801952e-05, 'epoch': 3.7}\n",
            "{'loss': 0.2152, 'learning_rate': 6.252397291801952e-05, 'epoch': 3.91}\n",
            "{'loss': 0.1546, 'learning_rate': 6.252397291801952e-05, 'epoch': 4.13}\n",
            "{'loss': 0.123, 'learning_rate': 6.252397291801952e-05, 'epoch': 4.35}\n",
            "{'loss': 0.4255, 'learning_rate': 6.252397291801952e-05, 'epoch': 4.57}\n",
            "{'loss': 0.2269, 'learning_rate': 6.252397291801952e-05, 'epoch': 4.78}\n",
            "{'loss': 0.1948, 'learning_rate': 6.252397291801952e-05, 'epoch': 5.0}\n",
            "{'loss': 0.1164, 'learning_rate': 6.252397291801952e-05, 'epoch': 5.22}\n",
            "{'loss': 0.1154, 'learning_rate': 6.252397291801952e-05, 'epoch': 5.43}\n",
            "{'loss': 0.1054, 'learning_rate': 6.252397291801952e-05, 'epoch': 5.65}\n",
            "{'loss': 0.1119, 'learning_rate': 6.252397291801952e-05, 'epoch': 5.87}\n",
            "{'loss': 0.1094, 'learning_rate': 6.252397291801952e-05, 'epoch': 6.09}\n",
            "{'loss': 0.0966, 'learning_rate': 6.252397291801952e-05, 'epoch': 6.3}\n",
            "{'loss': 0.0506, 'learning_rate': 6.252397291801952e-05, 'epoch': 6.52}\n",
            "{'loss': 0.195, 'learning_rate': 6.252397291801952e-05, 'epoch': 6.74}\n",
            "{'loss': 0.0898, 'learning_rate': 6.252397291801952e-05, 'epoch': 6.96}\n",
            "{'train_runtime': 88.2847, 'train_samples_per_second': 114.572, 'train_steps_per_second': 3.647, 'train_loss': 0.3321542686534039, 'epoch': 7.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 13/13 [00:01<00:00, 12.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 22:56:54,226] Trial 36 finished with value: 0.8717948717948718 and parameters: {'learning_rate': 6.252397291801952e-05, 'per_device_train_batch_size': 32, 'weight_decay': 0.21971344441616, 'num_train_epochs': 7, 'warmup_steps': 162, 'freeze_layers': 9, 'dropout': 0.2594800122312064, 'lr_scheduler_type': 'constant_with_warmup'}. Best is trial 19 with value: 0.9289340101522843.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: constant_with_warmup\n",
            " Warmup steps (True): 101\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6b6c4156d6b04feaac8c9638a293e352",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/414 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7058, 'learning_rate': 6.07332578495085e-06, 'epoch': 0.22}\n",
            "{'loss': 0.7067, 'learning_rate': 1.2905817293020558e-05, 'epoch': 0.43}\n",
            "{'loss': 0.6756, 'learning_rate': 1.9738308801090262e-05, 'epoch': 0.65}\n",
            "{'loss': 0.6459, 'learning_rate': 2.6570800309159968e-05, 'epoch': 0.87}\n",
            "{'loss': 0.6342, 'learning_rate': 3.4162457540348534e-05, 'epoch': 1.09}\n",
            "{'loss': 0.5517, 'learning_rate': 4.1754114771537096e-05, 'epoch': 1.3}\n",
            "{'loss': 0.4431, 'learning_rate': 4.934577200272566e-05, 'epoch': 1.52}\n",
            "{'loss': 0.4668, 'learning_rate': 5.693742923391422e-05, 'epoch': 1.74}\n",
            "{'loss': 0.5144, 'learning_rate': 6.452908646510278e-05, 'epoch': 1.96}\n",
            "{'loss': 0.5172, 'learning_rate': 7.212074369629134e-05, 'epoch': 2.17}\n",
            "{'loss': 0.3774, 'learning_rate': 7.667573803500448e-05, 'epoch': 2.39}\n",
            "{'loss': 0.3232, 'learning_rate': 7.667573803500448e-05, 'epoch': 2.61}\n",
            "{'loss': 0.2814, 'learning_rate': 7.667573803500448e-05, 'epoch': 2.83}\n",
            "{'loss': 0.2177, 'learning_rate': 7.667573803500448e-05, 'epoch': 3.04}\n",
            "{'loss': 0.2182, 'learning_rate': 7.667573803500448e-05, 'epoch': 3.26}\n",
            "{'loss': 0.1804, 'learning_rate': 7.667573803500448e-05, 'epoch': 3.48}\n",
            "{'loss': 0.2597, 'learning_rate': 7.667573803500448e-05, 'epoch': 3.7}\n",
            "{'loss': 0.1633, 'learning_rate': 7.667573803500448e-05, 'epoch': 3.91}\n",
            "{'loss': 0.075, 'learning_rate': 7.667573803500448e-05, 'epoch': 4.13}\n",
            "{'loss': 0.1568, 'learning_rate': 7.667573803500448e-05, 'epoch': 4.35}\n",
            "{'loss': 0.2282, 'learning_rate': 7.667573803500448e-05, 'epoch': 4.57}\n",
            "{'loss': 0.0991, 'learning_rate': 7.667573803500448e-05, 'epoch': 4.78}\n",
            "{'loss': 0.1607, 'learning_rate': 7.667573803500448e-05, 'epoch': 5.0}\n",
            "{'loss': 0.1246, 'learning_rate': 7.667573803500448e-05, 'epoch': 5.22}\n",
            "{'loss': 0.0787, 'learning_rate': 7.667573803500448e-05, 'epoch': 5.43}\n",
            "{'loss': 0.1787, 'learning_rate': 7.667573803500448e-05, 'epoch': 5.65}\n",
            "{'loss': 0.1793, 'learning_rate': 7.667573803500448e-05, 'epoch': 5.87}\n",
            "{'loss': 0.0833, 'learning_rate': 7.667573803500448e-05, 'epoch': 6.09}\n",
            "{'loss': 0.0167, 'learning_rate': 7.667573803500448e-05, 'epoch': 6.3}\n",
            "{'loss': 0.0523, 'learning_rate': 7.667573803500448e-05, 'epoch': 6.52}\n",
            "{'loss': 0.0847, 'learning_rate': 7.667573803500448e-05, 'epoch': 6.74}\n",
            "{'loss': 0.1637, 'learning_rate': 7.667573803500448e-05, 'epoch': 6.96}\n",
            "{'loss': 0.0582, 'learning_rate': 7.667573803500448e-05, 'epoch': 7.17}\n",
            "{'loss': 0.0491, 'learning_rate': 7.667573803500448e-05, 'epoch': 7.39}\n",
            "{'loss': 0.0856, 'learning_rate': 7.667573803500448e-05, 'epoch': 7.61}\n",
            "{'loss': 0.0343, 'learning_rate': 7.667573803500448e-05, 'epoch': 7.83}\n",
            "{'loss': 0.0242, 'learning_rate': 7.667573803500448e-05, 'epoch': 8.04}\n",
            "{'loss': 0.0957, 'learning_rate': 7.667573803500448e-05, 'epoch': 8.26}\n",
            "{'loss': 0.02, 'learning_rate': 7.667573803500448e-05, 'epoch': 8.48}\n",
            "{'loss': 0.033, 'learning_rate': 7.667573803500448e-05, 'epoch': 8.7}\n",
            "{'loss': 0.0409, 'learning_rate': 7.667573803500448e-05, 'epoch': 8.91}\n",
            "{'train_runtime': 118.8075, 'train_samples_per_second': 109.463, 'train_steps_per_second': 3.485, 'train_loss': 0.2423185787483114, 'epoch': 9.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 13/13 [00:01<00:00, 12.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 22:58:56,617] Trial 37 finished with value: 0.8773841961852861 and parameters: {'learning_rate': 7.667573803500448e-05, 'per_device_train_batch_size': 32, 'weight_decay': 0.2535859794180394, 'num_train_epochs': 9, 'warmup_steps': 101, 'freeze_layers': 9, 'dropout': 0.2932621830958261, 'lr_scheduler_type': 'constant_with_warmup'}. Best is trial 19 with value: 0.9289340101522843.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: constant_with_warmup\n",
            " Warmup steps (True): 136\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e24963c254c348b8ac7517dee6b40c36",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/460 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7045, 'learning_rate': 3.880874777035544e-06, 'epoch': 0.22}\n",
            "{'loss': 0.7126, 'learning_rate': 7.761749554071088e-06, 'epoch': 0.43}\n",
            "{'loss': 0.6778, 'learning_rate': 1.164262433110663e-05, 'epoch': 0.65}\n",
            "{'loss': 0.6581, 'learning_rate': 1.5523499108142176e-05, 'epoch': 0.87}\n",
            "{'loss': 0.6884, 'learning_rate': 1.9835582193737226e-05, 'epoch': 1.09}\n",
            "{'loss': 0.6487, 'learning_rate': 2.414766527933227e-05, 'epoch': 1.3}\n",
            "{'loss': 0.6209, 'learning_rate': 2.845974836492732e-05, 'epoch': 1.52}\n",
            "{'loss': 0.5839, 'learning_rate': 3.234062314196287e-05, 'epoch': 1.74}\n",
            "{'loss': 0.5728, 'learning_rate': 3.6652706227557914e-05, 'epoch': 1.96}\n",
            "{'loss': 0.4338, 'learning_rate': 4.096478931315296e-05, 'epoch': 2.17}\n",
            "{'loss': 0.4182, 'learning_rate': 4.5276872398748014e-05, 'epoch': 2.39}\n",
            "{'loss': 0.3903, 'learning_rate': 4.9588955484343054e-05, 'epoch': 2.61}\n",
            "{'loss': 0.4349, 'learning_rate': 5.39010385699381e-05, 'epoch': 2.83}\n",
            "{'loss': 0.3175, 'learning_rate': 5.8213121655533154e-05, 'epoch': 3.04}\n",
            "{'loss': 0.2515, 'learning_rate': 5.864432996409266e-05, 'epoch': 3.26}\n",
            "{'loss': 0.2684, 'learning_rate': 5.864432996409266e-05, 'epoch': 3.48}\n",
            "{'loss': 0.3418, 'learning_rate': 5.864432996409266e-05, 'epoch': 3.7}\n",
            "{'loss': 0.2046, 'learning_rate': 5.864432996409266e-05, 'epoch': 3.91}\n",
            "{'loss': 0.1155, 'learning_rate': 5.864432996409266e-05, 'epoch': 4.13}\n",
            "{'loss': 0.1455, 'learning_rate': 5.864432996409266e-05, 'epoch': 4.35}\n",
            "{'loss': 0.2218, 'learning_rate': 5.864432996409266e-05, 'epoch': 4.57}\n",
            "{'loss': 0.158, 'learning_rate': 5.864432996409266e-05, 'epoch': 4.78}\n",
            "{'loss': 0.1605, 'learning_rate': 5.864432996409266e-05, 'epoch': 5.0}\n",
            "{'loss': 0.0615, 'learning_rate': 5.864432996409266e-05, 'epoch': 5.22}\n",
            "{'loss': 0.1126, 'learning_rate': 5.864432996409266e-05, 'epoch': 5.43}\n",
            "{'loss': 0.1333, 'learning_rate': 5.864432996409266e-05, 'epoch': 5.65}\n",
            "{'loss': 0.1188, 'learning_rate': 5.864432996409266e-05, 'epoch': 5.87}\n",
            "{'loss': 0.0573, 'learning_rate': 5.864432996409266e-05, 'epoch': 6.09}\n",
            "{'loss': 0.0604, 'learning_rate': 5.864432996409266e-05, 'epoch': 6.3}\n",
            "{'loss': 0.03, 'learning_rate': 5.864432996409266e-05, 'epoch': 6.52}\n",
            "{'loss': 0.0217, 'learning_rate': 5.864432996409266e-05, 'epoch': 6.74}\n",
            "{'loss': 0.0679, 'learning_rate': 5.864432996409266e-05, 'epoch': 6.96}\n",
            "{'loss': 0.1124, 'learning_rate': 5.864432996409266e-05, 'epoch': 7.17}\n",
            "{'loss': 0.0482, 'learning_rate': 5.864432996409266e-05, 'epoch': 7.39}\n",
            "{'loss': 0.035, 'learning_rate': 5.864432996409266e-05, 'epoch': 7.61}\n",
            "{'loss': 0.0994, 'learning_rate': 5.864432996409266e-05, 'epoch': 7.83}\n",
            "{'loss': 0.0494, 'learning_rate': 5.864432996409266e-05, 'epoch': 8.04}\n",
            "{'loss': 0.0882, 'learning_rate': 5.864432996409266e-05, 'epoch': 8.26}\n",
            "{'loss': 0.0677, 'learning_rate': 5.864432996409266e-05, 'epoch': 8.48}\n",
            "{'loss': 0.0121, 'learning_rate': 5.864432996409266e-05, 'epoch': 8.7}\n",
            "{'loss': 0.0345, 'learning_rate': 5.864432996409266e-05, 'epoch': 8.91}\n",
            "{'loss': 0.0118, 'learning_rate': 5.864432996409266e-05, 'epoch': 9.13}\n",
            "{'loss': 0.0742, 'learning_rate': 5.864432996409266e-05, 'epoch': 9.35}\n",
            "{'loss': 0.0245, 'learning_rate': 5.864432996409266e-05, 'epoch': 9.57}\n",
            "{'loss': 0.0424, 'learning_rate': 5.864432996409266e-05, 'epoch': 9.78}\n",
            "{'loss': 0.0642, 'learning_rate': 5.864432996409266e-05, 'epoch': 10.0}\n",
            "{'train_runtime': 130.9692, 'train_samples_per_second': 110.331, 'train_steps_per_second': 3.512, 'train_loss': 0.24255101598151352, 'epoch': 10.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 13/13 [00:01<00:00, 12.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 23:01:11,395] Trial 38 finished with value: 0.8906666666666667 and parameters: {'learning_rate': 5.864432996409266e-05, 'per_device_train_batch_size': 32, 'weight_decay': 0.2022358374121332, 'num_train_epochs': 10, 'warmup_steps': 136, 'freeze_layers': 9, 'dropout': 0.21901447876244068, 'lr_scheduler_type': 'constant_with_warmup'}. Best is trial 19 with value: 0.9289340101522843.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: polynomial\n",
            " Warmup steps (True): 155\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c80d655468d4d5ca84276b138a6cae0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/414 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7133, 'learning_rate': 2.14316368907802e-06, 'epoch': 0.22}\n",
            "{'loss': 0.708, 'learning_rate': 4.0481980793695935e-06, 'epoch': 0.43}\n",
            "{'loss': 0.6986, 'learning_rate': 6.191361768447614e-06, 'epoch': 0.65}\n",
            "{'loss': 0.6784, 'learning_rate': 8.57265475631208e-06, 'epoch': 0.87}\n",
            "{'loss': 0.672, 'learning_rate': 1.0953947744176546e-05, 'epoch': 1.09}\n",
            "{'loss': 0.6635, 'learning_rate': 1.3097111433254566e-05, 'epoch': 1.3}\n",
            "{'loss': 0.6462, 'learning_rate': 1.5478404421119033e-05, 'epoch': 1.52}\n",
            "{'loss': 0.6296, 'learning_rate': 1.7621568110197052e-05, 'epoch': 1.74}\n",
            "{'loss': 0.5744, 'learning_rate': 2.000286109806152e-05, 'epoch': 1.96}\n",
            "{'loss': 0.4847, 'learning_rate': 2.2384154085925986e-05, 'epoch': 2.17}\n",
            "{'loss': 0.4637, 'learning_rate': 2.4765447073790455e-05, 'epoch': 2.39}\n",
            "{'loss': 0.4144, 'learning_rate': 2.714674006165492e-05, 'epoch': 2.61}\n",
            "{'loss': 0.5027, 'learning_rate': 2.9528033049519385e-05, 'epoch': 2.83}\n",
            "{'loss': 0.3624, 'learning_rate': 3.1909326037383854e-05, 'epoch': 3.04}\n",
            "{'loss': 0.3244, 'learning_rate': 3.429061902524832e-05, 'epoch': 3.26}\n",
            "{'loss': 0.3144, 'learning_rate': 3.6671912013112785e-05, 'epoch': 3.48}\n",
            "{'loss': 0.3933, 'learning_rate': 3.563092790723864e-05, 'epoch': 3.7}\n",
            "{'loss': 0.3066, 'learning_rate': 3.42096907909491e-05, 'epoch': 3.91}\n",
            "{'loss': 0.1906, 'learning_rate': 3.278845367465955e-05, 'epoch': 4.13}\n",
            "{'loss': 0.2045, 'learning_rate': 3.1367216558370005e-05, 'epoch': 4.35}\n",
            "{'loss': 0.2396, 'learning_rate': 2.994597944208045e-05, 'epoch': 4.57}\n",
            "{'loss': 0.2079, 'learning_rate': 2.852474232579091e-05, 'epoch': 4.78}\n",
            "{'loss': 0.2278, 'learning_rate': 2.7103505209501364e-05, 'epoch': 5.0}\n",
            "{'loss': 0.1191, 'learning_rate': 2.5682268093211817e-05, 'epoch': 5.22}\n",
            "{'loss': 0.1279, 'learning_rate': 2.4261030976922274e-05, 'epoch': 5.43}\n",
            "{'loss': 0.1001, 'learning_rate': 2.2839793860632727e-05, 'epoch': 5.65}\n",
            "{'loss': 0.1544, 'learning_rate': 2.141855674434318e-05, 'epoch': 5.87}\n",
            "{'loss': 0.1173, 'learning_rate': 1.9997319628053637e-05, 'epoch': 6.09}\n",
            "{'loss': 0.0863, 'learning_rate': 1.8576082511764094e-05, 'epoch': 6.3}\n",
            "{'loss': 0.1124, 'learning_rate': 1.7154845395474544e-05, 'epoch': 6.52}\n",
            "{'loss': 0.0538, 'learning_rate': 1.5733608279185e-05, 'epoch': 6.74}\n",
            "{'loss': 0.0564, 'learning_rate': 1.4312371162895455e-05, 'epoch': 6.96}\n",
            "{'loss': 0.0402, 'learning_rate': 1.2891134046605908e-05, 'epoch': 7.17}\n",
            "{'loss': 0.0477, 'learning_rate': 1.1469896930316367e-05, 'epoch': 7.39}\n",
            "{'loss': 0.04, 'learning_rate': 1.004865981402682e-05, 'epoch': 7.61}\n",
            "{'loss': 0.045, 'learning_rate': 8.627422697737273e-06, 'epoch': 7.83}\n",
            "{'loss': 0.0146, 'learning_rate': 7.2061855814477245e-06, 'epoch': 8.04}\n",
            "{'loss': 0.0511, 'learning_rate': 5.784948465158184e-06, 'epoch': 8.26}\n",
            "{'loss': 0.0364, 'learning_rate': 4.363711348868636e-06, 'epoch': 8.48}\n",
            "{'loss': 0.018, 'learning_rate': 2.9424742325790892e-06, 'epoch': 8.7}\n",
            "{'loss': 0.0232, 'learning_rate': 1.5212371162895467e-06, 'epoch': 8.91}\n",
            "{'train_runtime': 131.6972, 'train_samples_per_second': 98.749, 'train_steps_per_second': 3.144, 'train_loss': 0.286610561668207, 'epoch': 9.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 13/13 [00:01<00:00, 12.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 23:03:26,812] Trial 39 finished with value: 0.9222797927461139 and parameters: {'learning_rate': 3.691004131189923e-05, 'per_device_train_batch_size': 32, 'weight_decay': 0.1664171285747487, 'num_train_epochs': 9, 'warmup_steps': 155, 'freeze_layers': 9, 'dropout': 0.3474829264001382, 'lr_scheduler_type': 'polynomial'}. Best is trial 19 with value: 0.9289340101522843.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: polynomial\n",
            " Warmup steps (True): 197\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "32095afeda714720b5235b633dd8f30f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/368 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7053, 'learning_rate': 1.4330371891394275e-06, 'epoch': 0.22}\n",
            "{'loss': 0.7163, 'learning_rate': 3.2243336755637123e-06, 'epoch': 0.43}\n",
            "{'loss': 0.6827, 'learning_rate': 4.6573708647031405e-06, 'epoch': 0.65}\n",
            "{'loss': 0.6722, 'learning_rate': 6.448667351127425e-06, 'epoch': 0.87}\n",
            "{'loss': 0.7064, 'learning_rate': 8.060834188909281e-06, 'epoch': 1.09}\n",
            "{'loss': 0.6828, 'learning_rate': 9.852130675333565e-06, 'epoch': 1.3}\n",
            "{'loss': 0.6633, 'learning_rate': 1.164342716175785e-05, 'epoch': 1.52}\n",
            "{'loss': 0.6727, 'learning_rate': 1.3434723648182134e-05, 'epoch': 1.74}\n",
            "{'loss': 0.6097, 'learning_rate': 1.522602013460642e-05, 'epoch': 1.96}\n",
            "{'loss': 0.5721, 'learning_rate': 1.7017316621030704e-05, 'epoch': 2.17}\n",
            "{'loss': 0.5173, 'learning_rate': 1.880861310745499e-05, 'epoch': 2.39}\n",
            "{'loss': 0.4682, 'learning_rate': 2.0599909593879272e-05, 'epoch': 2.61}\n",
            "{'loss': 0.5019, 'learning_rate': 2.2391206080303558e-05, 'epoch': 2.83}\n",
            "{'loss': 0.3632, 'learning_rate': 2.418250256672784e-05, 'epoch': 3.04}\n",
            "{'loss': 0.2993, 'learning_rate': 2.5973799053152126e-05, 'epoch': 3.26}\n",
            "{'loss': 0.4037, 'learning_rate': 2.7765095539576412e-05, 'epoch': 3.48}\n",
            "{'loss': 0.3773, 'learning_rate': 2.9556392026000695e-05, 'epoch': 3.7}\n",
            "{'loss': 0.3245, 'learning_rate': 3.134768851242498e-05, 'epoch': 3.91}\n",
            "{'loss': 0.2216, 'learning_rate': 3.313898499884927e-05, 'epoch': 4.13}\n",
            "{'loss': 0.2023, 'learning_rate': 3.493028148527355e-05, 'epoch': 4.35}\n",
            "{'loss': 0.2426, 'learning_rate': 3.3642293260567374e-05, 'epoch': 4.57}\n",
            "{'loss': 0.2747, 'learning_rate': 3.158448385807858e-05, 'epoch': 4.78}\n",
            "{'loss': 0.2492, 'learning_rate': 2.9526674455589778e-05, 'epoch': 5.0}\n",
            "{'loss': 0.1446, 'learning_rate': 2.746886505310098e-05, 'epoch': 5.22}\n",
            "{'loss': 0.1404, 'learning_rate': 2.5411055650612185e-05, 'epoch': 5.43}\n",
            "{'loss': 0.1883, 'learning_rate': 2.335324624812339e-05, 'epoch': 5.65}\n",
            "{'loss': 0.1154, 'learning_rate': 2.12954368456346e-05, 'epoch': 5.87}\n",
            "{'loss': 0.121, 'learning_rate': 1.92376274431458e-05, 'epoch': 6.09}\n",
            "{'loss': 0.0736, 'learning_rate': 1.7179818040657002e-05, 'epoch': 6.3}\n",
            "{'loss': 0.0812, 'learning_rate': 1.512200863816821e-05, 'epoch': 6.52}\n",
            "{'loss': 0.0682, 'learning_rate': 1.3064199235679415e-05, 'epoch': 6.74}\n",
            "{'loss': 0.0777, 'learning_rate': 1.1006389833190618e-05, 'epoch': 6.96}\n",
            "{'loss': 0.0609, 'learning_rate': 8.948580430701825e-06, 'epoch': 7.17}\n",
            "{'loss': 0.0279, 'learning_rate': 6.890771028213027e-06, 'epoch': 7.39}\n",
            "{'loss': 0.0591, 'learning_rate': 4.832961625724232e-06, 'epoch': 7.61}\n",
            "{'loss': 0.0842, 'learning_rate': 2.775152223235436e-06, 'epoch': 7.83}\n",
            "{'train_runtime': 105.0051, 'train_samples_per_second': 110.09, 'train_steps_per_second': 3.505, 'train_loss': 0.3363265636296052, 'epoch': 8.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 13/13 [00:00<00:00, 13.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 23:05:15,300] Trial 40 finished with value: 0.9012658227848102 and parameters: {'learning_rate': 3.528854078255841e-05, 'per_device_train_batch_size': 32, 'weight_decay': 0.11135366266542637, 'num_train_epochs': 8, 'warmup_steps': 197, 'freeze_layers': 9, 'dropout': 0.3647043167287891, 'lr_scheduler_type': 'polynomial'}. Best is trial 19 with value: 0.9289340101522843.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: polynomial\n",
            " Warmup steps (True): 153\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bd0404bd913e4559934c4310fc93a0c2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/414 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7115, 'learning_rate': 2.1980315296677833e-06, 'epoch': 0.22}\n",
            "{'loss': 0.7033, 'learning_rate': 4.670817000544039e-06, 'epoch': 0.43}\n",
            "{'loss': 0.6852, 'learning_rate': 7.418356412628769e-06, 'epoch': 0.65}\n",
            "{'loss': 0.6813, 'learning_rate': 1.0165895824713497e-05, 'epoch': 0.87}\n",
            "{'loss': 0.6762, 'learning_rate': 1.2913435236798228e-05, 'epoch': 1.09}\n",
            "{'loss': 0.6454, 'learning_rate': 1.5660974648882956e-05, 'epoch': 1.3}\n",
            "{'loss': 0.6234, 'learning_rate': 1.8408514060967683e-05, 'epoch': 1.52}\n",
            "{'loss': 0.5848, 'learning_rate': 2.1156053473052414e-05, 'epoch': 1.74}\n",
            "{'loss': 0.5395, 'learning_rate': 2.3903592885137142e-05, 'epoch': 1.96}\n",
            "{'loss': 0.4471, 'learning_rate': 2.665113229722187e-05, 'epoch': 2.17}\n",
            "{'loss': 0.4829, 'learning_rate': 2.93986717093066e-05, 'epoch': 2.39}\n",
            "{'loss': 0.4186, 'learning_rate': 3.2146211121391325e-05, 'epoch': 2.61}\n",
            "{'loss': 0.4125, 'learning_rate': 3.489375053347606e-05, 'epoch': 2.83}\n",
            "{'loss': 0.2902, 'learning_rate': 3.764128994556079e-05, 'epoch': 3.04}\n",
            "{'loss': 0.2646, 'learning_rate': 4.038882935764552e-05, 'epoch': 3.26}\n",
            "{'loss': 0.2884, 'learning_rate': 4.139463495118147e-05, 'epoch': 3.48}\n",
            "{'loss': 0.3135, 'learning_rate': 3.9787839816894253e-05, 'epoch': 3.7}\n",
            "{'loss': 0.2245, 'learning_rate': 3.818104468260703e-05, 'epoch': 3.91}\n",
            "{'loss': 0.1431, 'learning_rate': 3.657424954831982e-05, 'epoch': 4.13}\n",
            "{'loss': 0.1224, 'learning_rate': 3.4967454414032606e-05, 'epoch': 4.35}\n",
            "{'loss': 0.1805, 'learning_rate': 3.3360659279745386e-05, 'epoch': 4.57}\n",
            "{'loss': 0.1991, 'learning_rate': 3.175386414545817e-05, 'epoch': 4.78}\n",
            "{'loss': 0.189, 'learning_rate': 3.014706901117095e-05, 'epoch': 5.0}\n",
            "{'loss': 0.1196, 'learning_rate': 2.854027387688373e-05, 'epoch': 5.22}\n",
            "{'loss': 0.0947, 'learning_rate': 2.6933478742596518e-05, 'epoch': 5.43}\n",
            "{'loss': 0.1168, 'learning_rate': 2.5326683608309297e-05, 'epoch': 5.65}\n",
            "{'loss': 0.0903, 'learning_rate': 2.3719888474022077e-05, 'epoch': 5.87}\n",
            "{'loss': 0.0888, 'learning_rate': 2.2113093339734867e-05, 'epoch': 6.09}\n",
            "{'loss': 0.0744, 'learning_rate': 2.050629820544765e-05, 'epoch': 6.3}\n",
            "{'loss': 0.0905, 'learning_rate': 1.8899503071160433e-05, 'epoch': 6.52}\n",
            "{'loss': 0.0868, 'learning_rate': 1.7292707936873216e-05, 'epoch': 6.74}\n",
            "{'loss': 0.0606, 'learning_rate': 1.5685912802586002e-05, 'epoch': 6.96}\n",
            "{'loss': 0.0323, 'learning_rate': 1.4079117668298787e-05, 'epoch': 7.17}\n",
            "{'loss': 0.0202, 'learning_rate': 1.2472322534011572e-05, 'epoch': 7.39}\n",
            "{'loss': 0.0129, 'learning_rate': 1.0865527399724348e-05, 'epoch': 7.61}\n",
            "{'loss': 0.0476, 'learning_rate': 9.258732265437133e-06, 'epoch': 7.83}\n",
            "{'loss': 0.0443, 'learning_rate': 7.651937131149916e-06, 'epoch': 8.04}\n",
            "{'loss': 0.0783, 'learning_rate': 6.0451419968627e-06, 'epoch': 8.26}\n",
            "{'loss': 0.0357, 'learning_rate': 4.438346862575484e-06, 'epoch': 8.48}\n",
            "{'loss': 0.0069, 'learning_rate': 2.8315517282882677e-06, 'epoch': 8.7}\n",
            "{'loss': 0.0126, 'learning_rate': 1.2247565940010516e-06, 'epoch': 8.91}\n",
            "{'train_runtime': 115.4185, 'train_samples_per_second': 112.677, 'train_steps_per_second': 3.587, 'train_loss': 0.2642915760085959, 'epoch': 9.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 13/13 [00:00<00:00, 13.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 23:07:14,376] Trial 41 finished with value: 0.910025706940874 and parameters: {'learning_rate': 4.2037353004896355e-05, 'per_device_train_batch_size': 32, 'weight_decay': 0.1663935254597588, 'num_train_epochs': 9, 'warmup_steps': 153, 'freeze_layers': 9, 'dropout': 0.34398726623651465, 'lr_scheduler_type': 'polynomial'}. Best is trial 19 with value: 0.9289340101522843.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: polynomial\n",
            " Warmup steps (True): 122\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4c0650e4d20d4885a22035713fbb846c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/460 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7049, 'learning_rate': 2.2242923098578097e-06, 'epoch': 0.22}\n",
            "{'loss': 0.714, 'learning_rate': 3.954297439747218e-06, 'epoch': 0.43}\n",
            "{'loss': 0.6795, 'learning_rate': 6.4257333395892275e-06, 'epoch': 0.65}\n",
            "{'loss': 0.6724, 'learning_rate': 8.897169239431239e-06, 'epoch': 0.87}\n",
            "{'loss': 0.6939, 'learning_rate': 1.1368605139273249e-05, 'epoch': 1.09}\n",
            "{'loss': 0.6659, 'learning_rate': 1.3840041039115262e-05, 'epoch': 1.3}\n",
            "{'loss': 0.6463, 'learning_rate': 1.6311476938957275e-05, 'epoch': 1.52}\n",
            "{'loss': 0.6499, 'learning_rate': 1.8782912838799284e-05, 'epoch': 1.74}\n",
            "{'loss': 0.5667, 'learning_rate': 2.1254348738641294e-05, 'epoch': 1.96}\n",
            "{'loss': 0.5101, 'learning_rate': 2.3725784638483304e-05, 'epoch': 2.17}\n",
            "{'loss': 0.4861, 'learning_rate': 2.6197220538325313e-05, 'epoch': 2.39}\n",
            "{'loss': 0.4251, 'learning_rate': 2.8668656438167323e-05, 'epoch': 2.61}\n",
            "{'loss': 0.4411, 'learning_rate': 2.9795878712059843e-05, 'epoch': 2.83}\n",
            "{'loss': 0.3204, 'learning_rate': 2.890678054702811e-05, 'epoch': 3.04}\n",
            "{'loss': 0.2992, 'learning_rate': 2.8017682381996377e-05, 'epoch': 3.26}\n",
            "{'loss': 0.3557, 'learning_rate': 2.7128584216964646e-05, 'epoch': 3.48}\n",
            "{'loss': 0.2928, 'learning_rate': 2.6239486051932915e-05, 'epoch': 3.7}\n",
            "{'loss': 0.2555, 'learning_rate': 2.535038788690118e-05, 'epoch': 3.91}\n",
            "{'loss': 0.175, 'learning_rate': 2.446128972186945e-05, 'epoch': 4.13}\n",
            "{'loss': 0.151, 'learning_rate': 2.3572191556837718e-05, 'epoch': 4.35}\n",
            "{'loss': 0.2494, 'learning_rate': 2.2683093391805987e-05, 'epoch': 4.57}\n",
            "{'loss': 0.2188, 'learning_rate': 2.1793995226774255e-05, 'epoch': 4.78}\n",
            "{'loss': 0.2024, 'learning_rate': 2.090489706174252e-05, 'epoch': 5.0}\n",
            "{'loss': 0.1248, 'learning_rate': 2.0015798896710793e-05, 'epoch': 5.22}\n",
            "{'loss': 0.1215, 'learning_rate': 1.9126700731679058e-05, 'epoch': 5.43}\n",
            "{'loss': 0.1515, 'learning_rate': 1.8237602566647327e-05, 'epoch': 5.65}\n",
            "{'loss': 0.0905, 'learning_rate': 1.7348504401615596e-05, 'epoch': 5.87}\n",
            "{'loss': 0.1099, 'learning_rate': 1.6459406236583865e-05, 'epoch': 6.09}\n",
            "{'loss': 0.0861, 'learning_rate': 1.557030807155213e-05, 'epoch': 6.3}\n",
            "{'loss': 0.0668, 'learning_rate': 1.4681209906520402e-05, 'epoch': 6.52}\n",
            "{'loss': 0.0592, 'learning_rate': 1.379211174148867e-05, 'epoch': 6.74}\n",
            "{'loss': 0.0999, 'learning_rate': 1.2903013576456936e-05, 'epoch': 6.96}\n",
            "{'loss': 0.056, 'learning_rate': 1.2013915411425207e-05, 'epoch': 7.17}\n",
            "{'loss': 0.0783, 'learning_rate': 1.1124817246393474e-05, 'epoch': 7.39}\n",
            "{'loss': 0.0586, 'learning_rate': 1.023571908136174e-05, 'epoch': 7.61}\n",
            "{'loss': 0.0803, 'learning_rate': 9.346620916330011e-06, 'epoch': 7.83}\n",
            "{'loss': 0.0615, 'learning_rate': 8.457522751298278e-06, 'epoch': 8.04}\n",
            "{'loss': 0.0487, 'learning_rate': 7.568424586266549e-06, 'epoch': 8.26}\n",
            "{'loss': 0.0448, 'learning_rate': 6.679326421234815e-06, 'epoch': 8.48}\n",
            "{'loss': 0.0153, 'learning_rate': 5.790228256203082e-06, 'epoch': 8.7}\n",
            "{'loss': 0.0434, 'learning_rate': 4.901130091171353e-06, 'epoch': 8.91}\n",
            "{'loss': 0.0213, 'learning_rate': 4.01203192613962e-06, 'epoch': 9.13}\n",
            "{'loss': 0.0122, 'learning_rate': 3.1229337611078868e-06, 'epoch': 9.35}\n",
            "{'loss': 0.0411, 'learning_rate': 2.2338355960761572e-06, 'epoch': 9.57}\n",
            "{'loss': 0.0294, 'learning_rate': 1.3447374310444243e-06, 'epoch': 9.78}\n",
            "{'loss': 0.0599, 'learning_rate': 4.556392660126912e-07, 'epoch': 10.0}\n",
            "{'train_runtime': 126.5177, 'train_samples_per_second': 114.213, 'train_steps_per_second': 3.636, 'train_loss': 0.25950327058849126, 'epoch': 10.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 13/13 [00:01<00:00, 12.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 23:09:24,493] Trial 42 finished with value: 0.9035532994923858 and parameters: {'learning_rate': 3.0151517978072533e-05, 'per_device_train_batch_size': 32, 'weight_decay': 0.19400753946661542, 'num_train_epochs': 10, 'warmup_steps': 122, 'freeze_layers': 9, 'dropout': 0.39613750353882254, 'lr_scheduler_type': 'polynomial'}. Best is trial 19 with value: 0.9289340101522843.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: polynomial\n",
            " Warmup steps (True): 218\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee89efe9e5b24a8db7fdcefcab954543",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/414 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7142, 'learning_rate': 7.716105659877487e-07, 'epoch': 0.22}\n",
            "{'loss': 0.7174, 'learning_rate': 1.7361237734724345e-06, 'epoch': 0.43}\n",
            "{'loss': 0.7099, 'learning_rate': 2.604185660208652e-06, 'epoch': 0.65}\n",
            "{'loss': 0.6947, 'learning_rate': 3.5686988676933376e-06, 'epoch': 0.87}\n",
            "{'loss': 0.7005, 'learning_rate': 4.436760754429554e-06, 'epoch': 1.09}\n",
            "{'loss': 0.6818, 'learning_rate': 5.40127396191424e-06, 'epoch': 1.3}\n",
            "{'loss': 0.6789, 'learning_rate': 6.269335848650457e-06, 'epoch': 1.52}\n",
            "{'loss': 0.6843, 'learning_rate': 7.233849056135143e-06, 'epoch': 1.74}\n",
            "{'loss': 0.6465, 'learning_rate': 8.198362263619828e-06, 'epoch': 1.96}\n",
            "{'loss': 0.6428, 'learning_rate': 9.162875471104514e-06, 'epoch': 2.17}\n",
            "{'loss': 0.6499, 'learning_rate': 1.01273886785892e-05, 'epoch': 2.39}\n",
            "{'loss': 0.635, 'learning_rate': 1.1091901886073886e-05, 'epoch': 2.61}\n",
            "{'loss': 0.6004, 'learning_rate': 1.2056415093558572e-05, 'epoch': 2.83}\n",
            "{'loss': 0.5537, 'learning_rate': 1.3020928301043257e-05, 'epoch': 3.04}\n",
            "{'loss': 0.5089, 'learning_rate': 1.3888990187779476e-05, 'epoch': 3.26}\n",
            "{'loss': 0.5134, 'learning_rate': 1.485350339526416e-05, 'epoch': 3.48}\n",
            "{'loss': 0.4407, 'learning_rate': 1.5818016602748846e-05, 'epoch': 3.7}\n",
            "{'loss': 0.445, 'learning_rate': 1.6782529810233533e-05, 'epoch': 3.91}\n",
            "{'loss': 0.336, 'learning_rate': 1.7747043017718217e-05, 'epoch': 4.13}\n",
            "{'loss': 0.3425, 'learning_rate': 1.8711556225202905e-05, 'epoch': 4.35}\n",
            "{'loss': 0.3706, 'learning_rate': 1.967606943268759e-05, 'epoch': 4.57}\n",
            "{'loss': 0.3674, 'learning_rate': 2.0640582640172276e-05, 'epoch': 4.78}\n",
            "{'loss': 0.3346, 'learning_rate': 2.038578421123249e-05, 'epoch': 5.0}\n",
            "{'loss': 0.2237, 'learning_rate': 1.9318111358009728e-05, 'epoch': 5.22}\n",
            "{'loss': 0.2413, 'learning_rate': 1.8250438504786965e-05, 'epoch': 5.43}\n",
            "{'loss': 0.1961, 'learning_rate': 1.7182765651564203e-05, 'epoch': 5.65}\n",
            "{'loss': 0.2457, 'learning_rate': 1.611509279834144e-05, 'epoch': 5.87}\n",
            "{'loss': 0.1923, 'learning_rate': 1.504741994511868e-05, 'epoch': 6.09}\n",
            "{'loss': 0.168, 'learning_rate': 1.3979747091895914e-05, 'epoch': 6.3}\n",
            "{'loss': 0.2175, 'learning_rate': 1.2912074238673156e-05, 'epoch': 6.52}\n",
            "{'loss': 0.1926, 'learning_rate': 1.1844401385450392e-05, 'epoch': 6.74}\n",
            "{'loss': 0.171, 'learning_rate': 1.0776728532227628e-05, 'epoch': 6.96}\n",
            "{'loss': 0.1267, 'learning_rate': 9.709055679004865e-06, 'epoch': 7.17}\n",
            "{'loss': 0.1239, 'learning_rate': 8.641382825782103e-06, 'epoch': 7.39}\n",
            "{'loss': 0.135, 'learning_rate': 7.573709972559338e-06, 'epoch': 7.61}\n",
            "{'loss': 0.1433, 'learning_rate': 6.506037119336577e-06, 'epoch': 7.83}\n",
            "{'loss': 0.121, 'learning_rate': 5.4383642661138125e-06, 'epoch': 8.04}\n",
            "{'loss': 0.1072, 'learning_rate': 4.370691412891051e-06, 'epoch': 8.26}\n",
            "{'loss': 0.1145, 'learning_rate': 3.303018559668287e-06, 'epoch': 8.48}\n",
            "{'loss': 0.0642, 'learning_rate': 2.2353457064455254e-06, 'epoch': 8.7}\n",
            "{'loss': 0.0673, 'learning_rate': 1.1676728532227616e-06, 'epoch': 8.91}\n",
            "{'train_runtime': 112.9732, 'train_samples_per_second': 115.116, 'train_steps_per_second': 3.665, 'train_loss': 0.3823772175552476, 'epoch': 9.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 13/13 [00:00<00:00, 13.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 23:11:20,895] Trial 43 finished with value: 0.9133858267716536 and parameters: {'learning_rate': 2.102638792316615e-05, 'per_device_train_batch_size': 32, 'weight_decay': 0.22087441826113255, 'num_train_epochs': 9, 'warmup_steps': 218, 'freeze_layers': 9, 'dropout': 0.32066796680731513, 'lr_scheduler_type': 'polynomial'}. Best is trial 19 with value: 0.9289340101522843.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: constant_with_warmup\n",
            " Warmup steps (True): 185\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "39c82a982e7840348275c05235279a34",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/322 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.705, 'learning_rate': 2.3348822020007855e-06, 'epoch': 0.22}\n",
            "{'loss': 0.7171, 'learning_rate': 4.410333048223706e-06, 'epoch': 0.43}\n",
            "{'loss': 0.6835, 'learning_rate': 7.004646606002356e-06, 'epoch': 0.65}\n",
            "{'loss': 0.6735, 'learning_rate': 9.598960163781008e-06, 'epoch': 0.87}\n",
            "{'loss': 0.6728, 'learning_rate': 1.2193273721559658e-05, 'epoch': 1.09}\n",
            "{'loss': 0.6511, 'learning_rate': 1.4787587279338308e-05, 'epoch': 1.3}\n",
            "{'loss': 0.6408, 'learning_rate': 1.738190083711696e-05, 'epoch': 1.52}\n",
            "{'loss': 0.6108, 'learning_rate': 1.997621439489561e-05, 'epoch': 1.74}\n",
            "{'loss': 0.5536, 'learning_rate': 2.257052795267426e-05, 'epoch': 1.96}\n",
            "{'loss': 0.5273, 'learning_rate': 2.516484151045291e-05, 'epoch': 2.17}\n",
            "{'loss': 0.5056, 'learning_rate': 2.7499723712453696e-05, 'epoch': 2.39}\n",
            "{'loss': 0.4333, 'learning_rate': 3.0094037270232348e-05, 'epoch': 2.61}\n",
            "{'loss': 0.3985, 'learning_rate': 3.2688350828011e-05, 'epoch': 2.83}\n",
            "{'loss': 0.3718, 'learning_rate': 3.528266438578965e-05, 'epoch': 3.04}\n",
            "{'loss': 0.3381, 'learning_rate': 3.78769779435683e-05, 'epoch': 3.26}\n",
            "{'loss': 0.3998, 'learning_rate': 4.047129150134695e-05, 'epoch': 3.48}\n",
            "{'loss': 0.4558, 'learning_rate': 4.30656050591256e-05, 'epoch': 3.7}\n",
            "{'loss': 0.3635, 'learning_rate': 4.565991861690425e-05, 'epoch': 3.91}\n",
            "{'loss': 0.2262, 'learning_rate': 4.799480081890503e-05, 'epoch': 4.13}\n",
            "{'loss': 0.2031, 'learning_rate': 4.799480081890503e-05, 'epoch': 4.35}\n",
            "{'loss': 0.2701, 'learning_rate': 4.799480081890503e-05, 'epoch': 4.57}\n",
            "{'loss': 0.2651, 'learning_rate': 4.799480081890503e-05, 'epoch': 4.78}\n",
            "{'loss': 0.2086, 'learning_rate': 4.799480081890503e-05, 'epoch': 5.0}\n",
            "{'loss': 0.2596, 'learning_rate': 4.799480081890503e-05, 'epoch': 5.22}\n",
            "{'loss': 0.1699, 'learning_rate': 4.799480081890503e-05, 'epoch': 5.43}\n",
            "{'loss': 0.1236, 'learning_rate': 4.799480081890503e-05, 'epoch': 5.65}\n",
            "{'loss': 0.1202, 'learning_rate': 4.799480081890503e-05, 'epoch': 5.87}\n",
            "{'loss': 0.0886, 'learning_rate': 4.799480081890503e-05, 'epoch': 6.09}\n",
            "{'loss': 0.1218, 'learning_rate': 4.799480081890503e-05, 'epoch': 6.3}\n",
            "{'loss': 0.1889, 'learning_rate': 4.799480081890503e-05, 'epoch': 6.52}\n",
            "{'loss': 0.1561, 'learning_rate': 4.799480081890503e-05, 'epoch': 6.74}\n",
            "{'loss': 0.1165, 'learning_rate': 4.799480081890503e-05, 'epoch': 6.96}\n",
            "{'train_runtime': 88.3389, 'train_samples_per_second': 114.502, 'train_steps_per_second': 3.645, 'train_loss': 0.3802264269371951, 'epoch': 7.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 13/13 [00:01<00:00, 12.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 23:12:52,797] Trial 44 finished with value: 0.8974358974358975 and parameters: {'learning_rate': 4.799480081890503e-05, 'per_device_train_batch_size': 32, 'weight_decay': 0.16813414234450075, 'num_train_epochs': 7, 'warmup_steps': 185, 'freeze_layers': 3, 'dropout': 0.2722948966848979, 'lr_scheduler_type': 'constant_with_warmup'}. Best is trial 19 with value: 0.9289340101522843.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: polynomial\n",
            " Warmup steps (True): 135\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0901b2915abf439bac11ca8325af23ca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/460 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.708, 'learning_rate': 3.3120850427355266e-07, 'epoch': 0.22}\n",
            "{'loss': 0.7133, 'learning_rate': 7.038180715812993e-07, 'epoch': 0.43}\n",
            "{'loss': 0.6907, 'learning_rate': 1.035026575854852e-06, 'epoch': 0.65}\n",
            "{'loss': 0.698, 'learning_rate': 1.4490372061967927e-06, 'epoch': 0.87}\n",
            "{'loss': 0.6977, 'learning_rate': 1.8630478365387336e-06, 'epoch': 1.09}\n",
            "{'loss': 0.6999, 'learning_rate': 2.2770584668806742e-06, 'epoch': 1.3}\n",
            "{'loss': 0.709, 'learning_rate': 2.691069097222615e-06, 'epoch': 1.52}\n",
            "{'loss': 0.6917, 'learning_rate': 3.1050797275645563e-06, 'epoch': 1.74}\n",
            "{'loss': 0.6765, 'learning_rate': 3.519090357906497e-06, 'epoch': 1.96}\n",
            "{'loss': 0.6641, 'learning_rate': 3.933100988248438e-06, 'epoch': 2.17}\n",
            "{'loss': 0.6561, 'learning_rate': 4.3471116185903784e-06, 'epoch': 2.39}\n",
            "{'loss': 0.6848, 'learning_rate': 4.761122248932319e-06, 'epoch': 2.61}\n",
            "{'loss': 0.665, 'learning_rate': 5.17513287927426e-06, 'epoch': 2.83}\n",
            "{'loss': 0.665, 'learning_rate': 5.589143509616201e-06, 'epoch': 3.04}\n",
            "{'loss': 0.6397, 'learning_rate': 5.420246786243394e-06, 'epoch': 3.26}\n",
            "{'loss': 0.6433, 'learning_rate': 5.251350062870589e-06, 'epoch': 3.48}\n",
            "{'loss': 0.6055, 'learning_rate': 5.082453339497782e-06, 'epoch': 3.7}\n",
            "{'loss': 0.6153, 'learning_rate': 4.913556616124976e-06, 'epoch': 3.91}\n",
            "{'loss': 0.5923, 'learning_rate': 4.74465989275217e-06, 'epoch': 4.13}\n",
            "{'loss': 0.5824, 'learning_rate': 4.575763169379364e-06, 'epoch': 4.35}\n",
            "{'loss': 0.5897, 'learning_rate': 4.4068664460065575e-06, 'epoch': 4.57}\n",
            "{'loss': 0.59, 'learning_rate': 4.237969722633752e-06, 'epoch': 4.78}\n",
            "{'loss': 0.5365, 'learning_rate': 4.069072999260945e-06, 'epoch': 5.0}\n",
            "{'loss': 0.5142, 'learning_rate': 3.900176275888139e-06, 'epoch': 5.22}\n",
            "{'loss': 0.5247, 'learning_rate': 3.731279552515333e-06, 'epoch': 5.43}\n",
            "{'loss': 0.5002, 'learning_rate': 3.562382829142527e-06, 'epoch': 5.65}\n",
            "{'loss': 0.5023, 'learning_rate': 3.3934861057697205e-06, 'epoch': 5.87}\n",
            "{'loss': 0.4832, 'learning_rate': 3.2245893823969144e-06, 'epoch': 6.09}\n",
            "{'loss': 0.4482, 'learning_rate': 3.055692659024108e-06, 'epoch': 6.3}\n",
            "{'loss': 0.4594, 'learning_rate': 2.8867959356513012e-06, 'epoch': 6.52}\n",
            "{'loss': 0.4294, 'learning_rate': 2.7178992122784955e-06, 'epoch': 6.74}\n",
            "{'loss': 0.4703, 'learning_rate': 2.5490024889056893e-06, 'epoch': 6.96}\n",
            "{'loss': 0.441, 'learning_rate': 2.380105765532883e-06, 'epoch': 7.17}\n",
            "{'loss': 0.4057, 'learning_rate': 2.211209042160077e-06, 'epoch': 7.39}\n",
            "{'loss': 0.4357, 'learning_rate': 2.042312318787271e-06, 'epoch': 7.61}\n",
            "{'loss': 0.454, 'learning_rate': 1.8734155954144647e-06, 'epoch': 7.83}\n",
            "{'loss': 0.4244, 'learning_rate': 1.7045188720416584e-06, 'epoch': 8.04}\n",
            "{'loss': 0.4339, 'learning_rate': 1.5356221486688526e-06, 'epoch': 8.26}\n",
            "{'loss': 0.4465, 'learning_rate': 1.3667254252960463e-06, 'epoch': 8.48}\n",
            "{'loss': 0.3833, 'learning_rate': 1.19782870192324e-06, 'epoch': 8.7}\n",
            "{'loss': 0.3771, 'learning_rate': 1.0458216508877144e-06, 'epoch': 8.91}\n",
            "{'loss': 0.3683, 'learning_rate': 8.769249275149083e-07, 'epoch': 9.13}\n",
            "{'loss': 0.4027, 'learning_rate': 7.08028204142102e-07, 'epoch': 9.35}\n",
            "{'loss': 0.389, 'learning_rate': 5.391314807692959e-07, 'epoch': 9.57}\n",
            "{'loss': 0.3599, 'learning_rate': 3.702347573964897e-07, 'epoch': 9.78}\n",
            "{'loss': 0.3916, 'learning_rate': 2.0133803402368346e-07, 'epoch': 10.0}\n",
            "{'train_runtime': 149.0585, 'train_samples_per_second': 96.942, 'train_steps_per_second': 3.086, 'train_loss': 0.5447737626407457, 'epoch': 10.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 13/13 [00:01<00:00, 12.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 23:15:25,301] Trial 45 finished with value: 0.8209366391184573 and parameters: {'learning_rate': 5.589143509616201e-06, 'per_device_train_batch_size': 32, 'weight_decay': 0.1502113788587189, 'num_train_epochs': 10, 'warmup_steps': 135, 'freeze_layers': 9, 'dropout': 0.4260621953789646, 'lr_scheduler_type': 'polynomial'}. Best is trial 19 with value: 0.9289340101522843.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: constant_with_warmup\n",
            " Warmup steps (True): 105\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cbf282b264ab455a9a7e6379dceb3586",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/368 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7132, 'learning_rate': 5.3453488132723535e-06, 'epoch': 0.22}\n",
            "{'loss': 0.6965, 'learning_rate': 1.0096769980625557e-05, 'epoch': 0.43}\n",
            "{'loss': 0.6812, 'learning_rate': 1.603604643981706e-05, 'epoch': 0.65}\n",
            "{'loss': 0.6525, 'learning_rate': 2.1975322899008566e-05, 'epoch': 0.87}\n",
            "{'loss': 0.6375, 'learning_rate': 2.7914599358200068e-05, 'epoch': 1.09}\n",
            "{'loss': 0.6031, 'learning_rate': 3.385387581739157e-05, 'epoch': 1.3}\n",
            "{'loss': 0.5489, 'learning_rate': 3.979315227658307e-05, 'epoch': 1.52}\n",
            "{'loss': 0.4658, 'learning_rate': 4.573242873577458e-05, 'epoch': 1.74}\n",
            "{'loss': 0.4649, 'learning_rate': 5.167170519496609e-05, 'epoch': 1.96}\n",
            "{'loss': 0.4152, 'learning_rate': 5.761098165415759e-05, 'epoch': 2.17}\n",
            "{'loss': 0.3457, 'learning_rate': 6.236240282151079e-05, 'epoch': 2.39}\n",
            "{'loss': 0.3168, 'learning_rate': 6.236240282151079e-05, 'epoch': 2.61}\n",
            "{'loss': 0.3286, 'learning_rate': 6.236240282151079e-05, 'epoch': 2.83}\n",
            "{'loss': 0.2377, 'learning_rate': 6.236240282151079e-05, 'epoch': 3.04}\n",
            "{'loss': 0.1457, 'learning_rate': 6.236240282151079e-05, 'epoch': 3.26}\n",
            "{'loss': 0.1618, 'learning_rate': 6.236240282151079e-05, 'epoch': 3.48}\n",
            "{'loss': 0.2842, 'learning_rate': 6.236240282151079e-05, 'epoch': 3.7}\n",
            "{'loss': 0.2045, 'learning_rate': 6.236240282151079e-05, 'epoch': 3.91}\n",
            "{'loss': 0.1354, 'learning_rate': 6.236240282151079e-05, 'epoch': 4.13}\n",
            "{'loss': 0.1189, 'learning_rate': 6.236240282151079e-05, 'epoch': 4.35}\n",
            "{'loss': 0.2143, 'learning_rate': 6.236240282151079e-05, 'epoch': 4.57}\n",
            "{'loss': 0.1482, 'learning_rate': 6.236240282151079e-05, 'epoch': 4.78}\n",
            "{'loss': 0.0584, 'learning_rate': 6.236240282151079e-05, 'epoch': 5.0}\n",
            "{'loss': 0.1003, 'learning_rate': 6.236240282151079e-05, 'epoch': 5.22}\n",
            "{'loss': 0.0893, 'learning_rate': 6.236240282151079e-05, 'epoch': 5.43}\n",
            "{'loss': 0.0678, 'learning_rate': 6.236240282151079e-05, 'epoch': 5.65}\n",
            "{'loss': 0.0496, 'learning_rate': 6.236240282151079e-05, 'epoch': 5.87}\n",
            "{'loss': 0.0834, 'learning_rate': 6.236240282151079e-05, 'epoch': 6.09}\n",
            "{'loss': 0.0429, 'learning_rate': 6.236240282151079e-05, 'epoch': 6.3}\n",
            "{'loss': 0.0429, 'learning_rate': 6.236240282151079e-05, 'epoch': 6.52}\n",
            "{'loss': 0.0738, 'learning_rate': 6.236240282151079e-05, 'epoch': 6.74}\n",
            "{'loss': 0.1467, 'learning_rate': 6.236240282151079e-05, 'epoch': 6.96}\n",
            "{'loss': 0.0692, 'learning_rate': 6.236240282151079e-05, 'epoch': 7.17}\n",
            "{'loss': 0.035, 'learning_rate': 6.236240282151079e-05, 'epoch': 7.39}\n",
            "{'loss': 0.0262, 'learning_rate': 6.236240282151079e-05, 'epoch': 7.61}\n",
            "{'loss': 0.0686, 'learning_rate': 6.236240282151079e-05, 'epoch': 7.83}\n",
            "{'train_runtime': 100.5182, 'train_samples_per_second': 115.004, 'train_steps_per_second': 3.661, 'train_loss': 0.2581516118801158, 'epoch': 8.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 13/13 [00:00<00:00, 13.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 23:17:09,338] Trial 46 finished with value: 0.8976377952755904 and parameters: {'learning_rate': 6.236240282151079e-05, 'per_device_train_batch_size': 32, 'weight_decay': 0.2381602103695057, 'num_train_epochs': 8, 'warmup_steps': 105, 'freeze_layers': 0, 'dropout': 0.11873903312837897, 'lr_scheduler_type': 'constant_with_warmup'}. Best is trial 19 with value: 0.9289340101522843.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: linear\n",
            " Warmup steps (True): 87\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a40fd4ceebed4f078f7885bc3533c269",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/414 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.711, 'learning_rate': 6.531077331380668e-06, 'epoch': 0.22}\n",
            "{'loss': 0.7005, 'learning_rate': 1.4694923995606502e-05, 'epoch': 0.43}\n",
            "{'loss': 0.6725, 'learning_rate': 2.2858770659832337e-05, 'epoch': 0.65}\n",
            "{'loss': 0.6564, 'learning_rate': 3.102261732405817e-05, 'epoch': 0.87}\n",
            "{'loss': 0.6598, 'learning_rate': 3.8370079321861423e-05, 'epoch': 1.09}\n",
            "{'loss': 0.6422, 'learning_rate': 4.6533925986087256e-05, 'epoch': 1.3}\n",
            "{'loss': 0.5266, 'learning_rate': 5.469777265031309e-05, 'epoch': 1.52}\n",
            "{'loss': 0.452, 'learning_rate': 6.286161931453894e-05, 'epoch': 1.74}\n",
            "{'loss': 0.4642, 'learning_rate': 7.102546597876476e-05, 'epoch': 1.96}\n",
            "{'loss': 0.5142, 'learning_rate': 6.885343338002578e-05, 'epoch': 2.17}\n",
            "{'loss': 0.4035, 'learning_rate': 6.668140078128679e-05, 'epoch': 2.39}\n",
            "{'loss': 0.3547, 'learning_rate': 6.45093681825478e-05, 'epoch': 2.61}\n",
            "{'loss': 0.2782, 'learning_rate': 6.233733558380883e-05, 'epoch': 2.83}\n",
            "{'loss': 0.3568, 'learning_rate': 6.016530298506984e-05, 'epoch': 3.04}\n",
            "{'loss': 0.2683, 'learning_rate': 5.799327038633086e-05, 'epoch': 3.26}\n",
            "{'loss': 0.2183, 'learning_rate': 5.5821237787591876e-05, 'epoch': 3.48}\n",
            "{'loss': 0.2305, 'learning_rate': 5.364920518885289e-05, 'epoch': 3.7}\n",
            "{'loss': 0.1645, 'learning_rate': 5.147717259011391e-05, 'epoch': 3.91}\n",
            "{'loss': 0.1487, 'learning_rate': 4.9522343251248827e-05, 'epoch': 4.13}\n",
            "{'loss': 0.1445, 'learning_rate': 4.735031065250984e-05, 'epoch': 4.35}\n",
            "{'loss': 0.235, 'learning_rate': 4.517827805377086e-05, 'epoch': 4.57}\n",
            "{'loss': 0.1259, 'learning_rate': 4.300624545503188e-05, 'epoch': 4.78}\n",
            "{'loss': 0.177, 'learning_rate': 4.083421285629289e-05, 'epoch': 5.0}\n",
            "{'loss': 0.0459, 'learning_rate': 3.866218025755391e-05, 'epoch': 5.22}\n",
            "{'loss': 0.0827, 'learning_rate': 3.649014765881493e-05, 'epoch': 5.43}\n",
            "{'loss': 0.101, 'learning_rate': 3.431811506007594e-05, 'epoch': 5.65}\n",
            "{'loss': 0.086, 'learning_rate': 3.214608246133695e-05, 'epoch': 5.87}\n",
            "{'loss': 0.0794, 'learning_rate': 2.9974049862597976e-05, 'epoch': 6.09}\n",
            "{'loss': 0.021, 'learning_rate': 2.780201726385899e-05, 'epoch': 6.3}\n",
            "{'loss': 0.0349, 'learning_rate': 2.5629984665120004e-05, 'epoch': 6.52}\n",
            "{'loss': 0.0695, 'learning_rate': 2.3457952066381023e-05, 'epoch': 6.74}\n",
            "{'loss': 0.0456, 'learning_rate': 2.128591946764204e-05, 'epoch': 6.96}\n",
            "{'loss': 0.011, 'learning_rate': 1.9113886868903055e-05, 'epoch': 7.17}\n",
            "{'loss': 0.0276, 'learning_rate': 1.694185427016407e-05, 'epoch': 7.39}\n",
            "{'loss': 0.0065, 'learning_rate': 1.4769821671425087e-05, 'epoch': 7.61}\n",
            "{'loss': 0.0191, 'learning_rate': 1.2597789072686104e-05, 'epoch': 7.83}\n",
            "{'loss': 0.0223, 'learning_rate': 1.0425756473947122e-05, 'epoch': 8.04}\n",
            "{'loss': 0.0412, 'learning_rate': 8.253723875208138e-06, 'epoch': 8.26}\n",
            "{'loss': 0.023, 'learning_rate': 6.081691276469154e-06, 'epoch': 8.48}\n",
            "{'loss': 0.0006, 'learning_rate': 3.90965867773017e-06, 'epoch': 8.7}\n",
            "{'loss': 0.0256, 'learning_rate': 1.7376260789911868e-06, 'epoch': 8.91}\n",
            "{'train_runtime': 112.8846, 'train_samples_per_second': 115.206, 'train_steps_per_second': 3.667, 'train_loss': 0.23789062456633886, 'epoch': 9.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 13/13 [00:00<00:00, 13.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 23:19:05,691] Trial 47 finished with value: 0.8974358974358975 and parameters: {'learning_rate': 7.102546597876476e-05, 'per_device_train_batch_size': 32, 'weight_decay': 0.0786916728644372, 'num_train_epochs': 9, 'warmup_steps': 87, 'freeze_layers': 9, 'dropout': 0.3477173690897347, 'lr_scheduler_type': 'linear'}. Best is trial 19 with value: 0.9289340101522843.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: cosine\n",
            " Warmup steps (True): 153\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5fe29289fb2b41da8167616c0b3f3ca5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/460 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7034, 'learning_rate': 4.559332300401547e-06, 'epoch': 0.22}\n",
            "{'loss': 0.7061, 'learning_rate': 1.0258497675903481e-05, 'epoch': 0.43}\n",
            "{'loss': 0.6676, 'learning_rate': 1.5957663051405417e-05, 'epoch': 0.65}\n",
            "{'loss': 0.6557, 'learning_rate': 2.1086911889357157e-05, 'epoch': 0.87}\n",
            "{'loss': 0.6754, 'learning_rate': 2.6786077264859093e-05, 'epoch': 1.09}\n",
            "{'loss': 0.615, 'learning_rate': 3.248524264036103e-05, 'epoch': 1.3}\n",
            "{'loss': 0.5829, 'learning_rate': 3.8184408015862964e-05, 'epoch': 1.52}\n",
            "{'loss': 0.5399, 'learning_rate': 4.3313656853814704e-05, 'epoch': 1.74}\n",
            "{'loss': 0.5586, 'learning_rate': 4.901282222931663e-05, 'epoch': 1.96}\n",
            "{'loss': 0.4131, 'learning_rate': 5.471198760481857e-05, 'epoch': 2.17}\n",
            "{'loss': 0.3938, 'learning_rate': 6.0411152980320504e-05, 'epoch': 2.39}\n",
            "{'loss': 0.3462, 'learning_rate': 6.611031835582243e-05, 'epoch': 2.61}\n",
            "{'loss': 0.3339, 'learning_rate': 7.180948373132437e-05, 'epoch': 2.83}\n",
            "{'loss': 0.2494, 'learning_rate': 7.75086491068263e-05, 'epoch': 3.04}\n",
            "{'loss': 0.2239, 'learning_rate': 8.320781448232825e-05, 'epoch': 3.26}\n",
            "{'loss': 0.2825, 'learning_rate': 8.717668676140344e-05, 'epoch': 3.48}\n",
            "{'loss': 0.3147, 'learning_rate': 8.681200759672926e-05, 'epoch': 3.7}\n",
            "{'loss': 0.2026, 'learning_rate': 8.599519946241938e-05, 'epoch': 3.91}\n",
            "{'loss': 0.1077, 'learning_rate': 8.473480838087598e-05, 'epoch': 4.13}\n",
            "{'loss': 0.294, 'learning_rate': 8.304402145194032e-05, 'epoch': 4.35}\n",
            "{'loss': 0.2178, 'learning_rate': 8.094052888015971e-05, 'epoch': 4.57}\n",
            "{'loss': 0.1696, 'learning_rate': 7.844633888739934e-05, 'epoch': 4.78}\n",
            "{'loss': 0.2, 'learning_rate': 7.55875474473131e-05, 'epoch': 5.0}\n",
            "{'loss': 0.2131, 'learning_rate': 7.239406525087449e-05, 'epoch': 5.22}\n",
            "{'loss': 0.1764, 'learning_rate': 6.889930475964592e-05, 'epoch': 5.43}\n",
            "{'loss': 0.1683, 'learning_rate': 6.513983062105635e-05, 'epoch': 5.65}\n",
            "{'loss': 0.1878, 'learning_rate': 6.115497710328818e-05, 'epoch': 5.87}\n",
            "{'loss': 0.1108, 'learning_rate': 5.698643655244031e-05, 'epoch': 6.09}\n",
            "{'loss': 0.1097, 'learning_rate': 5.2677823177817554e-05, 'epoch': 6.3}\n",
            "{'loss': 0.155, 'learning_rate': 4.827421672933295e-05, 'epoch': 6.52}\n",
            "{'loss': 0.1464, 'learning_rate': 4.382169084139102e-05, 'epoch': 6.74}\n",
            "{'loss': 0.1068, 'learning_rate': 3.936683097805123e-05, 'epoch': 6.96}\n",
            "{'loss': 0.098, 'learning_rate': 3.49562470230687e-05, 'epoch': 7.17}\n",
            "{'loss': 0.1151, 'learning_rate': 3.063608561443883e-05, 'epoch': 7.39}\n",
            "{'loss': 0.0065, 'learning_rate': 2.645154732574567e-05, 'epoch': 7.61}\n",
            "{'loss': 0.1145, 'learning_rate': 2.2446413745902886e-05, 'epoch': 7.83}\n",
            "{'loss': 0.0197, 'learning_rate': 1.86625894053125e-05, 'epoch': 8.04}\n",
            "{'loss': 0.1236, 'learning_rate': 1.5139663341132788e-05, 'epoch': 8.26}\n",
            "{'loss': 0.0247, 'learning_rate': 1.1914494888868441e-05, 'epoch': 8.48}\n",
            "{'loss': 0.0376, 'learning_rate': 9.020828034023406e-06, 'epoch': 8.7}\n",
            "{'loss': 0.0204, 'learning_rate': 6.488938358741176e-06, 'epoch': 8.91}\n",
            "{'loss': 0.012, 'learning_rate': 4.34531627732565e-06, 'epoch': 9.13}\n",
            "{'loss': 0.0543, 'learning_rate': 2.612389874855738e-06, 'epoch': 9.35}\n",
            "{'loss': 0.0603, 'learning_rate': 1.3082902487515707e-06, 'epoch': 9.57}\n",
            "{'loss': 0.0216, 'learning_rate': 4.4666180845417726e-07, 'epoch': 9.78}\n",
            "{'loss': 0.0435, 'learning_rate': 3.6519517997067946e-08, 'epoch': 10.0}\n",
            "{'train_runtime': 117.9779, 'train_samples_per_second': 122.481, 'train_steps_per_second': 3.899, 'train_loss': 0.2517384140225856, 'epoch': 10.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 13/13 [00:00<00:00, 13.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 23:21:07,140] Trial 48 finished with value: 0.9015544041450777 and parameters: {'learning_rate': 8.71972302451796e-05, 'per_device_train_batch_size': 32, 'weight_decay': 0.2662481883239539, 'num_train_epochs': 10, 'warmup_steps': 153, 'freeze_layers': 3, 'dropout': 0.3196628968386971, 'lr_scheduler_type': 'cosine'}. Best is trial 19 with value: 0.9289340101522843.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n",
            " Scheduler tuning: True | Using: constant_with_warmup\n",
            " Warmup steps (True): 217\n",
            " Dropout: (False)0.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fe5047affeb4459e9c310cb67751d557",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1629 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7618, 'learning_rate': 2.5458619313387135e-07, 'epoch': 0.06}\n",
            "{'loss': 0.6844, 'learning_rate': 5.81911298591706e-07, 'epoch': 0.11}\n",
            "{'loss': 0.7097, 'learning_rate': 9.092364040495407e-07, 'epoch': 0.17}\n",
            "{'loss': 0.7517, 'learning_rate': 1.2729309656693569e-06, 'epoch': 0.22}\n",
            "{'loss': 0.6848, 'learning_rate': 1.6366255272891731e-06, 'epoch': 0.28}\n",
            "{'loss': 0.6983, 'learning_rate': 2.0003200889089893e-06, 'epoch': 0.33}\n",
            "{'loss': 0.6666, 'learning_rate': 2.3640146505288054e-06, 'epoch': 0.39}\n",
            "{'loss': 0.7081, 'learning_rate': 2.727709212148622e-06, 'epoch': 0.44}\n",
            "{'loss': 0.6729, 'learning_rate': 3.0914037737684382e-06, 'epoch': 0.5}\n",
            "{'loss': 0.6755, 'learning_rate': 3.4550983353882542e-06, 'epoch': 0.55}\n",
            "{'loss': 0.7227, 'learning_rate': 3.818792897008071e-06, 'epoch': 0.61}\n",
            "{'loss': 0.6631, 'learning_rate': 4.182487458627887e-06, 'epoch': 0.66}\n",
            "{'loss': 0.6535, 'learning_rate': 4.546182020247703e-06, 'epoch': 0.72}\n",
            "{'loss': 0.6804, 'learning_rate': 4.909876581867519e-06, 'epoch': 0.77}\n",
            "{'loss': 0.6952, 'learning_rate': 5.237201687325354e-06, 'epoch': 0.83}\n",
            "{'loss': 0.6918, 'learning_rate': 5.60089624894517e-06, 'epoch': 0.88}\n",
            "{'loss': 0.6664, 'learning_rate': 5.964590810564986e-06, 'epoch': 0.94}\n",
            "{'loss': 0.6764, 'learning_rate': 6.328285372184802e-06, 'epoch': 0.99}\n",
            "{'loss': 0.6538, 'learning_rate': 6.691979933804619e-06, 'epoch': 1.05}\n",
            "{'loss': 0.6925, 'learning_rate': 7.055674495424435e-06, 'epoch': 1.1}\n",
            "{'loss': 0.6761, 'learning_rate': 7.419369057044252e-06, 'epoch': 1.16}\n",
            "{'loss': 0.6867, 'learning_rate': 7.783063618664068e-06, 'epoch': 1.22}\n",
            "{'loss': 0.6346, 'learning_rate': 7.892171987150013e-06, 'epoch': 1.27}\n",
            "{'loss': 0.646, 'learning_rate': 7.892171987150013e-06, 'epoch': 1.33}\n",
            "{'loss': 0.6258, 'learning_rate': 7.892171987150013e-06, 'epoch': 1.38}\n",
            "{'loss': 0.6402, 'learning_rate': 7.892171987150013e-06, 'epoch': 1.44}\n",
            "{'loss': 0.566, 'learning_rate': 7.892171987150013e-06, 'epoch': 1.49}\n",
            "{'loss': 0.6536, 'learning_rate': 7.892171987150013e-06, 'epoch': 1.55}\n",
            "{'loss': 0.5756, 'learning_rate': 7.892171987150013e-06, 'epoch': 1.6}\n",
            "{'loss': 0.5034, 'learning_rate': 7.892171987150013e-06, 'epoch': 1.66}\n",
            "{'loss': 0.5654, 'learning_rate': 7.892171987150013e-06, 'epoch': 1.71}\n",
            "{'loss': 0.505, 'learning_rate': 7.892171987150013e-06, 'epoch': 1.77}\n",
            "{'loss': 0.4241, 'learning_rate': 7.892171987150013e-06, 'epoch': 1.82}\n",
            "{'loss': 0.4563, 'learning_rate': 7.892171987150013e-06, 'epoch': 1.88}\n",
            "{'loss': 0.6272, 'learning_rate': 7.892171987150013e-06, 'epoch': 1.93}\n",
            "{'loss': 0.4313, 'learning_rate': 7.892171987150013e-06, 'epoch': 1.99}\n",
            "{'loss': 0.413, 'learning_rate': 7.892171987150013e-06, 'epoch': 2.04}\n",
            "{'loss': 0.343, 'learning_rate': 7.892171987150013e-06, 'epoch': 2.1}\n",
            "{'loss': 0.4015, 'learning_rate': 7.892171987150013e-06, 'epoch': 2.15}\n",
            "{'loss': 0.4308, 'learning_rate': 7.892171987150013e-06, 'epoch': 2.21}\n",
            "{'loss': 0.3861, 'learning_rate': 7.892171987150013e-06, 'epoch': 2.27}\n",
            "{'loss': 0.4528, 'learning_rate': 7.892171987150013e-06, 'epoch': 2.32}\n",
            "{'loss': 0.519, 'learning_rate': 7.892171987150013e-06, 'epoch': 2.38}\n",
            "{'loss': 0.3642, 'learning_rate': 7.892171987150013e-06, 'epoch': 2.43}\n",
            "{'loss': 0.3163, 'learning_rate': 7.892171987150013e-06, 'epoch': 2.49}\n",
            "{'loss': 0.4534, 'learning_rate': 7.892171987150013e-06, 'epoch': 2.54}\n",
            "{'loss': 0.5053, 'learning_rate': 7.892171987150013e-06, 'epoch': 2.6}\n",
            "{'loss': 0.372, 'learning_rate': 7.892171987150013e-06, 'epoch': 2.65}\n",
            "{'loss': 0.3291, 'learning_rate': 7.892171987150013e-06, 'epoch': 2.71}\n",
            "{'loss': 0.261, 'learning_rate': 7.892171987150013e-06, 'epoch': 2.76}\n",
            "{'loss': 0.4305, 'learning_rate': 7.892171987150013e-06, 'epoch': 2.82}\n",
            "{'loss': 0.3059, 'learning_rate': 7.892171987150013e-06, 'epoch': 2.87}\n",
            "{'loss': 0.3685, 'learning_rate': 7.892171987150013e-06, 'epoch': 2.93}\n",
            "{'loss': 0.2272, 'learning_rate': 7.892171987150013e-06, 'epoch': 2.98}\n",
            "{'loss': 0.2718, 'learning_rate': 7.892171987150013e-06, 'epoch': 3.04}\n",
            "{'loss': 0.2762, 'learning_rate': 7.892171987150013e-06, 'epoch': 3.09}\n",
            "{'loss': 0.1699, 'learning_rate': 7.892171987150013e-06, 'epoch': 3.15}\n",
            "{'loss': 0.3291, 'learning_rate': 7.892171987150013e-06, 'epoch': 3.2}\n",
            "{'loss': 0.2815, 'learning_rate': 7.892171987150013e-06, 'epoch': 3.26}\n",
            "{'loss': 0.2188, 'learning_rate': 7.892171987150013e-06, 'epoch': 3.31}\n",
            "{'loss': 0.4357, 'learning_rate': 7.892171987150013e-06, 'epoch': 3.37}\n",
            "{'loss': 0.3456, 'learning_rate': 7.892171987150013e-06, 'epoch': 3.43}\n",
            "{'loss': 0.3648, 'learning_rate': 7.892171987150013e-06, 'epoch': 3.48}\n",
            "{'loss': 0.4446, 'learning_rate': 7.892171987150013e-06, 'epoch': 3.54}\n",
            "{'loss': 0.2238, 'learning_rate': 7.892171987150013e-06, 'epoch': 3.59}\n",
            "{'loss': 0.4954, 'learning_rate': 7.892171987150013e-06, 'epoch': 3.65}\n",
            "{'loss': 0.3924, 'learning_rate': 7.892171987150013e-06, 'epoch': 3.7}\n",
            "{'loss': 0.2059, 'learning_rate': 7.892171987150013e-06, 'epoch': 3.76}\n",
            "{'loss': 0.3419, 'learning_rate': 7.892171987150013e-06, 'epoch': 3.81}\n",
            "{'loss': 0.3607, 'learning_rate': 7.892171987150013e-06, 'epoch': 3.87}\n",
            "{'loss': 0.2991, 'learning_rate': 7.892171987150013e-06, 'epoch': 3.92}\n",
            "{'loss': 0.292, 'learning_rate': 7.892171987150013e-06, 'epoch': 3.98}\n",
            "{'loss': 0.1934, 'learning_rate': 7.892171987150013e-06, 'epoch': 4.03}\n",
            "{'loss': 0.1004, 'learning_rate': 7.892171987150013e-06, 'epoch': 4.09}\n",
            "{'loss': 0.1622, 'learning_rate': 7.892171987150013e-06, 'epoch': 4.14}\n",
            "{'loss': 0.1832, 'learning_rate': 7.892171987150013e-06, 'epoch': 4.2}\n",
            "{'loss': 0.3389, 'learning_rate': 7.892171987150013e-06, 'epoch': 4.25}\n",
            "{'loss': 0.0943, 'learning_rate': 7.892171987150013e-06, 'epoch': 4.31}\n",
            "{'loss': 0.2004, 'learning_rate': 7.892171987150013e-06, 'epoch': 4.36}\n",
            "{'loss': 0.2085, 'learning_rate': 7.892171987150013e-06, 'epoch': 4.42}\n",
            "{'loss': 0.2398, 'learning_rate': 7.892171987150013e-06, 'epoch': 4.48}\n",
            "{'loss': 0.373, 'learning_rate': 7.892171987150013e-06, 'epoch': 4.53}\n",
            "{'loss': 0.4019, 'learning_rate': 7.892171987150013e-06, 'epoch': 4.59}\n",
            "{'loss': 0.3451, 'learning_rate': 7.892171987150013e-06, 'epoch': 4.64}\n",
            "{'loss': 0.2487, 'learning_rate': 7.892171987150013e-06, 'epoch': 4.7}\n",
            "{'loss': 0.1152, 'learning_rate': 7.892171987150013e-06, 'epoch': 4.75}\n",
            "{'loss': 0.3483, 'learning_rate': 7.892171987150013e-06, 'epoch': 4.81}\n",
            "{'loss': 0.3041, 'learning_rate': 7.892171987150013e-06, 'epoch': 4.86}\n",
            "{'loss': 0.1865, 'learning_rate': 7.892171987150013e-06, 'epoch': 4.92}\n",
            "{'loss': 0.2096, 'learning_rate': 7.892171987150013e-06, 'epoch': 4.97}\n",
            "{'loss': 0.2792, 'learning_rate': 7.892171987150013e-06, 'epoch': 5.03}\n",
            "{'loss': 0.1935, 'learning_rate': 7.892171987150013e-06, 'epoch': 5.08}\n",
            "{'loss': 0.1824, 'learning_rate': 7.892171987150013e-06, 'epoch': 5.14}\n",
            "{'loss': 0.236, 'learning_rate': 7.892171987150013e-06, 'epoch': 5.19}\n",
            "{'loss': 0.2146, 'learning_rate': 7.892171987150013e-06, 'epoch': 5.25}\n",
            "{'loss': 0.0839, 'learning_rate': 7.892171987150013e-06, 'epoch': 5.3}\n",
            "{'loss': 0.1626, 'learning_rate': 7.892171987150013e-06, 'epoch': 5.36}\n",
            "{'loss': 0.1584, 'learning_rate': 7.892171987150013e-06, 'epoch': 5.41}\n",
            "{'loss': 0.1119, 'learning_rate': 7.892171987150013e-06, 'epoch': 5.47}\n",
            "{'loss': 0.1676, 'learning_rate': 7.892171987150013e-06, 'epoch': 5.52}\n",
            "{'loss': 0.206, 'learning_rate': 7.892171987150013e-06, 'epoch': 5.58}\n",
            "{'loss': 0.0211, 'learning_rate': 7.892171987150013e-06, 'epoch': 5.64}\n",
            "{'loss': 0.1474, 'learning_rate': 7.892171987150013e-06, 'epoch': 5.69}\n",
            "{'loss': 0.166, 'learning_rate': 7.892171987150013e-06, 'epoch': 5.75}\n",
            "{'loss': 0.1876, 'learning_rate': 7.892171987150013e-06, 'epoch': 5.8}\n",
            "{'loss': 0.145, 'learning_rate': 7.892171987150013e-06, 'epoch': 5.86}\n",
            "{'loss': 0.0543, 'learning_rate': 7.892171987150013e-06, 'epoch': 5.91}\n",
            "{'loss': 0.4447, 'learning_rate': 7.892171987150013e-06, 'epoch': 5.97}\n",
            "{'loss': 0.2359, 'learning_rate': 7.892171987150013e-06, 'epoch': 6.02}\n",
            "{'loss': 0.294, 'learning_rate': 7.892171987150013e-06, 'epoch': 6.08}\n",
            "{'loss': 0.1401, 'learning_rate': 7.892171987150013e-06, 'epoch': 6.13}\n",
            "{'loss': 0.1028, 'learning_rate': 7.892171987150013e-06, 'epoch': 6.19}\n",
            "{'loss': 0.2379, 'learning_rate': 7.892171987150013e-06, 'epoch': 6.24}\n",
            "{'loss': 0.3514, 'learning_rate': 7.892171987150013e-06, 'epoch': 6.3}\n",
            "{'loss': 0.1126, 'learning_rate': 7.892171987150013e-06, 'epoch': 6.35}\n",
            "{'loss': 0.251, 'learning_rate': 7.892171987150013e-06, 'epoch': 6.41}\n",
            "{'loss': 0.0881, 'learning_rate': 7.892171987150013e-06, 'epoch': 6.46}\n",
            "{'loss': 0.0798, 'learning_rate': 7.892171987150013e-06, 'epoch': 6.52}\n",
            "{'loss': 0.1174, 'learning_rate': 7.892171987150013e-06, 'epoch': 6.57}\n",
            "{'loss': 0.202, 'learning_rate': 7.892171987150013e-06, 'epoch': 6.63}\n",
            "{'loss': 0.0815, 'learning_rate': 7.892171987150013e-06, 'epoch': 6.69}\n",
            "{'loss': 0.1859, 'learning_rate': 7.892171987150013e-06, 'epoch': 6.74}\n",
            "{'loss': 0.1353, 'learning_rate': 7.892171987150013e-06, 'epoch': 6.8}\n",
            "{'loss': 0.2778, 'learning_rate': 7.892171987150013e-06, 'epoch': 6.85}\n",
            "{'loss': 0.0786, 'learning_rate': 7.892171987150013e-06, 'epoch': 6.91}\n",
            "{'loss': 0.1714, 'learning_rate': 7.892171987150013e-06, 'epoch': 6.96}\n",
            "{'loss': 0.196, 'learning_rate': 7.892171987150013e-06, 'epoch': 7.02}\n",
            "{'loss': 0.1505, 'learning_rate': 7.892171987150013e-06, 'epoch': 7.07}\n",
            "{'loss': 0.1185, 'learning_rate': 7.892171987150013e-06, 'epoch': 7.13}\n",
            "{'loss': 0.0759, 'learning_rate': 7.892171987150013e-06, 'epoch': 7.18}\n",
            "{'loss': 0.0016, 'learning_rate': 7.892171987150013e-06, 'epoch': 7.24}\n",
            "{'loss': 0.0047, 'learning_rate': 7.892171987150013e-06, 'epoch': 7.29}\n",
            "{'loss': 0.0068, 'learning_rate': 7.892171987150013e-06, 'epoch': 7.35}\n",
            "{'loss': 0.1117, 'learning_rate': 7.892171987150013e-06, 'epoch': 7.4}\n",
            "{'loss': 0.0783, 'learning_rate': 7.892171987150013e-06, 'epoch': 7.46}\n",
            "{'loss': 0.0211, 'learning_rate': 7.892171987150013e-06, 'epoch': 7.51}\n",
            "{'loss': 0.0094, 'learning_rate': 7.892171987150013e-06, 'epoch': 7.57}\n",
            "{'loss': 0.2584, 'learning_rate': 7.892171987150013e-06, 'epoch': 7.62}\n",
            "{'loss': 0.1047, 'learning_rate': 7.892171987150013e-06, 'epoch': 7.68}\n",
            "{'loss': 0.2042, 'learning_rate': 7.892171987150013e-06, 'epoch': 7.73}\n",
            "{'loss': 0.1219, 'learning_rate': 7.892171987150013e-06, 'epoch': 7.79}\n",
            "{'loss': 0.118, 'learning_rate': 7.892171987150013e-06, 'epoch': 7.85}\n",
            "{'loss': 0.0292, 'learning_rate': 7.892171987150013e-06, 'epoch': 7.9}\n",
            "{'loss': 0.0441, 'learning_rate': 7.892171987150013e-06, 'epoch': 7.96}\n",
            "{'loss': 0.1306, 'learning_rate': 7.892171987150013e-06, 'epoch': 8.01}\n",
            "{'loss': 0.2296, 'learning_rate': 7.892171987150013e-06, 'epoch': 8.07}\n",
            "{'loss': 0.2119, 'learning_rate': 7.892171987150013e-06, 'epoch': 8.12}\n",
            "{'loss': 0.0746, 'learning_rate': 7.892171987150013e-06, 'epoch': 8.18}\n",
            "{'loss': 0.0033, 'learning_rate': 7.892171987150013e-06, 'epoch': 8.23}\n",
            "{'loss': 0.018, 'learning_rate': 7.892171987150013e-06, 'epoch': 8.29}\n",
            "{'loss': 0.0688, 'learning_rate': 7.892171987150013e-06, 'epoch': 8.34}\n",
            "{'loss': 0.0704, 'learning_rate': 7.892171987150013e-06, 'epoch': 8.4}\n",
            "{'loss': 0.1094, 'learning_rate': 7.892171987150013e-06, 'epoch': 8.45}\n",
            "{'loss': 0.1339, 'learning_rate': 7.892171987150013e-06, 'epoch': 8.51}\n",
            "{'loss': 0.0801, 'learning_rate': 7.892171987150013e-06, 'epoch': 8.56}\n",
            "{'loss': 0.0007, 'learning_rate': 7.892171987150013e-06, 'epoch': 8.62}\n",
            "{'loss': 0.0566, 'learning_rate': 7.892171987150013e-06, 'epoch': 8.67}\n",
            "{'loss': 0.0201, 'learning_rate': 7.892171987150013e-06, 'epoch': 8.73}\n",
            "{'loss': 0.1852, 'learning_rate': 7.892171987150013e-06, 'epoch': 8.78}\n",
            "{'loss': 0.1833, 'learning_rate': 7.892171987150013e-06, 'epoch': 8.84}\n",
            "{'loss': 0.001, 'learning_rate': 7.892171987150013e-06, 'epoch': 8.9}\n",
            "{'loss': 0.0625, 'learning_rate': 7.892171987150013e-06, 'epoch': 8.95}\n",
            "{'train_runtime': 153.2675, 'train_samples_per_second': 84.852, 'train_steps_per_second': 10.628, 'train_loss': 0.3043177626281519, 'epoch': 9.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 52/52 [00:01<00:00, 41.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-12 23:23:44,634] Trial 49 finished with value: 0.898936170212766 and parameters: {'learning_rate': 7.892171987150013e-06, 'per_device_train_batch_size': 8, 'weight_decay': 0.010045765158026854, 'num_train_epochs': 9, 'warmup_steps': 217, 'freeze_layers': 0, 'dropout': 0.27834427908396847, 'lr_scheduler_type': 'constant_with_warmup'}. Best is trial 19 with value: 0.9289340101522843.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Best trial:\n",
            "FrozenTrial(number=19, state=TrialState.COMPLETE, values=[0.9289340101522843], datetime_start=datetime.datetime(2025, 11, 12, 22, 9, 4, 59315), datetime_complete=datetime.datetime(2025, 11, 12, 22, 11, 51, 821785), params={'learning_rate': 8.408596909042147e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.19146450882672536, 'num_train_epochs': 9, 'warmup_steps': 113, 'freeze_layers': 6, 'dropout': 0.1411689003855268, 'lr_scheduler_type': 'cosine'}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'learning_rate': FloatDistribution(high=0.0001, log=True, low=5e-06, step=None), 'per_device_train_batch_size': CategoricalDistribution(choices=(8, 16, 32)), 'weight_decay': FloatDistribution(high=0.3, log=False, low=0.0, step=None), 'num_train_epochs': IntDistribution(high=10, log=False, low=4, step=1), 'warmup_steps': IntDistribution(high=300, log=False, low=0, step=1), 'freeze_layers': CategoricalDistribution(choices=(0, 3, 6, 9)), 'dropout': FloatDistribution(high=0.5, log=False, low=0.1, step=None), 'lr_scheduler_type': CategoricalDistribution(choices=('linear', 'cosine', 'cosine_with_restarts', 'polynomial', 'constant_with_warmup'))}, trial_id=19, value=None)\n",
            "Stratify:  False\n",
            "Selected: ['combined_123']\n",
            "Combo name: combined_123\n",
            "Label distribution (combined): {1: 930, 0: 1136}\n",
            "Train/val/test sizes: 1445 207 414\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\modeling_utils.py:463: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\willi\\miniconda3\\envs\\tGPU3.8\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7bc568572def4c8a93042fef61fbcea9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1629 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'train_runtime': 152.8831, 'train_samples_per_second': 85.065, 'train_steps_per_second': 10.655, 'train_loss': 0.4380611937202655, 'epoch': 9.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 52/52 [00:01<00:00, 46.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique preds: [0 1]\n",
            "Unique labels: [0 1]\n",
            "\n",
            " Final Test F1 Score (macro): 0.8802\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Final detailed eval: 100%|| 52/52 [00:01<00:00, 44.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Final model, tokenizer, scheduler (cosine), and metrics saved to ./results/()_bert_optuna\n"
          ]
        }
      ],
      "source": [
        "start_optuna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run Widget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "23dc837eb4e64a61bb34c56e373ed544",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Button(description='Run Default Training and Evaluation', layout=Layout(width='max-content'), style=ButtonStyl"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e871de0493f24845990fcf4400212616",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Button(description='Run Optuna', layout=Layout(width='max-content'), style=ButtonStyle())"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "add6393c45224052aacaded6c10b5b3d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# Create an output area\n",
        "out = widgets.Output()\n",
        "\n",
        "def on_train_click(b):\n",
        "    with out:  # capture all stdout/stderr into this widget\n",
        "        clear_output(wait=True)  # clears previous runs\n",
        "        print(\"Starting training...\")  \n",
        "        default_start_model_training_and_evaluation(\n",
        "            model_choice_int.value\n",
        "        )\n",
        "        print(\"Training finished!\")\n",
        "\n",
        "def on_optuna_click(b):\n",
        "    with out:  # capture all stdout/stderr into this widget\n",
        "        clear_output(wait=True)  # clears previous runs\n",
        "        print(\"Starting training...\")  \n",
        "        start_optuna()\n",
        "        print(\"Training finished!\")\n",
        "\n",
        "train_button = widgets.Button(description=\"Run Default Training and Evaluation\", layout={'width': 'max-content'})\n",
        "train_button.on_click(on_train_click)\n",
        "\n",
        "optuna_button = widgets.Button(description=\"Run Optuna\", layout={'width': 'max-content'})\n",
        "optuna_button.on_click(on_optuna_click)\n",
        "\n",
        "# Display everything together\n",
        "display(train_button, optuna_button, out)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tGPU3.8",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0079a78677fb455cbdd664642f43d149": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3407419c6574c5c825bbb9cdbfffa67",
            "placeholder": "",
            "style": "IPY_MODEL_4967c6af3ed64a3f83c7899a03863448",
            "value": "273M/273M[00:07&lt;00:00,36.5MB/s]"
          }
        },
        "00cff9e6d2134816bfb2ec87723bab2b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "117dd252c2184eeab00ff4235c3bcbd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12f134ee2a424be3abea6d494e4bfbab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f617d90baa54ce88cca00cc9e5e8b35",
            "max": 473,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af302a7f599b4821bdae724ed9c3d941",
            "value": 473
          }
        },
        "132d2b53c3df416bb8170ae1f36dd64c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4e15ccbf0c54cce94ffe77d6e5b4e51",
            "max": 272513919,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab8b5d02e34e46f7bdc6b6d1e2098040",
            "value": 272513919
          }
        },
        "147e68434b744af29a94cc2609ef79bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1680af92a9e8446996f2478effb9a3de": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1919e3d4ea3e458f97440ba5b72a21ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f8caf86d61640208c93cbec5b5dc2f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a1575d12c194176979318c2eb907fa1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bb57b1175f84b8cbb00733e1b94689a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2c81cbcb517e438ea3c8d590052214f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de50dc3ddbcf4af9ba799c0391ba493d",
              "IPY_MODEL_79c4f2796ef14b2ab8738c6421d4797f",
              "IPY_MODEL_52f986d016a640008a94cba62c268bfe"
            ],
            "layout": "IPY_MODEL_d99fd2c09b2847e0a0d2fac604d77eb9"
          }
        },
        "3888bb2d61dd43f5b12aeef07b44546b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3daa9b54e94e4febbe66d82447b9c22f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_855327eaff774f5887628fce5474d27a",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2bb57b1175f84b8cbb00733e1b94689a",
            "value": 112
          }
        },
        "4967c6af3ed64a3f83c7899a03863448": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b5ed4dd432f4cb79aabc5356ce25e8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6991a814f78430d9258fb7a13d2c129",
            "max": 272501104,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8ff2ea0eb1674004a11b74f3d2c44817",
            "value": 272501104
          }
        },
        "50cd16c5507149f0aca19242197a7663": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd049696ccb14b82a5ceec24dc607cc5",
            "max": 229513,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5449b174bc2a4a1f948a3309abdb7e7e",
            "value": 229513
          }
        },
        "52f986d016a640008a94cba62c268bfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_996403b2698c46cb997cd79aec731b06",
            "placeholder": "",
            "style": "IPY_MODEL_117dd252c2184eeab00ff4235c3bcbd3",
            "value": "62.0/62.0[00:00&lt;00:00,1.43kB/s]"
          }
        },
        "5449b174bc2a4a1f948a3309abdb7e7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "56c5cb0530e54ffe93e4e1ae552021da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5974ddb863a24cdf8263d242011c71c6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f617d90baa54ce88cca00cc9e5e8b35": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fe67b7f7fc349b2b9423c0f95be97f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ff58b5e014b4ad48287b65ab8d02397": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba5fad8a980e4d628d61b22f4807ab1e",
            "placeholder": "",
            "style": "IPY_MODEL_147e68434b744af29a94cc2609ef79bc",
            "value": "special_tokens_map.json:100%"
          }
        },
        "6808729f963a4e509ce9bc918cd67a81": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8c906bf36ee4d00b286f58d0ebeb463",
            "placeholder": "",
            "style": "IPY_MODEL_f98a639d3a1d4a3fb39b070f6aeac1d5",
            "value": "vocab.txt:100%"
          }
        },
        "75b2646922ab451b96ecaf6e24bd9c2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd8e32adfe6a48bbb3b49a63cc7db9e6",
              "IPY_MODEL_132d2b53c3df416bb8170ae1f36dd64c",
              "IPY_MODEL_0079a78677fb455cbdd664642f43d149"
            ],
            "layout": "IPY_MODEL_5974ddb863a24cdf8263d242011c71c6"
          }
        },
        "79c4f2796ef14b2ab8738c6421d4797f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d37fa3a2c39049deb835e4ab450fe6d3",
            "max": 62,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cabad1cfb1774bde8f42e76e7d6502e5",
            "value": 62
          }
        },
        "82225876103b45079803c3a10f64daa7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83ea2ddc426f41b0a00c7a21c5325992": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2f87ac85d934a519af2ef9730be4772",
            "placeholder": "",
            "style": "IPY_MODEL_5fe67b7f7fc349b2b9423c0f95be97f2",
            "value": "230k/230k[00:00&lt;00:00,655kB/s]"
          }
        },
        "855327eaff774f5887628fce5474d27a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a0782fcba27442194860a56b63ab4f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d30209173d6748ba8afaa62dac632079",
            "placeholder": "",
            "style": "IPY_MODEL_56c5cb0530e54ffe93e4e1ae552021da",
            "value": "112/112[00:00&lt;00:00,4.48kB/s]"
          }
        },
        "8ff2ea0eb1674004a11b74f3d2c44817": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "95ba3a1fe6384e1aabd44c2e98177a4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97a26a8fe0f64abe9644b7158bc13ad0",
            "placeholder": "",
            "style": "IPY_MODEL_9988f5cb7f7c41f58af4021da7cd5b3e",
            "value": "273M/273M[00:25&lt;00:00,7.21MB/s]"
          }
        },
        "97a26a8fe0f64abe9644b7158bc13ad0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "996403b2698c46cb997cd79aec731b06": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9988f5cb7f7c41f58af4021da7cd5b3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f6ff4717b324571b1f9f94dafeb2595": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afc865ab5ce8484c8a3bc88832b637d3",
            "placeholder": "",
            "style": "IPY_MODEL_3888bb2d61dd43f5b12aeef07b44546b",
            "value": "473/473[00:00&lt;00:00,6.95kB/s]"
          }
        },
        "ab8b5d02e34e46f7bdc6b6d1e2098040": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ad99c64fe4aa4692ae02d67218bf55c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ff58b5e014b4ad48287b65ab8d02397",
              "IPY_MODEL_3daa9b54e94e4febbe66d82447b9c22f",
              "IPY_MODEL_8a0782fcba27442194860a56b63ab4f6"
            ],
            "layout": "IPY_MODEL_dd3d0e9fd7fd430d837c4c0d0d6945c5"
          }
        },
        "af302a7f599b4821bdae724ed9c3d941": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "afc865ab5ce8484c8a3bc88832b637d3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b12290a8b0b94258a36f8f6ac5d5c4e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1abfc510db94181a9b979125398824a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4e15ccbf0c54cce94ffe77d6e5b4e51": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8c906bf36ee4d00b286f58d0ebeb463": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba5fad8a980e4d628d61b22f4807ab1e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c337f4764ef94235b217be28a6febe97": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1919e3d4ea3e458f97440ba5b72a21ab",
            "placeholder": "",
            "style": "IPY_MODEL_c8a439753dc845ed81c5649b29647b41",
            "value": "model.safetensors:100%"
          }
        },
        "c8a439753dc845ed81c5649b29647b41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9438a2c8eed43f29f1e42b0c7fd186a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c337f4764ef94235b217be28a6febe97",
              "IPY_MODEL_4b5ed4dd432f4cb79aabc5356ce25e8e",
              "IPY_MODEL_95ba3a1fe6384e1aabd44c2e98177a4e"
            ],
            "layout": "IPY_MODEL_2a1575d12c194176979318c2eb907fa1"
          }
        },
        "cabad1cfb1774bde8f42e76e7d6502e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cd8e32adfe6a48bbb3b49a63cc7db9e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82225876103b45079803c3a10f64daa7",
            "placeholder": "",
            "style": "IPY_MODEL_b1abfc510db94181a9b979125398824a",
            "value": "pytorch_model.bin:100%"
          }
        },
        "ce03369c12c54551bb57647b87fc2a1c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0ed0fbdb5a244fe93fef412a8b92050": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6808729f963a4e509ce9bc918cd67a81",
              "IPY_MODEL_50cd16c5507149f0aca19242197a7663",
              "IPY_MODEL_83ea2ddc426f41b0a00c7a21c5325992"
            ],
            "layout": "IPY_MODEL_ce03369c12c54551bb57647b87fc2a1c"
          }
        },
        "d30209173d6748ba8afaa62dac632079": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d340ce23d06240cf906b8d342599af85": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d37fa3a2c39049deb835e4ab450fe6d3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d99fd2c09b2847e0a0d2fac604d77eb9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd049696ccb14b82a5ceec24dc607cc5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd3d0e9fd7fd430d837c4c0d0d6945c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de50dc3ddbcf4af9ba799c0391ba493d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1680af92a9e8446996f2478effb9a3de",
            "placeholder": "",
            "style": "IPY_MODEL_b12290a8b0b94258a36f8f6ac5d5c4e4",
            "value": "tokenizer_config.json:100%"
          }
        },
        "e2f87ac85d934a519af2ef9730be4772": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3407419c6574c5c825bbb9cdbfffa67": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5d651568c394bc2bcd4520612abdcad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f015a9b67755439fb8e54899664ac3c1",
              "IPY_MODEL_12f134ee2a424be3abea6d494e4bfbab",
              "IPY_MODEL_9f6ff4717b324571b1f9f94dafeb2595"
            ],
            "layout": "IPY_MODEL_00cff9e6d2134816bfb2ec87723bab2b"
          }
        },
        "f015a9b67755439fb8e54899664ac3c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d340ce23d06240cf906b8d342599af85",
            "placeholder": "",
            "style": "IPY_MODEL_1f8caf86d61640208c93cbec5b5dc2f2",
            "value": "config.json:100%"
          }
        },
        "f6991a814f78430d9258fb7a13d2c129": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f98a639d3a1d4a3fb39b070f6aeac1d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
