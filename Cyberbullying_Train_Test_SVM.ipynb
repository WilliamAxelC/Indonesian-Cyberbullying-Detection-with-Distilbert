{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7_BJ4OHpWQ_i"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting fastai\n",
            "  Downloading fastai-2.7.18-py3-none-any.whl.metadata (9.1 kB)\n",
            "Collecting spacy\n",
            "  Downloading spacy-3.8.2.tar.gz (1.3 MB)\n",
            "     ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
            "     ---------------------------------------- 1.3/1.3 MB 7.4 MB/s eta 0:00:00\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'error'\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\willi\\miniconda3\\envs\\tgpu3.8\\lib\\site-packages)\n",
            "  error: subprocess-exited-with-error\n",
            "  \n",
            "  × pip subprocess to install build dependencies did not run successfully.\n",
            "  │ exit code: 1\n",
            "  ╰─> [95 lines of output]\n",
            "      Ignoring numpy: markers 'python_version >= \"3.9\"' don't match your environment\n",
            "      Collecting setuptools\n",
            "        Downloading setuptools-75.3.2-py3-none-any.whl.metadata (6.9 kB)\n",
            "      Collecting cython<3.0,>=0.25\n",
            "        Downloading Cython-0.29.37-py2.py3-none-any.whl.metadata (3.1 kB)\n",
            "      Collecting cymem<2.1.0,>=2.0.2\n",
            "        Downloading cymem-2.0.11.tar.gz (10 kB)\n",
            "        Installing build dependencies: started\n",
            "        Installing build dependencies: finished with status 'done'\n",
            "        Getting requirements to build wheel: started\n",
            "        Getting requirements to build wheel: finished with status 'done'\n",
            "        Preparing metadata (pyproject.toml): started\n",
            "        Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "      Collecting preshed<3.1.0,>=3.0.2\n",
            "        Downloading preshed-3.0.9-cp38-cp38-win_amd64.whl.metadata (2.2 kB)\n",
            "      Collecting murmurhash<1.1.0,>=0.28.0\n",
            "        Downloading murmurhash-1.0.13.tar.gz (13 kB)\n",
            "        Installing build dependencies: started\n",
            "        Installing build dependencies: finished with status 'done'\n",
            "        Getting requirements to build wheel: started\n",
            "        Getting requirements to build wheel: finished with status 'done'\n",
            "        Preparing metadata (pyproject.toml): started\n",
            "        Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "      Collecting thinc<8.4.0,>=8.3.0\n",
            "        Downloading thinc-8.3.2.tar.gz (193 kB)\n",
            "        Installing build dependencies: started\n",
            "        Installing build dependencies: finished with status 'error'\n",
            "        error: subprocess-exited-with-error\n",
            "      \n",
            "        × pip subprocess to install build dependencies did not run successfully.\n",
            "        │ exit code: 1\n",
            "        ╰─> [53 lines of output]\n",
            "            Ignoring numpy: markers 'python_version >= \"3.9\"' don't match your environment\n",
            "            Collecting setuptools\n",
            "              Using cached setuptools-75.3.2-py3-none-any.whl.metadata (6.9 kB)\n",
            "            Collecting cython<3.0,>=0.25\n",
            "              Using cached Cython-0.29.37-py2.py3-none-any.whl.metadata (3.1 kB)\n",
            "            Collecting murmurhash<1.1.0,>=1.0.2\n",
            "              Using cached murmurhash-1.0.13.tar.gz (13 kB)\n",
            "              Installing build dependencies: started\n",
            "              Installing build dependencies: finished with status 'done'\n",
            "              Getting requirements to build wheel: started\n",
            "              Getting requirements to build wheel: finished with status 'done'\n",
            "              Preparing metadata (pyproject.toml): started\n",
            "              Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "            Collecting cymem<2.1.0,>=2.0.2\n",
            "              Using cached cymem-2.0.11.tar.gz (10 kB)\n",
            "              Installing build dependencies: started\n",
            "              Installing build dependencies: finished with status 'done'\n",
            "              Getting requirements to build wheel: started\n",
            "              Getting requirements to build wheel: finished with status 'done'\n",
            "              Preparing metadata (pyproject.toml): started\n",
            "              Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "            Collecting preshed<3.1.0,>=3.0.2\n",
            "              Using cached preshed-3.0.9-cp38-cp38-win_amd64.whl.metadata (2.2 kB)\n",
            "            Collecting blis<1.1.0,>=1.0.0\n",
            "              Downloading blis-1.0.2.tar.gz (3.6 MB)\n",
            "                 ---------------------------------------- 0.0/3.6 MB ? eta -:--:--\n",
            "                 ----------------- ---------------------- 1.6/3.6 MB 8.4 MB/s eta 0:00:01\n",
            "                 -------------------------------- ------- 2.9/3.6 MB 7.3 MB/s eta 0:00:01\n",
            "                 ---------------------------------------- 3.6/3.6 MB 6.2 MB/s eta 0:00:00\n",
            "              Installing build dependencies: started\n",
            "              Installing build dependencies: finished with status 'error'\n",
            "              error: subprocess-exited-with-error\n",
            "      \n",
            "              × pip subprocess to install build dependencies did not run successfully.\n",
            "              │ exit code: 1\n",
            "              ╰─> [7 lines of output]\n",
            "                  Collecting setuptools\n",
            "                    Using cached setuptools-75.3.2-py3-none-any.whl.metadata (6.9 kB)\n",
            "                  Collecting cython>=0.25\n",
            "                    Using cached cython-3.1.1-cp38-cp38-win_amd64.whl.metadata (3.3 kB)\n",
            "                  ERROR: Ignored the following versions that require a different python version: 1.25.0 Requires-Python >=3.9; 1.25.1 Requires-Python >=3.9; 1.25.2 Requires-Python >=3.9; 1.26.0 Requires-Python <3.13,>=3.9; 1.26.1 Requires-Python <3.13,>=3.9; 1.26.2 Requires-Python >=3.9; 1.26.3 Requires-Python >=3.9; 1.26.4 Requires-Python >=3.9; 2.0.0 Requires-Python >=3.9; 2.0.1 Requires-Python >=3.9; 2.0.2 Requires-Python >=3.9; 2.1.0 Requires-Python >=3.10; 2.1.0rc1 Requires-Python >=3.10; 2.1.1 Requires-Python >=3.10; 2.1.2 Requires-Python >=3.10; 2.1.3 Requires-Python >=3.10; 2.2.0 Requires-Python >=3.10; 2.2.0rc1 Requires-Python >=3.10; 2.2.1 Requires-Python >=3.10; 2.2.2 Requires-Python >=3.10; 2.2.3 Requires-Python >=3.10; 2.2.4 Requires-Python >=3.10; 2.2.5 Requires-Python >=3.10; 2.2.6 Requires-Python >=3.10; 75.4.0 Requires-Python >=3.9; 75.5.0 Requires-Python >=3.9; 75.6.0 Requires-Python >=3.9; 75.7.0 Requires-Python >=3.9; 75.8.0 Requires-Python >=3.9; 75.8.1 Requires-Python >=3.9; 75.8.2 Requires-Python >=3.9; 75.9.0 Requires-Python >=3.9; 75.9.1 Requires-Python >=3.9; 76.0.0 Requires-Python >=3.9; 76.1.0 Requires-Python >=3.9; 77.0.1 Requires-Python >=3.9; 77.0.3 Requires-Python >=3.9; 78.0.1 Requires-Python >=3.9; 78.0.2 Requires-Python >=3.9; 78.1.0 Requires-Python >=3.9; 78.1.1 Requires-Python >=3.9; 79.0.0 Requires-Python >=3.9; 79.0.1 Requires-Python >=3.9; 80.0.0 Requires-Python >=3.9; 80.0.1 Requires-Python >=3.9; 80.1.0 Requires-Python >=3.9; 80.2.0 Requires-Python >=3.9; 80.3.0 Requires-Python >=3.9; 80.3.1 Requires-Python >=3.9; 80.4.0 Requires-Python >=3.9; 80.6.0 Requires-Python >=3.9; 80.7.0 Requires-Python >=3.9; 80.7.1 Requires-Python >=3.9; 80.8.0 Requires-Python >=3.9\n",
            "                  ERROR: Could not find a version that satisfies the requirement numpy<3.0.0,>=2.0.0 (from versions: 1.3.0, 1.4.1, 1.5.0, 1.5.1, 1.6.0, 1.6.1, 1.6.2, 1.7.0, 1.7.1, 1.7.2, 1.8.0, 1.8.1, 1.8.2, 1.9.0, 1.9.1, 1.9.2, 1.9.3, 1.10.0.post2, 1.10.1, 1.10.2, 1.10.4, 1.11.0, 1.11.1, 1.11.2, 1.11.3, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 1.13.3, 1.14.0, 1.14.1, 1.14.2, 1.14.3, 1.14.4, 1.14.5, 1.14.6, 1.15.0, 1.15.1, 1.15.2, 1.15.3, 1.15.4, 1.16.0, 1.16.1, 1.16.2, 1.16.3, 1.16.4, 1.16.5, 1.16.6, 1.17.0, 1.17.1, 1.17.2, 1.17.3, 1.17.4, 1.17.5, 1.18.0, 1.18.1, 1.18.2, 1.18.3, 1.18.4, 1.18.5, 1.19.0, 1.19.1, 1.19.2, 1.19.3, 1.19.4, 1.19.5, 1.20.0, 1.20.1, 1.20.2, 1.20.3, 1.21.0, 1.21.1, 1.21.2, 1.21.3, 1.21.4, 1.21.5, 1.21.6, 1.22.0, 1.22.1, 1.22.2, 1.22.3, 1.22.4, 1.23.0, 1.23.1, 1.23.2, 1.23.3, 1.23.4, 1.23.5, 1.24.0, 1.24.1, 1.24.2, 1.24.3, 1.24.4)\n",
            "                  ERROR: No matching distribution found for numpy<3.0.0,>=2.0.0\n",
            "                  [end of output]\n",
            "      \n",
            "              note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "            error: subprocess-exited-with-error\n",
            "      \n",
            "            × pip subprocess to install build dependencies did not run successfully.\n",
            "            │ exit code: 1\n",
            "            ╰─> See above for output.\n",
            "      \n",
            "            note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "            [end of output]\n",
            "      \n",
            "        note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "      error: subprocess-exited-with-error\n",
            "      \n",
            "      × pip subprocess to install build dependencies did not run successfully.\n",
            "      │ exit code: 1\n",
            "      ╰─> See above for output.\n",
            "      \n",
            "      note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "      [end of output]\n",
            "  \n",
            "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "\n",
            "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "error: subprocess-exited-with-error\n",
            "\n",
            "× pip subprocess to install build dependencies did not run successfully.\n",
            "│ exit code: 1\n",
            "╰─> See above for output.\n",
            "\n",
            "note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "UsageError: Line magic function `%python` not found (But cell magic `%%python` exists, did you mean that instead?).\n"
          ]
        }
      ],
      "source": [
        "# %pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "# %pip install transformers[torch]==4.30.2\n",
        "# %pip install accelerate -U\n",
        "# %pip install optuna\n",
        "%pip install fastai spacy\n",
        "%python -m spacy download en_core_web_sm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eynWtoOyVS48",
        "outputId": "8a2a94bb-34e1-49ba-84a2-3ad47d7ad362"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting embeddings: 100%|██████████| 190/190 [00:10<00:00, 18.34it/s]\n",
            "Extracting embeddings: 100%|██████████| 48/48 [00:02<00:00, 19.23it/s]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import f1_score\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 1. Load your dataset\n",
        "df = pd.read_csv(\"/content/combined_dataset.csv\")\n",
        "texts = df[\"clean_text\"].tolist()\n",
        "labels = df[\"encoded_label\"].tolist()\n",
        "\n",
        "# 2. Train-test split\n",
        "X_train_texts, X_test_texts, y_train, y_test = train_test_split(\n",
        "    texts, labels, test_size=0.2, random_state=42, stratify=labels\n",
        ")\n",
        "\n",
        "# 3. Load tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "bert_model = AutoModel.from_pretrained(\"distilbert-base-uncased\").eval().cuda()\n",
        "\n",
        "# 4. Custom dataset\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
        "        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=max_length, return_tensors=\"pt\")\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {k: v[idx] for k, v in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "train_dataset = TextDataset(X_train_texts, y_train, tokenizer)\n",
        "test_dataset = TextDataset(X_test_texts, y_test, tokenizer)\n",
        "\n",
        "# 5. Extract CLS embeddings\n",
        "def extract_cls_embeddings(model, dataset, batch_size=16):\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
        "    embeddings = []\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Extracting embeddings\"):\n",
        "            input_ids = batch[\"input_ids\"].cuda()\n",
        "            attention_mask = batch[\"attention_mask\"].cuda()\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            cls_embeds = outputs.last_hidden_state[:, 0, :]  # [CLS] token\n",
        "            embeddings.append(cls_embeds.cpu().numpy())\n",
        "    return np.vstack(embeddings)\n",
        "\n",
        "X_train = extract_cls_embeddings(bert_model, train_dataset)\n",
        "X_test = extract_cls_embeddings(bert_model, test_dataset)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJnqugGdd6RW"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# 6. Compute Pearson kernel\n",
        "def pearson_kernel(X1, X2):\n",
        "    X1_centered = X1 - X1.mean(axis=1, keepdims=True)\n",
        "    X2_centered = X2 - X2.mean(axis=1, keepdims=True)\n",
        "    num = np.dot(X1_centered, X2_centered.T)\n",
        "    denom = np.linalg.norm(X1_centered, axis=1, keepdims=True) * np.linalg.norm(X2_centered, axis=1, keepdims=True).T\n",
        "    return num / (denom + 1e-8)\n",
        "\n",
        "K_train = pearson_kernel(X_train, X_train)\n",
        "K_test = pearson_kernel(X_test, X_train)  # note: test vs train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IV79n0_Ad7--",
        "outputId": "c08eeb64-ba96-46be-c82b-0d56242a96bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🎯 Pearson-SVM F1 Score (macro): 0.8044\n",
            "\n",
            "📋 Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0     0.8093    0.8608    0.8343       424\n",
            "         1.0     0.8084    0.7433    0.7745       335\n",
            "\n",
            "    accuracy                         0.8090       759\n",
            "   macro avg     0.8089    0.8021    0.8044       759\n",
            "weighted avg     0.8089    0.8090    0.8079       759\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 7. Train SVM\n",
        "svm = SVC(kernel=\"precomputed\")\n",
        "svm.fit(K_train, y_train)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# 8. Predict and evaluate\n",
        "y_pred = svm.predict(K_test)\n",
        "f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
        "print(f\"\\n🎯 Pearson-SVM F1 Score (macro): {f1:.4f}\")\n",
        "\n",
        "print(\"\\n📋 Classification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred, digits=4))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tGPU3.8",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
